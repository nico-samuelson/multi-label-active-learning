{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aa5bb60",
   "metadata": {
    "papermill": {
     "duration": 0.012534,
     "end_time": "2025-03-29T15:15:11.042960",
     "exception": false,
     "start_time": "2025-03-29T15:15:11.030426",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd6c1c84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:15:11.067040Z",
     "iopub.status.busy": "2025-03-29T15:15:11.066687Z",
     "iopub.status.idle": "2025-03-29T15:15:35.439932Z",
     "shell.execute_reply": "2025-03-29T15:15:35.439011Z"
    },
    "papermill": {
     "duration": 24.387449,
     "end_time": "2025-03-29T15:15:35.441798",
     "exception": false,
     "start_time": "2025-03-29T15:15:11.054349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58bf4b9",
   "metadata": {
    "papermill": {
     "duration": 0.011368,
     "end_time": "2025-03-29T15:15:35.465301",
     "exception": false,
     "start_time": "2025-03-29T15:15:35.453933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e94e593",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:15:35.489338Z",
     "iopub.status.busy": "2025-03-29T15:15:35.488780Z",
     "iopub.status.idle": "2025-03-29T15:15:35.492527Z",
     "shell.execute_reply": "2025-03-29T15:15:35.491705Z"
    },
    "papermill": {
     "duration": 0.017183,
     "end_time": "2025-03-29T15:15:35.494103",
     "exception": false,
     "start_time": "2025-03-29T15:15:35.476920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "893c08d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:15:35.517340Z",
     "iopub.status.busy": "2025-03-29T15:15:35.517133Z",
     "iopub.status.idle": "2025-03-29T15:15:35.521059Z",
     "shell.execute_reply": "2025-03-29T15:15:35.520247Z"
    },
    "papermill": {
     "duration": 0.016759,
     "end_time": "2025-03-29T15:15:35.522212",
     "exception": false,
     "start_time": "2025-03-29T15:15:35.505453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9261d87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:15:35.545541Z",
     "iopub.status.busy": "2025-03-29T15:15:35.545313Z",
     "iopub.status.idle": "2025-03-29T15:15:35.555079Z",
     "shell.execute_reply": "2025-03-29T15:15:35.554308Z"
    },
    "papermill": {
     "duration": 0.022858,
     "end_time": "2025-03-29T15:15:35.556295",
     "exception": false,
     "start_time": "2025-03-29T15:15:35.533437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baf7e3f",
   "metadata": {
    "papermill": {
     "duration": 0.011087,
     "end_time": "2025-03-29T15:15:35.578580",
     "exception": false,
     "start_time": "2025-03-29T15:15:35.567493",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ed2ab6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:15:35.601976Z",
     "iopub.status.busy": "2025-03-29T15:15:35.601715Z",
     "iopub.status.idle": "2025-03-29T15:15:35.661157Z",
     "shell.execute_reply": "2025-03-29T15:15:35.659539Z"
    },
    "papermill": {
     "duration": 0.072649,
     "end_time": "2025-03-29T15:15:35.662709",
     "exception": false,
     "start_time": "2025-03-29T15:15:35.590060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "aspect_accuracies = manager.list()\n",
    "aspect_f1_micros = manager.list()\n",
    "aspect_f1_macros = manager.list()\n",
    "sentiment_accuracies = manager.list()\n",
    "sentiment_f1_micros = manager.list()\n",
    "sentiment_f1_macros = manager.list()\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'hoasa-lc'\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "sequence_length = 48\n",
    "\n",
    "aspect_list = ['ac', 'air_panas', 'bau', 'general', 'kebersihan', 'linen', 'service', 'sunrise_meal', 'tv', 'wifi']\n",
    "aspect_mapping = {'ac': 0, 'air_panas': 1, 'bau': 2, 'general': 3, 'kebersihan': 4, 'linen': 5, 'service': 6, 'sunrise_meal': 7, 'tv': 8, 'wifi': 9}\n",
    "label_mapping = {\"neg\": 0, \"neut\": 1, 'neg_pos': 1, 'pos': 2}\n",
    "ignored_keys = ['labels', 'ori_text', 'ori_label', 'ori_indices', 'aspect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249108d7",
   "metadata": {
    "papermill": {
     "duration": 0.010679,
     "end_time": "2025-03-29T15:15:35.684789",
     "exception": false,
     "start_time": "2025-03-29T15:15:35.674110",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2041e33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:15:35.708305Z",
     "iopub.status.busy": "2025-03-29T15:15:35.707987Z",
     "iopub.status.idle": "2025-03-29T15:15:35.794105Z",
     "shell.execute_reply": "2025-03-29T15:15:35.793279Z"
    },
    "papermill": {
     "duration": 0.09948,
     "end_time": "2025-03-29T15:15:35.795401",
     "exception": false,
     "start_time": "2025-03-29T15:15:35.695921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>ac</th>\n",
       "      <th>air_panas</th>\n",
       "      <th>bau</th>\n",
       "      <th>general</th>\n",
       "      <th>kebersihan</th>\n",
       "      <th>linen</th>\n",
       "      <th>service</th>\n",
       "      <th>sunrise_meal</th>\n",
       "      <th>tv</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kebersihan kurang...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sangat mengecewakan... hotel bad image, kebers...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tempat nyaman bersih tapi tv terlalu tinggi ti...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>pos</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>semuanya bagus sesuai profile,dan harga promo ...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>pos</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tempat tidur sangat keras, bantal besar dan ke...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review    ac air_panas   bau  \\\n",
       "0                               kebersihan kurang...  neut      neut  neut   \n",
       "1  sangat mengecewakan... hotel bad image, kebers...  neut      neut  neut   \n",
       "2  Tempat nyaman bersih tapi tv terlalu tinggi ti...  neut      neut  neut   \n",
       "3  semuanya bagus sesuai profile,dan harga promo ...  neut       neg  neut   \n",
       "4  Tempat tidur sangat keras, bantal besar dan ke...   neg       neg  neut   \n",
       "\n",
       "  general kebersihan linen service sunrise_meal    tv  wifi  \n",
       "0    neut        neg  neut    neut         neut  neut  neut  \n",
       "1    neut        neg  neut    neut         neut  neut  neut  \n",
       "2    neut        pos  neut    neut         neut   neg  neut  \n",
       "3     pos       neut  neut    neut         neut  neut  neut  \n",
       "4    neut       neut   neg    neut         neut  neut  neut  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/hoasa-dataset/train_preprocess.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/hoasa-dataset/valid_preprocess.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('/kaggle/input/hoasa-dataset/test_preprocess.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data, test_data], ignore_index=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65bd5681",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:15:35.818962Z",
     "iopub.status.busy": "2025-03-29T15:15:35.818717Z",
     "iopub.status.idle": "2025-03-29T15:15:35.826922Z",
     "shell.execute_reply": "2025-03-29T15:15:35.826321Z"
    },
    "papermill": {
     "duration": 0.02127,
     "end_time": "2025-03-29T15:15:35.828308",
     "exception": false,
     "start_time": "2025-03-29T15:15:35.807038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "471b99c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:15:35.851755Z",
     "iopub.status.busy": "2025-03-29T15:15:35.851519Z",
     "iopub.status.idle": "2025-03-29T15:15:35.862376Z",
     "shell.execute_reply": "2025-03-29T15:15:35.861781Z"
    },
    "papermill": {
     "duration": 0.023664,
     "end_time": "2025-03-29T15:15:35.863617",
     "exception": false,
     "start_time": "2025-03-29T15:15:35.839953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2283,) (2283, 10)\n",
      "(571,) (571, 10)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[1:]\n",
    "val_labels = val_data.columns[1:]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['review'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['review'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f5c79a",
   "metadata": {
    "papermill": {
     "duration": 0.011122,
     "end_time": "2025-03-29T15:15:35.886328",
     "exception": false,
     "start_time": "2025-03-29T15:15:35.875206",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f15acfe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:15:35.909489Z",
     "iopub.status.busy": "2025-03-29T15:15:35.909260Z",
     "iopub.status.idle": "2025-03-29T15:15:35.915268Z",
     "shell.execute_reply": "2025-03-29T15:15:35.914471Z"
    },
    "papermill": {
     "duration": 0.019226,
     "end_time": "2025-03-29T15:15:35.916676",
     "exception": false,
     "start_time": "2025-03-29T15:15:35.897450",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AspectDetectionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, label_mapping, tokenizer, max_length=sequence_length, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        \n",
    "        original_labels = [self.label_mapping[label] for label in self.labels[idx]]\n",
    "        encoded_labels = [1 if label == 1 else 0 for label in original_labels]\n",
    "        \n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['ori_indices'] = idx\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(original_labels, dtype=torch.float)\n",
    "        item['labels'] = torch.tensor(encoded_labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1de79e91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:15:35.940147Z",
     "iopub.status.busy": "2025-03-29T15:15:35.939912Z",
     "iopub.status.idle": "2025-03-29T15:15:35.946838Z",
     "shell.execute_reply": "2025-03-29T15:15:35.946287Z"
    },
    "papermill": {
     "duration": 0.019965,
     "end_time": "2025-03-29T15:15:35.948047",
     "exception": false,
     "start_time": "2025-03-29T15:15:35.928082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, texts, labels, aspects, indices, label_mapping, tokenizer, max_length=96, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.aspects = aspects\n",
    "        self.indices = indices\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = aspect_token + ' ' + self.aspects[idx] + ' ' + review_token + ' ' + self.texts[idx] \n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        if isinstance(self.labels[idx], str):\n",
    "            self.labels[idx] = self.label_mapping[self.labels[idx]]\n",
    "        elif torch.is_tensor(self.labels[idx]):\n",
    "            self.labels[idx] = int(self.labels[idx].item())\n",
    "\n",
    "        encoded_label = 1 if self.labels[idx] == 2 else self.labels[idx]\n",
    "        one_hot_label = F.one_hot(torch.tensor(encoded_label, dtype=torch.long), num_classes=2).float()\n",
    "\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['aspect'] = self.aspects[idx]\n",
    "        item['labels'] = one_hot_label\n",
    "        item['ori_indices'] = self.indices[idx]\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d64c755e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:15:35.971019Z",
     "iopub.status.busy": "2025-03-29T15:15:35.970788Z",
     "iopub.status.idle": "2025-03-29T15:15:36.706810Z",
     "shell.execute_reply": "2025-03-29T15:15:36.706211Z"
    },
    "papermill": {
     "duration": 0.749015,
     "end_time": "2025-03-29T15:15:36.708273",
     "exception": false,
     "start_time": "2025-03-29T15:15:35.959258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58e2ef3a1dc459285f9a961b22b316e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb0d371d0db4fdd9d91e6d573b25ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b253f3e0f0aa4b2b9811ab39d9d17896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4abeaff4274198aefc44bcb0138570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "review_token = '[REVIEW]'\n",
    "aspect_token = '[ASPECT]'\n",
    "special_tokens_dict = {'additional_special_tokens': [review_token, aspect_token]}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3daa0ff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:15:36.733203Z",
     "iopub.status.busy": "2025-03-29T15:15:36.732973Z",
     "iopub.status.idle": "2025-03-29T15:15:36.736941Z",
     "shell.execute_reply": "2025-03-29T15:15:36.736352Z"
    },
    "papermill": {
     "duration": 0.017494,
     "end_time": "2025-03-29T15:15:36.738218",
     "exception": false,
     "start_time": "2025-03-29T15:15:36.720724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_aspect_dataset(X_train, y_train, X_val, y_val, sequence_length, num_workers=4):\n",
    "    train_dataset = AspectDetectionDataset(X_train, y_train, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = AspectDetectionDataset(X_val, y_val, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43cfb83b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:15:36.762307Z",
     "iopub.status.busy": "2025-03-29T15:15:36.762104Z",
     "iopub.status.idle": "2025-03-29T15:15:36.771896Z",
     "shell.execute_reply": "2025-03-29T15:15:36.771331Z"
    },
    "papermill": {
     "duration": 0.023464,
     "end_time": "2025-03-29T15:15:36.773194",
     "exception": false,
     "start_time": "2025-03-29T15:15:36.749730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sentiment_dataset(device, train_dataset, val_dataset, aspect_detection_model, tokenizer, max_length=sequence_length):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    aspect_detection_model.to(device)\n",
    "    aspect_detection_model.eval()\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    train_aspects = []\n",
    "    train_indices = []\n",
    "\n",
    "    val_data = []\n",
    "    val_labels = []\n",
    "    val_aspects = []\n",
    "    val_indices = []\n",
    "\n",
    "    # Transform train set\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        train_aspects.append(aspect_list[j])\n",
    "                        train_data.append(batch['ori_text'][i])\n",
    "                        train_labels.append(batch['ori_label'][i][j])\n",
    "                        train_indices.append(batch['ori_indices'][i])\n",
    "            \n",
    "        # Transform validation set\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        val_aspects.append(aspect_list[j])\n",
    "                        val_data.append(batch['ori_text'][i])\n",
    "                        val_labels.append(batch['ori_label'][i][j])\n",
    "                        val_indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    train_dataset = SentimentAnalysisDataset(train_data, train_labels, train_aspects, train_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "    val_dataset = SentimentAnalysisDataset(val_data, val_labels, val_aspects, val_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710ade47",
   "metadata": {
    "papermill": {
     "duration": 0.012076,
     "end_time": "2025-03-29T15:15:36.797225",
     "exception": false,
     "start_time": "2025-03-29T15:15:36.785149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd3bf1d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:15:36.821611Z",
     "iopub.status.busy": "2025-03-29T15:15:36.821396Z",
     "iopub.status.idle": "2025-03-29T15:15:36.825001Z",
     "shell.execute_reply": "2025-03-29T15:15:36.824375Z"
    },
    "papermill": {
     "duration": 0.016879,
     "end_time": "2025-03-29T15:15:36.826088",
     "exception": false,
     "start_time": "2025-03-29T15:15:36.809209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a9f4641",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:15:36.850679Z",
     "iopub.status.busy": "2025-03-29T15:15:36.850465Z",
     "iopub.status.idle": "2025-03-29T15:15:36.854848Z",
     "shell.execute_reply": "2025-03-29T15:15:36.854218Z"
    },
    "papermill": {
     "duration": 0.018063,
     "end_time": "2025-03-29T15:15:36.856142",
     "exception": false,
     "start_time": "2025-03-29T15:15:36.838079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p, label, classes):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        labels=label,\n",
    "        target_names=classes,\n",
    "        zero_division=0\n",
    "    ) \n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdb737d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:15:36.880938Z",
     "iopub.status.busy": "2025-03-29T15:15:36.880711Z",
     "iopub.status.idle": "2025-03-29T15:15:36.886722Z",
     "shell.execute_reply": "2025-03-29T15:15:36.886116Z"
    },
    "papermill": {
     "duration": 0.019624,
     "end_time": "2025-03-29T15:15:36.887778",
     "exception": false,
     "start_time": "2025-03-29T15:15:36.868154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics_overall(p, classes):\n",
    "    preds = torch.tensor(p.predictions)\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Ensure it's in the correct shape\n",
    "    if preds.shape != labels.shape:\n",
    "        raise ValueError(\"Shape mismatch: predictions and labels must have the same shape.\")\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Compute per-label (column-wise) precision, recall, F1\n",
    "    precision_list, recall_list, f1_micro_list, f1_macro_list = [], [], [], []\n",
    "    \n",
    "    for i in range(labels.shape[1]):  # Loop through each column (multi-output)\n",
    "        prec, rec, f1_micro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='micro', zero_division=0\n",
    "        )\n",
    "        _, _, f1_macro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='macro', zero_division=0\n",
    "        )\n",
    "\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        f1_micro_list.append(f1_micro)\n",
    "        f1_macro_list.append(f1_macro)\n",
    "\n",
    "    # Compute average metrics across all outputs\n",
    "    precision = sum(precision_list) / len(precision_list)\n",
    "    recall = sum(recall_list) / len(recall_list)\n",
    "    f1_micro = sum(f1_micro_list) / len(f1_micro_list)\n",
    "    f1_macro = sum(f1_macro_list) / len(f1_macro_list)\n",
    "\n",
    "    # Generate classification report per output\n",
    "    reports = [classification_report(labels[:, i], preds[:, i], target_names=classes, zero_division=0) for i in range(labels.shape[1])]\n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'reports': reports  # Returns list of reports, one for each output label\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de409f71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:15:36.911699Z",
     "iopub.status.busy": "2025-03-29T15:15:36.911502Z",
     "iopub.status.idle": "2025-03-29T15:15:36.936554Z",
     "shell.execute_reply": "2025-03-29T15:15:36.935945Z"
    },
    "papermill": {
     "duration": 0.038401,
     "end_time": "2025-03-29T15:15:36.937620",
     "exception": false,
     "start_time": "2025-03-29T15:15:36.899219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, aspect_metrics, sentiment_metrics, metrics, trials, seed):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in aspect_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    aspect_optimizer = torch.optim.AdamW(aspect_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    aspect_train_loader, aspect_val_loader, aspect_train_dataset, aspect_val_dataset = build_aspect_dataset(current_X_train, current_y_train, X_val, y_val, sequence_length)\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader = accelerator.prepare(\n",
    "        aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader\n",
    "    )\n",
    "\n",
    "    aspect_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ASPECT DETECTION\n",
    "    accelerator.print(\"ASPECT DETECTION\")\n",
    "    for epoch in range(epochs):\n",
    "        aspect_model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in aspect_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            aspect_optimizer.zero_grad()\n",
    "            outputs = aspect_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            aspect_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        aspect_model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in aspect_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = aspect_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}),\n",
    "            None,\n",
    "            aspect_list,\n",
    "        )\n",
    "\n",
    "        if aspect_result is None or result['f1_micro'] >= aspect_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(aspect_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-aspect-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            aspect_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(aspect_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"\\nAspect detection accuracy: {round(aspect_result['accuracy'], 4)}, F1 Micro: {round(aspect_result['f1_micro'], 4)}, F1 Macro: {round(aspect_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(aspect_result['report'])\n",
    "\n",
    "    best_aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{trials + 1}-model')\n",
    "    best_aspect_model = accelerator.prepare(best_aspect_model)\n",
    "\n",
    "    # SENTIMENT ANALYSIS ON NON NEUTRAL ASPECTS\n",
    "    accelerator.print(\"--------------------------------------------------\")\n",
    "    accelerator.print(\"SENTIMENT ANALYSIS\")\n",
    "\n",
    "    sentiment_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=2,\n",
    "    )\n",
    "    sentiment_optimizer = torch.optim.AdamW(sentiment_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "    for name, param in sentiment_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    sentiment_train_loader, sentiment_val_loader, sentiment_train_dataset, sentiment_val_dataset = build_sentiment_dataset(\n",
    "        device, aspect_train_dataset, aspect_val_dataset, best_aspect_model, tokenizer, max_length=sequence_length\n",
    "    )\n",
    "    sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader = accelerator.prepare(\n",
    "        sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader\n",
    "    )\n",
    "    sentiment_result = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sentiment_model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in sentiment_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            sentiment_optimizer.zero_grad()\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            sentiment_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        sentiment_model.eval()\n",
    "        sentiment_val_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in sentiment_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                \n",
    "                outputs = sentiment_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                for i in range(len(preds)):\n",
    "                    val_output = {\n",
    "                        'label': batch['labels'][i],\n",
    "                        'aspect': batch['aspect'][i],\n",
    "                        'ori_indices': batch['ori_indices'][i],\n",
    "                        'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                    }\n",
    "                    sentiment_val_outputs.append(val_output)\n",
    "\n",
    "        sentiment_val_outputs = accelerator.gather_for_metrics(sentiment_val_outputs)\n",
    "        unique_val_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_val_outputs}\n",
    "        sentiment_val_outputs = list(unique_val_outputs.values())\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': [item['pred'] for item in sentiment_val_outputs], 'label_ids': [np.argmax(item['label'].cpu().numpy()) for item in sentiment_val_outputs]}),\n",
    "            [0, 1],\n",
    "            ['negative', 'positive']\n",
    "        )\n",
    "\n",
    "        if sentiment_result is None or result['f1_micro'] >= sentiment_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            sentiment_result = result\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(sentiment_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                 f'{filename}-sentiment-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(sentiment_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    accelerator.print(f\"\\nSentiment analysis accuracy: {round(sentiment_result['accuracy'], 4)}, F1 Micro: {round(sentiment_result['f1_micro'], 4)}, F1 Macro: {round(sentiment_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(sentiment_result['report'])\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    best_sentiment_model = BertForSequenceClassification.from_pretrained( f'{filename}-sentiment-{trials + 1}-model')\n",
    "    best_sentiment_model = accelerator.prepare(best_sentiment_model)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    aspect_labels = []\n",
    "    aspect_indices = []\n",
    "    aspect_preds = []\n",
    "\n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = []\n",
    "    \n",
    "    best_aspect_model.eval()\n",
    "    best_sentiment_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in aspect_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_aspect_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            aspect_indices.append(accelerator.gather(batch['ori_indices']))\n",
    "            aspect_labels.append(accelerator.gather(batch['ori_label']))\n",
    "            aspect_preds.append(accelerator.gather(preds))\n",
    "\n",
    "        aspect_indices = torch.cat(aspect_indices).cpu().numpy()\n",
    "        aspect_labels = torch.cat(aspect_labels).cpu().numpy()\n",
    "        aspect_preds = torch.cat(aspect_preds).cpu().numpy()\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        aspect_outputs = [\n",
    "            {'ori_indices': aspect_indices[i], \n",
    "             'ori_labels': aspect_labels[i], \n",
    "             'pred': aspect_preds[i]}\n",
    "            for i in range(len(aspect_preds))\n",
    "        ]\n",
    "        aspect_outputs = {x['ori_indices'].item(): x for x in aspect_outputs}\n",
    "    \n",
    "        for batch in sentiment_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_sentiment_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "    \n",
    "            for i in range(len(preds)):\n",
    "                output = {\n",
    "                    'aspect': batch['aspect'][i],\n",
    "                    'ori_indices': batch['ori_indices'][i],\n",
    "                    'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                }\n",
    "                sentiment_outputs.append(output)\n",
    "\n",
    "        sentiment_outputs = accelerator.gather_for_metrics(sentiment_outputs)\n",
    "        sentiment_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_outputs}\n",
    "\n",
    "    # Replcae non neutral aspect to its predicted sentiment\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        i = -1\n",
    "        for (ori_index, aspect), value in sentiment_outputs.items():\n",
    "            aspect = aspect_mapping[aspect]\n",
    "            aspect_outputs[ori_index]['pred'][aspect] = 2 if value['pred'] == 1.0 else value['pred']\n",
    "\n",
    "        result = compute_metrics_overall(\n",
    "            type('EvalOutput', (object,), {'predictions': [output['pred'] for output in aspect_outputs.values()], 'label_ids': [output['ori_labels'] for output in aspect_outputs.values()]}),\n",
    "            ['negative', 'neutral', 'positive'],\n",
    "        )\n",
    "\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        for i in range(len(train_labels)):\n",
    "            accelerator.print(f\"Aspect {aspect_list[i]} report:\")\n",
    "            accelerator.print(result['reports'][i])\n",
    "       \n",
    "        aspect_metrics[0].append(aspect_result['accuracy'])\n",
    "        aspect_metrics[1].append(aspect_result['f1_micro'])\n",
    "        aspect_metrics[2].append(aspect_result['f1_macro'])\n",
    "        sentiment_metrics[0].append(sentiment_result['accuracy'])\n",
    "        sentiment_metrics[1].append(sentiment_result['f1_micro'])\n",
    "        sentiment_metrics[2].append(sentiment_result['f1_macro'])\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(result['accuracy'])\n",
    "        metrics[2].append(result['f1_micro'])\n",
    "        metrics[3].append(result['f1_macro'])\n",
    "        \n",
    "    accelerator.print(f\"Total train time: {duration} s\")\n",
    "    accelerator.end_training()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c305d5be",
   "metadata": {
    "papermill": {
     "duration": 0.011816,
     "end_time": "2025-03-29T15:15:36.962033",
     "exception": false,
     "start_time": "2025-03-29T15:15:36.950217",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2c9c046",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:15:36.986907Z",
     "iopub.status.busy": "2025-03-29T15:15:36.986676Z",
     "iopub.status.idle": "2025-03-29T15:15:36.991804Z",
     "shell.execute_reply": "2025-03-29T15:15:36.991175Z"
    },
    "papermill": {
     "duration": 0.01889,
     "end_time": "2025-03-29T15:15:36.993172",
     "exception": false,
     "start_time": "2025-03-29T15:15:36.974282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cd2859",
   "metadata": {
    "papermill": {
     "duration": 0.012411,
     "end_time": "2025-03-29T15:15:37.017139",
     "exception": false,
     "start_time": "2025-03-29T15:15:37.004728",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "983eeceb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:15:37.041155Z",
     "iopub.status.busy": "2025-03-29T15:15:37.040953Z",
     "iopub.status.idle": "2025-03-29T15:15:37.055475Z",
     "shell.execute_reply": "2025-03-29T15:15:37.054932Z"
    },
    "papermill": {
     "duration": 0.027818,
     "end_time": "2025-03-29T15:15:37.056653",
     "exception": false,
     "start_time": "2025-03-29T15:15:37.028835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def least_confidence_sampling(aspect_model, sentiment_model, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, n_samples=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model.to(device)\n",
    "    aspect_model.eval()\n",
    "    sentiment_model.to(device)\n",
    "    sentiment_model.eval()\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    aspect_dataset = AspectDetectionDataset(\n",
    "        X_pool, \n",
    "        [['neut' for i in range(len(train_labels))] for x in range(len(X_pool))], \n",
    "        label_mapping, \n",
    "        tokenizer, \n",
    "        max_length=sequence_length\n",
    "    )\n",
    "    aspect_loader = DataLoader(\n",
    "        aspect_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = {}\n",
    "\n",
    "    aspects = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    indices = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Pass through aspect detction model\n",
    "    for batch in aspect_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = aspect_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "            preds = torch.sigmoid(outputs.logits)\n",
    "\n",
    "        for i in range(len(preds)):\n",
    "            aspect_outputs[batch['ori_indices'][i].item()] = np.max(preds[i].cpu().numpy())\n",
    "            \n",
    "            for j in range(len(preds[i])):\n",
    "                if int(preds[i][j].round()) != 1:\n",
    "                    aspects.append(aspect_list[j])\n",
    "                    data.append(batch['ori_text'][i])\n",
    "                    labels.append(batch['ori_label'][i][j])\n",
    "                    indices.append(batch['ori_indices'][i])\n",
    "    \n",
    "    sentiment_dataset = SentimentAnalysisDataset(data, labels, aspects, indices, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    sentiment_loader = torch.utils.data.DataLoader(\n",
    "        sentiment_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4,\n",
    "    )\n",
    "\n",
    "    # Pass through sentiment analysis model\n",
    "    for batch in sentiment_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = sentiment_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "            preds = torch.sigmoid(outputs.logits)\n",
    "\n",
    "        for i in range(len(preds)):\n",
    "            ori_index = batch['ori_indices'][i].item()\n",
    "            if ori_index in sentiment_outputs.keys():\n",
    "                max_pred = np.max(preds[i].cpu().numpy())\n",
    "                sentiment_outputs[ori_index] = max_pred if max_pred > sentiment_outputs[ori_index] else sentiment_outputs[ori_index]\n",
    "            else:\n",
    "                sentiment_outputs[ori_index] = np.max(preds[i].cpu().numpy())\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        aspect_outputs = dict(sorted(aspect_outputs.items()))\n",
    "    \n",
    "        # accelerator.print(aspect_outputs)\n",
    "        for key, val in sentiment_outputs.items():\n",
    "            aspect_outputs[key] = 1 - ((val + aspect_outputs[key]) / 2)\n",
    "    \n",
    "        # accelerator.print(aspect_outputs)\n",
    "        uncertainties = np.array(list(aspect_outputs.values()))\n",
    "        sorted_unc = np.argsort(uncertainties)\n",
    "        sorted_unc = sorted_unc[::-1]\n",
    "\n",
    "        threshold = np.percentile(uncertainties, 90)\n",
    "        items_greater_than_average = uncertainties[uncertainties >= threshold]\n",
    "        num_of_candidates = len(items_greater_than_average)\n",
    "        \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "        \n",
    "        if num_of_candidates <= n_samples and n_samples < nearest_cp - current_train_size:\n",
    "            least_confident_indices = sorted_unc[:n_samples]\n",
    "        elif num_of_candidates > n_samples and num_of_candidates < nearest_cp - current_train_size:\n",
    "            least_confident_indices = sorted_unc[:max(n_samples, min(math.ceil(0.1*len(sorted_unc)), num_of_candidates))]\n",
    "        else:\n",
    "            least_confident_indices = sorted_unc[:nearest_cp - current_train_size]\n",
    "    \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend([remaining_indices[i] for i in least_confident_indices])\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                'ac': [y_train[i][0] for i in temp],\n",
    "                'air_panas': [y_train[i][1] for i in temp],\n",
    "                'bau': [y_train[i][2] for i in temp],\n",
    "                'general': [y_train[i][3] for i in temp],\n",
    "                'kebersihan': [y_train[i][4] for i in temp],\n",
    "                'linen': [y_train[i][5] for i in temp],\n",
    "                'service': [y_train[i][6] for i in temp],\n",
    "                'sunrise_meal': [y_train[i][7] for i in temp],\n",
    "                'tv': [y_train[i][8] for i in temp],\n",
    "                'wifi': [y_train[i][9] for i in temp],\n",
    "            })\n",
    "    \n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "    \n",
    "        end_time = time.time() \n",
    "        duration = end_time - start_time\n",
    "    \n",
    "        sampling_dur.append(duration)\n",
    "        for i in least_confident_indices:\n",
    "            new_samples.append(remaining_indices[i])\n",
    "            \n",
    "        print(\"Nearest checkpoint:\", nearest_cp)\n",
    "        print(\"Threshold:\", threshold)\n",
    "        print(\"Samples above threshold:\", num_of_candidates)\n",
    "        print(\"Acquired samples:\", len(least_confident_indices))\n",
    "        print(f\"Sampling duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e16bd68",
   "metadata": {
    "papermill": {
     "duration": 0.01154,
     "end_time": "2025-03-29T15:15:37.080006",
     "exception": false,
     "start_time": "2025-03-29T15:15:37.068466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cf1e728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:15:37.104773Z",
     "iopub.status.busy": "2025-03-29T15:15:37.104574Z",
     "iopub.status.idle": "2025-03-29T15:15:37.113495Z",
     "shell.execute_reply": "2025-03-29T15:15:37.112952Z"
    },
    "papermill": {
     "duration": 0.022633,
     "end_time": "2025-03-29T15:15:37.114701",
     "exception": false,
     "start_time": "2025-03-29T15:15:37.092068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    aspect_accuracies = manager.list()\n",
    "    aspect_f1_micros = manager.list()\n",
    "    aspect_f1_macros = manager.list()\n",
    "    sentiment_accuracies = manager.list()\n",
    "    sentiment_f1_micros = manager.list()\n",
    "    sentiment_f1_macros = manager.list()\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        # Train the model\n",
    "        args = (\n",
    "            current_train_size, \n",
    "            train_indices, \n",
    "            (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "            (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "            (data_used, accuracies, f1_micros, f1_macros), \n",
    "            i,\n",
    "            seed\n",
    "        )\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{i+1}-model')\n",
    "        sentiment_model = BertForSequenceClassification.from_pretrained(f'{filename}-sentiment-{i+1}-model')\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (\n",
    "            aspect_model, \n",
    "            sentiment_model, \n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices, \n",
    "            remaining_indices, \n",
    "            sampling_dur, \n",
    "            new_samples, \n",
    "            i\n",
    "        )\n",
    "        notebook_launcher(least_confidence_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    args = (\n",
    "        current_train_size, \n",
    "        train_indices, \n",
    "        (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "        (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "        (data_used, accuracies, f1_micros, f1_macros), \n",
    "        i,\n",
    "        seed\n",
    "    )\n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    aspect_accuracies, aspect_f1_micros, aspect_f1_macros = list(aspect_accuracies), list(aspect_f1_micros), list(aspect_f1_macros)\n",
    "    sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros = list(sentiment_accuracies), list(sentiment_f1_micros), list(sentiment_f1_macros)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Aspect Accuracy': aspect_accuracies,\n",
    "        'Aspect F1 Micro': aspect_f1_micros,\n",
    "        'Aspect F1 Macro': aspect_f1_macros,\n",
    "        'Sentiment Accuracy': sentiment_accuracies,\n",
    "        'Sentiment F1 Micro': sentiment_f1_micros,\n",
    "        'Sentiment F1 Macro': sentiment_f1_macros,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7f2ff23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:15:37.138834Z",
     "iopub.status.busy": "2025-03-29T15:15:37.138606Z",
     "iopub.status.idle": "2025-03-29T15:15:37.141855Z",
     "shell.execute_reply": "2025-03-29T15:15:37.141105Z"
    },
    "papermill": {
     "duration": 0.016547,
     "end_time": "2025-03-29T15:15:37.143093",
     "exception": false,
     "start_time": "2025-03-29T15:15:37.126546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc272c1e",
   "metadata": {
    "papermill": {
     "duration": 0.011742,
     "end_time": "2025-03-29T15:15:37.167205",
     "exception": false,
     "start_time": "2025-03-29T15:15:37.155463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "549e8337",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:15:37.191093Z",
     "iopub.status.busy": "2025-03-29T15:15:37.190809Z",
     "iopub.status.idle": "2025-03-29T17:11:22.752143Z",
     "shell.execute_reply": "2025-03-29T17:11:22.751174Z"
    },
    "papermill": {
     "duration": 6945.574818,
     "end_time": "2025-03-29T17:11:22.753627",
     "exception": false,
     "start_time": "2025-03-29T15:15:37.178809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5865, Accuracy: 0.7995, F1 Micro: 0.8876, F1 Macro: 0.8805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4747, Accuracy: 0.801, F1 Micro: 0.8892, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4337, Accuracy: 0.8007, F1 Micro: 0.8893, F1 Macro: 0.8848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.425, Accuracy: 0.8033, F1 Micro: 0.8905, F1 Macro: 0.8856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4065, Accuracy: 0.8064, F1 Micro: 0.8916, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4121, Accuracy: 0.8101, F1 Micro: 0.8933, F1 Macro: 0.8874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3857, Accuracy: 0.8177, F1 Micro: 0.8971, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3725, Accuracy: 0.8321, F1 Micro: 0.9044, F1 Macro: 0.8994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3428, Accuracy: 0.841, F1 Micro: 0.9088, F1 Macro: 0.9042\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3197, Accuracy: 0.8507, F1 Micro: 0.9137, F1 Macro: 0.9092\n",
      "\n",
      "Aspect detection accuracy: 0.8507, F1 Micro: 0.9137, F1 Macro: 0.9092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.84      1.00      0.91       462\n",
      "   air_panas       0.84      1.00      0.91       480\n",
      "         bau       0.86      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.80      0.85      0.83       317\n",
      "       linen       0.71      0.99      0.83       392\n",
      "     service       0.88      0.97      0.93       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.86      1.00      0.93       498\n",
      "\n",
      "   micro avg       0.85      0.99      0.91      4614\n",
      "   macro avg       0.85      0.98      0.91      4614\n",
      "weighted avg       0.85      0.99      0.91      4614\n",
      " samples avg       0.85      0.99      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6014, Accuracy: 0.6293, F1 Micro: 0.6293, F1 Macro: 0.3862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5503, Accuracy: 0.6293, F1 Micro: 0.6293, F1 Macro: 0.3862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4934, Accuracy: 0.6293, F1 Micro: 0.6293, F1 Macro: 0.3862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3898, Accuracy: 0.6878, F1 Micro: 0.6878, F1 Macro: 0.5444\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3441, Accuracy: 0.7488, F1 Micro: 0.7488, F1 Macro: 0.6959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2311, Accuracy: 0.7634, F1 Micro: 0.7634, F1 Macro: 0.719\n",
      "Epoch 7/10, Train Loss: 0.181, Accuracy: 0.7439, F1 Micro: 0.7439, F1 Macro: 0.6915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2402, Accuracy: 0.7756, F1 Micro: 0.7756, F1 Macro: 0.7399\n",
      "Epoch 9/10, Train Loss: 0.1526, Accuracy: 0.7512, F1 Micro: 0.7512, F1 Macro: 0.6996\n",
      "Epoch 10/10, Train Loss: 0.1164, Accuracy: 0.7537, F1 Micro: 0.7537, F1 Macro: 0.7047\n",
      "\n",
      "Sentiment analysis accuracy: 0.7756, F1 Micro: 0.7756, F1 Macro: 0.7399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.91      0.84       258\n",
      "    positive       0.78      0.55      0.64       152\n",
      "\n",
      "    accuracy                           0.78       410\n",
      "   macro avg       0.78      0.73      0.74       410\n",
      "weighted avg       0.78      0.78      0.76       410\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8419, F1 Micro: 0.8419, F1 Macro: 0.4131\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.27      0.42        97\n",
      "     neutral       0.84      1.00      0.91       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.59      0.42      0.44       571\n",
      "weighted avg       0.84      0.85      0.81       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.01      0.02        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       1.00      0.10      0.18        10\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.94      0.37      0.37       571\n",
      "weighted avg       0.86      0.84      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        78\n",
      "     neutral       0.86      1.00      0.92       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.74      0.86      0.80       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.69      0.71       200\n",
      "     neutral       0.80      0.85      0.83       315\n",
      "    positive       0.43      0.38      0.40        56\n",
      "\n",
      "    accuracy                           0.75       571\n",
      "   macro avg       0.66      0.64      0.65       571\n",
      "weighted avg       0.74      0.75      0.75       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.18      0.30       162\n",
      "     neutral       0.71      0.99      0.83       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.72       571\n",
      "   macro avg       0.52      0.39      0.37       571\n",
      "weighted avg       0.72      0.72      0.64       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.48      0.59        85\n",
      "     neutral       0.88      0.98      0.93       418\n",
      "    positive       0.76      0.62      0.68        68\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.80      0.69      0.73       571\n",
      "weighted avg       0.85      0.86      0.85       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        74\n",
      "     neutral       0.87      1.00      0.93       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.80       571\n",
      "\n",
      "Total train time: 85.23809456825256 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.9342491030693054\n",
      "Samples above threshold: 215\n",
      "Acquired samples: 215\n",
      "Sampling duration: 11.165383100509644 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5271, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.432, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4093, Accuracy: 0.8019, F1 Micro: 0.8898, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.357, Accuracy: 0.8227, F1 Micro: 0.8998, F1 Macro: 0.894\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3235, Accuracy: 0.8729, F1 Micro: 0.9258, F1 Macro: 0.9209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2741, Accuracy: 0.8962, F1 Micro: 0.9382, F1 Macro: 0.9337\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.228, Accuracy: 0.9062, F1 Micro: 0.944, F1 Macro: 0.9399\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2014, Accuracy: 0.9186, F1 Micro: 0.951, F1 Macro: 0.9474\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.187, Accuracy: 0.924, F1 Micro: 0.954, F1 Macro: 0.951\n",
      "Epoch 10/10, Train Loss: 0.1478, Accuracy: 0.9227, F1 Micro: 0.9533, F1 Macro: 0.9502\n",
      "\n",
      "Aspect detection accuracy: 0.924, F1 Micro: 0.954, F1 Macro: 0.951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.98       462\n",
      "   air_panas       0.93      0.99      0.96       480\n",
      "         bau       0.94      0.98      0.96       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.87      0.91      0.89       317\n",
      "       linen       0.84      0.98      0.90       392\n",
      "     service       0.90      0.97      0.94       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.92      0.99      0.95      4614\n",
      "   macro avg       0.92      0.98      0.95      4614\n",
      "weighted avg       0.93      0.99      0.95      4614\n",
      " samples avg       0.92      0.98      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3704, Accuracy: 0.7589, F1 Micro: 0.7589, F1 Macro: 0.4315\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2631, Accuracy: 0.7816, F1 Micro: 0.7816, F1 Macro: 0.5338\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1592, Accuracy: 0.8174, F1 Micro: 0.8174, F1 Macro: 0.7573\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1442, Accuracy: 0.8449, F1 Micro: 0.8449, F1 Macro: 0.7873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1368, Accuracy: 0.8473, F1 Micro: 0.8473, F1 Macro: 0.7884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1095, Accuracy: 0.8568, F1 Micro: 0.8568, F1 Macro: 0.7671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0754, Accuracy: 0.8568, F1 Micro: 0.8568, F1 Macro: 0.7613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1107, Accuracy: 0.8616, F1 Micro: 0.8616, F1 Macro: 0.7996\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0623, Accuracy: 0.8675, F1 Micro: 0.8675, F1 Macro: 0.8016\n",
      "Epoch 10/10, Train Loss: 0.0708, Accuracy: 0.8663, F1 Micro: 0.8663, F1 Macro: 0.7978\n",
      "\n",
      "Sentiment analysis accuracy: 0.8675, F1 Micro: 0.8675, F1 Macro: 0.8016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92       636\n",
      "    positive       0.80      0.60      0.69       202\n",
      "\n",
      "    accuracy                           0.87       838\n",
      "   macro avg       0.84      0.78      0.80       838\n",
      "weighted avg       0.86      0.87      0.86       838\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.6035\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89        97\n",
      "     neutral       0.98      0.99      0.98       459\n",
      "    positive       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.78      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.65      0.76        86\n",
      "     neutral       0.93      0.99      0.96       475\n",
      "    positive       0.25      0.10      0.14        10\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.70      0.58      0.62       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.65      0.73        78\n",
      "     neutral       0.94      0.98      0.96       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.54      0.56       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.69      0.77       200\n",
      "     neutral       0.86      0.91      0.89       315\n",
      "    positive       0.59      0.86      0.70        56\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.78      0.82      0.79       571\n",
      "weighted avg       0.84      0.83      0.83       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.65      0.77       162\n",
      "     neutral       0.84      0.98      0.90       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.59      0.54      0.56       571\n",
      "weighted avg       0.83      0.85      0.83       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.58      0.65        85\n",
      "     neutral       0.90      0.98      0.94       418\n",
      "    positive       0.87      0.69      0.77        68\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.84      0.75      0.79       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.63      0.63      0.63       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.64      0.65      0.65       571\n",
      "weighted avg       0.98      0.99      0.98       571\n",
      "\n",
      "Total train time: 113.65927195549011 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0618901252746582\n",
      "Samples above threshold: 193\n",
      "Acquired samples: 193\n",
      "Sampling duration: 15.127748250961304 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5102, Accuracy: 0.8009, F1 Micro: 0.8894, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4375, Accuracy: 0.8073, F1 Micro: 0.8912, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4066, Accuracy: 0.8288, F1 Micro: 0.9021, F1 Macro: 0.8956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3565, Accuracy: 0.8752, F1 Micro: 0.9268, F1 Macro: 0.9218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2858, Accuracy: 0.8993, F1 Micro: 0.9401, F1 Macro: 0.9362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2448, Accuracy: 0.9222, F1 Micro: 0.9528, F1 Macro: 0.9489\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2144, Accuracy: 0.9252, F1 Micro: 0.9547, F1 Macro: 0.9514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1825, Accuracy: 0.9283, F1 Micro: 0.9565, F1 Macro: 0.9532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1607, Accuracy: 0.9358, F1 Micro: 0.9608, F1 Macro: 0.9576\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1408, Accuracy: 0.938, F1 Micro: 0.9622, F1 Macro: 0.959\n",
      "\n",
      "Aspect detection accuracy: 0.938, F1 Micro: 0.9622, F1 Macro: 0.959\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.96      0.99      0.98       480\n",
      "         bau       0.95      0.99      0.97       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.85      0.91      0.88       317\n",
      "       linen       0.90      0.97      0.93       392\n",
      "     service       0.95      0.96      0.96       423\n",
      "sunrise_meal       0.95      1.00      0.97       530\n",
      "          tv       0.98      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      4614\n",
      "   macro avg       0.94      0.98      0.96      4614\n",
      "weighted avg       0.94      0.98      0.96      4614\n",
      " samples avg       0.94      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4726, Accuracy: 0.8062, F1 Micro: 0.8062, F1 Macro: 0.6636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.355, Accuracy: 0.8428, F1 Micro: 0.8428, F1 Macro: 0.7777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3147, Accuracy: 0.8504, F1 Micro: 0.8504, F1 Macro: 0.788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2424, Accuracy: 0.8579, F1 Micro: 0.8579, F1 Macro: 0.7791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.193, Accuracy: 0.8698, F1 Micro: 0.8698, F1 Macro: 0.8018\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1706, Accuracy: 0.8708, F1 Micro: 0.8708, F1 Macro: 0.8038\n",
      "Epoch 7/10, Train Loss: 0.1131, Accuracy: 0.8568, F1 Micro: 0.8568, F1 Macro: 0.7694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1202, Accuracy: 0.8773, F1 Micro: 0.8773, F1 Macro: 0.8203\n",
      "Epoch 9/10, Train Loss: 0.0937, Accuracy: 0.8708, F1 Micro: 0.8708, F1 Macro: 0.816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0751, Accuracy: 0.8827, F1 Micro: 0.8827, F1 Macro: 0.8261\n",
      "\n",
      "Sentiment analysis accuracy: 0.8827, F1 Micro: 0.8827, F1 Macro: 0.8261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93       697\n",
      "    positive       0.87      0.62      0.73       232\n",
      "\n",
      "    accuracy                           0.88       929\n",
      "   macro avg       0.88      0.80      0.83       929\n",
      "weighted avg       0.88      0.88      0.88       929\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9299, F1 Micro: 0.9299, F1 Macro: 0.7492\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.81      0.86        86\n",
      "     neutral       0.96      0.99      0.98       475\n",
      "    positive       0.75      0.30      0.43        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.87      0.70      0.76       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.68      0.77        78\n",
      "     neutral       0.95      0.99      0.97       491\n",
      "    positive       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.73      0.72      0.71       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.67      0.03      0.06        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.51      0.34      0.33       571\n",
      "weighted avg       0.84      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82       200\n",
      "     neutral       0.85      0.91      0.88       315\n",
      "    positive       0.84      0.73      0.78        56\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.85      0.81      0.83       571\n",
      "weighted avg       0.85      0.85      0.85       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.77      0.82       162\n",
      "     neutral       0.90      0.97      0.93       387\n",
      "    positive       0.55      0.27      0.36        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.78      0.67      0.71       571\n",
      "weighted avg       0.88      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.75      0.78        85\n",
      "     neutral       0.95      0.97      0.96       418\n",
      "    positive       0.86      0.82      0.84        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.85      0.86       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.21      0.31        29\n",
      "     neutral       0.95      1.00      0.97       525\n",
      "    positive       0.70      0.41      0.52        17\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.75      0.54      0.60       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.81      0.86        54\n",
      "     neutral       0.98      1.00      0.99       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.97      0.77      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.86      0.91       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 141.22674179077148 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.02789716720581054\n",
      "Samples above threshold: 174\n",
      "Acquired samples: 174\n",
      "Sampling duration: 14.10930609703064 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5077, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4444, Accuracy: 0.8142, F1 Micro: 0.8957, F1 Macro: 0.8911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3939, Accuracy: 0.8637, F1 Micro: 0.921, F1 Macro: 0.917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3104, Accuracy: 0.9106, F1 Micro: 0.9465, F1 Macro: 0.9431\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2515, Accuracy: 0.9283, F1 Micro: 0.9566, F1 Macro: 0.9537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2103, Accuracy: 0.9314, F1 Micro: 0.9584, F1 Macro: 0.9554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1871, Accuracy: 0.9403, F1 Micro: 0.9636, F1 Macro: 0.9608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1599, Accuracy: 0.9431, F1 Micro: 0.9652, F1 Macro: 0.9624\n",
      "Epoch 9/10, Train Loss: 0.1428, Accuracy: 0.941, F1 Micro: 0.9639, F1 Macro: 0.9609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1235, Accuracy: 0.9469, F1 Micro: 0.9673, F1 Macro: 0.9647\n",
      "\n",
      "Aspect detection accuracy: 0.9469, F1 Micro: 0.9673, F1 Macro: 0.9647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.88      1.00      0.94       500\n",
      "  kebersihan       0.91      0.90      0.90       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.96      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.97      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4778, Accuracy: 0.7894, F1 Micro: 0.7894, F1 Macro: 0.6242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3404, Accuracy: 0.8425, F1 Micro: 0.8425, F1 Macro: 0.7867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2801, Accuracy: 0.8495, F1 Micro: 0.8495, F1 Macro: 0.7722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2184, Accuracy: 0.8606, F1 Micro: 0.8606, F1 Macro: 0.8079\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1945, Accuracy: 0.8776, F1 Micro: 0.8776, F1 Macro: 0.8281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1313, Accuracy: 0.8826, F1 Micro: 0.8826, F1 Macro: 0.8286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1161, Accuracy: 0.8837, F1 Micro: 0.8837, F1 Macro: 0.8376\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0905, Accuracy: 0.8857, F1 Micro: 0.8857, F1 Macro: 0.8343\n",
      "Epoch 9/10, Train Loss: 0.0734, Accuracy: 0.8806, F1 Micro: 0.8806, F1 Macro: 0.8245\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.099, Accuracy: 0.8907, F1 Micro: 0.8907, F1 Macro: 0.8448\n",
      "\n",
      "Sentiment analysis accuracy: 0.8907, F1 Micro: 0.8907, F1 Macro: 0.8448\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93       734\n",
      "    positive       0.90      0.66      0.76       263\n",
      "\n",
      "    accuracy                           0.89       997\n",
      "   macro avg       0.89      0.82      0.84       997\n",
      "weighted avg       0.89      0.89      0.88       997\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9399, F1 Micro: 0.9399, F1 Macro: 0.7915\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.87      0.87      0.87        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.83      0.87        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.50      0.30      0.37        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.80      0.71      0.74       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.73      0.79        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.74      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.88      1.00      0.94       496\n",
      "    positive       0.82      0.13      0.23        68\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.57      0.38      0.39       571\n",
      "weighted avg       0.86      0.88      0.84       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.84      0.84       200\n",
      "     neutral       0.91      0.90      0.90       315\n",
      "    positive       0.78      0.88      0.82        56\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.85      0.87      0.86       571\n",
      "weighted avg       0.88      0.87      0.87       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.80      0.83       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.64      0.32      0.42        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.80      0.70      0.73       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.28      0.40        29\n",
      "     neutral       0.96      1.00      0.98       525\n",
      "    positive       0.92      0.65      0.76        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.87      0.64      0.71       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.75      0.50      0.60         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.80      0.84       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.95      0.97        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 163.75789165496826 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.020318722724914553\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 156\n",
      "Sampling duration: 12.633574485778809 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5115, Accuracy: 0.8019, F1 Micro: 0.8898, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4384, Accuracy: 0.8432, F1 Micro: 0.9097, F1 Macro: 0.9048\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3514, Accuracy: 0.904, F1 Micro: 0.9429, F1 Macro: 0.9398\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2779, Accuracy: 0.924, F1 Micro: 0.9541, F1 Macro: 0.9513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2243, Accuracy: 0.9396, F1 Micro: 0.9631, F1 Macro: 0.9604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1895, Accuracy: 0.9446, F1 Micro: 0.9661, F1 Macro: 0.9636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1558, Accuracy: 0.9465, F1 Micro: 0.9672, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1369, Accuracy: 0.9484, F1 Micro: 0.9683, F1 Macro: 0.9656\n",
      "Epoch 9/10, Train Loss: 0.1226, Accuracy: 0.9469, F1 Micro: 0.9675, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1071, Accuracy: 0.9535, F1 Micro: 0.9713, F1 Macro: 0.9686\n",
      "\n",
      "Aspect detection accuracy: 0.9535, F1 Micro: 0.9713, F1 Macro: 0.9686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.95      0.99      0.97       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.94      0.90      0.92       317\n",
      "       linen       0.89      0.97      0.93       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4711, Accuracy: 0.8152, F1 Micro: 0.8152, F1 Macro: 0.7084\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3295, Accuracy: 0.8628, F1 Micro: 0.8628, F1 Macro: 0.8188\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2729, Accuracy: 0.8667, F1 Micro: 0.8667, F1 Macro: 0.8248\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2113, Accuracy: 0.8949, F1 Micro: 0.8949, F1 Macro: 0.8592\n",
      "Epoch 5/10, Train Loss: 0.1473, Accuracy: 0.8891, F1 Micro: 0.8891, F1 Macro: 0.8477\n",
      "Epoch 6/10, Train Loss: 0.1069, Accuracy: 0.893, F1 Micro: 0.893, F1 Macro: 0.8539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0782, Accuracy: 0.8979, F1 Micro: 0.8979, F1 Macro: 0.8629\n",
      "Epoch 8/10, Train Loss: 0.0587, Accuracy: 0.8959, F1 Micro: 0.8959, F1 Macro: 0.8584\n",
      "Epoch 9/10, Train Loss: 0.0455, Accuracy: 0.8891, F1 Micro: 0.8891, F1 Macro: 0.8473\n",
      "Epoch 10/10, Train Loss: 0.0458, Accuracy: 0.8949, F1 Micro: 0.8949, F1 Macro: 0.8553\n",
      "\n",
      "Sentiment analysis accuracy: 0.8979, F1 Micro: 0.8979, F1 Macro: 0.8629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93       740\n",
      "    positive       0.91      0.70      0.79       288\n",
      "\n",
      "    accuracy                           0.90      1028\n",
      "   macro avg       0.90      0.84      0.86      1028\n",
      "weighted avg       0.90      0.90      0.89      1028\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.8102\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.82      0.93      0.87        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.95      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.75      0.30      0.43        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.88      0.73      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.68      0.78        78\n",
      "     neutral       0.95      0.99      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.72      0.81       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.95       496\n",
      "    positive       0.81      0.44      0.57        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.58      0.48      0.51       571\n",
      "weighted avg       0.89      0.91      0.89       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.89      0.87       200\n",
      "     neutral       0.94      0.90      0.92       315\n",
      "    positive       0.82      0.96      0.89        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.87      0.91      0.89       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.77      0.81       162\n",
      "     neutral       0.89      0.97      0.93       387\n",
      "    positive       0.50      0.14      0.21        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.75      0.62      0.65       571\n",
      "weighted avg       0.87      0.88      0.87       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.84        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.94      0.88      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.89      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.38      0.52        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.73      0.77       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.80      0.67      0.73         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.86      0.88       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 176.36494135856628 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.016631555557250977\n",
      "Samples above threshold: 141\n",
      "Acquired samples: 141\n",
      "Sampling duration: 11.581409692764282 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5051, Accuracy: 0.8125, F1 Micro: 0.8936, F1 Macro: 0.8851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4216, Accuracy: 0.8741, F1 Micro: 0.9263, F1 Macro: 0.9221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3144, Accuracy: 0.9179, F1 Micro: 0.9507, F1 Macro: 0.948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2509, Accuracy: 0.9363, F1 Micro: 0.9613, F1 Macro: 0.959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2055, Accuracy: 0.9394, F1 Micro: 0.9631, F1 Macro: 0.9602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1683, Accuracy: 0.9443, F1 Micro: 0.966, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1445, Accuracy: 0.9486, F1 Micro: 0.9685, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1298, Accuracy: 0.9507, F1 Micro: 0.9696, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1107, Accuracy: 0.9531, F1 Micro: 0.9711, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.097, Accuracy: 0.958, F1 Micro: 0.974, F1 Macro: 0.9712\n",
      "\n",
      "Aspect detection accuracy: 0.958, F1 Micro: 0.974, F1 Macro: 0.9712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.93      0.99      0.96       500\n",
      "  kebersihan       0.93      0.91      0.92       317\n",
      "       linen       0.90      0.97      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4719, Accuracy: 0.8202, F1 Micro: 0.8202, F1 Macro: 0.7239\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3033, Accuracy: 0.8738, F1 Micro: 0.8738, F1 Macro: 0.8411\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2167, Accuracy: 0.8955, F1 Micro: 0.8955, F1 Macro: 0.862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.154, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8657\n",
      "Epoch 5/10, Train Loss: 0.1096, Accuracy: 0.8964, F1 Micro: 0.8964, F1 Macro: 0.8651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0868, Accuracy: 0.904, F1 Micro: 0.904, F1 Macro: 0.8749\n",
      "Epoch 7/10, Train Loss: 0.0768, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8707\n",
      "Epoch 8/10, Train Loss: 0.0631, Accuracy: 0.8936, F1 Micro: 0.8936, F1 Macro: 0.8595\n",
      "Epoch 9/10, Train Loss: 0.0427, Accuracy: 0.9021, F1 Micro: 0.9021, F1 Macro: 0.8699\n",
      "Epoch 10/10, Train Loss: 0.0287, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.8695\n",
      "\n",
      "Sentiment analysis accuracy: 0.904, F1 Micro: 0.904, F1 Macro: 0.8749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       758\n",
      "    positive       0.91      0.74      0.81       304\n",
      "\n",
      "    accuracy                           0.90      1062\n",
      "   macro avg       0.91      0.85      0.87      1062\n",
      "weighted avg       0.90      0.90      0.90      1062\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9513, F1 Micro: 0.9513, F1 Macro: 0.8411\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.86      0.90        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.78      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.77      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.99      0.96       496\n",
      "    positive       0.87      0.57      0.69        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.52      0.55       571\n",
      "weighted avg       0.91      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86       200\n",
      "     neutral       0.93      0.90      0.92       315\n",
      "    positive       0.81      0.93      0.87        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.87      0.90      0.88       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.78      0.83       162\n",
      "     neutral       0.90      0.97      0.94       387\n",
      "    positive       0.62      0.36      0.46        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.80      0.70      0.74       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 196.32998752593994 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.01643312573432923\n",
      "Samples above threshold: 127\n",
      "Acquired samples: 127\n",
      "Sampling duration: 10.612231016159058 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4986, Accuracy: 0.8109, F1 Micro: 0.8941, F1 Macro: 0.8895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3963, Accuracy: 0.8936, F1 Micro: 0.9368, F1 Macro: 0.9336\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2949, Accuracy: 0.9278, F1 Micro: 0.9565, F1 Macro: 0.9541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2277, Accuracy: 0.9394, F1 Micro: 0.9632, F1 Macro: 0.9604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1858, Accuracy: 0.9462, F1 Micro: 0.9671, F1 Macro: 0.9647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1583, Accuracy: 0.9505, F1 Micro: 0.9696, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1306, Accuracy: 0.9582, F1 Micro: 0.9741, F1 Macro: 0.9716\n",
      "Epoch 8/10, Train Loss: 0.114, Accuracy: 0.9543, F1 Micro: 0.972, F1 Macro: 0.9694\n",
      "Epoch 9/10, Train Loss: 0.0997, Accuracy: 0.9543, F1 Micro: 0.9719, F1 Macro: 0.9695\n",
      "Epoch 10/10, Train Loss: 0.0873, Accuracy: 0.9566, F1 Micro: 0.9732, F1 Macro: 0.9709\n",
      "\n",
      "Aspect detection accuracy: 0.9582, F1 Micro: 0.9741, F1 Macro: 0.9716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.92      0.92      0.92       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4844, Accuracy: 0.8466, F1 Micro: 0.8466, F1 Macro: 0.8038\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3102, Accuracy: 0.8734, F1 Micro: 0.8734, F1 Macro: 0.8254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2214, Accuracy: 0.8974, F1 Micro: 0.8974, F1 Macro: 0.8628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.147, Accuracy: 0.9003, F1 Micro: 0.9003, F1 Macro: 0.8654\n",
      "Epoch 5/10, Train Loss: 0.1324, Accuracy: 0.8926, F1 Micro: 0.8926, F1 Macro: 0.8583\n",
      "Epoch 6/10, Train Loss: 0.0885, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.8602\n",
      "Epoch 7/10, Train Loss: 0.0587, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.865\n",
      "Epoch 8/10, Train Loss: 0.0675, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0507, Accuracy: 0.9022, F1 Micro: 0.9022, F1 Macro: 0.8694\n",
      "Epoch 10/10, Train Loss: 0.0495, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.865\n",
      "\n",
      "Sentiment analysis accuracy: 0.9022, F1 Micro: 0.9022, F1 Macro: 0.8694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       755\n",
      "    positive       0.90      0.73      0.80       288\n",
      "\n",
      "    accuracy                           0.90      1043\n",
      "   macro avg       0.90      0.85      0.87      1043\n",
      "weighted avg       0.90      0.90      0.90      1043\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.8392\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.95       496\n",
      "    positive       0.86      0.44      0.58        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.59      0.48      0.51       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85       200\n",
      "     neutral       0.92      0.92      0.92       315\n",
      "    positive       0.86      0.88      0.87        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.88      0.88      0.88       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.77      0.83       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.50      0.41      0.45        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.77      0.72      0.74       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.94      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.81      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 203.0581202507019 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.018606042861938475\n",
      "Samples above threshold: 114\n",
      "Acquired samples: 114\n",
      "Sampling duration: 9.555897235870361 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4961, Accuracy: 0.8085, F1 Micro: 0.8929, F1 Macro: 0.8881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3872, Accuracy: 0.895, F1 Micro: 0.9377, F1 Macro: 0.9347\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2748, Accuracy: 0.9375, F1 Micro: 0.9619, F1 Macro: 0.9594\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2121, Accuracy: 0.9436, F1 Micro: 0.9655, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.175, Accuracy: 0.9503, F1 Micro: 0.9696, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1508, Accuracy: 0.9519, F1 Micro: 0.9704, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1225, Accuracy: 0.9583, F1 Micro: 0.9743, F1 Macro: 0.9718\n",
      "Epoch 8/10, Train Loss: 0.1062, Accuracy: 0.9578, F1 Micro: 0.974, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0872, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0772, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.974\n",
      "\n",
      "Aspect detection accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.91      0.93       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4429, Accuracy: 0.8546, F1 Micro: 0.8546, F1 Macro: 0.813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2677, Accuracy: 0.8675, F1 Micro: 0.8675, F1 Macro: 0.819\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1951, Accuracy: 0.8914, F1 Micro: 0.8914, F1 Macro: 0.8619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1352, Accuracy: 0.8979, F1 Micro: 0.8979, F1 Macro: 0.866\n",
      "Epoch 5/10, Train Loss: 0.1221, Accuracy: 0.8951, F1 Micro: 0.8951, F1 Macro: 0.8632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0751, Accuracy: 0.8997, F1 Micro: 0.8997, F1 Macro: 0.8711\n",
      "Epoch 7/10, Train Loss: 0.0637, Accuracy: 0.8951, F1 Micro: 0.8951, F1 Macro: 0.8674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0494, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8703\n",
      "Epoch 9/10, Train Loss: 0.042, Accuracy: 0.896, F1 Micro: 0.896, F1 Macro: 0.8626\n",
      "Epoch 10/10, Train Loss: 0.0281, Accuracy: 0.8997, F1 Micro: 0.8997, F1 Macro: 0.8685\n",
      "\n",
      "Sentiment analysis accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8703\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       770\n",
      "    positive       0.94      0.70      0.81       317\n",
      "\n",
      "    accuracy                           0.90      1087\n",
      "   macro avg       0.92      0.84      0.87      1087\n",
      "weighted avg       0.91      0.90      0.90      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.955, F1 Micro: 0.955, F1 Macro: 0.8519\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.77      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.60      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.90      0.88       200\n",
      "     neutral       0.95      0.91      0.93       315\n",
      "    positive       0.84      0.95      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.83      0.84       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.83      0.23      0.36        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.87      0.68      0.72       571\n",
      "weighted avg       0.90      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.95      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 229.2928488254547 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.011401653289794922\n",
      "Samples above threshold: 103\n",
      "Acquired samples: 103\n",
      "Sampling duration: 8.853497505187988 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4919, Accuracy: 0.8222, F1 Micro: 0.8997, F1 Macro: 0.8945\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3638, Accuracy: 0.9062, F1 Micro: 0.9441, F1 Macro: 0.9414\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2536, Accuracy: 0.9326, F1 Micro: 0.9592, F1 Macro: 0.9568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2007, Accuracy: 0.941, F1 Micro: 0.964, F1 Macro: 0.9615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1629, Accuracy: 0.9455, F1 Micro: 0.9667, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1335, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1208, Accuracy: 0.9589, F1 Micro: 0.9745, F1 Macro: 0.9719\n",
      "Epoch 8/10, Train Loss: 0.099, Accuracy: 0.9573, F1 Micro: 0.9737, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0864, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9738\n",
      "Epoch 10/10, Train Loss: 0.0765, Accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.9719\n",
      "\n",
      "Aspect detection accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9738\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.95      0.91      0.93       317\n",
      "       linen       0.91      0.98      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4187, Accuracy: 0.8561, F1 Micro: 0.8561, F1 Macro: 0.8103\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2958, Accuracy: 0.8625, F1 Micro: 0.8625, F1 Macro: 0.8121\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1891, Accuracy: 0.8937, F1 Micro: 0.8937, F1 Macro: 0.8664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1245, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.8642\n",
      "Epoch 5/10, Train Loss: 0.098, Accuracy: 0.8946, F1 Micro: 0.8946, F1 Macro: 0.863\n",
      "Epoch 6/10, Train Loss: 0.0676, Accuracy: 0.8873, F1 Micro: 0.8873, F1 Macro: 0.8517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0527, Accuracy: 0.901, F1 Micro: 0.901, F1 Macro: 0.8743\n",
      "Epoch 8/10, Train Loss: 0.0412, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.8661\n",
      "Epoch 9/10, Train Loss: 0.0497, Accuracy: 0.8983, F1 Micro: 0.8983, F1 Macro: 0.8668\n",
      "Epoch 10/10, Train Loss: 0.019, Accuracy: 0.8983, F1 Micro: 0.8983, F1 Macro: 0.8681\n",
      "\n",
      "Sentiment analysis accuracy: 0.901, F1 Micro: 0.901, F1 Macro: 0.8743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93       770\n",
      "    positive       0.90      0.75      0.82       321\n",
      "\n",
      "    accuracy                           0.90      1091\n",
      "   macro avg       0.90      0.86      0.87      1091\n",
      "weighted avg       0.90      0.90      0.90      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9543, F1 Micro: 0.9543, F1 Macro: 0.8586\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.97      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.78      0.80        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.76      0.92      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89       200\n",
      "     neutral       0.95      0.91      0.93       315\n",
      "    positive       0.83      0.96      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.93      0.90       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.77      0.83       162\n",
      "     neutral       0.91      0.98      0.94       387\n",
      "    positive       0.65      0.50      0.56        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.82      0.75      0.78       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 230.42938590049744 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.011797499656677247\n",
      "Samples above threshold: 92\n",
      "Acquired samples: 62\n",
      "Sampling duration: 8.01887583732605 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4922, Accuracy: 0.8292, F1 Micro: 0.9027, F1 Macro: 0.8976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.355, Accuracy: 0.9139, F1 Micro: 0.9486, F1 Macro: 0.9461\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2448, Accuracy: 0.9325, F1 Micro: 0.9591, F1 Macro: 0.9565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1922, Accuracy: 0.9503, F1 Micro: 0.9694, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1674, Accuracy: 0.9543, F1 Micro: 0.9719, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1339, Accuracy: 0.9545, F1 Micro: 0.972, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1119, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9727\n",
      "Epoch 8/10, Train Loss: 0.0937, Accuracy: 0.9569, F1 Micro: 0.9735, F1 Macro: 0.9712\n",
      "Epoch 9/10, Train Loss: 0.0824, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0734, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9735\n",
      "\n",
      "Aspect detection accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.91      0.93       317\n",
      "       linen       0.91      0.96      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4156, Accuracy: 0.8527, F1 Micro: 0.8527, F1 Macro: 0.8047\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2597, Accuracy: 0.8728, F1 Micro: 0.8728, F1 Macro: 0.8466\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1755, Accuracy: 0.8765, F1 Micro: 0.8765, F1 Macro: 0.8338\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1255, Accuracy: 0.893, F1 Micro: 0.893, F1 Macro: 0.861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0826, Accuracy: 0.9003, F1 Micro: 0.9003, F1 Macro: 0.8736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0878, Accuracy: 0.9021, F1 Micro: 0.9021, F1 Macro: 0.8762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0737, Accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.8775\n",
      "Epoch 8/10, Train Loss: 0.0453, Accuracy: 0.893, F1 Micro: 0.893, F1 Macro: 0.864\n",
      "Epoch 9/10, Train Loss: 0.0397, Accuracy: 0.9021, F1 Micro: 0.9021, F1 Macro: 0.8735\n",
      "Epoch 10/10, Train Loss: 0.0401, Accuracy: 0.8994, F1 Micro: 0.8994, F1 Macro: 0.8706\n",
      "\n",
      "Sentiment analysis accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.8775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.93       766\n",
      "    positive       0.93      0.73      0.82       327\n",
      "\n",
      "    accuracy                           0.90      1093\n",
      "   macro avg       0.91      0.86      0.88      1093\n",
      "weighted avg       0.91      0.90      0.90      1093\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9548, F1 Micro: 0.9548, F1 Macro: 0.8741\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.81      0.74      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.75      0.62      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.89      0.88       200\n",
      "     neutral       0.94      0.91      0.93       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.78      0.82       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.69      0.41      0.51        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.82      0.72      0.76       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.84      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 242.75793147087097 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.009282737970352173\n",
      "Samples above threshold: 86\n",
      "Acquired samples: 86\n",
      "Sampling duration: 7.57892632484436 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4856, Accuracy: 0.8378, F1 Micro: 0.9075, F1 Macro: 0.9026\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3297, Accuracy: 0.9184, F1 Micro: 0.9508, F1 Macro: 0.9481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2332, Accuracy: 0.9415, F1 Micro: 0.9643, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.182, Accuracy: 0.9462, F1 Micro: 0.967, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1535, Accuracy: 0.9547, F1 Micro: 0.9722, F1 Macro: 0.9696\n",
      "Epoch 6/10, Train Loss: 0.1274, Accuracy: 0.954, F1 Micro: 0.9717, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1123, Accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0942, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0768, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9756\n",
      "Epoch 10/10, Train Loss: 0.0699, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9737\n",
      "\n",
      "Aspect detection accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4134, Accuracy: 0.856, F1 Micro: 0.856, F1 Macro: 0.8009\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2589, Accuracy: 0.887, F1 Micro: 0.887, F1 Macro: 0.8492\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1537, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1177, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0955, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0731, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8812\n",
      "Epoch 7/10, Train Loss: 0.0481, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8759\n",
      "Epoch 8/10, Train Loss: 0.0417, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8815\n",
      "Epoch 9/10, Train Loss: 0.0335, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8807\n",
      "Epoch 10/10, Train Loss: 0.0179, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8784\n",
      "\n",
      "Sentiment analysis accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       778\n",
      "    positive       0.94      0.73      0.82       319\n",
      "\n",
      "    accuracy                           0.91      1097\n",
      "   macro avg       0.92      0.86      0.88      1097\n",
      "weighted avg       0.91      0.91      0.91      1097\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.958, F1 Micro: 0.958, F1 Macro: 0.8704\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.77      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.83      0.71      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.89      0.88       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.85      0.93      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.76      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.95      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.81      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 251.54261589050293 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.009589707851409912\n",
      "Samples above threshold: 77\n",
      "Acquired samples: 77\n",
      "Sampling duration: 6.886684417724609 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4808, Accuracy: 0.8375, F1 Micro: 0.9071, F1 Macro: 0.9019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3262, Accuracy: 0.9257, F1 Micro: 0.9551, F1 Macro: 0.9527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2262, Accuracy: 0.9443, F1 Micro: 0.9659, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1886, Accuracy: 0.9446, F1 Micro: 0.9662, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1477, Accuracy: 0.9589, F1 Micro: 0.9746, F1 Macro: 0.972\n",
      "Epoch 6/10, Train Loss: 0.1228, Accuracy: 0.9583, F1 Micro: 0.9743, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1035, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0892, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0756, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0632, Accuracy: 0.9648, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9648, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3691, Accuracy: 0.8694, F1 Micro: 0.8694, F1 Macro: 0.8204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2365, Accuracy: 0.8955, F1 Micro: 0.8955, F1 Macro: 0.8593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1743, Accuracy: 0.9021, F1 Micro: 0.9021, F1 Macro: 0.8699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1143, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8878\n",
      "Epoch 5/10, Train Loss: 0.0836, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8858\n",
      "Epoch 6/10, Train Loss: 0.0818, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8821\n",
      "Epoch 7/10, Train Loss: 0.0564, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8824\n",
      "Epoch 8/10, Train Loss: 0.0436, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8853\n",
      "Epoch 9/10, Train Loss: 0.0332, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0297, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8888\n",
      "\n",
      "Sentiment analysis accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       767\n",
      "    positive       0.92      0.77      0.84       305\n",
      "\n",
      "    accuracy                           0.91      1072\n",
      "   macro avg       0.92      0.87      0.89      1072\n",
      "weighted avg       0.91      0.91      0.91      1072\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9578, F1 Micro: 0.9578, F1 Macro: 0.8701\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.86      0.87       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.78      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.85      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.88      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.74      0.78       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.67      0.94      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.82      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 259.7276475429535 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.007050013542175293\n",
      "Samples above threshold: 70\n",
      "Acquired samples: 70\n",
      "Sampling duration: 6.1553733348846436 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4775, Accuracy: 0.8583, F1 Micro: 0.918, F1 Macro: 0.9132\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3118, Accuracy: 0.9273, F1 Micro: 0.956, F1 Macro: 0.9534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2159, Accuracy: 0.9457, F1 Micro: 0.9668, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1732, Accuracy: 0.9531, F1 Micro: 0.9712, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1422, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.973\n",
      "Epoch 6/10, Train Loss: 0.1178, Accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1001, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0846, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0718, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9755\n",
      "Epoch 10/10, Train Loss: 0.0622, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9743\n",
      "\n",
      "Aspect detection accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3747, Accuracy: 0.8626, F1 Micro: 0.8626, F1 Macro: 0.819\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2218, Accuracy: 0.881, F1 Micro: 0.881, F1 Macro: 0.8385\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1818, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.124, Accuracy: 0.9075, F1 Micro: 0.9075, F1 Macro: 0.8794\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1063, Accuracy: 0.9075, F1 Micro: 0.9075, F1 Macro: 0.8797\n",
      "Epoch 6/10, Train Loss: 0.0622, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0555, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8858\n",
      "Epoch 8/10, Train Loss: 0.0293, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8776\n",
      "Epoch 9/10, Train Loss: 0.0396, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8784\n",
      "Epoch 10/10, Train Loss: 0.0203, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8789\n",
      "\n",
      "Sentiment analysis accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8858\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       779\n",
      "    positive       0.94      0.74      0.83       313\n",
      "\n",
      "    accuracy                           0.91      1092\n",
      "   macro avg       0.92      0.86      0.89      1092\n",
      "weighted avg       0.92      0.91      0.91      1092\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9587, F1 Micro: 0.9587, F1 Macro: 0.8681\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.90      0.93        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.80      0.85       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.81      0.69      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.56      0.57       571\n",
      "weighted avg       0.92      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.90      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.88      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       1.00      0.36      0.53        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.73      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        85\n",
      "     neutral       0.97      0.99      0.98       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.83      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 271.3345718383789 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.007380437850952149\n",
      "Samples above threshold: 63\n",
      "Acquired samples: 52\n",
      "Sampling duration: 5.9320783615112305 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4726, Accuracy: 0.8514, F1 Micro: 0.9145, F1 Macro: 0.9101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3092, Accuracy: 0.9299, F1 Micro: 0.9575, F1 Macro: 0.955\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2152, Accuracy: 0.9431, F1 Micro: 0.9653, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1676, Accuracy: 0.95, F1 Micro: 0.9694, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1377, Accuracy: 0.9571, F1 Micro: 0.9736, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1182, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0985, Accuracy: 0.959, F1 Micro: 0.9747, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0816, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.0694, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9732\n",
      "Epoch 10/10, Train Loss: 0.0592, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9735\n",
      "\n",
      "Aspect detection accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.37, Accuracy: 0.8673, F1 Micro: 0.8673, F1 Macro: 0.82\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2333, Accuracy: 0.9007, F1 Micro: 0.9007, F1 Macro: 0.8745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1595, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8815\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1117, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.8815\n",
      "Epoch 5/10, Train Loss: 0.0915, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8766\n",
      "Epoch 6/10, Train Loss: 0.0529, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8773\n",
      "Epoch 7/10, Train Loss: 0.0367, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8695\n",
      "Epoch 8/10, Train Loss: 0.0472, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0341, Accuracy: 0.9165, F1 Micro: 0.9165, F1 Macro: 0.8909\n",
      "Epoch 10/10, Train Loss: 0.0298, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.885\n",
      "\n",
      "Sentiment analysis accuracy: 0.9165, F1 Micro: 0.9165, F1 Macro: 0.8909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       770\n",
      "    positive       0.94      0.76      0.84       308\n",
      "\n",
      "    accuracy                           0.92      1078\n",
      "   macro avg       0.92      0.87      0.89      1078\n",
      "weighted avg       0.92      0.92      0.91      1078\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.8551\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.87      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.82      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.77      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.81      0.65      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.58      0.54      0.56       571\n",
      "weighted avg       0.91      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.74      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.84      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.80      0.67      0.73         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.87      0.89       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 277.09273052215576 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.008154511451721191\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 58\n",
      "Sampling duration: 5.459591388702393 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4659, Accuracy: 0.8693, F1 Micro: 0.9235, F1 Macro: 0.9185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.294, Accuracy: 0.9252, F1 Micro: 0.955, F1 Macro: 0.9521\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2119, Accuracy: 0.9469, F1 Micro: 0.9674, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1637, Accuracy: 0.9552, F1 Micro: 0.9724, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1359, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9738\n",
      "Epoch 6/10, Train Loss: 0.1103, Accuracy: 0.9589, F1 Micro: 0.9746, F1 Macro: 0.9722\n",
      "Epoch 7/10, Train Loss: 0.0891, Accuracy: 0.9615, F1 Micro: 0.9762, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0809, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0674, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9747\n",
      "Epoch 10/10, Train Loss: 0.0577, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "\n",
      "Aspect detection accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.95      0.92      0.93       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3701, Accuracy: 0.8621, F1 Micro: 0.8621, F1 Macro: 0.8241\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2214, Accuracy: 0.8897, F1 Micro: 0.8897, F1 Macro: 0.8533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1491, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.8801\n",
      "Epoch 4/10, Train Loss: 0.113, Accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.8649\n",
      "Epoch 5/10, Train Loss: 0.0831, Accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.8652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0529, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8862\n",
      "Epoch 7/10, Train Loss: 0.0458, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8651\n",
      "Epoch 8/10, Train Loss: 0.0441, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8848\n",
      "Epoch 9/10, Train Loss: 0.0389, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8774\n",
      "Epoch 10/10, Train Loss: 0.028, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8768\n",
      "\n",
      "Sentiment analysis accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8862\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       775\n",
      "    positive       0.94      0.75      0.83       313\n",
      "\n",
      "    accuracy                           0.91      1088\n",
      "   macro avg       0.92      0.86      0.89      1088\n",
      "weighted avg       0.91      0.91      0.91      1088\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9574, F1 Micro: 0.9574, F1 Macro: 0.8757\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.92      0.93        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.80      0.84       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.78      0.81        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.88      0.63      0.74        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.59      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89       200\n",
      "     neutral       0.95      0.92      0.93       315\n",
      "    positive       0.84      0.95      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.85       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.75      0.79       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 281.4556803703308 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.007474136352539064\n",
      "Samples above threshold: 52\n",
      "Acquired samples: 52\n",
      "Sampling duration: 5.164303541183472 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4665, Accuracy: 0.8703, F1 Micro: 0.9243, F1 Macro: 0.92\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2934, Accuracy: 0.9273, F1 Micro: 0.956, F1 Macro: 0.9534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2047, Accuracy: 0.945, F1 Micro: 0.9663, F1 Macro: 0.9636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1659, Accuracy: 0.958, F1 Micro: 0.9741, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1354, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9728\n",
      "Epoch 6/10, Train Loss: 0.1106, Accuracy: 0.9587, F1 Micro: 0.9744, F1 Macro: 0.9719\n",
      "Epoch 7/10, Train Loss: 0.0914, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0791, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9746\n",
      "Epoch 9/10, Train Loss: 0.0668, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9738\n",
      "Epoch 10/10, Train Loss: 0.0575, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3595, Accuracy: 0.8645, F1 Micro: 0.8645, F1 Macro: 0.8167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2091, Accuracy: 0.8876, F1 Micro: 0.8876, F1 Macro: 0.8507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1486, Accuracy: 0.9041, F1 Micro: 0.9041, F1 Macro: 0.8771\n",
      "Epoch 4/10, Train Loss: 0.1118, Accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.8646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.081, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0612, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8824\n",
      "Epoch 7/10, Train Loss: 0.0428, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0374, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.885\n",
      "Epoch 9/10, Train Loss: 0.0261, Accuracy: 0.8977, F1 Micro: 0.8977, F1 Macro: 0.8643\n",
      "Epoch 10/10, Train Loss: 0.0343, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8786\n",
      "\n",
      "Sentiment analysis accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       768\n",
      "    positive       0.95      0.74      0.83       317\n",
      "\n",
      "    accuracy                           0.91      1085\n",
      "   macro avg       0.92      0.86      0.89      1085\n",
      "weighted avg       0.91      0.91      0.91      1085\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9571, F1 Micro: 0.9571, F1 Macro: 0.8708\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.88      0.72      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.57      0.59       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.85      0.93      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.70      0.32      0.44        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.83      0.70      0.74       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 292.16872692108154 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.007680535316467285\n",
      "Samples above threshold: 47\n",
      "Acquired samples: 50\n",
      "Sampling duration: 5.033966064453125 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.458, Accuracy: 0.8708, F1 Micro: 0.924, F1 Macro: 0.9179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2818, Accuracy: 0.9332, F1 Micro: 0.9595, F1 Macro: 0.9574\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2002, Accuracy: 0.9493, F1 Micro: 0.9689, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1591, Accuracy: 0.9561, F1 Micro: 0.9729, F1 Macro: 0.9706\n",
      "Epoch 5/10, Train Loss: 0.131, Accuracy: 0.9542, F1 Micro: 0.9718, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1062, Accuracy: 0.9604, F1 Micro: 0.9754, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0894, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9747\n",
      "Epoch 8/10, Train Loss: 0.0744, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9732\n",
      "Epoch 9/10, Train Loss: 0.0643, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9742\n",
      "Epoch 10/10, Train Loss: 0.0553, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3571, Accuracy: 0.8659, F1 Micro: 0.8659, F1 Macro: 0.8179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.213, Accuracy: 0.8921, F1 Micro: 0.8921, F1 Macro: 0.8539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1549, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.118, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0716, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0568, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8876\n",
      "Epoch 7/10, Train Loss: 0.0572, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0485, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8867\n",
      "Epoch 9/10, Train Loss: 0.0314, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8813\n",
      "Epoch 10/10, Train Loss: 0.0278, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8804\n",
      "\n",
      "Sentiment analysis accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       764\n",
      "    positive       0.95      0.74      0.83       302\n",
      "\n",
      "    accuracy                           0.91      1066\n",
      "   macro avg       0.93      0.86      0.89      1066\n",
      "weighted avg       0.92      0.91      0.91      1066\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9564, F1 Micro: 0.9564, F1 Macro: 0.8598\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.76      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.78      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.84      0.63      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.54      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.85       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       0.88      0.32      0.47        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.71      0.75       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.69      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 293.8072566986084 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0083809494972229\n",
      "Samples above threshold: 42\n",
      "Acquired samples: 50\n",
      "Sampling duration: 4.386321067810059 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4515, Accuracy: 0.871, F1 Micro: 0.9246, F1 Macro: 0.9209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2771, Accuracy: 0.9347, F1 Micro: 0.9604, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1971, Accuracy: 0.9474, F1 Micro: 0.9678, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.153, Accuracy: 0.9613, F1 Micro: 0.9761, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1241, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9749\n",
      "Epoch 6/10, Train Loss: 0.1035, Accuracy: 0.9604, F1 Micro: 0.9756, F1 Macro: 0.9736\n",
      "Epoch 7/10, Train Loss: 0.0866, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "Epoch 8/10, Train Loss: 0.0723, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9747\n",
      "Epoch 9/10, Train Loss: 0.0619, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9746\n",
      "Epoch 10/10, Train Loss: 0.0528, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.93      0.98      0.96       500\n",
      "  kebersihan       0.95      0.91      0.93       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3853, Accuracy: 0.8725, F1 Micro: 0.8725, F1 Macro: 0.8322\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2225, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.8731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1625, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1259, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8862\n",
      "Epoch 5/10, Train Loss: 0.1079, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8764\n",
      "Epoch 6/10, Train Loss: 0.0663, Accuracy: 0.9085, F1 Micro: 0.9085, F1 Macro: 0.8765\n",
      "Epoch 7/10, Train Loss: 0.0592, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8803\n",
      "Epoch 8/10, Train Loss: 0.0575, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8752\n",
      "Epoch 9/10, Train Loss: 0.0457, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8629\n",
      "Epoch 10/10, Train Loss: 0.0348, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8836\n",
      "\n",
      "Sentiment analysis accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8862\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       778\n",
      "    positive       0.93      0.75      0.83       304\n",
      "\n",
      "    accuracy                           0.91      1082\n",
      "   macro avg       0.92      0.86      0.89      1082\n",
      "weighted avg       0.92      0.91      0.91      1082\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9571, F1 Micro: 0.9571, F1 Macro: 0.8607\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.78      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.92      0.93       571\n",
      "weighted avg       0.95      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.83      0.56      0.67        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.51      0.54       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.89       200\n",
      "     neutral       0.95      0.91      0.93       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.93      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.76      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.94      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.91      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.48      0.61        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.68      0.88      0.77        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.79      0.79       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 291.1873822212219 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.015225768089294434\n",
      "Samples above threshold: 37\n",
      "Acquired samples: 50\n",
      "Sampling duration: 3.9453940391540527 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4569, Accuracy: 0.8733, F1 Micro: 0.9253, F1 Macro: 0.9205\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2779, Accuracy: 0.9361, F1 Micro: 0.961, F1 Macro: 0.9585\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1948, Accuracy: 0.9493, F1 Micro: 0.9689, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1532, Accuracy: 0.959, F1 Micro: 0.9747, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1235, Accuracy: 0.9599, F1 Micro: 0.9751, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1067, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.974\n",
      "Epoch 7/10, Train Loss: 0.0857, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9728\n",
      "Epoch 8/10, Train Loss: 0.0709, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.062, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "Epoch 10/10, Train Loss: 0.054, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.93      0.98      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3424, Accuracy: 0.8711, F1 Micro: 0.8711, F1 Macro: 0.8306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2191, Accuracy: 0.8952, F1 Micro: 0.8952, F1 Macro: 0.8648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1589, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.881\n",
      "Epoch 4/10, Train Loss: 0.0928, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0698, Accuracy: 0.9156, F1 Micro: 0.9156, F1 Macro: 0.8891\n",
      "Epoch 6/10, Train Loss: 0.0657, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.8823\n",
      "Epoch 7/10, Train Loss: 0.045, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8872\n",
      "Epoch 8/10, Train Loss: 0.0348, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.888\n",
      "Epoch 9/10, Train Loss: 0.0238, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8831\n",
      "Epoch 10/10, Train Loss: 0.022, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8855\n",
      "\n",
      "Sentiment analysis accuracy: 0.9156, F1 Micro: 0.9156, F1 Macro: 0.8891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       773\n",
      "    positive       0.93      0.75      0.83       305\n",
      "\n",
      "    accuracy                           0.92      1078\n",
      "   macro avg       0.92      0.87      0.89      1078\n",
      "weighted avg       0.92      0.92      0.91      1078\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9574, F1 Micro: 0.9574, F1 Macro: 0.8682\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.86      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.78      0.81        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.84      0.60      0.70        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.53      0.55       571\n",
      "weighted avg       0.91      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.75      0.27      0.40        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.85      0.69      0.73       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.92      0.97      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.66      0.70        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 302.3970844745636 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0060013532638549805\n",
      "Samples above threshold: 32\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.914414405822754 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4475, Accuracy: 0.8764, F1 Micro: 0.9276, F1 Macro: 0.9237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.274, Accuracy: 0.9337, F1 Micro: 0.9598, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1943, Accuracy: 0.9514, F1 Micro: 0.9702, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1512, Accuracy: 0.9547, F1 Micro: 0.9721, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1282, Accuracy: 0.9601, F1 Micro: 0.9754, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1106, Accuracy: 0.9618, F1 Micro: 0.9764, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0873, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9746\n",
      "Epoch 8/10, Train Loss: 0.0744, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "Epoch 9/10, Train Loss: 0.059, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.055, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3564, Accuracy: 0.868, F1 Micro: 0.868, F1 Macro: 0.8238\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2006, Accuracy: 0.8879, F1 Micro: 0.8879, F1 Macro: 0.8528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1327, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8762\n",
      "Epoch 4/10, Train Loss: 0.0901, Accuracy: 0.8987, F1 Micro: 0.8987, F1 Macro: 0.8694\n",
      "Epoch 5/10, Train Loss: 0.0625, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8768\n",
      "Epoch 6/10, Train Loss: 0.0556, Accuracy: 0.8969, F1 Micro: 0.8969, F1 Macro: 0.871\n",
      "Epoch 7/10, Train Loss: 0.0398, Accuracy: 0.8942, F1 Micro: 0.8942, F1 Macro: 0.8606\n",
      "Epoch 8/10, Train Loss: 0.0347, Accuracy: 0.8942, F1 Micro: 0.8942, F1 Macro: 0.864\n",
      "Epoch 9/10, Train Loss: 0.0142, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8718\n",
      "Epoch 10/10, Train Loss: 0.0239, Accuracy: 0.8951, F1 Micro: 0.8951, F1 Macro: 0.8676\n",
      "\n",
      "Sentiment analysis accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       782\n",
      "    positive       0.91      0.74      0.82       324\n",
      "\n",
      "    accuracy                           0.90      1106\n",
      "   macro avg       0.91      0.86      0.88      1106\n",
      "weighted avg       0.90      0.90      0.90      1106\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.8649\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.82      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.81      0.65      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.58      0.54      0.56       571\n",
      "weighted avg       0.91      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.77      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.83      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 310.6017644405365 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.007669270038604736\n",
      "Samples above threshold: 29\n",
      "Acquired samples: 50\n",
      "Sampling duration: 3.4728190898895264 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4568, Accuracy: 0.8833, F1 Micro: 0.9315, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2707, Accuracy: 0.9344, F1 Micro: 0.9601, F1 Macro: 0.9575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1926, Accuracy: 0.9462, F1 Micro: 0.9671, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.149, Accuracy: 0.9589, F1 Micro: 0.9746, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1269, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9733\n",
      "Epoch 6/10, Train Loss: 0.1012, Accuracy: 0.9589, F1 Micro: 0.9747, F1 Macro: 0.9728\n",
      "Epoch 7/10, Train Loss: 0.0882, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0726, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0613, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0537, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.96      0.91      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.36, Accuracy: 0.8548, F1 Micro: 0.8548, F1 Macro: 0.7975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.195, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8802\n",
      "Epoch 3/10, Train Loss: 0.1329, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8766\n",
      "Epoch 4/10, Train Loss: 0.0815, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0684, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.885\n",
      "Epoch 6/10, Train Loss: 0.0531, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8794\n",
      "Epoch 7/10, Train Loss: 0.0407, Accuracy: 0.9044, F1 Micro: 0.9044, F1 Macro: 0.8749\n",
      "Epoch 8/10, Train Loss: 0.0375, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8799\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0235, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0232, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8874\n",
      "\n",
      "Sentiment analysis accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       782\n",
      "    positive       0.95      0.75      0.83       327\n",
      "\n",
      "    accuracy                           0.91      1109\n",
      "   macro avg       0.92      0.86      0.89      1109\n",
      "weighted avg       0.92      0.91      0.91      1109\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.8756\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.90      0.93        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.83      0.72      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.90       200\n",
      "     neutral       0.96      0.91      0.94       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.94      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.85       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.75      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.69      0.74        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 313.8146302700043 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0050427913665771484\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 50\n",
      "Sampling duration: 3.0907022953033447 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4484, Accuracy: 0.8849, F1 Micro: 0.9321, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2674, Accuracy: 0.9314, F1 Micro: 0.9585, F1 Macro: 0.9562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1894, Accuracy: 0.9519, F1 Micro: 0.9705, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1488, Accuracy: 0.9557, F1 Micro: 0.9728, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1241, Accuracy: 0.959, F1 Micro: 0.9747, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0998, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0824, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.976\n",
      "Epoch 8/10, Train Loss: 0.0706, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.0604, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0502, Accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3529, Accuracy: 0.8747, F1 Micro: 0.8747, F1 Macro: 0.8311\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.189, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8813\n",
      "Epoch 3/10, Train Loss: 0.1287, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0974, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0613, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0422, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.8874\n",
      "Epoch 7/10, Train Loss: 0.0244, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8855\n",
      "Epoch 8/10, Train Loss: 0.0277, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8847\n",
      "Epoch 9/10, Train Loss: 0.0209, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0223, Accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.8893\n",
      "\n",
      "Sentiment analysis accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.8893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       775\n",
      "    positive       0.94      0.75      0.84       310\n",
      "\n",
      "    accuracy                           0.92      1085\n",
      "   macro avg       0.92      0.87      0.89      1085\n",
      "weighted avg       0.92      0.92      0.91      1085\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.8628\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.76      0.79       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.88      0.74      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.57      0.59       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.85       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.75      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.87      0.87        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.94      0.97      0.96        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.82      0.87       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 325.35801219940186 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.003989070653915405\n",
      "Samples above threshold: 19\n",
      "Acquired samples: 50\n",
      "Sampling duration: 2.699833631515503 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4367, Accuracy: 0.8872, F1 Micro: 0.9335, F1 Macro: 0.9302\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2619, Accuracy: 0.938, F1 Micro: 0.9623, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1789, Accuracy: 0.9528, F1 Micro: 0.971, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1465, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1196, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1007, Accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.977\n",
      "Epoch 7/10, Train Loss: 0.0792, Accuracy: 0.9639, F1 Micro: 0.9775, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.0678, Accuracy: 0.9637, F1 Micro: 0.9774, F1 Macro: 0.9748\n",
      "Epoch 9/10, Train Loss: 0.0565, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9761\n",
      "Epoch 10/10, Train Loss: 0.05, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.96      0.92      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3436, Accuracy: 0.8717, F1 Micro: 0.8717, F1 Macro: 0.8334\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2132, Accuracy: 0.8835, F1 Micro: 0.8835, F1 Macro: 0.8406\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1362, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0954, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8814\n",
      "Epoch 5/10, Train Loss: 0.0869, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8785\n",
      "Epoch 6/10, Train Loss: 0.0648, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0509, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8792\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.048, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0467, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0365, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8881\n",
      "\n",
      "Sentiment analysis accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       788\n",
      "    positive       0.92      0.76      0.84       319\n",
      "\n",
      "    accuracy                           0.91      1107\n",
      "   macro avg       0.92      0.87      0.89      1107\n",
      "weighted avg       0.91      0.91      0.91      1107\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.8816\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.80      0.84       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.81      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.62      0.66       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.90       200\n",
      "     neutral       0.96      0.92      0.94       315\n",
      "    positive       0.82      0.98      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.71      0.45      0.56        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.84      0.76      0.79       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.55      0.70        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 323.6146104335785 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.009064942598342896\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 50\n",
      "Sampling duration: 2.362602949142456 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4342, Accuracy: 0.8892, F1 Micro: 0.9345, F1 Macro: 0.9315\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2539, Accuracy: 0.9394, F1 Micro: 0.963, F1 Macro: 0.9609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.179, Accuracy: 0.9564, F1 Micro: 0.9731, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1463, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1177, Accuracy: 0.9622, F1 Micro: 0.9766, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0973, Accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9766\n",
      "Epoch 7/10, Train Loss: 0.0768, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "Epoch 8/10, Train Loss: 0.0676, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0553, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9763\n",
      "Epoch 10/10, Train Loss: 0.0481, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.91      0.93       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3666, Accuracy: 0.8189, F1 Micro: 0.8189, F1 Macro: 0.7283\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1958, Accuracy: 0.8928, F1 Micro: 0.8928, F1 Macro: 0.8664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1356, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1035, Accuracy: 0.9018, F1 Micro: 0.9018, F1 Macro: 0.8724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0744, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0551, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0361, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8892\n",
      "Epoch 8/10, Train Loss: 0.0294, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8764\n",
      "Epoch 9/10, Train Loss: 0.0288, Accuracy: 0.9018, F1 Micro: 0.9018, F1 Macro: 0.8746\n",
      "Epoch 10/10, Train Loss: 0.0209, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8843\n",
      "\n",
      "Sentiment analysis accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8892\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       784\n",
      "    positive       0.94      0.76      0.84       326\n",
      "\n",
      "    accuracy                           0.91      1110\n",
      "   macro avg       0.92      0.87      0.89      1110\n",
      "weighted avg       0.92      0.91      0.91      1110\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.8926\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.88      0.93        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.78      0.70      0.74        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.86      0.88       571\n",
      "weighted avg       0.98      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.67      0.73       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.92      0.89       200\n",
      "     neutral       0.95      0.91      0.93       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.81      0.59      0.68        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.89      0.87        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.96      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 331.4855351448059 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.004582226276397705\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 50\n",
      "Sampling duration: 2.084099769592285 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4292, Accuracy: 0.8934, F1 Micro: 0.9369, F1 Macro: 0.9341\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.249, Accuracy: 0.9378, F1 Micro: 0.9623, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1807, Accuracy: 0.9514, F1 Micro: 0.9702, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1415, Accuracy: 0.9576, F1 Micro: 0.9738, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1156, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.096, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0793, Accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0648, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9761\n",
      "Epoch 9/10, Train Loss: 0.0538, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0477, Accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3365, Accuracy: 0.8591, F1 Micro: 0.8591, F1 Macro: 0.8045\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1785, Accuracy: 0.8997, F1 Micro: 0.8997, F1 Macro: 0.8727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1206, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0873, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8845\n",
      "Epoch 5/10, Train Loss: 0.0606, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8819\n",
      "Epoch 6/10, Train Loss: 0.0525, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8854\n",
      "Epoch 7/10, Train Loss: 0.0385, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8776\n",
      "Epoch 8/10, Train Loss: 0.0282, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8832\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0382, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.888\n",
      "Epoch 10/10, Train Loss: 0.0253, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8842\n",
      "\n",
      "Sentiment analysis accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       783\n",
      "    positive       0.91      0.77      0.84       324\n",
      "\n",
      "    accuracy                           0.91      1107\n",
      "   macro avg       0.91      0.87      0.89      1107\n",
      "weighted avg       0.91      0.91      0.91      1107\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.8699\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.83      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.76      0.81        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.58      0.59       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.83      0.86       162\n",
      "     neutral       0.93      0.96      0.94       387\n",
      "    positive       0.68      0.59      0.63        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.83      0.79      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.98      0.97      0.98       418\n",
      "    positive       0.89      0.96      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.84      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 336.78227376937866 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0033055245876312256\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 36\n",
      "Sampling duration: 1.551889419555664 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4292, Accuracy: 0.8918, F1 Micro: 0.9356, F1 Macro: 0.9325\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2509, Accuracy: 0.9372, F1 Micro: 0.9617, F1 Macro: 0.9593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1804, Accuracy: 0.9477, F1 Micro: 0.968, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1452, Accuracy: 0.9587, F1 Micro: 0.9745, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1152, Accuracy: 0.9618, F1 Micro: 0.9764, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0946, Accuracy: 0.962, F1 Micro: 0.9765, F1 Macro: 0.9742\n",
      "Epoch 7/10, Train Loss: 0.0782, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0672, Accuracy: 0.9667, F1 Micro: 0.9793, F1 Macro: 0.9773\n",
      "Epoch 9/10, Train Loss: 0.0553, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "Epoch 10/10, Train Loss: 0.0465, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9667, F1 Micro: 0.9793, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.93      0.98      0.96       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.327, Accuracy: 0.8787, F1 Micro: 0.8787, F1 Macro: 0.8377\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1911, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1343, Accuracy: 0.9204, F1 Micro: 0.9204, F1 Macro: 0.8963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1056, Accuracy: 0.9204, F1 Micro: 0.9204, F1 Macro: 0.8975\n",
      "Epoch 5/10, Train Loss: 0.0586, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.8935\n",
      "Epoch 6/10, Train Loss: 0.0465, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.8903\n",
      "Epoch 7/10, Train Loss: 0.0383, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8817\n",
      "Epoch 8/10, Train Loss: 0.0359, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8867\n",
      "Epoch 9/10, Train Loss: 0.0218, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.8905\n",
      "Epoch 10/10, Train Loss: 0.0205, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8888\n",
      "\n",
      "Sentiment analysis accuracy: 0.9204, F1 Micro: 0.9204, F1 Macro: 0.8975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.95       776\n",
      "    positive       0.91      0.80      0.85       304\n",
      "\n",
      "    accuracy                           0.92      1080\n",
      "   macro avg       0.92      0.88      0.90      1080\n",
      "weighted avg       0.92      0.92      0.92      1080\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.8502\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.77      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.88      0.74      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.57      0.59       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.83      0.96      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.84      0.88       162\n",
      "     neutral       0.93      0.98      0.96       387\n",
      "    positive       0.81      0.59      0.68        22\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.89      0.80      0.84       571\n",
      "weighted avg       0.93      0.93      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.85        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.90      0.93      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.86      0.99      0.91       571\n",
      "weighted avg       1.00      0.99      1.00       571\n",
      "\n",
      "Total train time: 332.93512296676636 s\n",
      "Total runtime: 6944.554147481918 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157fbfa3",
   "metadata": {
    "papermill": {
     "duration": 0.186344,
     "end_time": "2025-03-29T17:11:23.132099",
     "exception": false,
     "start_time": "2025-03-29T17:11:22.945755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2e968d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6846, Accuracy: 0.7771, F1 Micro: 0.873, F1 Macro: 0.8661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5356, Accuracy: 0.8012, F1 Micro: 0.8896, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4856, Accuracy: 0.8019, F1 Micro: 0.8899, F1 Macro: 0.8853\n",
      "Epoch 4/10, Train Loss: 0.4451, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Epoch 5/10, Train Loss: 0.447, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4104, Accuracy: 0.8038, F1 Micro: 0.8908, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4062, Accuracy: 0.8099, F1 Micro: 0.893, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4023, Accuracy: 0.8189, F1 Micro: 0.8974, F1 Macro: 0.8906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3668, Accuracy: 0.8349, F1 Micro: 0.9047, F1 Macro: 0.8978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3363, Accuracy: 0.8422, F1 Micro: 0.9091, F1 Macro: 0.9034\n",
      "\n",
      "Aspect detection accuracy: 0.8422, F1 Micro: 0.9091, F1 Macro: 0.9034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.80      1.00      0.89       462\n",
      "   air_panas       0.83      1.00      0.91       480\n",
      "         bau       0.86      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.66      0.86      0.75       317\n",
      "       linen       0.73      0.99      0.84       392\n",
      "     service       0.92      0.96      0.94       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.91      1.00      0.95       498\n",
      "\n",
      "   micro avg       0.84      0.99      0.91      4614\n",
      "   macro avg       0.84      0.98      0.90      4614\n",
      "weighted avg       0.85      0.99      0.91      4614\n",
      " samples avg       0.84      0.99      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6158, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4961, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4198, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4426, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3147, Accuracy: 0.7391, F1 Micro: 0.7391, F1 Macro: 0.6783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2361, Accuracy: 0.7636, F1 Micro: 0.7636, F1 Macro: 0.7349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2395, Accuracy: 0.7663, F1 Micro: 0.7663, F1 Macro: 0.7452\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2328, Accuracy: 0.7935, F1 Micro: 0.7935, F1 Macro: 0.781\n",
      "Epoch 9/10, Train Loss: 0.1405, Accuracy: 0.7799, F1 Micro: 0.7799, F1 Macro: 0.7604\n",
      "Epoch 10/10, Train Loss: 0.0903, Accuracy: 0.7745, F1 Micro: 0.7745, F1 Macro: 0.7461\n",
      "\n",
      "Sentiment analysis accuracy: 0.7935, F1 Micro: 0.7935, F1 Macro: 0.781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.84      0.83       226\n",
      "    positive       0.74      0.72      0.73       142\n",
      "\n",
      "    accuracy                           0.79       368\n",
      "   macro avg       0.78      0.78      0.78       368\n",
      "weighted avg       0.79      0.79      0.79       368\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8343, F1 Micro: 0.8343, F1 Macro: 0.4065\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        97\n",
      "     neutral       0.80      1.00      0.89       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.80       571\n",
      "   macro avg       0.27      0.33      0.30       571\n",
      "weighted avg       0.65      0.80      0.72       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.28      0.33      0.30       571\n",
      "weighted avg       0.69      0.83      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.03      0.05        78\n",
      "     neutral       0.86      1.00      0.93       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.51      0.34      0.32       571\n",
      "weighted avg       0.83      0.86      0.80       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.36      0.49       200\n",
      "     neutral       0.66      0.86      0.75       315\n",
      "    positive       0.27      0.32      0.30        56\n",
      "\n",
      "    accuracy                           0.63       571\n",
      "   macro avg       0.56      0.51      0.51       571\n",
      "weighted avg       0.65      0.63      0.61       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.23      0.37       162\n",
      "     neutral       0.72      0.99      0.84       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.74       571\n",
      "   macro avg       0.55      0.41      0.40       571\n",
      "weighted avg       0.75      0.74      0.67       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.61      0.71        85\n",
      "     neutral       0.92      0.96      0.94       418\n",
      "    positive       0.72      0.75      0.73        68\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.83      0.78      0.79       571\n",
      "weighted avg       0.88      0.89      0.88       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.36      0.52        74\n",
      "     neutral       0.91      1.00      0.95       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.61      0.45      0.49       571\n",
      "weighted avg       0.91      0.91      0.89       571\n",
      "\n",
      "Total train time: 80.9882264137268 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.9419968128204346\n",
      "Samples above threshold: 215\n",
      "Acquired samples: 215\n",
      "Sampling duration: 11.928537845611572 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5973, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4879, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4778, Accuracy: 0.8023, F1 Micro: 0.8901, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4397, Accuracy: 0.8203, F1 Micro: 0.8987, F1 Macro: 0.8936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4026, Accuracy: 0.859, F1 Micro: 0.9181, F1 Macro: 0.9123\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3551, Accuracy: 0.8885, F1 Micro: 0.9336, F1 Macro: 0.9272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.309, Accuracy: 0.9017, F1 Micro: 0.9408, F1 Macro: 0.9345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2676, Accuracy: 0.9189, F1 Micro: 0.9508, F1 Macro: 0.9467\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2355, Accuracy: 0.9274, F1 Micro: 0.9559, F1 Macro: 0.9527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2117, Accuracy: 0.9276, F1 Micro: 0.956, F1 Macro: 0.9529\n",
      "\n",
      "Aspect detection accuracy: 0.9276, F1 Micro: 0.956, F1 Macro: 0.9529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.95      0.99      0.97       480\n",
      "         bau       0.96      0.96      0.96       496\n",
      "     general       0.87      0.99      0.93       500\n",
      "  kebersihan       0.89      0.88      0.89       317\n",
      "       linen       0.83      0.97      0.90       392\n",
      "     service       0.93      0.99      0.96       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.93      0.98      0.96      4614\n",
      "   macro avg       0.93      0.98      0.95      4614\n",
      "weighted avg       0.93      0.98      0.96      4614\n",
      " samples avg       0.93      0.98      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4424, Accuracy: 0.7458, F1 Micro: 0.7458, F1 Macro: 0.4272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3306, Accuracy: 0.818, F1 Micro: 0.818, F1 Macro: 0.7564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2536, Accuracy: 0.8368, F1 Micro: 0.8368, F1 Macro: 0.7786\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1977, Accuracy: 0.8391, F1 Micro: 0.8391, F1 Macro: 0.7849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.134, Accuracy: 0.8557, F1 Micro: 0.8557, F1 Macro: 0.7962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1173, Accuracy: 0.8635, F1 Micro: 0.8635, F1 Macro: 0.8088\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0531, Accuracy: 0.8646, F1 Micro: 0.8646, F1 Macro: 0.81\n",
      "Epoch 8/10, Train Loss: 0.0547, Accuracy: 0.8479, F1 Micro: 0.8479, F1 Macro: 0.7962\n",
      "Epoch 9/10, Train Loss: 0.0796, Accuracy: 0.859, F1 Micro: 0.859, F1 Macro: 0.8051\n",
      "Epoch 10/10, Train Loss: 0.0974, Accuracy: 0.8579, F1 Micro: 0.8579, F1 Macro: 0.776\n",
      "\n",
      "Sentiment analysis accuracy: 0.8646, F1 Micro: 0.8646, F1 Macro: 0.81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.91       672\n",
      "    positive       0.78      0.65      0.71       229\n",
      "\n",
      "    accuracy                           0.86       901\n",
      "   macro avg       0.83      0.79      0.81       901\n",
      "weighted avg       0.86      0.86      0.86       901\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.6875\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.90      0.93        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.78      0.93      0.85        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.72      0.82        86\n",
      "     neutral       0.95      0.99      0.97       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.87      0.74      0.79       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.76      0.74        78\n",
      "     neutral       0.96      0.96      0.96       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.56      0.57      0.57       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      0.99      0.93       496\n",
      "    positive       0.50      0.03      0.06        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.46      0.34      0.33       571\n",
      "weighted avg       0.82      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.78      0.81       200\n",
      "     neutral       0.89      0.88      0.88       315\n",
      "    positive       0.64      0.86      0.73        56\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.79      0.84      0.81       571\n",
      "weighted avg       0.85      0.84      0.84       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.60      0.73       162\n",
      "     neutral       0.83      0.97      0.90       387\n",
      "    positive       0.18      0.09      0.12        22\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.64      0.56      0.58       571\n",
      "weighted avg       0.83      0.84      0.82       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.62      0.74        85\n",
      "     neutral       0.93      0.99      0.96       418\n",
      "    positive       0.78      0.78      0.78        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.97      0.75      0.80       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.89      0.93        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.96      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 127.52838039398193 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.05615657567977905\n",
      "Samples above threshold: 193\n",
      "Acquired samples: 193\n",
      "Sampling duration: 16.188644647598267 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5539, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4888, Accuracy: 0.8033, F1 Micro: 0.8906, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4301, Accuracy: 0.8266, F1 Micro: 0.9009, F1 Macro: 0.8932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3895, Accuracy: 0.8783, F1 Micro: 0.9282, F1 Macro: 0.9227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3251, Accuracy: 0.9097, F1 Micro: 0.9455, F1 Macro: 0.9406\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2733, Accuracy: 0.9248, F1 Micro: 0.954, F1 Macro: 0.9497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.238, Accuracy: 0.9312, F1 Micro: 0.9581, F1 Macro: 0.9552\n",
      "Epoch 8/10, Train Loss: 0.2051, Accuracy: 0.9311, F1 Micro: 0.958, F1 Macro: 0.9553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1781, Accuracy: 0.9368, F1 Micro: 0.9613, F1 Macro: 0.9583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1571, Accuracy: 0.9399, F1 Micro: 0.9632, F1 Macro: 0.9608\n",
      "\n",
      "Aspect detection accuracy: 0.9399, F1 Micro: 0.9632, F1 Macro: 0.9608\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.96      0.99      0.98       480\n",
      "         bau       0.96      0.97      0.97       496\n",
      "     general       0.89      0.98      0.93       500\n",
      "  kebersihan       0.90      0.92      0.91       317\n",
      "       linen       0.88      0.98      0.92       392\n",
      "     service       0.96      0.96      0.96       423\n",
      "sunrise_meal       0.94      1.00      0.97       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      4614\n",
      "   macro avg       0.94      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.96      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5527, Accuracy: 0.7621, F1 Micro: 0.7621, F1 Macro: 0.5409\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3696, Accuracy: 0.8579, F1 Micro: 0.8579, F1 Macro: 0.8016\n",
      "Epoch 3/10, Train Loss: 0.2844, Accuracy: 0.8435, F1 Micro: 0.8435, F1 Macro: 0.7616\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2217, Accuracy: 0.8764, F1 Micro: 0.8764, F1 Macro: 0.8286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1534, Accuracy: 0.8774, F1 Micro: 0.8774, F1 Macro: 0.8308\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1271, Accuracy: 0.8836, F1 Micro: 0.8836, F1 Macro: 0.8407\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1152, Accuracy: 0.895, F1 Micro: 0.895, F1 Macro: 0.8529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0601, Accuracy: 0.895, F1 Micro: 0.895, F1 Macro: 0.8552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0439, Accuracy: 0.8991, F1 Micro: 0.8991, F1 Macro: 0.8612\n",
      "Epoch 10/10, Train Loss: 0.0563, Accuracy: 0.895, F1 Micro: 0.895, F1 Macro: 0.8516\n",
      "\n",
      "Sentiment analysis accuracy: 0.8991, F1 Micro: 0.8991, F1 Macro: 0.8612\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       711\n",
      "    positive       0.90      0.70      0.79       260\n",
      "\n",
      "    accuracy                           0.90       971\n",
      "   macro avg       0.90      0.84      0.86       971\n",
      "weighted avg       0.90      0.90      0.89       971\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9342, F1 Micro: 0.9342, F1 Macro: 0.7672\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.90      0.93        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.87      0.87      0.87        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.80      0.86        86\n",
      "     neutral       0.96      0.99      0.98       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.83      0.80      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.74      0.78        78\n",
      "     neutral       0.96      0.97      0.97       491\n",
      "    positive       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.74      0.75       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.89      0.98      0.93       496\n",
      "    positive       0.56      0.21      0.30        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.48      0.39      0.41       571\n",
      "weighted avg       0.84      0.87      0.84       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85       200\n",
      "     neutral       0.91      0.92      0.91       315\n",
      "    positive       0.84      0.91      0.87        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.87      0.89      0.88       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.73      0.82       162\n",
      "     neutral       0.88      0.98      0.92       387\n",
      "    positive       0.45      0.23      0.30        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.75      0.64      0.68       571\n",
      "weighted avg       0.87      0.88      0.87       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.84      0.82        85\n",
      "     neutral       0.95      0.96      0.96       418\n",
      "    positive       0.95      0.85      0.90        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.90      0.88      0.89       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.14      0.24        29\n",
      "     neutral       0.94      1.00      0.97       525\n",
      "    positive       0.57      0.24      0.33        17\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.77      0.46      0.51       571\n",
      "weighted avg       0.92      0.93      0.91       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.62      0.83      0.71         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.85      0.90      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.98      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 156.66045475006104 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.02951711416244507\n",
      "Samples above threshold: 174\n",
      "Acquired samples: 174\n",
      "Sampling duration: 15.558743000030518 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5645, Accuracy: 0.8068, F1 Micro: 0.8913, F1 Macro: 0.8843\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4766, Accuracy: 0.8151, F1 Micro: 0.8941, F1 Macro: 0.8829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4186, Accuracy: 0.8625, F1 Micro: 0.9189, F1 Macro: 0.9092\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3386, Accuracy: 0.9102, F1 Micro: 0.9455, F1 Macro: 0.9382\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2738, Accuracy: 0.9266, F1 Micro: 0.9555, F1 Macro: 0.9527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2383, Accuracy: 0.9312, F1 Micro: 0.9581, F1 Macro: 0.9551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2085, Accuracy: 0.9382, F1 Micro: 0.9622, F1 Macro: 0.9595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.18, Accuracy: 0.9479, F1 Micro: 0.9678, F1 Macro: 0.9649\n",
      "Epoch 9/10, Train Loss: 0.1523, Accuracy: 0.9476, F1 Micro: 0.9676, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1391, Accuracy: 0.9505, F1 Micro: 0.9693, F1 Macro: 0.9655\n",
      "\n",
      "Aspect detection accuracy: 0.9505, F1 Micro: 0.9693, F1 Macro: 0.9655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.97      0.97       496\n",
      "     general       0.94      0.97      0.95       500\n",
      "  kebersihan       0.94      0.85      0.89       317\n",
      "       linen       0.90      0.96      0.93       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.97      0.97      4614\n",
      "   macro avg       0.96      0.97      0.97      4614\n",
      "weighted avg       0.96      0.97      0.97      4614\n",
      " samples avg       0.96      0.97      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5202, Accuracy: 0.818, F1 Micro: 0.818, F1 Macro: 0.7549\n",
      "Epoch 2/10, Train Loss: 0.3115, Accuracy: 0.8125, F1 Micro: 0.8125, F1 Macro: 0.7329\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2546, Accuracy: 0.852, F1 Micro: 0.852, F1 Macro: 0.8084\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.174, Accuracy: 0.8722, F1 Micro: 0.8722, F1 Macro: 0.8402\n",
      "Epoch 5/10, Train Loss: 0.1398, Accuracy: 0.8695, F1 Micro: 0.8695, F1 Macro: 0.8386\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1177, Accuracy: 0.8869, F1 Micro: 0.8869, F1 Macro: 0.8598\n",
      "Epoch 7/10, Train Loss: 0.0756, Accuracy: 0.8676, F1 Micro: 0.8676, F1 Macro: 0.8315\n",
      "Epoch 8/10, Train Loss: 0.0587, Accuracy: 0.8732, F1 Micro: 0.8732, F1 Macro: 0.8378\n",
      "Epoch 9/10, Train Loss: 0.0889, Accuracy: 0.8759, F1 Micro: 0.8759, F1 Macro: 0.8422\n",
      "Epoch 10/10, Train Loss: 0.0704, Accuracy: 0.8842, F1 Micro: 0.8842, F1 Macro: 0.8562\n",
      "\n",
      "Sentiment analysis accuracy: 0.8869, F1 Micro: 0.8869, F1 Macro: 0.8598\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.97      0.92       747\n",
      "    positive       0.91      0.71      0.80       341\n",
      "\n",
      "    accuracy                           0.89      1088\n",
      "   macro avg       0.89      0.84      0.86      1088\n",
      "weighted avg       0.89      0.89      0.88      1088\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9431, F1 Micro: 0.9431, F1 Macro: 0.8266\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.81      0.88        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.83      0.84       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.77      0.78        78\n",
      "     neutral       0.96      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.75      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.97      0.95       496\n",
      "    positive       0.76      0.65      0.70        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.57      0.54      0.55       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.89      0.85       200\n",
      "     neutral       0.94      0.84      0.89       315\n",
      "    positive       0.72      0.95      0.82        56\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.83      0.89      0.85       571\n",
      "weighted avg       0.88      0.87      0.87       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.78      0.83       162\n",
      "     neutral       0.90      0.97      0.93       387\n",
      "    positive       0.55      0.27      0.36        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.77      0.67      0.71       571\n",
      "weighted avg       0.88      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.92      0.87      0.89        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.89      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.31      0.45        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.62      0.88      0.73        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.73      0.72       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.95      0.97        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 178.9522352218628 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.025159454345703127\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 156\n",
      "Sampling duration: 14.346128463745117 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5513, Accuracy: 0.8052, F1 Micro: 0.8914, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.472, Accuracy: 0.8193, F1 Micro: 0.8973, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3935, Accuracy: 0.8965, F1 Micro: 0.9376, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2974, Accuracy: 0.9312, F1 Micro: 0.958, F1 Macro: 0.9549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2421, Accuracy: 0.9365, F1 Micro: 0.9611, F1 Macro: 0.9576\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2128, Accuracy: 0.9429, F1 Micro: 0.965, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1798, Accuracy: 0.9481, F1 Micro: 0.9681, F1 Macro: 0.9657\n",
      "Epoch 8/10, Train Loss: 0.1574, Accuracy: 0.9451, F1 Micro: 0.9663, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1338, Accuracy: 0.9488, F1 Micro: 0.9684, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1182, Accuracy: 0.9519, F1 Micro: 0.9702, F1 Macro: 0.9673\n",
      "\n",
      "Aspect detection accuracy: 0.9519, F1 Micro: 0.9702, F1 Macro: 0.9673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.97      0.96       496\n",
      "     general       0.93      0.98      0.96       500\n",
      "  kebersihan       0.92      0.91      0.91       317\n",
      "       linen       0.89      0.97      0.93       392\n",
      "     service       0.97      0.95      0.96       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4957, Accuracy: 0.8341, F1 Micro: 0.8341, F1 Macro: 0.7898\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3225, Accuracy: 0.8511, F1 Micro: 0.8511, F1 Macro: 0.8008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2338, Accuracy: 0.8746, F1 Micro: 0.8746, F1 Macro: 0.8407\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1717, Accuracy: 0.8812, F1 Micro: 0.8812, F1 Macro: 0.8435\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1258, Accuracy: 0.8878, F1 Micro: 0.8878, F1 Macro: 0.8562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1171, Accuracy: 0.8897, F1 Micro: 0.8897, F1 Macro: 0.8559\n",
      "Epoch 7/10, Train Loss: 0.072, Accuracy: 0.8803, F1 Micro: 0.8803, F1 Macro: 0.8443\n",
      "Epoch 8/10, Train Loss: 0.0719, Accuracy: 0.885, F1 Micro: 0.885, F1 Macro: 0.8517\n",
      "Epoch 9/10, Train Loss: 0.0379, Accuracy: 0.886, F1 Micro: 0.886, F1 Macro: 0.8517\n",
      "Epoch 10/10, Train Loss: 0.0325, Accuracy: 0.886, F1 Micro: 0.886, F1 Macro: 0.8541\n",
      "\n",
      "Sentiment analysis accuracy: 0.8897, F1 Micro: 0.8897, F1 Macro: 0.8559\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93       744\n",
      "    positive       0.93      0.68      0.79       317\n",
      "\n",
      "    accuracy                           0.89      1061\n",
      "   macro avg       0.91      0.83      0.86      1061\n",
      "weighted avg       0.89      0.89      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9461, F1 Micro: 0.9461, F1 Macro: 0.8317\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.97      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.83      0.86        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.86      0.77      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.77      0.78        78\n",
      "     neutral       0.96      0.97      0.96       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.75      0.80       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.84      0.60      0.70        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.53      0.55       571\n",
      "weighted avg       0.91      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.86       200\n",
      "     neutral       0.92      0.90      0.91       315\n",
      "    positive       0.86      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.88      0.89      0.88       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.79      0.84       162\n",
      "     neutral       0.89      0.98      0.93       387\n",
      "    positive       0.60      0.14      0.22        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.80      0.63      0.66       571\n",
      "weighted avg       0.88      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.87      0.82        85\n",
      "     neutral       0.97      0.95      0.96       418\n",
      "    positive       0.95      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.91      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.41      0.56        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.75      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 204.16577982902527 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.01853764057159424\n",
      "Samples above threshold: 141\n",
      "Acquired samples: 141\n",
      "Sampling duration: 12.564958810806274 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5303, Accuracy: 0.8042, F1 Micro: 0.8908, F1 Macro: 0.8859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4455, Accuracy: 0.8467, F1 Micro: 0.9112, F1 Macro: 0.9038\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.346, Accuracy: 0.912, F1 Micro: 0.9474, F1 Macro: 0.9438\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2556, Accuracy: 0.928, F1 Micro: 0.9564, F1 Macro: 0.9533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2183, Accuracy: 0.9396, F1 Micro: 0.9632, F1 Macro: 0.9607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1889, Accuracy: 0.9455, F1 Micro: 0.9666, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1612, Accuracy: 0.9474, F1 Micro: 0.9677, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1389, Accuracy: 0.9521, F1 Micro: 0.9705, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1218, Accuracy: 0.9549, F1 Micro: 0.972, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.102, Accuracy: 0.9557, F1 Micro: 0.9726, F1 Macro: 0.9702\n",
      "\n",
      "Aspect detection accuracy: 0.9557, F1 Micro: 0.9726, F1 Macro: 0.9702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.93      0.98      0.96       500\n",
      "  kebersihan       0.93      0.92      0.92       317\n",
      "       linen       0.91      0.98      0.94       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4684, Accuracy: 0.8015, F1 Micro: 0.8015, F1 Macro: 0.6864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3203, Accuracy: 0.861, F1 Micro: 0.861, F1 Macro: 0.8312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.247, Accuracy: 0.8955, F1 Micro: 0.8955, F1 Macro: 0.8633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1755, Accuracy: 0.9041, F1 Micro: 0.9041, F1 Macro: 0.8754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1178, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.094, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8862\n",
      "Epoch 7/10, Train Loss: 0.063, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8792\n",
      "Epoch 8/10, Train Loss: 0.0445, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8809\n",
      "Epoch 9/10, Train Loss: 0.0625, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8826\n",
      "Epoch 10/10, Train Loss: 0.0279, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.8642\n",
      "\n",
      "Sentiment analysis accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8862\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       744\n",
      "    positive       0.93      0.75      0.83       299\n",
      "\n",
      "    accuracy                           0.91      1043\n",
      "   macro avg       0.92      0.86      0.89      1043\n",
      "weighted avg       0.91      0.91      0.91      1043\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.8387\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.84      0.88        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.74      0.78        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.74      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.84      0.60      0.70        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.53      0.55       571\n",
      "weighted avg       0.91      0.92      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88       200\n",
      "     neutral       0.93      0.92      0.92       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.80      0.85       162\n",
      "     neutral       0.91      0.98      0.94       387\n",
      "    positive       0.67      0.36      0.47        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.83      0.71      0.75       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.95      0.87      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.89      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.38      0.52        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.75      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.97      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 223.70328426361084 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.014775878190994263\n",
      "Samples above threshold: 127\n",
      "Acquired samples: 127\n",
      "Sampling duration: 11.259314775466919 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5199, Accuracy: 0.8049, F1 Micro: 0.8914, F1 Macro: 0.8868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4212, Accuracy: 0.8717, F1 Micro: 0.9252, F1 Macro: 0.9209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3095, Accuracy: 0.9276, F1 Micro: 0.9561, F1 Macro: 0.953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2371, Accuracy: 0.9398, F1 Micro: 0.9632, F1 Macro: 0.9606\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1907, Accuracy: 0.9443, F1 Micro: 0.9659, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1609, Accuracy: 0.9483, F1 Micro: 0.9682, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1425, Accuracy: 0.9519, F1 Micro: 0.9704, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1254, Accuracy: 0.9521, F1 Micro: 0.9705, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1078, Accuracy: 0.9561, F1 Micro: 0.9728, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0922, Accuracy: 0.9564, F1 Micro: 0.9731, F1 Macro: 0.9709\n",
      "\n",
      "Aspect detection accuracy: 0.9564, F1 Micro: 0.9731, F1 Macro: 0.9709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.93      0.98      0.96       500\n",
      "  kebersihan       0.92      0.94      0.93       317\n",
      "       linen       0.90      0.98      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.449, Accuracy: 0.8502, F1 Micro: 0.8502, F1 Macro: 0.8\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2901, Accuracy: 0.8664, F1 Micro: 0.8664, F1 Macro: 0.8156\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2237, Accuracy: 0.8664, F1 Micro: 0.8664, F1 Macro: 0.8103\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1642, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8728\n",
      "Epoch 5/10, Train Loss: 0.1241, Accuracy: 0.8979, F1 Micro: 0.8979, F1 Macro: 0.8701\n",
      "Epoch 6/10, Train Loss: 0.079, Accuracy: 0.8969, F1 Micro: 0.8969, F1 Macro: 0.8619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0682, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8729\n",
      "Epoch 8/10, Train Loss: 0.0597, Accuracy: 0.8969, F1 Micro: 0.8969, F1 Macro: 0.8615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0361, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8776\n",
      "Epoch 10/10, Train Loss: 0.0459, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8745\n",
      "\n",
      "Sentiment analysis accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       749\n",
      "    positive       0.90      0.75      0.82       299\n",
      "\n",
      "    accuracy                           0.91      1048\n",
      "   macro avg       0.90      0.86      0.88      1048\n",
      "weighted avg       0.91      0.91      0.90      1048\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9497, F1 Micro: 0.9497, F1 Macro: 0.8478\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.82      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.79      0.79        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.85      0.57      0.68        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.52      0.55       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88       200\n",
      "     neutral       0.92      0.94      0.93       315\n",
      "    positive       0.84      0.95      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83       162\n",
      "     neutral       0.90      0.98      0.94       387\n",
      "    positive       0.53      0.36      0.43        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.78      0.70      0.73       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.84        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.92      0.85      0.89        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.88      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 247.68651723861694 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.012524747848510742\n",
      "Samples above threshold: 114\n",
      "Acquired samples: 114\n",
      "Sampling duration: 10.241656064987183 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5165, Accuracy: 0.8122, F1 Micro: 0.8943, F1 Macro: 0.8881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.412, Accuracy: 0.8903, F1 Micro: 0.9352, F1 Macro: 0.93\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2869, Accuracy: 0.9319, F1 Micro: 0.9587, F1 Macro: 0.9558\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2184, Accuracy: 0.9439, F1 Micro: 0.9657, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1918, Accuracy: 0.9503, F1 Micro: 0.9695, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1618, Accuracy: 0.9564, F1 Micro: 0.9731, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1347, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9727\n",
      "Epoch 8/10, Train Loss: 0.1135, Accuracy: 0.9585, F1 Micro: 0.9743, F1 Macro: 0.9722\n",
      "Epoch 9/10, Train Loss: 0.0942, Accuracy: 0.9587, F1 Micro: 0.9744, F1 Macro: 0.9722\n",
      "Epoch 10/10, Train Loss: 0.0866, Accuracy: 0.9587, F1 Micro: 0.9744, F1 Macro: 0.9723\n",
      "\n",
      "Aspect detection accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.91      0.95      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.431, Accuracy: 0.8561, F1 Micro: 0.8561, F1 Macro: 0.805\n",
      "Epoch 2/10, Train Loss: 0.3039, Accuracy: 0.8495, F1 Micro: 0.8495, F1 Macro: 0.7821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2198, Accuracy: 0.8937, F1 Micro: 0.8937, F1 Macro: 0.8603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1455, Accuracy: 0.8956, F1 Micro: 0.8956, F1 Macro: 0.8637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1044, Accuracy: 0.8975, F1 Micro: 0.8975, F1 Macro: 0.8625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.089, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0745, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8765\n",
      "Epoch 8/10, Train Loss: 0.0655, Accuracy: 0.904, F1 Micro: 0.904, F1 Macro: 0.8728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0474, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8765\n",
      "Epoch 10/10, Train Loss: 0.0479, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.8763\n",
      "\n",
      "Sentiment analysis accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       758\n",
      "    positive       0.93      0.73      0.82       305\n",
      "\n",
      "    accuracy                           0.91      1063\n",
      "   macro avg       0.91      0.85      0.88      1063\n",
      "weighted avg       0.91      0.91      0.90      1063\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9527, F1 Micro: 0.9527, F1 Macro: 0.8408\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.85        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.81      0.73      0.77       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.79      0.79        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.75      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.84      0.63      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.54      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87       200\n",
      "     neutral       0.91      0.95      0.93       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.71      0.45      0.56        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.84      0.76      0.79       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.85        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.94      0.88      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.89      0.91       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.81      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 253.3110432624817 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.016528427600860596\n",
      "Samples above threshold: 103\n",
      "Acquired samples: 103\n",
      "Sampling duration: 9.311637878417969 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5142, Accuracy: 0.8122, F1 Micro: 0.8943, F1 Macro: 0.8888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.399, Accuracy: 0.9087, F1 Micro: 0.945, F1 Macro: 0.94\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2719, Accuracy: 0.9361, F1 Micro: 0.9611, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2168, Accuracy: 0.9446, F1 Micro: 0.9661, F1 Macro: 0.9639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1731, Accuracy: 0.9502, F1 Micro: 0.9694, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1477, Accuracy: 0.9552, F1 Micro: 0.9723, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1317, Accuracy: 0.9575, F1 Micro: 0.9736, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1151, Accuracy: 0.9606, F1 Micro: 0.9755, F1 Macro: 0.9735\n",
      "Epoch 9/10, Train Loss: 0.0973, Accuracy: 0.9589, F1 Micro: 0.9745, F1 Macro: 0.9721\n",
      "Epoch 10/10, Train Loss: 0.083, Accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.9732\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9755, F1 Macro: 0.9735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4025, Accuracy: 0.8418, F1 Micro: 0.8418, F1 Macro: 0.8004\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2781, Accuracy: 0.874, F1 Micro: 0.874, F1 Macro: 0.8284\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1952, Accuracy: 0.8878, F1 Micro: 0.8878, F1 Macro: 0.849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1433, Accuracy: 0.896, F1 Micro: 0.896, F1 Macro: 0.8623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1119, Accuracy: 0.9034, F1 Micro: 0.9034, F1 Macro: 0.8718\n",
      "Epoch 6/10, Train Loss: 0.0851, Accuracy: 0.8997, F1 Micro: 0.8997, F1 Macro: 0.8678\n",
      "Epoch 7/10, Train Loss: 0.057, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0537, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8808\n",
      "Epoch 9/10, Train Loss: 0.0394, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8709\n",
      "Epoch 10/10, Train Loss: 0.0462, Accuracy: 0.8997, F1 Micro: 0.8997, F1 Macro: 0.8691\n",
      "\n",
      "Sentiment analysis accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       773\n",
      "    positive       0.94      0.73      0.82       314\n",
      "\n",
      "    accuracy                           0.91      1087\n",
      "   macro avg       0.92      0.86      0.88      1087\n",
      "weighted avg       0.91      0.91      0.91      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9548, F1 Micro: 0.9548, F1 Macro: 0.8521\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.80      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.79      0.79        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.75      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.82      0.62      0.71        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.53      0.55       571\n",
      "weighted avg       0.91      0.92      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.84      0.93      0.88        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.64      0.41      0.50        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.82      0.75      0.77       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.85        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.95      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.52      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.78      0.79       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 268.84743094444275 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.014728206396102906\n",
      "Samples above threshold: 92\n",
      "Acquired samples: 62\n",
      "Sampling duration: 8.748777627944946 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5093, Accuracy: 0.8031, F1 Micro: 0.8905, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3838, Accuracy: 0.9109, F1 Micro: 0.9465, F1 Macro: 0.942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.268, Accuracy: 0.9321, F1 Micro: 0.9587, F1 Macro: 0.9557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2071, Accuracy: 0.9484, F1 Micro: 0.9684, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1747, Accuracy: 0.9519, F1 Micro: 0.9704, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1448, Accuracy: 0.9533, F1 Micro: 0.9712, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1254, Accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1064, Accuracy: 0.9589, F1 Micro: 0.9746, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0917, Accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.9744\n",
      "Epoch 10/10, Train Loss: 0.0787, Accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.9731\n",
      "\n",
      "Aspect detection accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.9744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.92      0.98      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3883, Accuracy: 0.8698, F1 Micro: 0.8698, F1 Macro: 0.8248\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2551, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.8631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2033, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1255, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0966, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0646, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0639, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.8955\n",
      "Epoch 8/10, Train Loss: 0.0369, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8831\n",
      "Epoch 9/10, Train Loss: 0.0266, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0212, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.8996\n",
      "\n",
      "Sentiment analysis accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.8996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       757\n",
      "    positive       0.95      0.77      0.85       295\n",
      "\n",
      "    accuracy                           0.92      1052\n",
      "   macro avg       0.93      0.88      0.90      1052\n",
      "weighted avg       0.93      0.92      0.92      1052\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9566, F1 Micro: 0.9566, F1 Macro: 0.8627\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.89        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.91      0.78      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.73      0.80        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.74      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.83      0.66      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.76      0.59      0.64       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.88       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.73      0.77       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.87      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.96      0.94      0.95        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.77      0.81       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 280.7160198688507 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.00974223017692566\n",
      "Samples above threshold: 86\n",
      "Acquired samples: 86\n",
      "Sampling duration: 8.118154048919678 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5155, Accuracy: 0.8273, F1 Micro: 0.9009, F1 Macro: 0.8927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3644, Accuracy: 0.9134, F1 Micro: 0.9481, F1 Macro: 0.9446\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2563, Accuracy: 0.9392, F1 Micro: 0.963, F1 Macro: 0.9605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2023, Accuracy: 0.945, F1 Micro: 0.9664, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1608, Accuracy: 0.9536, F1 Micro: 0.9714, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1409, Accuracy: 0.9576, F1 Micro: 0.9738, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1144, Accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.9732\n",
      "Epoch 8/10, Train Loss: 0.1028, Accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0797, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9735\n",
      "Epoch 10/10, Train Loss: 0.0738, Accuracy: 0.959, F1 Micro: 0.9747, F1 Macro: 0.9728\n",
      "\n",
      "Aspect detection accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.96      0.97      0.96       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4255, Accuracy: 0.868, F1 Micro: 0.868, F1 Macro: 0.8227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.241, Accuracy: 0.8903, F1 Micro: 0.8903, F1 Macro: 0.8562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1697, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8716\n",
      "Epoch 4/10, Train Loss: 0.1462, Accuracy: 0.8987, F1 Micro: 0.8987, F1 Macro: 0.8734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0926, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.067, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8887\n",
      "Epoch 7/10, Train Loss: 0.0368, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8797\n",
      "Epoch 8/10, Train Loss: 0.0539, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8802\n",
      "Epoch 9/10, Train Loss: 0.0199, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8771\n",
      "Epoch 10/10, Train Loss: 0.0225, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8857\n",
      "\n",
      "Sentiment analysis accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       768\n",
      "    positive       0.93      0.76      0.84       308\n",
      "\n",
      "    accuracy                           0.91      1076\n",
      "   macro avg       0.92      0.87      0.89      1076\n",
      "weighted avg       0.92      0.91      0.91      1076\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9555, F1 Micro: 0.9555, F1 Macro: 0.871\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.86      0.87       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.77      0.82        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.76      0.60      0.64       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.84      0.95      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.86       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.64      0.32      0.42        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.82      0.71      0.74       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.79      0.81        85\n",
      "     neutral       0.96      0.97      0.96       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.89      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 287.08542466163635 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.009827005863189698\n",
      "Samples above threshold: 77\n",
      "Acquired samples: 77\n",
      "Sampling duration: 7.334867477416992 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4991, Accuracy: 0.8226, F1 Micro: 0.8981, F1 Macro: 0.8901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3463, Accuracy: 0.9191, F1 Micro: 0.951, F1 Macro: 0.9466\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2444, Accuracy: 0.9413, F1 Micro: 0.9641, F1 Macro: 0.9614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1882, Accuracy: 0.9488, F1 Micro: 0.9686, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1559, Accuracy: 0.9566, F1 Micro: 0.9731, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1379, Accuracy: 0.9585, F1 Micro: 0.9743, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1117, Accuracy: 0.9601, F1 Micro: 0.9752, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0963, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "Epoch 9/10, Train Loss: 0.08, Accuracy: 0.9582, F1 Micro: 0.9742, F1 Macro: 0.9723\n",
      "Epoch 10/10, Train Loss: 0.0695, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9738\n",
      "\n",
      "Aspect detection accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.95      0.94      0.94       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4093, Accuracy: 0.8573, F1 Micro: 0.8573, F1 Macro: 0.8237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2382, Accuracy: 0.8879, F1 Micro: 0.8879, F1 Macro: 0.8511\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1737, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.126, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8829\n",
      "Epoch 5/10, Train Loss: 0.1119, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8766\n",
      "Epoch 6/10, Train Loss: 0.0615, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0532, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8874\n",
      "Epoch 8/10, Train Loss: 0.0403, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8834\n",
      "Epoch 9/10, Train Loss: 0.0393, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8761\n",
      "Epoch 10/10, Train Loss: 0.0313, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8732\n",
      "\n",
      "Sentiment analysis accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       767\n",
      "    positive       0.91      0.77      0.83       312\n",
      "\n",
      "    accuracy                           0.91      1079\n",
      "   macro avg       0.91      0.87      0.89      1079\n",
      "weighted avg       0.91      0.91      0.91      1079\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9559, F1 Micro: 0.9559, F1 Macro: 0.8691\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.79      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.71      0.60      0.64       571\n",
      "weighted avg       0.92      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91       200\n",
      "     neutral       0.95      0.94      0.94       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.85       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.69      0.50      0.58        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.84      0.76      0.79       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.41      0.56        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.65      0.88      0.75        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.76      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 295.560750246048 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.010390222072601324\n",
      "Samples above threshold: 70\n",
      "Acquired samples: 70\n",
      "Sampling duration: 6.756494760513306 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.485, Accuracy: 0.8335, F1 Micro: 0.905, F1 Macro: 0.899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3319, Accuracy: 0.9189, F1 Micro: 0.9506, F1 Macro: 0.945\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2357, Accuracy: 0.9411, F1 Micro: 0.9641, F1 Macro: 0.9618\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1843, Accuracy: 0.9503, F1 Micro: 0.9694, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1516, Accuracy: 0.955, F1 Micro: 0.9722, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1241, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1121, Accuracy: 0.9582, F1 Micro: 0.9741, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0952, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0786, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0676, Accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3917, Accuracy: 0.8555, F1 Micro: 0.8555, F1 Macro: 0.8046\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2251, Accuracy: 0.8844, F1 Micro: 0.8844, F1 Macro: 0.8481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1614, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1209, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8742\n",
      "Epoch 5/10, Train Loss: 0.0843, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8525\n",
      "Epoch 6/10, Train Loss: 0.064, Accuracy: 0.8979, F1 Micro: 0.8979, F1 Macro: 0.8676\n",
      "Epoch 7/10, Train Loss: 0.052, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.8662\n",
      "Epoch 8/10, Train Loss: 0.0494, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.8683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0363, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8734\n",
      "Epoch 10/10, Train Loss: 0.0247, Accuracy: 0.8934, F1 Micro: 0.8934, F1 Macro: 0.858\n",
      "\n",
      "Sentiment analysis accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       783\n",
      "    positive       0.91      0.73      0.81       324\n",
      "\n",
      "    accuracy                           0.90      1107\n",
      "   macro avg       0.91      0.85      0.87      1107\n",
      "weighted avg       0.90      0.90      0.90      1107\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.8714\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.87      0.69      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.61      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.67      0.36      0.47        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.82      0.73      0.76       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.65      0.88      0.75        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.78      0.78       571\n",
      "weighted avg       0.97      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 311.2502112388611 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.007143044471740725\n",
      "Samples above threshold: 63\n",
      "Acquired samples: 52\n",
      "Sampling duration: 6.221469163894653 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4867, Accuracy: 0.8405, F1 Micro: 0.9079, F1 Macro: 0.8996\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3173, Accuracy: 0.9229, F1 Micro: 0.9535, F1 Macro: 0.9504\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2271, Accuracy: 0.9444, F1 Micro: 0.9659, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1792, Accuracy: 0.9514, F1 Micro: 0.9701, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1461, Accuracy: 0.958, F1 Micro: 0.9741, F1 Macro: 0.9721\n",
      "Epoch 6/10, Train Loss: 0.1241, Accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.106, Accuracy: 0.9582, F1 Micro: 0.9742, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0889, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0748, Accuracy: 0.9615, F1 Micro: 0.976, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0625, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.94      0.95       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3972, Accuracy: 0.8545, F1 Micro: 0.8545, F1 Macro: 0.7954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.236, Accuracy: 0.8888, F1 Micro: 0.8888, F1 Macro: 0.8597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.173, Accuracy: 0.9018, F1 Micro: 0.9018, F1 Macro: 0.8701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1098, Accuracy: 0.9166, F1 Micro: 0.9166, F1 Macro: 0.891\n",
      "Epoch 5/10, Train Loss: 0.0992, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.876\n",
      "Epoch 6/10, Train Loss: 0.064, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8823\n",
      "Epoch 7/10, Train Loss: 0.0507, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8842\n",
      "Epoch 8/10, Train Loss: 0.0399, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8867\n",
      "Epoch 9/10, Train Loss: 0.0286, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8771\n",
      "Epoch 10/10, Train Loss: 0.0289, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8883\n",
      "\n",
      "Sentiment analysis accuracy: 0.9166, F1 Micro: 0.9166, F1 Macro: 0.891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       773\n",
      "    positive       0.93      0.76      0.84       306\n",
      "\n",
      "    accuracy                           0.92      1079\n",
      "   macro avg       0.92      0.87      0.89      1079\n",
      "weighted avg       0.92      0.92      0.91      1079\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.865\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.97      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.89      0.71      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91       200\n",
      "     neutral       0.95      0.94      0.95       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.76      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.85        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.62      0.76      0.68        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.74      0.75       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 315.6623795032501 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.00800633430480957\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 58\n",
      "Sampling duration: 5.720816612243652 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4837, Accuracy: 0.8561, F1 Micro: 0.9165, F1 Macro: 0.9103\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3161, Accuracy: 0.9245, F1 Micro: 0.9544, F1 Macro: 0.9514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2247, Accuracy: 0.947, F1 Micro: 0.9675, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1813, Accuracy: 0.9542, F1 Micro: 0.9717, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1474, Accuracy: 0.9573, F1 Micro: 0.9736, F1 Macro: 0.9718\n",
      "Epoch 6/10, Train Loss: 0.1194, Accuracy: 0.955, F1 Micro: 0.9723, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.102, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9749\n",
      "Epoch 8/10, Train Loss: 0.0889, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9745\n",
      "Epoch 9/10, Train Loss: 0.0734, Accuracy: 0.9609, F1 Micro: 0.9757, F1 Macro: 0.9732\n",
      "Epoch 10/10, Train Loss: 0.0632, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9739\n",
      "\n",
      "Aspect detection accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.95      0.94      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3837, Accuracy: 0.8607, F1 Micro: 0.8607, F1 Macro: 0.8238\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2293, Accuracy: 0.8808, F1 Micro: 0.8808, F1 Macro: 0.8396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1747, Accuracy: 0.8964, F1 Micro: 0.8964, F1 Macro: 0.8654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1247, Accuracy: 0.9019, F1 Micro: 0.9019, F1 Macro: 0.8722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0982, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0726, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8815\n",
      "Epoch 7/10, Train Loss: 0.0495, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8802\n",
      "Epoch 8/10, Train Loss: 0.0528, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8736\n",
      "Epoch 9/10, Train Loss: 0.0399, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8802\n",
      "Epoch 10/10, Train Loss: 0.0362, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.873\n",
      "\n",
      "Sentiment analysis accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       771\n",
      "    positive       0.92      0.75      0.83       320\n",
      "\n",
      "    accuracy                           0.91      1091\n",
      "   macro avg       0.91      0.86      0.88      1091\n",
      "weighted avg       0.91      0.91      0.90      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9562, F1 Micro: 0.9562, F1 Macro: 0.8694\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.79      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.81      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.66      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91       200\n",
      "     neutral       0.95      0.94      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.81      0.85       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       0.73      0.50      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.76      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.81      0.83        85\n",
      "     neutral       0.97      0.96      0.97       418\n",
      "    positive       0.88      0.96      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.91      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.70      0.94      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.83      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.97      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 320.02585649490356 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.011301839351654052\n",
      "Samples above threshold: 52\n",
      "Acquired samples: 52\n",
      "Sampling duration: 5.32829213142395 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4893, Accuracy: 0.8476, F1 Micro: 0.9121, F1 Macro: 0.9058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3159, Accuracy: 0.9297, F1 Micro: 0.9574, F1 Macro: 0.9546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2246, Accuracy: 0.9451, F1 Micro: 0.9663, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1739, Accuracy: 0.9563, F1 Micro: 0.973, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1473, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1199, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9741\n",
      "Epoch 7/10, Train Loss: 0.1008, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0849, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0742, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0627, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9754\n",
      "\n",
      "Aspect detection accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3768, Accuracy: 0.8724, F1 Micro: 0.8724, F1 Macro: 0.8311\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2045, Accuracy: 0.8944, F1 Micro: 0.8944, F1 Macro: 0.87\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1605, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1001, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8893\n",
      "Epoch 5/10, Train Loss: 0.0729, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8815\n",
      "Epoch 6/10, Train Loss: 0.046, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8786\n",
      "Epoch 7/10, Train Loss: 0.045, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8804\n",
      "Epoch 8/10, Train Loss: 0.0312, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8809\n",
      "Epoch 9/10, Train Loss: 0.034, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.8849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.018, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.8928\n",
      "\n",
      "Sentiment analysis accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.8928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       775\n",
      "    positive       0.94      0.76      0.84       314\n",
      "\n",
      "    accuracy                           0.92      1089\n",
      "   macro avg       0.93      0.87      0.89      1089\n",
      "weighted avg       0.92      0.92      0.91      1089\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8771\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.76      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.71      0.61      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.89       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       162\n",
      "     neutral       0.93      0.96      0.94       387\n",
      "    positive       0.67      0.36      0.47        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.82      0.73      0.76       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.84      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.81      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 334.0401794910431 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.005739033222198486\n",
      "Samples above threshold: 47\n",
      "Acquired samples: 50\n",
      "Sampling duration: 5.104548215866089 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4747, Accuracy: 0.8646, F1 Micro: 0.9209, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2989, Accuracy: 0.9345, F1 Micro: 0.9601, F1 Macro: 0.9573\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2111, Accuracy: 0.9498, F1 Micro: 0.9691, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1679, Accuracy: 0.9523, F1 Micro: 0.9707, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1355, Accuracy: 0.9545, F1 Micro: 0.9719, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1182, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0982, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0811, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9741\n",
      "Epoch 9/10, Train Loss: 0.0688, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0612, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3748, Accuracy: 0.8677, F1 Micro: 0.8677, F1 Macro: 0.8287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2285, Accuracy: 0.8927, F1 Micro: 0.8927, F1 Macro: 0.8662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1613, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8897\n",
      "Epoch 4/10, Train Loss: 0.1033, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0871, Accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.8889\n",
      "Epoch 6/10, Train Loss: 0.0469, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0513, Accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.8902\n",
      "Epoch 8/10, Train Loss: 0.0378, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0341, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.8956\n",
      "Epoch 10/10, Train Loss: 0.0201, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8881\n",
      "\n",
      "Sentiment analysis accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.8956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       767\n",
      "    positive       0.93      0.77      0.85       314\n",
      "\n",
      "    accuracy                           0.92      1081\n",
      "   macro avg       0.92      0.88      0.90      1081\n",
      "weighted avg       0.92      0.92      0.92      1081\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.8866\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.29      0.40         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.78      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.82      0.68      0.73       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.80      0.84       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.70      0.32      0.44        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.83      0.70      0.74       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.81      0.85        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.66      0.76        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.84      0.87       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 340.7226469516754 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.005405068397521973\n",
      "Samples above threshold: 42\n",
      "Acquired samples: 50\n",
      "Sampling duration: 4.530345439910889 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4726, Accuracy: 0.8752, F1 Micro: 0.9254, F1 Macro: 0.916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2965, Accuracy: 0.9373, F1 Micro: 0.9616, F1 Macro: 0.9586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2049, Accuracy: 0.9477, F1 Micro: 0.9679, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1665, Accuracy: 0.9505, F1 Micro: 0.9697, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1328, Accuracy: 0.9604, F1 Micro: 0.9754, F1 Macro: 0.9729\n",
      "Epoch 6/10, Train Loss: 0.1147, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0953, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.976\n",
      "Epoch 8/10, Train Loss: 0.0803, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0678, Accuracy: 0.9653, F1 Micro: 0.9785, F1 Macro: 0.9764\n",
      "Epoch 10/10, Train Loss: 0.0578, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9653, F1 Micro: 0.9785, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.97      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.90      0.98      0.94       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3445, Accuracy: 0.8741, F1 Micro: 0.8741, F1 Macro: 0.8365\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2005, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1498, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.89\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0965, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8899\n",
      "Epoch 5/10, Train Loss: 0.0752, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0519, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8938\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0551, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.031, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.8938\n",
      "Epoch 9/10, Train Loss: 0.0184, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8888\n",
      "Epoch 10/10, Train Loss: 0.0301, Accuracy: 0.8963, F1 Micro: 0.8963, F1 Macro: 0.8593\n",
      "\n",
      "Sentiment analysis accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.8938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       769\n",
      "    positive       0.93      0.77      0.84       311\n",
      "\n",
      "    accuracy                           0.92      1080\n",
      "   macro avg       0.92      0.87      0.89      1080\n",
      "weighted avg       0.92      0.92      0.92      1080\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9581, F1 Micro: 0.9581, F1 Macro: 0.859\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.83      0.93      0.87       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.96      0.97      0.97       496\n",
      "    positive       0.80      0.78      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.70      0.63      0.65       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.79      0.84       162\n",
      "     neutral       0.90      0.98      0.94       387\n",
      "    positive       1.00      0.27      0.43        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.93      0.68      0.74       571\n",
      "weighted avg       0.90      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.67      0.94      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.82      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 342.45783495903015 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.005638539791107178\n",
      "Samples above threshold: 37\n",
      "Acquired samples: 50\n",
      "Sampling duration: 4.21924090385437 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4758, Accuracy: 0.8691, F1 Micro: 0.9233, F1 Macro: 0.9186\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2953, Accuracy: 0.9276, F1 Micro: 0.956, F1 Macro: 0.953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2045, Accuracy: 0.9455, F1 Micro: 0.9665, F1 Macro: 0.9632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1648, Accuracy: 0.9549, F1 Micro: 0.972, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1355, Accuracy: 0.9576, F1 Micro: 0.9739, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1152, Accuracy: 0.9595, F1 Micro: 0.9751, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0943, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9751\n",
      "Epoch 8/10, Train Loss: 0.0772, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.974\n",
      "Epoch 9/10, Train Loss: 0.0667, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0558, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.35, Accuracy: 0.8731, F1 Micro: 0.8731, F1 Macro: 0.8357\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2157, Accuracy: 0.8922, F1 Micro: 0.8922, F1 Macro: 0.8568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1477, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.108, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0684, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8838\n",
      "Epoch 6/10, Train Loss: 0.0593, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8716\n",
      "Epoch 7/10, Train Loss: 0.0484, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0344, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.889\n",
      "Epoch 9/10, Train Loss: 0.0278, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8713\n",
      "Epoch 10/10, Train Loss: 0.0223, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8864\n",
      "\n",
      "Sentiment analysis accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       778\n",
      "    positive       0.93      0.76      0.84       317\n",
      "\n",
      "    accuracy                           0.91      1095\n",
      "   macro avg       0.92      0.87      0.89      1095\n",
      "weighted avg       0.92      0.91      0.91      1095\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8757\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.72      0.62      0.65       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.90       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.74      0.79       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.84      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.89      0.96      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 352.7206563949585 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.005130589008331299\n",
      "Samples above threshold: 32\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.766754150390625 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4692, Accuracy: 0.8795, F1 Micro: 0.9289, F1 Macro: 0.9229\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2896, Accuracy: 0.9361, F1 Micro: 0.9612, F1 Macro: 0.9587\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1996, Accuracy: 0.949, F1 Micro: 0.9686, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1639, Accuracy: 0.9549, F1 Micro: 0.9721, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1347, Accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1124, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0926, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "Epoch 8/10, Train Loss: 0.0777, Accuracy: 0.9637, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Epoch 9/10, Train Loss: 0.0637, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.0545, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.99      0.98       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3608, Accuracy: 0.8532, F1 Micro: 0.8532, F1 Macro: 0.7924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2152, Accuracy: 0.8927, F1 Micro: 0.8927, F1 Macro: 0.8562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1218, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8862\n",
      "Epoch 4/10, Train Loss: 0.1046, Accuracy: 0.9037, F1 Micro: 0.9037, F1 Macro: 0.8791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0713, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0479, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.8929\n",
      "Epoch 7/10, Train Loss: 0.0506, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0336, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.8929\n",
      "Epoch 9/10, Train Loss: 0.0265, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.885\n",
      "Epoch 10/10, Train Loss: 0.026, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8864\n",
      "\n",
      "Sentiment analysis accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.8929\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       777\n",
      "    positive       0.94      0.76      0.84       313\n",
      "\n",
      "    accuracy                           0.92      1090\n",
      "   macro avg       0.92      0.87      0.89      1090\n",
      "weighted avg       0.92      0.92      0.91      1090\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9594, F1 Micro: 0.9594, F1 Macro: 0.8738\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.91      0.90        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.78      0.84        78\n",
      "     neutral       0.97      0.99      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.96      0.92      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.82      0.75      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.62      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.84      0.95      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.88      0.32      0.47        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.72      0.76       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.66      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 349.4768853187561 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.008000969886779785\n",
      "Samples above threshold: 29\n",
      "Acquired samples: 50\n",
      "Sampling duration: 3.4754161834716797 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4677, Accuracy: 0.8658, F1 Micro: 0.9217, F1 Macro: 0.9159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2859, Accuracy: 0.9382, F1 Micro: 0.962, F1 Macro: 0.9589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2051, Accuracy: 0.951, F1 Micro: 0.9699, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1608, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1314, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1084, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "Epoch 7/10, Train Loss: 0.091, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9735\n",
      "Epoch 8/10, Train Loss: 0.0768, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0664, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "Epoch 10/10, Train Loss: 0.055, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.92      0.98      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3388, Accuracy: 0.876, F1 Micro: 0.876, F1 Macro: 0.8327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1851, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.135, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0906, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.8928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0692, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.8943\n",
      "Epoch 6/10, Train Loss: 0.0566, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8743\n",
      "Epoch 7/10, Train Loss: 0.0424, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8867\n",
      "Epoch 8/10, Train Loss: 0.0263, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8875\n",
      "Epoch 9/10, Train Loss: 0.0237, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.8911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0176, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.893\n",
      "\n",
      "Sentiment analysis accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       771\n",
      "    positive       0.94      0.76      0.84       302\n",
      "\n",
      "    accuracy                           0.92      1073\n",
      "   macro avg       0.93      0.87      0.89      1073\n",
      "weighted avg       0.92      0.92      0.92      1073\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.8584\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.75      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.82      0.68      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       1.00      0.23      0.37        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.68      0.73       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.48      0.61        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.77      0.79       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 355.58878922462463 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0046360790729522705\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 50\n",
      "Sampling duration: 3.2880988121032715 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.455, Accuracy: 0.8804, F1 Micro: 0.93, F1 Macro: 0.9257\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2754, Accuracy: 0.9356, F1 Micro: 0.9609, F1 Macro: 0.9586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1924, Accuracy: 0.9495, F1 Micro: 0.969, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1541, Accuracy: 0.9564, F1 Micro: 0.9731, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.128, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1071, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9753\n",
      "Epoch 7/10, Train Loss: 0.0926, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0741, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9759\n",
      "Epoch 9/10, Train Loss: 0.0623, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0539, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.95      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3536, Accuracy: 0.8711, F1 Micro: 0.8711, F1 Macro: 0.8379\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1933, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1335, Accuracy: 0.9022, F1 Micro: 0.9022, F1 Macro: 0.8723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1024, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8791\n",
      "Epoch 5/10, Train Loss: 0.0688, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0548, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0387, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8856\n",
      "Epoch 8/10, Train Loss: 0.0374, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0358, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.8888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0231, Accuracy: 0.9196, F1 Micro: 0.9196, F1 Macro: 0.8963\n",
      "\n",
      "Sentiment analysis accuracy: 0.9196, F1 Micro: 0.9196, F1 Macro: 0.8963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       780\n",
      "    positive       0.93      0.78      0.85       314\n",
      "\n",
      "    accuracy                           0.92      1094\n",
      "   macro avg       0.92      0.88      0.90      1094\n",
      "weighted avg       0.92      0.92      0.92      1094\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.8896\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.78      0.70      0.74        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.91      0.86      0.88       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.94      0.95       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.29      0.40         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.82      0.68      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.81      0.65      0.70       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.89      0.91       200\n",
      "     neutral       0.94      0.95      0.94       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.76      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.84      0.84        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 369.4272940158844 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0036690235137939453\n",
      "Samples above threshold: 19\n",
      "Acquired samples: 50\n",
      "Sampling duration: 2.7446577548980713 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4592, Accuracy: 0.8837, F1 Micro: 0.9311, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2712, Accuracy: 0.9349, F1 Micro: 0.9605, F1 Macro: 0.9583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1943, Accuracy: 0.9472, F1 Micro: 0.9677, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1553, Accuracy: 0.9568, F1 Micro: 0.9734, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1218, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1037, Accuracy: 0.9622, F1 Micro: 0.9766, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0864, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9744\n",
      "Epoch 8/10, Train Loss: 0.0719, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0623, Accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.9768\n",
      "Epoch 10/10, Train Loss: 0.0522, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.98       496\n",
      "     general       0.96      0.99      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.92      0.98      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3219, Accuracy: 0.8579, F1 Micro: 0.8579, F1 Macro: 0.8041\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2002, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.8632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1223, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.876\n",
      "Epoch 4/10, Train Loss: 0.088, Accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0802, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8903\n",
      "Epoch 6/10, Train Loss: 0.0521, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0329, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8931\n",
      "Epoch 8/10, Train Loss: 0.0303, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.027, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.8937\n",
      "Epoch 10/10, Train Loss: 0.0255, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8916\n",
      "\n",
      "Sentiment analysis accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.8937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       779\n",
      "    positive       0.94      0.76      0.84       312\n",
      "\n",
      "    accuracy                           0.92      1091\n",
      "   macro avg       0.93      0.87      0.89      1091\n",
      "weighted avg       0.92      0.92      0.92      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9604, F1 Micro: 0.9604, F1 Macro: 0.8812\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85        78\n",
      "     neutral       0.98      0.97      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.99      0.97       496\n",
      "    positive       0.86      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.62      0.67       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.91      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.73      0.36      0.48        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.72      0.76       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.84      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 371.3364133834839 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.004058718681335449\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 50\n",
      "Sampling duration: 2.3934173583984375 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4522, Accuracy: 0.8844, F1 Micro: 0.9314, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2655, Accuracy: 0.9406, F1 Micro: 0.9637, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1872, Accuracy: 0.9502, F1 Micro: 0.9695, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1538, Accuracy: 0.9578, F1 Micro: 0.974, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1239, Accuracy: 0.9613, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1016, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "Epoch 7/10, Train Loss: 0.0847, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.0717, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0598, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "Epoch 10/10, Train Loss: 0.0521, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.96      0.97      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.91      0.98      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3549, Accuracy: 0.8659, F1 Micro: 0.8659, F1 Macro: 0.8192\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.19, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1448, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0898, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0595, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8843\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0573, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8889\n",
      "Epoch 7/10, Train Loss: 0.0356, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8812\n",
      "Epoch 8/10, Train Loss: 0.0432, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0317, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0288, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.893\n",
      "\n",
      "Sentiment analysis accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       777\n",
      "    positive       0.94      0.76      0.84       319\n",
      "\n",
      "    accuracy                           0.92      1096\n",
      "   macro avg       0.93      0.87      0.89      1096\n",
      "weighted avg       0.92      0.92      0.91      1096\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8751\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.96      0.97      0.96       496\n",
      "    positive       0.78      0.78      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.75      0.63      0.66       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.82      0.86       162\n",
      "     neutral       0.91      0.98      0.95       387\n",
      "    positive       0.88      0.32      0.47        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.71      0.76       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.93      0.96       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 381.6022984981537 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.003525853157043457\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 50\n",
      "Sampling duration: 1.916719675064087 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4526, Accuracy: 0.8889, F1 Micro: 0.934, F1 Macro: 0.9289\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2608, Accuracy: 0.9365, F1 Micro: 0.9613, F1 Macro: 0.9589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1841, Accuracy: 0.9528, F1 Micro: 0.971, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1484, Accuracy: 0.9545, F1 Micro: 0.9719, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1194, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9746\n",
      "Epoch 6/10, Train Loss: 0.1035, Accuracy: 0.9608, F1 Micro: 0.9756, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0844, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.0687, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0579, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.0484, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.98       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.90      0.98      0.94       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3387, Accuracy: 0.869, F1 Micro: 0.869, F1 Macro: 0.8316\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.203, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1394, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0944, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.076, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8898\n",
      "Epoch 6/10, Train Loss: 0.0436, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.057, Accuracy: 0.9201, F1 Micro: 0.9201, F1 Macro: 0.8971\n",
      "Epoch 8/10, Train Loss: 0.0349, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8896\n",
      "Epoch 9/10, Train Loss: 0.0266, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8904\n",
      "Epoch 10/10, Train Loss: 0.0214, Accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.8925\n",
      "\n",
      "Sentiment analysis accuracy: 0.9201, F1 Micro: 0.9201, F1 Macro: 0.8971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.95       771\n",
      "    positive       0.92      0.79      0.85       305\n",
      "\n",
      "    accuracy                           0.92      1076\n",
      "   macro avg       0.92      0.88      0.90      1076\n",
      "weighted avg       0.92      0.92      0.92      1076\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.8709\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.87      0.86        78\n",
      "     neutral       0.98      0.97      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.95      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.88      0.72      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.57      0.59       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.76      0.84       162\n",
      "     neutral       0.90      0.98      0.94       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.87      0.75      0.80       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.88      0.96      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.78      0.80       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.93      0.96       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 381.2300567626953 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.004406988620758057\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 36\n",
      "Sampling duration: 1.5267078876495361 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4466, Accuracy: 0.8861, F1 Micro: 0.9329, F1 Macro: 0.9285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.264, Accuracy: 0.9432, F1 Micro: 0.9653, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1807, Accuracy: 0.9531, F1 Micro: 0.9712, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1478, Accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1204, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0989, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0783, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9761\n",
      "Epoch 8/10, Train Loss: 0.0693, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.0569, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0488, Accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3406, Accuracy: 0.8699, F1 Micro: 0.8699, F1 Macro: 0.8255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1768, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8799\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1459, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8839\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0988, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.064, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0735, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.8968\n",
      "Epoch 7/10, Train Loss: 0.0501, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8836\n",
      "Epoch 8/10, Train Loss: 0.0243, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8899\n",
      "Epoch 9/10, Train Loss: 0.0253, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.8906\n",
      "Epoch 10/10, Train Loss: 0.0181, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8908\n",
      "\n",
      "Sentiment analysis accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.8968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       778\n",
      "    positive       0.95      0.76      0.85       306\n",
      "\n",
      "    accuracy                           0.92      1084\n",
      "   macro avg       0.93      0.87      0.90      1084\n",
      "weighted avg       0.92      0.92      0.92      1084\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9604, F1 Micro: 0.9604, F1 Macro: 0.8775\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.85      0.89        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.78      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.86        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.86      0.63      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.54      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.76      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.97      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.69      0.75        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 389.3606321811676 s\n",
      "Total runtime: 7894.473915576935 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df920be4",
   "metadata": {
    "papermill": {
     "duration": 0.1872,
     "end_time": "2025-03-29T17:11:23.938390",
     "exception": false,
     "start_time": "2025-03-29T17:11:23.751190",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa70102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6341, Accuracy: 0.7974, F1 Micro: 0.8859, F1 Macro: 0.8768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5134, Accuracy: 0.8014, F1 Micro: 0.8897, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4829, Accuracy: 0.8017, F1 Micro: 0.8897, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4632, Accuracy: 0.8045, F1 Micro: 0.8906, F1 Macro: 0.8847\n",
      "Epoch 5/10, Train Loss: 0.4642, Accuracy: 0.8047, F1 Micro: 0.8903, F1 Macro: 0.8835\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4501, Accuracy: 0.8075, F1 Micro: 0.891, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.451, Accuracy: 0.8149, F1 Micro: 0.8947, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4034, Accuracy: 0.8273, F1 Micro: 0.9007, F1 Macro: 0.892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3957, Accuracy: 0.8345, F1 Micro: 0.9041, F1 Macro: 0.8954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3562, Accuracy: 0.8448, F1 Micro: 0.9097, F1 Macro: 0.9016\n",
      "\n",
      "Aspect detection accuracy: 0.8448, F1 Micro: 0.9097, F1 Macro: 0.9016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.83      1.00      0.90       462\n",
      "   air_panas       0.83      1.00      0.91       480\n",
      "         bau       0.86      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.70      0.75      0.73       317\n",
      "       linen       0.77      0.94      0.85       392\n",
      "     service       0.90      0.98      0.94       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.88      1.00      0.94       498\n",
      "\n",
      "   micro avg       0.85      0.98      0.91      4614\n",
      "   macro avg       0.85      0.97      0.90      4614\n",
      "weighted avg       0.85      0.98      0.91      4614\n",
      " samples avg       0.85      0.97      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7316, Accuracy: 0.5412, F1 Micro: 0.5412, F1 Macro: 0.3512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.612, Accuracy: 0.5412, F1 Micro: 0.5412, F1 Macro: 0.3512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5437, Accuracy: 0.5645, F1 Micro: 0.5645, F1 Macro: 0.4185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5596, Accuracy: 0.5751, F1 Micro: 0.5751, F1 Macro: 0.4522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4998, Accuracy: 0.5877, F1 Micro: 0.5877, F1 Macro: 0.5659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.478, Accuracy: 0.6025, F1 Micro: 0.6025, F1 Macro: 0.5626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3806, Accuracy: 0.666, F1 Micro: 0.666, F1 Macro: 0.6564\n",
      "Epoch 8/10, Train Loss: 0.3522, Accuracy: 0.6195, F1 Micro: 0.6195, F1 Macro: 0.5823\n",
      "Epoch 9/10, Train Loss: 0.3548, Accuracy: 0.6575, F1 Micro: 0.6575, F1 Macro: 0.6482\n",
      "Epoch 10/10, Train Loss: 0.3088, Accuracy: 0.6237, F1 Micro: 0.6237, F1 Macro: 0.6009\n",
      "\n",
      "Sentiment analysis accuracy: 0.666, F1 Micro: 0.666, F1 Macro: 0.6564\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.77      0.71       256\n",
      "    positive       0.67      0.54      0.60       217\n",
      "\n",
      "    accuracy                           0.67       473\n",
      "   macro avg       0.67      0.66      0.66       473\n",
      "weighted avg       0.67      0.67      0.66       473\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8285, F1 Micro: 0.8285, F1 Macro: 0.4061\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.16      0.28        97\n",
      "     neutral       0.83      1.00      0.91       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.61      0.39      0.40       571\n",
      "weighted avg       0.83      0.83      0.78       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.28      0.33      0.30       571\n",
      "weighted avg       0.69      0.83      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        78\n",
      "     neutral       0.86      1.00      0.92       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.74      0.86      0.80       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.43      0.50       200\n",
      "     neutral       0.70      0.75      0.73       315\n",
      "    positive       0.28      0.45      0.34        56\n",
      "\n",
      "    accuracy                           0.61       571\n",
      "   macro avg       0.53      0.54      0.52       571\n",
      "weighted avg       0.62      0.61      0.61       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.30      0.42       162\n",
      "     neutral       0.76      0.94      0.84       387\n",
      "    positive       0.17      0.18      0.18        22\n",
      "\n",
      "    accuracy                           0.73       571\n",
      "   macro avg       0.54      0.47      0.48       571\n",
      "weighted avg       0.72      0.73      0.70       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.41      0.51        85\n",
      "     neutral       0.90      0.98      0.93       418\n",
      "    positive       0.72      0.68      0.70        68\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.76      0.69      0.71       571\n",
      "weighted avg       0.84      0.86      0.84       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.24        74\n",
      "     neutral       0.88      1.00      0.94       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.63      0.38      0.39       571\n",
      "weighted avg       0.89      0.88      0.84       571\n",
      "\n",
      "Total train time: 83.8447048664093 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.9298849105834961\n",
      "Samples above threshold: 215\n",
      "Acquired samples: 215\n",
      "Sampling duration: 11.936604261398315 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.553, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.437, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4232, Accuracy: 0.8019, F1 Micro: 0.8899, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4113, Accuracy: 0.8109, F1 Micro: 0.8932, F1 Macro: 0.8859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3647, Accuracy: 0.8523, F1 Micro: 0.9144, F1 Macro: 0.9079\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3096, Accuracy: 0.8875, F1 Micro: 0.9329, F1 Macro: 0.9257\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2672, Accuracy: 0.8977, F1 Micro: 0.939, F1 Macro: 0.9343\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2208, Accuracy: 0.9187, F1 Micro: 0.9509, F1 Macro: 0.9469\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1924, Accuracy: 0.9196, F1 Micro: 0.9515, F1 Macro: 0.9479\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1711, Accuracy: 0.9285, F1 Micro: 0.9566, F1 Macro: 0.953\n",
      "\n",
      "Aspect detection accuracy: 0.9285, F1 Micro: 0.9566, F1 Macro: 0.953\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.97      0.99      0.98       462\n",
      "   air_panas       0.94      0.99      0.96       480\n",
      "         bau       0.93      1.00      0.96       496\n",
      "     general       0.92      0.98      0.95       500\n",
      "  kebersihan       0.84      0.91      0.87       317\n",
      "       linen       0.87      0.96      0.91       392\n",
      "     service       0.93      0.98      0.95       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.98      1.00      0.99       516\n",
      "        wifi       0.98      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.93      0.98      0.96      4614\n",
      "   macro avg       0.93      0.98      0.95      4614\n",
      "weighted avg       0.93      0.98      0.96      4614\n",
      " samples avg       0.93      0.98      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5739, Accuracy: 0.7205, F1 Micro: 0.7205, F1 Macro: 0.4188\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.47, Accuracy: 0.7614, F1 Micro: 0.7614, F1 Macro: 0.5616\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.297, Accuracy: 0.8295, F1 Micro: 0.8295, F1 Macro: 0.7905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2248, Accuracy: 0.8614, F1 Micro: 0.8614, F1 Macro: 0.8117\n",
      "Epoch 5/10, Train Loss: 0.1512, Accuracy: 0.858, F1 Micro: 0.858, F1 Macro: 0.812\n",
      "Epoch 6/10, Train Loss: 0.149, Accuracy: 0.8602, F1 Micro: 0.8602, F1 Macro: 0.8145\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1448, Accuracy: 0.867, F1 Micro: 0.867, F1 Macro: 0.8219\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1012, Accuracy: 0.8693, F1 Micro: 0.8693, F1 Macro: 0.8244\n",
      "Epoch 9/10, Train Loss: 0.0879, Accuracy: 0.8659, F1 Micro: 0.8659, F1 Macro: 0.8305\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0954, Accuracy: 0.8739, F1 Micro: 0.8739, F1 Macro: 0.8256\n",
      "\n",
      "Sentiment analysis accuracy: 0.8739, F1 Micro: 0.8739, F1 Macro: 0.8256\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.97      0.92       634\n",
      "    positive       0.89      0.62      0.73       246\n",
      "\n",
      "    accuracy                           0.87       880\n",
      "   macro avg       0.88      0.80      0.83       880\n",
      "weighted avg       0.88      0.87      0.87       880\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.6241\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90        97\n",
      "     neutral       0.97      0.99      0.98       459\n",
      "    positive       1.00      0.33      0.50        15\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.96      0.74      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.71      0.77        86\n",
      "     neutral       0.94      0.99      0.96       475\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.91      0.93      0.92       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.53      0.68        78\n",
      "     neutral       0.93      1.00      0.96       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.63      0.51      0.55       571\n",
      "weighted avg       0.93      0.93      0.92       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.98      0.95       496\n",
      "    positive       0.79      0.44      0.57        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.57      0.47      0.50       571\n",
      "weighted avg       0.89      0.91      0.89       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.79       200\n",
      "     neutral       0.85      0.90      0.87       315\n",
      "    positive       0.75      0.70      0.72        56\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.81      0.78      0.79       571\n",
      "weighted avg       0.83      0.83      0.83       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.73      0.79       162\n",
      "     neutral       0.87      0.96      0.91       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.57      0.57      0.57       571\n",
      "weighted avg       0.83      0.86      0.84       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        85\n",
      "     neutral       0.93      0.98      0.95       418\n",
      "    positive       0.76      0.84      0.80        68\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.86      0.79      0.81       571\n",
      "weighted avg       0.90      0.90      0.89       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.07      0.13        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       1.00      0.06      0.11        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.97      0.38      0.40       571\n",
      "weighted avg       0.93      0.92      0.89       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        54\n",
      "     neutral       0.98      1.00      0.99       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.63      0.62      0.62       571\n",
      "weighted avg       0.96      0.97      0.97       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.85      0.89        74\n",
      "     neutral       0.98      1.00      0.99       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.63      0.62      0.62       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Total train time: 122.57024240493774 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.053423404693603516\n",
      "Samples above threshold: 193\n",
      "Acquired samples: 193\n",
      "Sampling duration: 16.45598864555359 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5161, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4342, Accuracy: 0.805, F1 Micro: 0.8914, F1 Macro: 0.8871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4134, Accuracy: 0.8196, F1 Micro: 0.8983, F1 Macro: 0.8944\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3681, Accuracy: 0.8562, F1 Micro: 0.9168, F1 Macro: 0.9127\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3087, Accuracy: 0.8899, F1 Micro: 0.9348, F1 Macro: 0.9311\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2625, Accuracy: 0.9092, F1 Micro: 0.9454, F1 Macro: 0.9417\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2112, Accuracy: 0.9286, F1 Micro: 0.9567, F1 Macro: 0.9535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1806, Accuracy: 0.9335, F1 Micro: 0.9597, F1 Macro: 0.9565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.161, Accuracy: 0.942, F1 Micro: 0.9645, F1 Macro: 0.961\n",
      "Epoch 10/10, Train Loss: 0.1371, Accuracy: 0.9417, F1 Micro: 0.9644, F1 Macro: 0.9613\n",
      "\n",
      "Aspect detection accuracy: 0.942, F1 Micro: 0.9645, F1 Macro: 0.961\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.94      0.99      0.96       496\n",
      "     general       0.90      0.99      0.94       500\n",
      "  kebersihan       0.89      0.88      0.89       317\n",
      "       linen       0.87      0.98      0.92       392\n",
      "     service       0.95      0.98      0.96       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.98      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      4614\n",
      "   macro avg       0.94      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.96      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5568, Accuracy: 0.7531, F1 Micro: 0.7531, F1 Macro: 0.5887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4134, Accuracy: 0.7958, F1 Micro: 0.7958, F1 Macro: 0.6746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3177, Accuracy: 0.8167, F1 Micro: 0.8167, F1 Macro: 0.7878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2444, Accuracy: 0.851, F1 Micro: 0.851, F1 Macro: 0.7941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2197, Accuracy: 0.875, F1 Micro: 0.875, F1 Macro: 0.8329\n",
      "Epoch 6/10, Train Loss: 0.192, Accuracy: 0.8729, F1 Micro: 0.8729, F1 Macro: 0.8406\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1838, Accuracy: 0.8865, F1 Micro: 0.8865, F1 Macro: 0.8571\n",
      "Epoch 8/10, Train Loss: 0.1529, Accuracy: 0.8833, F1 Micro: 0.8833, F1 Macro: 0.8512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0867, Accuracy: 0.8969, F1 Micro: 0.8969, F1 Macro: 0.8663\n",
      "Epoch 10/10, Train Loss: 0.1118, Accuracy: 0.8917, F1 Micro: 0.8917, F1 Macro: 0.8535\n",
      "\n",
      "Sentiment analysis accuracy: 0.8969, F1 Micro: 0.8969, F1 Macro: 0.8663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93       686\n",
      "    positive       0.89      0.73      0.80       274\n",
      "\n",
      "    accuracy                           0.90       960\n",
      "   macro avg       0.89      0.85      0.87       960\n",
      "weighted avg       0.90      0.90      0.89       960\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.934, F1 Micro: 0.934, F1 Macro: 0.7728\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.92      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.87      0.87      0.87        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.85        86\n",
      "     neutral       0.96      0.99      0.98       475\n",
      "    positive       0.80      0.40      0.53        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.88      0.74      0.79       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.60      0.72        78\n",
      "     neutral       0.94      0.99      0.96       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.95      0.70      0.78       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.90      0.99      0.94       496\n",
      "    positive       0.79      0.32      0.46        68\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.56      0.44      0.47       571\n",
      "weighted avg       0.88      0.90      0.87       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83       200\n",
      "     neutral       0.89      0.88      0.89       315\n",
      "    positive       0.74      0.91      0.82        56\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.83      0.87      0.85       571\n",
      "weighted avg       0.86      0.86      0.86       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.69      0.79       162\n",
      "     neutral       0.87      0.98      0.92       387\n",
      "    positive       0.50      0.18      0.27        22\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.76      0.62      0.66       571\n",
      "weighted avg       0.86      0.87      0.86       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.71      0.79        85\n",
      "     neutral       0.94      0.98      0.96       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.88      0.89       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.14      0.24        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.62      0.88      0.73        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.80      0.67      0.65       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.87      0.90        54\n",
      "     neutral       0.98      1.00      0.99       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.97      0.79      0.85       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.86      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 147.5303192138672 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.036974298954010006\n",
      "Samples above threshold: 174\n",
      "Acquired samples: 174\n",
      "Sampling duration: 15.951828002929688 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5278, Accuracy: 0.8033, F1 Micro: 0.8905, F1 Macro: 0.8856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4666, Accuracy: 0.8116, F1 Micro: 0.8946, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4056, Accuracy: 0.8583, F1 Micro: 0.9179, F1 Macro: 0.9135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3283, Accuracy: 0.9047, F1 Micro: 0.9432, F1 Macro: 0.9394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2777, Accuracy: 0.9286, F1 Micro: 0.9567, F1 Macro: 0.953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2263, Accuracy: 0.9399, F1 Micro: 0.9634, F1 Macro: 0.9607\n",
      "Epoch 7/10, Train Loss: 0.1919, Accuracy: 0.9389, F1 Micro: 0.9627, F1 Macro: 0.9604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1694, Accuracy: 0.945, F1 Micro: 0.9663, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1455, Accuracy: 0.9458, F1 Micro: 0.9668, F1 Macro: 0.9638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1282, Accuracy: 0.9524, F1 Micro: 0.9707, F1 Macro: 0.968\n",
      "\n",
      "Aspect detection accuracy: 0.9524, F1 Micro: 0.9707, F1 Macro: 0.968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.95      0.99      0.97       480\n",
      "         bau       0.95      0.99      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.91      0.92       317\n",
      "       linen       0.90      0.97      0.93       392\n",
      "     service       0.95      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5476, Accuracy: 0.7965, F1 Micro: 0.7965, F1 Macro: 0.671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3706, Accuracy: 0.8633, F1 Micro: 0.8633, F1 Macro: 0.8224\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3331, Accuracy: 0.8692, F1 Micro: 0.8692, F1 Macro: 0.8293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2503, Accuracy: 0.8761, F1 Micro: 0.8761, F1 Macro: 0.8356\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1889, Accuracy: 0.8938, F1 Micro: 0.8938, F1 Macro: 0.8642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1303, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1162, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0876, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8818\n",
      "Epoch 9/10, Train Loss: 0.0643, Accuracy: 0.8997, F1 Micro: 0.8997, F1 Macro: 0.8672\n",
      "Epoch 10/10, Train Loss: 0.0326, Accuracy: 0.9007, F1 Micro: 0.9007, F1 Macro: 0.8687\n",
      "\n",
      "Sentiment analysis accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       724\n",
      "    positive       0.90      0.76      0.83       293\n",
      "\n",
      "    accuracy                           0.91      1017\n",
      "   macro avg       0.90      0.86      0.88      1017\n",
      "weighted avg       0.91      0.91      0.91      1017\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9454, F1 Micro: 0.9454, F1 Macro: 0.8114\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.74      0.83        86\n",
      "     neutral       0.95      0.99      0.97       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.82      0.71      0.76       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.68      0.77        78\n",
      "     neutral       0.95      0.99      0.97       491\n",
      "    positive       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.78      0.72      0.75       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.84      0.60      0.70        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.53      0.55       571\n",
      "weighted avg       0.91      0.92      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.87       200\n",
      "     neutral       0.93      0.91      0.92       315\n",
      "    positive       0.79      0.95      0.86        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.87      0.90      0.88       571\n",
      "weighted avg       0.90      0.89      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.77      0.83       162\n",
      "     neutral       0.90      0.97      0.93       387\n",
      "    positive       0.50      0.23      0.31        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.76      0.66      0.69       571\n",
      "weighted avg       0.88      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.76      0.82        85\n",
      "     neutral       0.95      0.99      0.97       418\n",
      "    positive       0.94      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.88      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.41      0.56        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.76      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.98      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 184.33257675170898 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.024394690990448\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 156\n",
      "Sampling duration: 14.43656039237976 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5218, Accuracy: 0.8033, F1 Micro: 0.8906, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4456, Accuracy: 0.8306, F1 Micro: 0.9038, F1 Macro: 0.8991\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.379, Accuracy: 0.8858, F1 Micro: 0.9327, F1 Macro: 0.9287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2878, Accuracy: 0.9264, F1 Micro: 0.9555, F1 Macro: 0.9523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2392, Accuracy: 0.9411, F1 Micro: 0.9641, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.199, Accuracy: 0.9413, F1 Micro: 0.9642, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1696, Accuracy: 0.9464, F1 Micro: 0.9672, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1466, Accuracy: 0.9521, F1 Micro: 0.9705, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1281, Accuracy: 0.9566, F1 Micro: 0.9731, F1 Macro: 0.9705\n",
      "Epoch 10/10, Train Loss: 0.1109, Accuracy: 0.9557, F1 Micro: 0.9727, F1 Macro: 0.9701\n",
      "\n",
      "Aspect detection accuracy: 0.9566, F1 Micro: 0.9731, F1 Macro: 0.9705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.96      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.97      0.96       500\n",
      "  kebersihan       0.92      0.91      0.92       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5371, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.7954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3599, Accuracy: 0.8693, F1 Micro: 0.8693, F1 Macro: 0.837\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.273, Accuracy: 0.8958, F1 Micro: 0.8958, F1 Macro: 0.8678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2195, Accuracy: 0.8987, F1 Micro: 0.8987, F1 Macro: 0.8748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1488, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1169, Accuracy: 0.9034, F1 Micro: 0.9034, F1 Macro: 0.878\n",
      "Epoch 7/10, Train Loss: 0.0874, Accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.87\n",
      "Epoch 8/10, Train Loss: 0.0766, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8739\n",
      "Epoch 9/10, Train Loss: 0.0593, Accuracy: 0.8977, F1 Micro: 0.8977, F1 Macro: 0.8702\n",
      "Epoch 10/10, Train Loss: 0.0466, Accuracy: 0.892, F1 Micro: 0.892, F1 Macro: 0.8599\n",
      "\n",
      "Sentiment analysis accuracy: 0.9034, F1 Micro: 0.9034, F1 Macro: 0.878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       741\n",
      "    positive       0.91      0.75      0.82       315\n",
      "\n",
      "    accuracy                           0.90      1056\n",
      "   macro avg       0.91      0.86      0.88      1056\n",
      "weighted avg       0.90      0.90      0.90      1056\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9489, F1 Micro: 0.9489, F1 Macro: 0.8341\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.80      0.86        86\n",
      "     neutral       0.96      0.99      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.77      0.81       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.74      0.79        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.74      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.97      0.96       496\n",
      "    positive       0.80      0.71      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.58      0.56      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.85       200\n",
      "     neutral       0.92      0.91      0.92       315\n",
      "    positive       0.72      0.93      0.81        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.84      0.89      0.86       571\n",
      "weighted avg       0.89      0.88      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.81      0.85       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.73      0.78       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.78      0.83        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.89      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.77      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.88      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 202.30616354942322 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.021634459495544434\n",
      "Samples above threshold: 141\n",
      "Acquired samples: 141\n",
      "Sampling duration: 12.986982583999634 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5135, Accuracy: 0.8043, F1 Micro: 0.8908, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4492, Accuracy: 0.8472, F1 Micro: 0.9115, F1 Macro: 0.9049\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3573, Accuracy: 0.9155, F1 Micro: 0.949, F1 Macro: 0.9453\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2712, Accuracy: 0.9345, F1 Micro: 0.9601, F1 Macro: 0.9569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.22, Accuracy: 0.9446, F1 Micro: 0.9661, F1 Macro: 0.9635\n",
      "Epoch 6/10, Train Loss: 0.1828, Accuracy: 0.9441, F1 Micro: 0.9659, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1542, Accuracy: 0.9517, F1 Micro: 0.9703, F1 Macro: 0.9677\n",
      "Epoch 8/10, Train Loss: 0.1332, Accuracy: 0.946, F1 Micro: 0.967, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1155, Accuracy: 0.9528, F1 Micro: 0.971, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1053, Accuracy: 0.9552, F1 Micro: 0.9724, F1 Macro: 0.9696\n",
      "\n",
      "Aspect detection accuracy: 0.9552, F1 Micro: 0.9724, F1 Macro: 0.9696\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.99      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.86      0.95      0.91       317\n",
      "       linen       0.90      0.99      0.94       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.99      0.97      4614\n",
      " samples avg       0.96      0.99      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5272, Accuracy: 0.8634, F1 Micro: 0.8634, F1 Macro: 0.8098\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3359, Accuracy: 0.8752, F1 Micro: 0.8752, F1 Macro: 0.8298\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2563, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1834, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8838\n",
      "Epoch 5/10, Train Loss: 0.1554, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1139, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0622, Accuracy: 0.9238, F1 Micro: 0.9238, F1 Macro: 0.9026\n",
      "Epoch 8/10, Train Loss: 0.0669, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.8977\n",
      "Epoch 9/10, Train Loss: 0.0725, Accuracy: 0.904, F1 Micro: 0.904, F1 Macro: 0.8713\n",
      "Epoch 10/10, Train Loss: 0.054, Accuracy: 0.9178, F1 Micro: 0.9178, F1 Macro: 0.8947\n",
      "\n",
      "Sentiment analysis accuracy: 0.9238, F1 Micro: 0.9238, F1 Macro: 0.9026\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.97      0.95       723\n",
      "    positive       0.92      0.80      0.86       287\n",
      "\n",
      "    accuracy                           0.92      1010\n",
      "   macro avg       0.92      0.89      0.90      1010\n",
      "weighted avg       0.92      0.92      0.92      1010\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.8464\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.84      0.87        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.81      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.73      0.80        78\n",
      "     neutral       0.96      0.99      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.74      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.83      0.72      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.76      0.84       200\n",
      "     neutral       0.86      0.95      0.90       315\n",
      "    positive       0.81      0.89      0.85        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.87      0.87      0.86       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.77      0.84       162\n",
      "     neutral       0.90      0.99      0.94       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.91      0.72      0.78       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.85        85\n",
      "     neutral       0.96      0.97      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.41      0.55        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.62      0.59      0.61        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.80      0.67      0.71       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 222.42086696624756 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.014200145006179811\n",
      "Samples above threshold: 127\n",
      "Acquired samples: 127\n",
      "Sampling duration: 11.218137502670288 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5147, Accuracy: 0.8054, F1 Micro: 0.8896, F1 Macro: 0.8795\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4239, Accuracy: 0.8722, F1 Micro: 0.9251, F1 Macro: 0.9201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3174, Accuracy: 0.9264, F1 Micro: 0.9554, F1 Macro: 0.9519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2455, Accuracy: 0.9441, F1 Micro: 0.9657, F1 Macro: 0.9629\n",
      "Epoch 5/10, Train Loss: 0.2027, Accuracy: 0.9411, F1 Micro: 0.9641, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1677, Accuracy: 0.946, F1 Micro: 0.967, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1386, Accuracy: 0.9526, F1 Micro: 0.9709, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1228, Accuracy: 0.9538, F1 Micro: 0.9716, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1081, Accuracy: 0.9568, F1 Micro: 0.9733, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0943, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.9717\n",
      "\n",
      "Aspect detection accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.9717\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.95      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.92      0.92      0.92       317\n",
      "       linen       0.95      0.95      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4807, Accuracy: 0.8204, F1 Micro: 0.8204, F1 Macro: 0.7289\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2915, Accuracy: 0.8728, F1 Micro: 0.8728, F1 Macro: 0.8347\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2345, Accuracy: 0.8906, F1 Micro: 0.8906, F1 Macro: 0.8549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1552, Accuracy: 0.8915, F1 Micro: 0.8915, F1 Macro: 0.857\n",
      "Epoch 5/10, Train Loss: 0.1218, Accuracy: 0.8831, F1 Micro: 0.8831, F1 Macro: 0.8418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0762, Accuracy: 0.899, F1 Micro: 0.899, F1 Macro: 0.8672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0758, Accuracy: 0.8999, F1 Micro: 0.8999, F1 Macro: 0.8689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.065, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8809\n",
      "Epoch 9/10, Train Loss: 0.0376, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8683\n",
      "Epoch 10/10, Train Loss: 0.042, Accuracy: 0.8962, F1 Micro: 0.8962, F1 Macro: 0.8623\n",
      "\n",
      "Sentiment analysis accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       758\n",
      "    positive       0.93      0.74      0.82       311\n",
      "\n",
      "    accuracy                           0.91      1069\n",
      "   macro avg       0.92      0.86      0.88      1069\n",
      "weighted avg       0.91      0.91      0.90      1069\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9525, F1 Micro: 0.9525, F1 Macro: 0.8496\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.83      0.88        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.71      0.78        78\n",
      "     neutral       0.95      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.73      0.80       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.84      0.63      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.54      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       200\n",
      "     neutral       0.92      0.92      0.92       315\n",
      "    positive       0.86      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.90      0.89       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87       162\n",
      "     neutral       0.95      0.95      0.95       387\n",
      "    positive       0.62      0.45      0.53        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.81      0.76      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.72      0.76      0.74        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.77      0.80       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 243.83534479141235 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.012173271179199219\n",
      "Samples above threshold: 114\n",
      "Acquired samples: 114\n",
      "Sampling duration: 10.505022525787354 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5041, Accuracy: 0.8076, F1 Micro: 0.8911, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4053, Accuracy: 0.8894, F1 Micro: 0.9347, F1 Macro: 0.9303\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2901, Accuracy: 0.9306, F1 Micro: 0.9579, F1 Macro: 0.9553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2195, Accuracy: 0.9462, F1 Micro: 0.967, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1818, Accuracy: 0.9535, F1 Micro: 0.9714, F1 Macro: 0.9687\n",
      "Epoch 6/10, Train Loss: 0.1521, Accuracy: 0.9531, F1 Micro: 0.9711, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1268, Accuracy: 0.954, F1 Micro: 0.9717, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1074, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0957, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9715\n",
      "Epoch 10/10, Train Loss: 0.0823, Accuracy: 0.9554, F1 Micro: 0.9725, F1 Macro: 0.9701\n",
      "\n",
      "Aspect detection accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.92      0.93       317\n",
      "       linen       0.90      0.98      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4459, Accuracy: 0.8316, F1 Micro: 0.8316, F1 Macro: 0.75\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2888, Accuracy: 0.8861, F1 Micro: 0.8861, F1 Macro: 0.855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2145, Accuracy: 0.89, F1 Micro: 0.89, F1 Macro: 0.8507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.157, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1057, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8843\n",
      "Epoch 6/10, Train Loss: 0.0749, Accuracy: 0.8986, F1 Micro: 0.8986, F1 Macro: 0.8633\n",
      "Epoch 7/10, Train Loss: 0.0689, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8629\n",
      "Epoch 8/10, Train Loss: 0.0688, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0383, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0452, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8899\n",
      "\n",
      "Sentiment analysis accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       747\n",
      "    positive       0.94      0.76      0.84       298\n",
      "\n",
      "    accuracy                           0.92      1045\n",
      "   macro avg       0.92      0.87      0.89      1045\n",
      "weighted avg       0.92      0.92      0.91      1045\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9525, F1 Micro: 0.9525, F1 Macro: 0.8461\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.84      0.88        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.78      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.73      0.79        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.74      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.85      0.60      0.71        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.53      0.56       571\n",
      "weighted avg       0.91      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.93      0.92      0.92       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.78      0.83       162\n",
      "     neutral       0.90      0.98      0.94       387\n",
      "    positive       1.00      0.36      0.53        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.93      0.71      0.77       571\n",
      "weighted avg       0.90      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.82      0.86        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 257.75492763519287 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.01129305362701416\n",
      "Samples above threshold: 103\n",
      "Acquired samples: 103\n",
      "Sampling duration: 9.384135961532593 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4975, Accuracy: 0.8191, F1 Micro: 0.8977, F1 Macro: 0.8916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3828, Accuracy: 0.8995, F1 Micro: 0.9403, F1 Macro: 0.9366\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2675, Accuracy: 0.9358, F1 Micro: 0.9609, F1 Macro: 0.9581\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2131, Accuracy: 0.9488, F1 Micro: 0.9685, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1695, Accuracy: 0.9516, F1 Micro: 0.9703, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1415, Accuracy: 0.9549, F1 Micro: 0.9722, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.128, Accuracy: 0.9575, F1 Micro: 0.9738, F1 Macro: 0.9712\n",
      "Epoch 8/10, Train Loss: 0.1084, Accuracy: 0.9566, F1 Micro: 0.9732, F1 Macro: 0.9707\n",
      "Epoch 9/10, Train Loss: 0.0915, Accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0795, Accuracy: 0.959, F1 Micro: 0.9745, F1 Macro: 0.9718\n",
      "\n",
      "Aspect detection accuracy: 0.959, F1 Micro: 0.9745, F1 Macro: 0.9718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.98      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.92      0.92      0.92       317\n",
      "       linen       0.93      0.95      0.94       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4609, Accuracy: 0.8393, F1 Micro: 0.8393, F1 Macro: 0.781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2913, Accuracy: 0.8658, F1 Micro: 0.8658, F1 Macro: 0.8341\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.224, Accuracy: 0.8913, F1 Micro: 0.8913, F1 Macro: 0.8641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1417, Accuracy: 0.895, F1 Micro: 0.895, F1 Macro: 0.8673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1085, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8773\n",
      "Epoch 6/10, Train Loss: 0.085, Accuracy: 0.8977, F1 Micro: 0.8977, F1 Macro: 0.8698\n",
      "Epoch 7/10, Train Loss: 0.0577, Accuracy: 0.8959, F1 Micro: 0.8959, F1 Macro: 0.8648\n",
      "Epoch 8/10, Train Loss: 0.0467, Accuracy: 0.8977, F1 Micro: 0.8977, F1 Macro: 0.8684\n",
      "Epoch 9/10, Train Loss: 0.041, Accuracy: 0.8986, F1 Micro: 0.8986, F1 Macro: 0.8725\n",
      "Epoch 10/10, Train Loss: 0.0314, Accuracy: 0.9014, F1 Micro: 0.9014, F1 Macro: 0.8736\n",
      "\n",
      "Sentiment analysis accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       762\n",
      "    positive       0.94      0.73      0.82       333\n",
      "\n",
      "    accuracy                           0.90      1095\n",
      "   macro avg       0.92      0.85      0.88      1095\n",
      "weighted avg       0.91      0.90      0.90      1095\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9527, F1 Micro: 0.9527, F1 Macro: 0.8658\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.98      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        86\n",
      "     neutral       0.98      0.98      0.98       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.80      0.79      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.73      0.79        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.74      0.81       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.82      0.74      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.67      0.73       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       200\n",
      "     neutral       0.92      0.92      0.92       315\n",
      "    positive       0.85      0.93      0.89        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.88      0.90      0.89       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85       162\n",
      "     neutral       0.93      0.96      0.94       387\n",
      "    positive       0.75      0.41      0.53        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.84      0.73      0.77       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86        85\n",
      "     neutral       0.96      0.97      0.97       418\n",
      "    positive       0.90      0.93      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 273.1382911205292 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.01109076738357544\n",
      "Samples above threshold: 92\n",
      "Acquired samples: 62\n",
      "Sampling duration: 8.737752437591553 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4975, Accuracy: 0.8285, F1 Micro: 0.9025, F1 Macro: 0.8981\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3787, Accuracy: 0.9149, F1 Micro: 0.9489, F1 Macro: 0.9454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2586, Accuracy: 0.9389, F1 Micro: 0.9626, F1 Macro: 0.9598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2009, Accuracy: 0.9481, F1 Micro: 0.9682, F1 Macro: 0.9658\n",
      "Epoch 5/10, Train Loss: 0.169, Accuracy: 0.9465, F1 Micro: 0.9673, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1425, Accuracy: 0.9554, F1 Micro: 0.9725, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1204, Accuracy: 0.959, F1 Micro: 0.9747, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0981, Accuracy: 0.9597, F1 Micro: 0.975, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0906, Accuracy: 0.9601, F1 Micro: 0.9752, F1 Macro: 0.9726\n",
      "Epoch 10/10, Train Loss: 0.0768, Accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.9724\n",
      "\n",
      "Aspect detection accuracy: 0.9601, F1 Micro: 0.9752, F1 Macro: 0.9726\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.91      0.93       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4475, Accuracy: 0.8478, F1 Micro: 0.8478, F1 Macro: 0.7952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2595, Accuracy: 0.8808, F1 Micro: 0.8808, F1 Macro: 0.8446\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2095, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.8673\n",
      "Epoch 4/10, Train Loss: 0.1332, Accuracy: 0.8873, F1 Micro: 0.8873, F1 Macro: 0.8517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1254, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.8685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0682, Accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.8779\n",
      "Epoch 7/10, Train Loss: 0.0657, Accuracy: 0.8955, F1 Micro: 0.8955, F1 Macro: 0.8637\n",
      "Epoch 8/10, Train Loss: 0.046, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8758\n",
      "Epoch 9/10, Train Loss: 0.0272, Accuracy: 0.8946, F1 Micro: 0.8946, F1 Macro: 0.8617\n",
      "Epoch 10/10, Train Loss: 0.0457, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8761\n",
      "\n",
      "Sentiment analysis accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.8779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.94       763\n",
      "    positive       0.94      0.73      0.82       328\n",
      "\n",
      "    accuracy                           0.90      1091\n",
      "   macro avg       0.92      0.85      0.88      1091\n",
      "weighted avg       0.91      0.90      0.90      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9543, F1 Micro: 0.9543, F1 Macro: 0.8693\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.97      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.85      0.89        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.76      0.80        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.89      0.88       200\n",
      "     neutral       0.95      0.90      0.93       315\n",
      "    positive       0.81      0.96      0.88        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.87      0.92      0.89       571\n",
      "weighted avg       0.91      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.77      0.82       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.78      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 279.90706729888916 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.011699259281158447\n",
      "Samples above threshold: 86\n",
      "Acquired samples: 86\n",
      "Sampling duration: 8.068777561187744 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4852, Accuracy: 0.8309, F1 Micro: 0.9029, F1 Macro: 0.8962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3592, Accuracy: 0.9201, F1 Micro: 0.9517, F1 Macro: 0.9484\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2458, Accuracy: 0.9413, F1 Micro: 0.9642, F1 Macro: 0.9616\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1889, Accuracy: 0.9503, F1 Micro: 0.9694, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1577, Accuracy: 0.955, F1 Micro: 0.9722, F1 Macro: 0.9696\n",
      "Epoch 6/10, Train Loss: 0.1303, Accuracy: 0.9547, F1 Micro: 0.972, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1143, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0972, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9733\n",
      "Epoch 9/10, Train Loss: 0.0827, Accuracy: 0.9566, F1 Micro: 0.9732, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0744, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9734\n",
      "\n",
      "Aspect detection accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4403, Accuracy: 0.8475, F1 Micro: 0.8475, F1 Macro: 0.7886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2757, Accuracy: 0.8845, F1 Micro: 0.8845, F1 Macro: 0.846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1924, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8772\n",
      "Epoch 4/10, Train Loss: 0.1181, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.87\n",
      "Epoch 5/10, Train Loss: 0.1009, Accuracy: 0.8956, F1 Micro: 0.8956, F1 Macro: 0.8611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0689, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8764\n",
      "Epoch 7/10, Train Loss: 0.0706, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8708\n",
      "Epoch 8/10, Train Loss: 0.0444, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8702\n",
      "Epoch 9/10, Train Loss: 0.0426, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8692\n",
      "Epoch 10/10, Train Loss: 0.0163, Accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.8756\n",
      "\n",
      "Sentiment analysis accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       768\n",
      "    positive       0.92      0.73      0.82       314\n",
      "\n",
      "    accuracy                           0.90      1082\n",
      "   macro avg       0.91      0.85      0.88      1082\n",
      "weighted avg       0.91      0.90      0.90      1082\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9546, F1 Micro: 0.9546, F1 Macro: 0.8707\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.77      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.82      0.62      0.71        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.58      0.64       571\n",
      "weighted avg       0.93      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.74      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.80      0.85        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.90      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 289.8510363101959 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.008321791887283325\n",
      "Samples above threshold: 77\n",
      "Acquired samples: 77\n",
      "Sampling duration: 7.603137731552124 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4842, Accuracy: 0.8267, F1 Micro: 0.9016, F1 Macro: 0.8976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.352, Accuracy: 0.9141, F1 Micro: 0.9484, F1 Macro: 0.9452\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2431, Accuracy: 0.9436, F1 Micro: 0.9655, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1865, Accuracy: 0.9526, F1 Micro: 0.9708, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1518, Accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1315, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9723\n",
      "Epoch 7/10, Train Loss: 0.1091, Accuracy: 0.9582, F1 Micro: 0.9741, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.095, Accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9724\n",
      "Epoch 9/10, Train Loss: 0.0815, Accuracy: 0.9589, F1 Micro: 0.9746, F1 Macro: 0.9722\n",
      "Epoch 10/10, Train Loss: 0.066, Accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9726\n",
      "\n",
      "Aspect detection accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.91      0.94      0.93       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4399, Accuracy: 0.8364, F1 Micro: 0.8364, F1 Macro: 0.7976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2389, Accuracy: 0.8551, F1 Micro: 0.8551, F1 Macro: 0.7975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1856, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8812\n",
      "Epoch 4/10, Train Loss: 0.1275, Accuracy: 0.9037, F1 Micro: 0.9037, F1 Macro: 0.8756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1003, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8785\n",
      "Epoch 6/10, Train Loss: 0.072, Accuracy: 0.9037, F1 Micro: 0.9037, F1 Macro: 0.8753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0617, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8842\n",
      "Epoch 8/10, Train Loss: 0.0363, Accuracy: 0.9075, F1 Micro: 0.9075, F1 Macro: 0.881\n",
      "Epoch 9/10, Train Loss: 0.0341, Accuracy: 0.9037, F1 Micro: 0.9037, F1 Macro: 0.8747\n",
      "Epoch 10/10, Train Loss: 0.0255, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8831\n",
      "\n",
      "Sentiment analysis accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       756\n",
      "    positive       0.94      0.74      0.83       314\n",
      "\n",
      "    accuracy                           0.91      1070\n",
      "   macro avg       0.92      0.86      0.88      1070\n",
      "weighted avg       0.91      0.91      0.91      1070\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.8609\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.78      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.84      0.88       200\n",
      "     neutral       0.91      0.94      0.93       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.80      0.83       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.86      0.27      0.41        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.88      0.68      0.73       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.91      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 295.38779306411743 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.010012888908386232\n",
      "Samples above threshold: 70\n",
      "Acquired samples: 70\n",
      "Sampling duration: 6.670581579208374 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4749, Accuracy: 0.846, F1 Micro: 0.9113, F1 Macro: 0.9059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3325, Accuracy: 0.9243, F1 Micro: 0.9541, F1 Macro: 0.9504\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2324, Accuracy: 0.9429, F1 Micro: 0.9651, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1762, Accuracy: 0.951, F1 Micro: 0.9699, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1518, Accuracy: 0.9545, F1 Micro: 0.972, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1253, Accuracy: 0.9578, F1 Micro: 0.974, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1065, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9733\n",
      "Epoch 8/10, Train Loss: 0.0872, Accuracy: 0.9589, F1 Micro: 0.9745, F1 Macro: 0.9721\n",
      "Epoch 9/10, Train Loss: 0.0754, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0671, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9734\n",
      "\n",
      "Aspect detection accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.93       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.408, Accuracy: 0.8601, F1 Micro: 0.8601, F1 Macro: 0.813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2388, Accuracy: 0.8815, F1 Micro: 0.8815, F1 Macro: 0.8434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1525, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8829\n",
      "Epoch 4/10, Train Loss: 0.1158, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8795\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.082, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8837\n",
      "Epoch 6/10, Train Loss: 0.0617, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.8719\n",
      "Epoch 7/10, Train Loss: 0.0456, Accuracy: 0.9002, F1 Micro: 0.9002, F1 Macro: 0.8737\n",
      "Epoch 8/10, Train Loss: 0.0474, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.88\n",
      "Epoch 9/10, Train Loss: 0.0225, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.878\n",
      "Epoch 10/10, Train Loss: 0.0319, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8794\n",
      "\n",
      "Sentiment analysis accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8837\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       759\n",
      "    positive       0.94      0.74      0.83       313\n",
      "\n",
      "    accuracy                           0.91      1072\n",
      "   macro avg       0.92      0.86      0.88      1072\n",
      "weighted avg       0.91      0.91      0.91      1072\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.8633\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.82      0.84       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.81      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88       200\n",
      "     neutral       0.93      0.94      0.93       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       1.00      0.27      0.43        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.92      0.68      0.73       571\n",
      "weighted avg       0.90      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86        85\n",
      "     neutral       0.96      0.97      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 306.9553964138031 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.007163190841674805\n",
      "Samples above threshold: 63\n",
      "Acquired samples: 52\n",
      "Sampling duration: 6.083849668502808 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4766, Accuracy: 0.849, F1 Micro: 0.912, F1 Macro: 0.9044\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3176, Accuracy: 0.9253, F1 Micro: 0.9549, F1 Macro: 0.952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2185, Accuracy: 0.945, F1 Micro: 0.9663, F1 Macro: 0.9639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1741, Accuracy: 0.9549, F1 Micro: 0.9722, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1426, Accuracy: 0.9557, F1 Micro: 0.9727, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1195, Accuracy: 0.9601, F1 Micro: 0.9752, F1 Macro: 0.9726\n",
      "Epoch 7/10, Train Loss: 0.1009, Accuracy: 0.9571, F1 Micro: 0.9736, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0887, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0721, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9742\n",
      "Epoch 10/10, Train Loss: 0.0629, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9741\n",
      "\n",
      "Aspect detection accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4112, Accuracy: 0.8592, F1 Micro: 0.8592, F1 Macro: 0.8108\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2532, Accuracy: 0.8813, F1 Micro: 0.8813, F1 Macro: 0.8447\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1816, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1257, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.099, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8843\n",
      "Epoch 6/10, Train Loss: 0.0841, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8792\n",
      "Epoch 7/10, Train Loss: 0.0525, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8801\n",
      "Epoch 8/10, Train Loss: 0.0432, Accuracy: 0.9034, F1 Micro: 0.9034, F1 Macro: 0.8761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0379, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.889\n",
      "Epoch 10/10, Train Loss: 0.0348, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.874\n",
      "\n",
      "Sentiment analysis accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94       768\n",
      "    positive       0.90      0.78      0.84       319\n",
      "\n",
      "    accuracy                           0.91      1087\n",
      "   macro avg       0.91      0.87      0.89      1087\n",
      "weighted avg       0.91      0.91      0.91      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9555, F1 Micro: 0.9555, F1 Macro: 0.8576\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.97      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.86      0.90        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.85      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.81      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.82      0.93      0.86       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.76      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.58      0.59       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.81      0.96      0.88        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.93      0.90       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.85       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.74      0.79       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.80      0.86        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.89      0.91      0.90        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.90      0.91       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.68      0.88      0.77        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.79       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 317.27802205085754 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.00665593147277832\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 58\n",
      "Sampling duration: 5.8438849449157715 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.476, Accuracy: 0.8432, F1 Micro: 0.9104, F1 Macro: 0.9059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3142, Accuracy: 0.9285, F1 Micro: 0.9567, F1 Macro: 0.9538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2193, Accuracy: 0.9455, F1 Micro: 0.9666, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.168, Accuracy: 0.9533, F1 Micro: 0.9712, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1395, Accuracy: 0.9594, F1 Micro: 0.9748, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1141, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9725\n",
      "Epoch 7/10, Train Loss: 0.1007, Accuracy: 0.9575, F1 Micro: 0.9736, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0827, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0716, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9745\n",
      "Epoch 10/10, Train Loss: 0.0595, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.974\n",
      "\n",
      "Aspect detection accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4087, Accuracy: 0.8532, F1 Micro: 0.8532, F1 Macro: 0.8047\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2385, Accuracy: 0.8848, F1 Micro: 0.8848, F1 Macro: 0.846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1682, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1057, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0874, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.076, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8874\n",
      "Epoch 7/10, Train Loss: 0.0569, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0453, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.034, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0221, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8893\n",
      "\n",
      "Sentiment analysis accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       766\n",
      "    positive       0.95      0.75      0.84       310\n",
      "\n",
      "    accuracy                           0.92      1076\n",
      "   macro avg       0.93      0.86      0.89      1076\n",
      "weighted avg       0.92      0.92      0.91      1076\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9566, F1 Micro: 0.9566, F1 Macro: 0.8752\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.76      0.80        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.82      0.66      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.59      0.65       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.76      0.81       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.78      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 330.4486720561981 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.006416893005371094\n",
      "Samples above threshold: 52\n",
      "Acquired samples: 52\n",
      "Sampling duration: 5.558233976364136 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4742, Accuracy: 0.8531, F1 Micro: 0.9148, F1 Macro: 0.9089\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3133, Accuracy: 0.9318, F1 Micro: 0.9586, F1 Macro: 0.956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2123, Accuracy: 0.9458, F1 Micro: 0.9668, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1706, Accuracy: 0.9517, F1 Micro: 0.9704, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1367, Accuracy: 0.958, F1 Micro: 0.974, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1161, Accuracy: 0.9587, F1 Micro: 0.9744, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1017, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0825, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0713, Accuracy: 0.9637, F1 Micro: 0.9776, F1 Macro: 0.9756\n",
      "Epoch 10/10, Train Loss: 0.0606, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9637, F1 Micro: 0.9776, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.92      0.96      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.99      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.99      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4032, Accuracy: 0.865, F1 Micro: 0.865, F1 Macro: 0.8072\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2298, Accuracy: 0.9002, F1 Micro: 0.9002, F1 Macro: 0.8643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1439, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1083, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.8915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0737, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.8948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0483, Accuracy: 0.9268, F1 Micro: 0.9268, F1 Macro: 0.903\n",
      "Epoch 7/10, Train Loss: 0.0518, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.8927\n",
      "Epoch 8/10, Train Loss: 0.0386, Accuracy: 0.923, F1 Micro: 0.923, F1 Macro: 0.899\n",
      "Epoch 9/10, Train Loss: 0.0275, Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.8981\n",
      "Epoch 10/10, Train Loss: 0.0203, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.893\n",
      "\n",
      "Sentiment analysis accuracy: 0.9268, F1 Micro: 0.9268, F1 Macro: 0.903\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       760\n",
      "    positive       0.95      0.78      0.85       292\n",
      "\n",
      "    accuracy                           0.93      1052\n",
      "   macro avg       0.93      0.88      0.90      1052\n",
      "weighted avg       0.93      0.93      0.92      1052\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.8695\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.86      0.90        86\n",
      "     neutral       0.97      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.79      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.84      0.88       200\n",
      "     neutral       0.92      0.96      0.94       315\n",
      "    positive       0.87      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.91      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.95      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.91      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 331.74056029319763 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.006216883659362793\n",
      "Samples above threshold: 47\n",
      "Acquired samples: 50\n",
      "Sampling duration: 4.899562835693359 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4687, Accuracy: 0.8571, F1 Micro: 0.9171, F1 Macro: 0.9113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3059, Accuracy: 0.9316, F1 Micro: 0.9584, F1 Macro: 0.9562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2061, Accuracy: 0.9472, F1 Micro: 0.9676, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1608, Accuracy: 0.9533, F1 Micro: 0.9713, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1368, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1148, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.094, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0824, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0669, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0574, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.95      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3768, Accuracy: 0.8591, F1 Micro: 0.8591, F1 Macro: 0.8093\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2435, Accuracy: 0.8978, F1 Micro: 0.8978, F1 Macro: 0.8684\n",
      "Epoch 3/10, Train Loss: 0.1625, Accuracy: 0.8969, F1 Micro: 0.8969, F1 Macro: 0.863\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1259, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.872\n",
      "Epoch 5/10, Train Loss: 0.0901, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0638, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0656, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.039, Accuracy: 0.9162, F1 Micro: 0.9162, F1 Macro: 0.8904\n",
      "Epoch 9/10, Train Loss: 0.0324, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8829\n",
      "Epoch 10/10, Train Loss: 0.0206, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8861\n",
      "\n",
      "Sentiment analysis accuracy: 0.9162, F1 Micro: 0.9162, F1 Macro: 0.8904\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       773\n",
      "    positive       0.95      0.75      0.84       313\n",
      "\n",
      "    accuracy                           0.92      1086\n",
      "   macro avg       0.93      0.87      0.89      1086\n",
      "weighted avg       0.92      0.92      0.91      1086\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9592, F1 Micro: 0.9592, F1 Macro: 0.8711\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.97      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.78      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.88      0.74      0.80        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.62      0.67       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.87       162\n",
      "     neutral       0.95      0.96      0.96       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.78      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.94      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.69      0.74        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 343.63078117370605 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.005152702331542969\n",
      "Samples above threshold: 42\n",
      "Acquired samples: 50\n",
      "Sampling duration: 4.71493935585022 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4666, Accuracy: 0.8665, F1 Micro: 0.9224, F1 Macro: 0.9176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.291, Accuracy: 0.9361, F1 Micro: 0.9611, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2024, Accuracy: 0.9481, F1 Micro: 0.9682, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1602, Accuracy: 0.9543, F1 Micro: 0.9718, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1305, Accuracy: 0.9563, F1 Micro: 0.973, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1119, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0939, Accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9746\n",
      "Epoch 8/10, Train Loss: 0.0804, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9746\n",
      "Epoch 9/10, Train Loss: 0.0638, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9745\n",
      "Epoch 10/10, Train Loss: 0.0526, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.91      0.93       317\n",
      "       linen       0.95      0.95      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3994, Accuracy: 0.8419, F1 Micro: 0.8419, F1 Macro: 0.8125\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.237, Accuracy: 0.8863, F1 Micro: 0.8863, F1 Macro: 0.8564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1772, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.8665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1203, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.8688\n",
      "Epoch 5/10, Train Loss: 0.0924, Accuracy: 0.8908, F1 Micro: 0.8908, F1 Macro: 0.8613\n",
      "Epoch 6/10, Train Loss: 0.0913, Accuracy: 0.8908, F1 Micro: 0.8908, F1 Macro: 0.8595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0689, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8689\n",
      "Epoch 8/10, Train Loss: 0.0526, Accuracy: 0.8961, F1 Micro: 0.8961, F1 Macro: 0.8675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0482, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0226, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8745\n",
      "\n",
      "Sentiment analysis accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       789\n",
      "    positive       0.94      0.72      0.82       337\n",
      "\n",
      "    accuracy                           0.90      1126\n",
      "   macro avg       0.91      0.85      0.87      1126\n",
      "weighted avg       0.91      0.90      0.90      1126\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9574, F1 Micro: 0.9574, F1 Macro: 0.8736\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.98      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.82      0.69      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.76      0.60      0.65       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.90      0.88       200\n",
      "     neutral       0.94      0.91      0.93       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.90      0.88       162\n",
      "     neutral       0.95      0.96      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.77      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.82      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 345.57713532447815 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.010210514068603516\n",
      "Samples above threshold: 37\n",
      "Acquired samples: 50\n",
      "Sampling duration: 4.2890143394470215 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4573, Accuracy: 0.8745, F1 Micro: 0.9256, F1 Macro: 0.9185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2921, Accuracy: 0.9304, F1 Micro: 0.9578, F1 Macro: 0.9552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2073, Accuracy: 0.9488, F1 Micro: 0.9686, F1 Macro: 0.9664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.161, Accuracy: 0.9543, F1 Micro: 0.9719, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1284, Accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9723\n",
      "Epoch 6/10, Train Loss: 0.1098, Accuracy: 0.9587, F1 Micro: 0.9744, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.092, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9746\n",
      "Epoch 8/10, Train Loss: 0.0756, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.0654, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9744\n",
      "Epoch 10/10, Train Loss: 0.0557, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.93      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3905, Accuracy: 0.8583, F1 Micro: 0.8583, F1 Macro: 0.8108\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2136, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8785\n",
      "Epoch 3/10, Train Loss: 0.1596, Accuracy: 0.8979, F1 Micro: 0.8979, F1 Macro: 0.8651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0987, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8814\n",
      "Epoch 5/10, Train Loss: 0.0846, Accuracy: 0.8979, F1 Micro: 0.8979, F1 Macro: 0.8721\n",
      "Epoch 6/10, Train Loss: 0.0651, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0426, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8861\n",
      "Epoch 8/10, Train Loss: 0.0384, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.8756\n",
      "Epoch 9/10, Train Loss: 0.0277, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8776\n",
      "Epoch 10/10, Train Loss: 0.0318, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.871\n",
      "\n",
      "Sentiment analysis accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       769\n",
      "    positive       0.94      0.75      0.83       318\n",
      "\n",
      "    accuracy                           0.91      1087\n",
      "   macro avg       0.92      0.86      0.89      1087\n",
      "weighted avg       0.91      0.91      0.91      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9564, F1 Micro: 0.9564, F1 Macro: 0.8581\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.82      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.83      0.71      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.86      0.27      0.41        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.70      0.74       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.88      0.77      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 343.83166313171387 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.007665097713470459\n",
      "Samples above threshold: 32\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.680941343307495 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4666, Accuracy: 0.8698, F1 Micro: 0.9234, F1 Macro: 0.9168\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2944, Accuracy: 0.9319, F1 Micro: 0.9585, F1 Macro: 0.9556\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2014, Accuracy: 0.9472, F1 Micro: 0.9677, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1528, Accuracy: 0.9547, F1 Micro: 0.972, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1297, Accuracy: 0.9578, F1 Micro: 0.974, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1084, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0911, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0756, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9751\n",
      "Epoch 9/10, Train Loss: 0.0647, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0552, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.38, Accuracy: 0.8638, F1 Micro: 0.8638, F1 Macro: 0.814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2106, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1449, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1175, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8829\n",
      "Epoch 5/10, Train Loss: 0.0701, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0484, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8861\n",
      "Epoch 7/10, Train Loss: 0.0463, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8737\n",
      "Epoch 8/10, Train Loss: 0.0325, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8858\n",
      "Epoch 9/10, Train Loss: 0.0356, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.885\n",
      "Epoch 10/10, Train Loss: 0.023, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.876\n",
      "\n",
      "Sentiment analysis accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       771\n",
      "    positive       0.95      0.74      0.83       308\n",
      "\n",
      "    accuracy                           0.91      1079\n",
      "   macro avg       0.93      0.86      0.89      1079\n",
      "weighted avg       0.92      0.91      0.91      1079\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9574, F1 Micro: 0.9574, F1 Macro: 0.8674\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.65      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.93      0.59      0.65       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       1.00      0.27      0.43        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.69      0.74       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.84      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.55      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.77      0.80       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 357.6324338912964 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.004488587379455566\n",
      "Samples above threshold: 29\n",
      "Acquired samples: 50\n",
      "Sampling duration: 3.4872829914093018 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.446, Accuracy: 0.8786, F1 Micro: 0.9283, F1 Macro: 0.922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2777, Accuracy: 0.9335, F1 Micro: 0.9596, F1 Macro: 0.9573\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1942, Accuracy: 0.946, F1 Micro: 0.9669, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1535, Accuracy: 0.9561, F1 Micro: 0.9728, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1247, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1062, Accuracy: 0.9608, F1 Micro: 0.9756, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0866, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0752, Accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0631, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.976\n",
      "Epoch 10/10, Train Loss: 0.055, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.95      0.91      0.93       317\n",
      "       linen       0.94      0.97      0.96       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3932, Accuracy: 0.8578, F1 Micro: 0.8578, F1 Macro: 0.8073\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2093, Accuracy: 0.885, F1 Micro: 0.885, F1 Macro: 0.8449\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1467, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.118, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8888\n",
      "Epoch 5/10, Train Loss: 0.0643, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8865\n",
      "Epoch 6/10, Train Loss: 0.0621, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8844\n",
      "Epoch 7/10, Train Loss: 0.0391, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8805\n",
      "Epoch 8/10, Train Loss: 0.0322, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8846\n",
      "Epoch 9/10, Train Loss: 0.0275, Accuracy: 0.904, F1 Micro: 0.904, F1 Macro: 0.8752\n",
      "Epoch 10/10, Train Loss: 0.0264, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8739\n",
      "\n",
      "Sentiment analysis accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       783\n",
      "    positive       0.94      0.75      0.84       321\n",
      "\n",
      "    accuracy                           0.91      1104\n",
      "   macro avg       0.92      0.87      0.89      1104\n",
      "weighted avg       0.92      0.91      0.91      1104\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9594, F1 Micro: 0.9594, F1 Macro: 0.8758\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.98      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.91      0.89       200\n",
      "     neutral       0.95      0.91      0.93       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88       162\n",
      "     neutral       0.94      0.98      0.96       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.88      0.78      0.82       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.84      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.84      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 359.3728175163269 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.006547331809997559\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 50\n",
      "Sampling duration: 3.061103582382202 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4542, Accuracy: 0.8717, F1 Micro: 0.925, F1 Macro: 0.9206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2799, Accuracy: 0.9337, F1 Micro: 0.9597, F1 Macro: 0.957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1957, Accuracy: 0.9507, F1 Micro: 0.9697, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1533, Accuracy: 0.9568, F1 Micro: 0.9733, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1278, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1061, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9744\n",
      "Epoch 7/10, Train Loss: 0.0889, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0724, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.0629, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0512, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3619, Accuracy: 0.8608, F1 Micro: 0.8608, F1 Macro: 0.821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1997, Accuracy: 0.8944, F1 Micro: 0.8944, F1 Macro: 0.8629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1384, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1046, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0743, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8875\n",
      "Epoch 6/10, Train Loss: 0.0643, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0406, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8863\n",
      "Epoch 8/10, Train Loss: 0.0309, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8795\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0365, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0289, Accuracy: 0.9172, F1 Micro: 0.9172, F1 Macro: 0.8933\n",
      "\n",
      "Sentiment analysis accuracy: 0.9172, F1 Micro: 0.9172, F1 Macro: 0.8933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       777\n",
      "    positive       0.95      0.76      0.84       322\n",
      "\n",
      "    accuracy                           0.92      1099\n",
      "   macro avg       0.93      0.87      0.89      1099\n",
      "weighted avg       0.92      0.92      0.91      1099\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.8858\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.83      0.74      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.71      0.62      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.88       200\n",
      "     neutral       0.92      0.94      0.93       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.94      0.76      0.81       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89        85\n",
      "     neutral       0.98      0.97      0.98       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 369.8879222869873 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0038515031337738037\n",
      "Samples above threshold: 19\n",
      "Acquired samples: 50\n",
      "Sampling duration: 2.7816977500915527 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4449, Accuracy: 0.8707, F1 Micro: 0.924, F1 Macro: 0.9183\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2664, Accuracy: 0.9352, F1 Micro: 0.9607, F1 Macro: 0.9585\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1933, Accuracy: 0.9472, F1 Micro: 0.9676, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1514, Accuracy: 0.9597, F1 Micro: 0.975, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1271, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0988, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0826, Accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9766\n",
      "Epoch 8/10, Train Loss: 0.0712, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9761\n",
      "Epoch 9/10, Train Loss: 0.06, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.05, Accuracy: 0.9663, F1 Micro: 0.979, F1 Macro: 0.9771\n",
      "\n",
      "Aspect detection accuracy: 0.9663, F1 Micro: 0.979, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.97      0.97       500\n",
      "  kebersihan       0.96      0.92      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.98      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3762, Accuracy: 0.867, F1 Micro: 0.867, F1 Macro: 0.829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.182, Accuracy: 0.8994, F1 Micro: 0.8994, F1 Macro: 0.8735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.135, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0863, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8878\n",
      "Epoch 5/10, Train Loss: 0.0638, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0461, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8917\n",
      "Epoch 7/10, Train Loss: 0.0366, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8883\n",
      "Epoch 8/10, Train Loss: 0.0311, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8842\n",
      "Epoch 9/10, Train Loss: 0.0157, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8857\n",
      "Epoch 10/10, Train Loss: 0.0289, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8855\n",
      "\n",
      "Sentiment analysis accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8917\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.99      0.94       787\n",
      "    positive       0.96      0.75      0.84       326\n",
      "\n",
      "    accuracy                           0.92      1113\n",
      "   macro avg       0.93      0.87      0.89      1113\n",
      "weighted avg       0.92      0.92      0.91      1113\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.8807\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.81      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.97      0.97       496\n",
      "    positive       0.76      0.76      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.63      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.92      0.90       200\n",
      "     neutral       0.96      0.92      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.92      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       1.00      0.36      0.53        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.94      0.74      0.79       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.84      0.87       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 373.4759783744812 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0038592517375946045\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 50\n",
      "Sampling duration: 2.366440773010254 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4367, Accuracy: 0.8818, F1 Micro: 0.9302, F1 Macro: 0.9249\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2636, Accuracy: 0.9384, F1 Micro: 0.9623, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1864, Accuracy: 0.9465, F1 Micro: 0.9672, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.151, Accuracy: 0.9536, F1 Micro: 0.9714, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1245, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9753\n",
      "Epoch 6/10, Train Loss: 0.1017, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "Epoch 7/10, Train Loss: 0.0839, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "Epoch 8/10, Train Loss: 0.0694, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0589, Accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.9768\n",
      "Epoch 10/10, Train Loss: 0.0478, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.95      0.95      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3633, Accuracy: 0.87, F1 Micro: 0.87, F1 Macro: 0.8305\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2129, Accuracy: 0.8982, F1 Micro: 0.8982, F1 Macro: 0.8659\n",
      "Epoch 3/10, Train Loss: 0.1392, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.8635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1104, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0811, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8879\n",
      "Epoch 6/10, Train Loss: 0.0624, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8876\n",
      "Epoch 7/10, Train Loss: 0.0429, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.8796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0463, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8923\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0353, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8916\n",
      "Epoch 10/10, Train Loss: 0.0205, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8853\n",
      "\n",
      "Sentiment analysis accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8916\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       786\n",
      "    positive       0.93      0.77      0.84       314\n",
      "\n",
      "    accuracy                           0.92      1100\n",
      "   macro avg       0.92      0.87      0.89      1100\n",
      "weighted avg       0.92      0.92      0.91      1100\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.8829\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.88      0.92        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.71      1.00      0.83        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.96      0.91       571\n",
      "weighted avg       0.98      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.90      0.93        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.78      0.70      0.74        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.86      0.89       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.77      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.29      0.40         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.82      0.66      0.71       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.87      0.89       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.83      0.98      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.90      0.87       162\n",
      "     neutral       0.95      0.95      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.75      0.79       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.69      0.78        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.86      0.89       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 374.0178747177124 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0038017332553863525\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 50\n",
      "Sampling duration: 2.035715103149414 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.439, Accuracy: 0.879, F1 Micro: 0.9286, F1 Macro: 0.9229\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2644, Accuracy: 0.9332, F1 Micro: 0.9594, F1 Macro: 0.9571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1943, Accuracy: 0.9457, F1 Micro: 0.9668, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1462, Accuracy: 0.9568, F1 Micro: 0.9734, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1184, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1005, Accuracy: 0.9618, F1 Micro: 0.9764, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0807, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0671, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9767\n",
      "Epoch 9/10, Train Loss: 0.0568, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9752\n",
      "Epoch 10/10, Train Loss: 0.0466, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3491, Accuracy: 0.8578, F1 Micro: 0.8578, F1 Macro: 0.8049\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2007, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.134, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8781\n",
      "Epoch 4/10, Train Loss: 0.1007, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0695, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0685, Accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.8896\n",
      "Epoch 7/10, Train Loss: 0.0447, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.88\n",
      "Epoch 8/10, Train Loss: 0.0331, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8852\n",
      "Epoch 9/10, Train Loss: 0.0277, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8838\n",
      "Epoch 10/10, Train Loss: 0.0294, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8878\n",
      "\n",
      "Sentiment analysis accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.8896\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       781\n",
      "    positive       0.95      0.75      0.84       323\n",
      "\n",
      "    accuracy                           0.91      1104\n",
      "   macro avg       0.93      0.87      0.89      1104\n",
      "weighted avg       0.92      0.91      0.91      1104\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.882\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.97      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.79      0.82        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.69      0.74       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.91      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       162\n",
      "     neutral       0.93      0.98      0.95       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.75      0.80       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.87      0.87        85\n",
      "     neutral       0.98      0.97      0.98       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.89      0.75      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 382.91479659080505 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.004463851451873779\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 36\n",
      "Sampling duration: 1.57688570022583 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4397, Accuracy: 0.8802, F1 Micro: 0.9292, F1 Macro: 0.9236\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2563, Accuracy: 0.937, F1 Micro: 0.9616, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1848, Accuracy: 0.9516, F1 Micro: 0.9702, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1464, Accuracy: 0.9528, F1 Micro: 0.971, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1169, Accuracy: 0.9589, F1 Micro: 0.9745, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.097, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Epoch 7/10, Train Loss: 0.0791, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9737\n",
      "Epoch 8/10, Train Loss: 0.0699, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0593, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0463, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3584, Accuracy: 0.8552, F1 Micro: 0.8552, F1 Macro: 0.7983\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1871, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8765\n",
      "Epoch 3/10, Train Loss: 0.1426, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0925, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8886\n",
      "Epoch 5/10, Train Loss: 0.0567, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8804\n",
      "Epoch 6/10, Train Loss: 0.0617, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8836\n",
      "Epoch 7/10, Train Loss: 0.0465, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8828\n",
      "Epoch 8/10, Train Loss: 0.0355, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8847\n",
      "Epoch 9/10, Train Loss: 0.0221, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0251, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8889\n",
      "\n",
      "Sentiment analysis accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       782\n",
      "    positive       0.93      0.76      0.84       316\n",
      "\n",
      "    accuracy                           0.91      1098\n",
      "   macro avg       0.92      0.87      0.89      1098\n",
      "weighted avg       0.92      0.91      0.91      1098\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9592, F1 Micro: 0.9592, F1 Macro: 0.8811\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.82      0.69      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.60      0.66       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.76      0.59      0.67        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.84      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.91      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 387.38726472854614 s\n",
      "Total runtime: 7905.870037317276 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6936a4",
   "metadata": {
    "papermill": {
     "duration": 0.186932,
     "end_time": "2025-03-29T17:11:24.708600",
     "exception": false,
     "start_time": "2025-03-29T17:11:24.521668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9ccdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6072, Accuracy: 0.7955, F1 Micro: 0.8818, F1 Macro: 0.8546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4916, Accuracy: 0.8016, F1 Micro: 0.8877, F1 Macro: 0.8774\n",
      "Epoch 3/10, Train Loss: 0.453, Accuracy: 0.8024, F1 Micro: 0.8857, F1 Macro: 0.8609\n",
      "Epoch 4/10, Train Loss: 0.4515, Accuracy: 0.8021, F1 Micro: 0.8849, F1 Macro: 0.8543\n",
      "Epoch 5/10, Train Loss: 0.417, Accuracy: 0.8047, F1 Micro: 0.8868, F1 Macro: 0.862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4402, Accuracy: 0.8092, F1 Micro: 0.8902, F1 Macro: 0.874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3799, Accuracy: 0.8141, F1 Micro: 0.8937, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3851, Accuracy: 0.8252, F1 Micro: 0.899, F1 Macro: 0.8873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3532, Accuracy: 0.8361, F1 Micro: 0.9044, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3254, Accuracy: 0.8502, F1 Micro: 0.9121, F1 Macro: 0.9018\n",
      "\n",
      "Aspect detection accuracy: 0.8502, F1 Micro: 0.9121, F1 Macro: 0.9018\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.86      1.00      0.93       462\n",
      "   air_panas       0.90      0.99      0.94       480\n",
      "         bau       0.87      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.77      0.66      0.71       317\n",
      "       linen       0.74      0.98      0.84       392\n",
      "     service       0.82      0.98      0.89       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.89      1.00      0.94       498\n",
      "\n",
      "   micro avg       0.86      0.97      0.91      4614\n",
      "   macro avg       0.85      0.96      0.90      4614\n",
      "weighted avg       0.86      0.97      0.91      4614\n",
      " samples avg       0.86      0.97      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5988, Accuracy: 0.6204, F1 Micro: 0.6204, F1 Macro: 0.3829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5281, Accuracy: 0.6204, F1 Micro: 0.6204, F1 Macro: 0.3829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4888, Accuracy: 0.6259, F1 Micro: 0.6259, F1 Macro: 0.4027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3707, Accuracy: 0.6861, F1 Micro: 0.6861, F1 Macro: 0.5752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3492, Accuracy: 0.7336, F1 Micro: 0.7336, F1 Macro: 0.6917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2739, Accuracy: 0.7372, F1 Micro: 0.7372, F1 Macro: 0.7005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3739, Accuracy: 0.7409, F1 Micro: 0.7409, F1 Macro: 0.7103\n",
      "Epoch 8/10, Train Loss: 0.2974, Accuracy: 0.7281, F1 Micro: 0.7281, F1 Macro: 0.6718\n",
      "Epoch 9/10, Train Loss: 0.18, Accuracy: 0.7372, F1 Micro: 0.7372, F1 Macro: 0.703\n",
      "Epoch 10/10, Train Loss: 0.1429, Accuracy: 0.7281, F1 Micro: 0.7281, F1 Macro: 0.6706\n",
      "\n",
      "Sentiment analysis accuracy: 0.7409, F1 Micro: 0.7409, F1 Macro: 0.7103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.86      0.80       340\n",
      "    positive       0.70      0.55      0.62       208\n",
      "\n",
      "    accuracy                           0.74       548\n",
      "   macro avg       0.73      0.70      0.71       548\n",
      "weighted avg       0.74      0.74      0.73       548\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8385, F1 Micro: 0.8385, F1 Macro: 0.4347\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.36      0.51        97\n",
      "     neutral       0.87      1.00      0.93       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.58      0.45      0.48       571\n",
      "weighted avg       0.84      0.86      0.83       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.43      0.56        86\n",
      "     neutral       0.90      0.99      0.94       475\n",
      "    positive       0.20      0.10      0.13        10\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.63      0.51      0.54       571\n",
      "weighted avg       0.87      0.89      0.87       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.12      0.20        78\n",
      "     neutral       0.87      1.00      0.93       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.59      0.37      0.38       571\n",
      "weighted avg       0.87      0.87      0.83       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.65      0.65       200\n",
      "     neutral       0.77      0.66      0.71       315\n",
      "    positive       0.26      0.48      0.34        56\n",
      "\n",
      "    accuracy                           0.64       571\n",
      "   macro avg       0.56      0.60      0.57       571\n",
      "weighted avg       0.68      0.64      0.65       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.30      0.44       162\n",
      "     neutral       0.74      0.98      0.84       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.75       571\n",
      "   macro avg       0.53      0.43      0.43       571\n",
      "weighted avg       0.74      0.75      0.70       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.18      0.29        85\n",
      "     neutral       0.81      0.98      0.89       418\n",
      "    positive       0.60      0.44      0.51        68\n",
      "\n",
      "    accuracy                           0.80       571\n",
      "   macro avg       0.77      0.53      0.56       571\n",
      "weighted avg       0.80      0.80      0.76       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.24      0.39        74\n",
      "     neutral       0.89      1.00      0.94       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.61      0.41      0.44       571\n",
      "weighted avg       0.90      0.89      0.87       571\n",
      "\n",
      "Total train time: 80.47178912162781 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.928224503993988\n",
      "Samples above threshold: 215\n",
      "Acquired samples: 215\n",
      "Sampling duration: 12.789677143096924 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5377, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4504, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.438, Accuracy: 0.8068, F1 Micro: 0.8923, F1 Macro: 0.8879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4025, Accuracy: 0.8444, F1 Micro: 0.9099, F1 Macro: 0.9027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3454, Accuracy: 0.8729, F1 Micro: 0.9244, F1 Macro: 0.9154\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3041, Accuracy: 0.8917, F1 Micro: 0.9346, F1 Macro: 0.925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.259, Accuracy: 0.909, F1 Micro: 0.9446, F1 Macro: 0.9379\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.218, Accuracy: 0.9186, F1 Micro: 0.9504, F1 Macro: 0.945\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2053, Accuracy: 0.9248, F1 Micro: 0.9543, F1 Macro: 0.9501\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1766, Accuracy: 0.9304, F1 Micro: 0.9574, F1 Macro: 0.9536\n",
      "\n",
      "Aspect detection accuracy: 0.9304, F1 Micro: 0.9574, F1 Macro: 0.9536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.96      0.98      0.97       480\n",
      "         bau       0.93      0.99      0.96       496\n",
      "     general       0.88      0.98      0.93       500\n",
      "  kebersihan       0.87      0.86      0.87       317\n",
      "       linen       0.88      0.96      0.92       392\n",
      "     service       0.94      0.96      0.95       423\n",
      "sunrise_meal       0.94      1.00      0.97       530\n",
      "          tv       0.98      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      4614\n",
      "   macro avg       0.94      0.97      0.95      4614\n",
      "weighted avg       0.94      0.98      0.96      4614\n",
      " samples avg       0.94      0.98      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4924, Accuracy: 0.7202, F1 Micro: 0.7202, F1 Macro: 0.4187\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3399, Accuracy: 0.7656, F1 Micro: 0.7656, F1 Macro: 0.6193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.298, Accuracy: 0.7835, F1 Micro: 0.7835, F1 Macro: 0.6564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2831, Accuracy: 0.8289, F1 Micro: 0.8289, F1 Macro: 0.7587\n",
      "Epoch 5/10, Train Loss: 0.2194, Accuracy: 0.8194, F1 Micro: 0.8194, F1 Macro: 0.772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1741, Accuracy: 0.83, F1 Micro: 0.83, F1 Macro: 0.755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1713, Accuracy: 0.8416, F1 Micro: 0.8416, F1 Macro: 0.78\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1463, Accuracy: 0.8448, F1 Micro: 0.8448, F1 Macro: 0.777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1282, Accuracy: 0.8501, F1 Micro: 0.8501, F1 Macro: 0.7991\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0893, Accuracy: 0.8522, F1 Micro: 0.8522, F1 Macro: 0.8068\n",
      "\n",
      "Sentiment analysis accuracy: 0.8522, F1 Micro: 0.8522, F1 Macro: 0.8068\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90       682\n",
      "    positive       0.78      0.66      0.71       265\n",
      "\n",
      "    accuracy                           0.85       947\n",
      "   macro avg       0.83      0.79      0.81       947\n",
      "weighted avg       0.85      0.85      0.85       947\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.6851\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.91      0.67      0.77        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.87      0.90       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.77      0.81        86\n",
      "     neutral       0.96      0.98      0.97       475\n",
      "    positive       0.50      0.50      0.50        10\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.78      0.75      0.76       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.58      0.69        78\n",
      "     neutral       0.93      0.99      0.96       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.52      0.55       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.88      0.98      0.93       496\n",
      "    positive       0.43      0.09      0.15        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.43      0.36      0.36       571\n",
      "weighted avg       0.81      0.87      0.82       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.71      0.77       200\n",
      "     neutral       0.87      0.86      0.87       315\n",
      "    positive       0.56      0.88      0.68        56\n",
      "\n",
      "    accuracy                           0.81       571\n",
      "   macro avg       0.75      0.82      0.77       571\n",
      "weighted avg       0.83      0.81      0.82       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.76      0.80       162\n",
      "     neutral       0.88      0.96      0.92       387\n",
      "    positive       1.00      0.05      0.09        22\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.91      0.59      0.60       571\n",
      "weighted avg       0.87      0.87      0.85       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.56      0.67        85\n",
      "     neutral       0.94      0.97      0.95       418\n",
      "    positive       0.70      0.84      0.76        68\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.82      0.79      0.79       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.10      0.19        29\n",
      "     neutral       0.94      1.00      0.97       525\n",
      "    positive       0.75      0.53      0.62        17\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.54      0.59       571\n",
      "weighted avg       0.94      0.94      0.92       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.87      0.90        54\n",
      "     neutral       0.98      1.00      0.99       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.63      0.62      0.63       571\n",
      "weighted avg       0.96      0.97      0.97       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.85      0.97      0.89       571\n",
      "weighted avg       0.99      0.98      0.98       571\n",
      "\n",
      "Total train time: 130.76731991767883 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.06826463341712952\n",
      "Samples above threshold: 193\n",
      "Acquired samples: 193\n",
      "Sampling duration: 16.83437752723694 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5089, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4314, Accuracy: 0.8073, F1 Micro: 0.8924, F1 Macro: 0.8874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3973, Accuracy: 0.8457, F1 Micro: 0.9109, F1 Macro: 0.9053\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3297, Accuracy: 0.875, F1 Micro: 0.9262, F1 Macro: 0.9197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2751, Accuracy: 0.9184, F1 Micro: 0.9504, F1 Macro: 0.9453\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2305, Accuracy: 0.9312, F1 Micro: 0.958, F1 Macro: 0.9542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1993, Accuracy: 0.9368, F1 Micro: 0.9614, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1631, Accuracy: 0.9411, F1 Micro: 0.9639, F1 Macro: 0.9614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.143, Accuracy: 0.9429, F1 Micro: 0.9649, F1 Macro: 0.9624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1232, Accuracy: 0.949, F1 Micro: 0.9684, F1 Macro: 0.9656\n",
      "\n",
      "Aspect detection accuracy: 0.949, F1 Micro: 0.9684, F1 Macro: 0.9656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.98      0.98       480\n",
      "         bau       0.97      0.95      0.96       496\n",
      "     general       0.91      0.98      0.94       500\n",
      "  kebersihan       0.92      0.91      0.91       317\n",
      "       linen       0.89      0.97      0.93       392\n",
      "     service       0.96      0.97      0.96       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.97      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.97      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.475, Accuracy: 0.702, F1 Micro: 0.702, F1 Macro: 0.4125\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3987, Accuracy: 0.8054, F1 Micro: 0.8054, F1 Macro: 0.7507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2785, Accuracy: 0.8166, F1 Micro: 0.8166, F1 Macro: 0.7407\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.201, Accuracy: 0.8436, F1 Micro: 0.8436, F1 Macro: 0.8057\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2077, Accuracy: 0.8547, F1 Micro: 0.8547, F1 Macro: 0.8089\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1498, Accuracy: 0.8594, F1 Micro: 0.8594, F1 Macro: 0.8241\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1038, Accuracy: 0.8669, F1 Micro: 0.8669, F1 Macro: 0.8198\n",
      "Epoch 8/10, Train Loss: 0.0955, Accuracy: 0.8361, F1 Micro: 0.8361, F1 Macro: 0.7653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0853, Accuracy: 0.8678, F1 Micro: 0.8678, F1 Macro: 0.8261\n",
      "Epoch 10/10, Train Loss: 0.0645, Accuracy: 0.8631, F1 Micro: 0.8631, F1 Macro: 0.8302\n",
      "\n",
      "Sentiment analysis accuracy: 0.8678, F1 Micro: 0.8678, F1 Macro: 0.8261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.97      0.91       754\n",
      "    positive       0.89      0.63      0.74       320\n",
      "\n",
      "    accuracy                           0.87      1074\n",
      "   macro avg       0.88      0.80      0.83      1074\n",
      "weighted avg       0.87      0.87      0.86      1074\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.7623\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.86        86\n",
      "     neutral       0.98      0.98      0.98       475\n",
      "    positive       0.45      0.50      0.48        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.76      0.78      0.77       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.82      0.77        78\n",
      "     neutral       0.97      0.95      0.96       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.57      0.59      0.58       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.91      0.98      0.94       496\n",
      "    positive       0.71      0.43      0.53        68\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.54      0.47      0.49       571\n",
      "weighted avg       0.88      0.90      0.88       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85       200\n",
      "     neutral       0.92      0.90      0.91       315\n",
      "    positive       0.82      0.89      0.85        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.86      0.88      0.87       571\n",
      "weighted avg       0.89      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82       162\n",
      "     neutral       0.89      0.97      0.93       387\n",
      "    positive       1.00      0.05      0.09        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.92      0.60      0.61       571\n",
      "weighted avg       0.89      0.88      0.87       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.76      0.81        85\n",
      "     neutral       0.96      0.97      0.97       418\n",
      "    positive       0.85      0.94      0.90        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.89      0.89      0.89       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.45      0.58        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.78      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.71      0.73       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 158.86025738716125 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.041211569309234614\n",
      "Samples above threshold: 174\n",
      "Acquired samples: 174\n",
      "Sampling duration: 16.60048770904541 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5241, Accuracy: 0.8019, F1 Micro: 0.89, F1 Macro: 0.8856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4665, Accuracy: 0.8137, F1 Micro: 0.8951, F1 Macro: 0.8891\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3999, Accuracy: 0.8833, F1 Micro: 0.9307, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3188, Accuracy: 0.9142, F1 Micro: 0.9482, F1 Macro: 0.9437\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2479, Accuracy: 0.9351, F1 Micro: 0.9603, F1 Macro: 0.9569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2101, Accuracy: 0.9406, F1 Micro: 0.9634, F1 Macro: 0.9601\n",
      "Epoch 7/10, Train Loss: 0.1825, Accuracy: 0.9403, F1 Micro: 0.9634, F1 Macro: 0.9604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1619, Accuracy: 0.9446, F1 Micro: 0.9661, F1 Macro: 0.9636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.144, Accuracy: 0.9476, F1 Micro: 0.9678, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1225, Accuracy: 0.9502, F1 Micro: 0.9693, F1 Macro: 0.9671\n",
      "\n",
      "Aspect detection accuracy: 0.9502, F1 Micro: 0.9693, F1 Macro: 0.9671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.96      0.99      0.98       480\n",
      "         bau       0.96      0.97      0.97       496\n",
      "     general       0.91      0.98      0.94       500\n",
      "  kebersihan       0.92      0.92      0.92       317\n",
      "       linen       0.87      0.98      0.92       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.95      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5302, Accuracy: 0.7657, F1 Micro: 0.7657, F1 Macro: 0.5749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3438, Accuracy: 0.8445, F1 Micro: 0.8445, F1 Macro: 0.7793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2557, Accuracy: 0.8504, F1 Micro: 0.8504, F1 Macro: 0.7765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1741, Accuracy: 0.8923, F1 Micro: 0.8923, F1 Macro: 0.8525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.127, Accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.8524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1261, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0809, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8685\n",
      "Epoch 8/10, Train Loss: 0.074, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8638\n",
      "Epoch 9/10, Train Loss: 0.0617, Accuracy: 0.8963, F1 Micro: 0.8963, F1 Macro: 0.8576\n",
      "Epoch 10/10, Train Loss: 0.0788, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8692\n",
      "\n",
      "Sentiment analysis accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8685\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.94       726\n",
      "    positive       0.95      0.69      0.80       277\n",
      "\n",
      "    accuracy                           0.90      1003\n",
      "   macro avg       0.92      0.84      0.87      1003\n",
      "weighted avg       0.91      0.90      0.90      1003\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9441, F1 Micro: 0.9441, F1 Macro: 0.7957\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.80      0.86        86\n",
      "     neutral       0.96      0.99      0.98       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.91      0.77      0.82       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.78      0.80        78\n",
      "     neutral       0.96      0.97      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.59      0.59       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.91      0.98      0.94       496\n",
      "    positive       0.78      0.37      0.50        68\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.56      0.45      0.48       571\n",
      "weighted avg       0.88      0.90      0.88       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.87       200\n",
      "     neutral       0.92      0.92      0.92       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.73      0.80       162\n",
      "     neutral       0.87      0.98      0.92       387\n",
      "    positive       1.00      0.09      0.17        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.92      0.60      0.63       571\n",
      "weighted avg       0.88      0.88      0.86       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.88      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.94      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.41      0.56        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.88      0.73      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.89      0.91        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.97      0.85      0.90       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 180.7818877696991 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.020619952678680425\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 156\n",
      "Sampling duration: 13.596449851989746 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5272, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4536, Accuracy: 0.8609, F1 Micro: 0.9188, F1 Macro: 0.9125\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3496, Accuracy: 0.9137, F1 Micro: 0.9479, F1 Macro: 0.9432\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2636, Accuracy: 0.9352, F1 Micro: 0.9604, F1 Macro: 0.9565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2182, Accuracy: 0.9422, F1 Micro: 0.9647, F1 Macro: 0.9623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1888, Accuracy: 0.9464, F1 Micro: 0.967, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1711, Accuracy: 0.9464, F1 Micro: 0.9671, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1435, Accuracy: 0.9503, F1 Micro: 0.9694, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1266, Accuracy: 0.9507, F1 Micro: 0.9696, F1 Macro: 0.9672\n",
      "Epoch 10/10, Train Loss: 0.1131, Accuracy: 0.9498, F1 Micro: 0.9691, F1 Macro: 0.9668\n",
      "\n",
      "Aspect detection accuracy: 0.9507, F1 Micro: 0.9696, F1 Macro: 0.9672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.97      0.97       496\n",
      "     general       0.90      0.99      0.94       500\n",
      "  kebersihan       0.91      0.92      0.92       317\n",
      "       linen       0.90      0.96      0.93       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5004, Accuracy: 0.8171, F1 Micro: 0.8171, F1 Macro: 0.746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3022, Accuracy: 0.8385, F1 Micro: 0.8385, F1 Macro: 0.7559\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2268, Accuracy: 0.8628, F1 Micro: 0.8628, F1 Macro: 0.7978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1774, Accuracy: 0.893, F1 Micro: 0.893, F1 Macro: 0.8605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1373, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0998, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1003, Accuracy: 0.8998, F1 Micro: 0.8998, F1 Macro: 0.8633\n",
      "Epoch 8/10, Train Loss: 0.0623, Accuracy: 0.8872, F1 Micro: 0.8872, F1 Macro: 0.8405\n",
      "Epoch 9/10, Train Loss: 0.0625, Accuracy: 0.892, F1 Micro: 0.892, F1 Macro: 0.8547\n",
      "Epoch 10/10, Train Loss: 0.0446, Accuracy: 0.8949, F1 Micro: 0.8949, F1 Macro: 0.8584\n",
      "\n",
      "Sentiment analysis accuracy: 0.8998, F1 Micro: 0.8998, F1 Macro: 0.8633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       744\n",
      "    positive       0.92      0.69      0.79       284\n",
      "\n",
      "    accuracy                           0.90      1028\n",
      "   macro avg       0.91      0.84      0.86      1028\n",
      "weighted avg       0.90      0.90      0.89      1028\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9448, F1 Micro: 0.9448, F1 Macro: 0.8143\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.88        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.78      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.76      0.78        78\n",
      "     neutral       0.96      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.74      0.80       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.90      0.99      0.94       496\n",
      "    positive       0.76      0.28      0.41        68\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.55      0.42      0.45       571\n",
      "weighted avg       0.87      0.89      0.87       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.86       200\n",
      "     neutral       0.91      0.92      0.92       315\n",
      "    positive       0.80      0.95      0.87        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.87      0.90      0.88       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.80      0.84       162\n",
      "     neutral       0.90      0.97      0.93       387\n",
      "    positive       0.88      0.32      0.47        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.88      0.70      0.75       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.87      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.95      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.48      0.61        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.75      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.95      0.95        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.87      0.87      0.87       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 208.4218533039093 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.019754672050476076\n",
      "Samples above threshold: 141\n",
      "Acquired samples: 141\n",
      "Sampling duration: 12.188224792480469 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5225, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4374, Accuracy: 0.8712, F1 Micro: 0.9243, F1 Macro: 0.9186\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3132, Accuracy: 0.9267, F1 Micro: 0.9553, F1 Macro: 0.951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2461, Accuracy: 0.9356, F1 Micro: 0.9608, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2039, Accuracy: 0.9464, F1 Micro: 0.9671, F1 Macro: 0.9647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1752, Accuracy: 0.949, F1 Micro: 0.9686, F1 Macro: 0.9666\n",
      "Epoch 7/10, Train Loss: 0.1519, Accuracy: 0.9481, F1 Micro: 0.9682, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1312, Accuracy: 0.9523, F1 Micro: 0.9706, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1132, Accuracy: 0.9538, F1 Micro: 0.9715, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1001, Accuracy: 0.9543, F1 Micro: 0.9719, F1 Macro: 0.9694\n",
      "\n",
      "Aspect detection accuracy: 0.9543, F1 Micro: 0.9719, F1 Macro: 0.9694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.97      0.96      0.97       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.90      0.94      0.92       317\n",
      "       linen       0.89      0.98      0.93       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.99      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.454, Accuracy: 0.8371, F1 Micro: 0.8371, F1 Macro: 0.7764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3238, Accuracy: 0.8736, F1 Micro: 0.8736, F1 Macro: 0.8291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2281, Accuracy: 0.8954, F1 Micro: 0.8954, F1 Macro: 0.8569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1765, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.126, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1012, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0796, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8832\n",
      "Epoch 8/10, Train Loss: 0.0638, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0484, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8879\n",
      "Epoch 10/10, Train Loss: 0.0365, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8635\n",
      "\n",
      "Sentiment analysis accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94       737\n",
      "    positive       0.92      0.76      0.83       276\n",
      "\n",
      "    accuracy                           0.92      1013\n",
      "   macro avg       0.92      0.87      0.89      1013\n",
      "weighted avg       0.92      0.92      0.91      1013\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.8417\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.97      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.81      0.88        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.84      0.85       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.82      0.80        78\n",
      "     neutral       0.97      0.96      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.76      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.95       496\n",
      "    positive       0.91      0.46      0.61        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.61      0.48      0.52       571\n",
      "weighted avg       0.91      0.92      0.90       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.82      0.87       200\n",
      "     neutral       0.90      0.94      0.92       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.90      0.90       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.74      0.83       162\n",
      "     neutral       0.89      0.98      0.93       387\n",
      "    positive       0.54      0.32      0.40        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.79      0.68      0.72       571\n",
      "weighted avg       0.89      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.97      0.88      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.68      0.88      0.77        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.78      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 225.76073670387268 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.012954819202423095\n",
      "Samples above threshold: 127\n",
      "Acquired samples: 127\n",
      "Sampling duration: 11.017511367797852 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5144, Accuracy: 0.8062, F1 Micro: 0.8917, F1 Macro: 0.8863\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3987, Accuracy: 0.8979, F1 Micro: 0.9391, F1 Macro: 0.9337\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.288, Accuracy: 0.9323, F1 Micro: 0.9588, F1 Macro: 0.9555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2259, Accuracy: 0.9405, F1 Micro: 0.9637, F1 Macro: 0.961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1887, Accuracy: 0.9469, F1 Micro: 0.9675, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1633, Accuracy: 0.9512, F1 Micro: 0.9699, F1 Macro: 0.9674\n",
      "Epoch 7/10, Train Loss: 0.1424, Accuracy: 0.9488, F1 Micro: 0.9686, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1143, Accuracy: 0.9561, F1 Micro: 0.9729, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9724\n",
      "Epoch 10/10, Train Loss: 0.0894, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9725\n",
      "\n",
      "Aspect detection accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.91      0.95      0.93       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4657, Accuracy: 0.8559, F1 Micro: 0.8559, F1 Macro: 0.8155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2615, Accuracy: 0.8757, F1 Micro: 0.8757, F1 Macro: 0.8328\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2207, Accuracy: 0.8983, F1 Micro: 0.8983, F1 Macro: 0.8725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1652, Accuracy: 0.9021, F1 Micro: 0.9021, F1 Macro: 0.8702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1171, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0802, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8801\n",
      "Epoch 7/10, Train Loss: 0.0465, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.8698\n",
      "Epoch 8/10, Train Loss: 0.0555, Accuracy: 0.904, F1 Micro: 0.904, F1 Macro: 0.8755\n",
      "Epoch 9/10, Train Loss: 0.0387, Accuracy: 0.904, F1 Micro: 0.904, F1 Macro: 0.8749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0306, Accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.8808\n",
      "\n",
      "Sentiment analysis accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.8808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       756\n",
      "    positive       0.95      0.73      0.82       306\n",
      "\n",
      "    accuracy                           0.91      1062\n",
      "   macro avg       0.92      0.85      0.88      1062\n",
      "weighted avg       0.91      0.91      0.91      1062\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.8612\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.78      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.81      0.80        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.86      0.63      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.54      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.87       200\n",
      "     neutral       0.91      0.95      0.93       315\n",
      "    positive       0.88      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.90      0.90       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.83      0.86       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.86      0.27      0.41        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.88      0.69      0.74       571\n",
      "weighted avg       0.90      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 239.67926478385925 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.01376485824584961\n",
      "Samples above threshold: 114\n",
      "Acquired samples: 114\n",
      "Sampling duration: 10.190072536468506 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5017, Accuracy: 0.8104, F1 Micro: 0.8937, F1 Macro: 0.8881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3704, Accuracy: 0.9146, F1 Micro: 0.9482, F1 Macro: 0.9432\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.263, Accuracy: 0.9358, F1 Micro: 0.9608, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2115, Accuracy: 0.942, F1 Micro: 0.9645, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1664, Accuracy: 0.9488, F1 Micro: 0.9685, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1494, Accuracy: 0.9526, F1 Micro: 0.9708, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1229, Accuracy: 0.9547, F1 Micro: 0.972, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1071, Accuracy: 0.9589, F1 Micro: 0.9745, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.092, Accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9725\n",
      "Epoch 10/10, Train Loss: 0.0816, Accuracy: 0.9589, F1 Micro: 0.9745, F1 Macro: 0.9719\n",
      "\n",
      "Aspect detection accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.98      0.98       480\n",
      "         bau       0.96      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.93       317\n",
      "       linen       0.90      0.97      0.93       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4307, Accuracy: 0.8475, F1 Micro: 0.8475, F1 Macro: 0.8126\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2899, Accuracy: 0.8567, F1 Micro: 0.8567, F1 Macro: 0.8041\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1996, Accuracy: 0.8845, F1 Micro: 0.8845, F1 Macro: 0.8456\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.141, Accuracy: 0.8909, F1 Micro: 0.8909, F1 Macro: 0.8572\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1076, Accuracy: 0.9002, F1 Micro: 0.9002, F1 Macro: 0.8711\n",
      "Epoch 6/10, Train Loss: 0.0638, Accuracy: 0.8965, F1 Micro: 0.8965, F1 Macro: 0.8666\n",
      "Epoch 7/10, Train Loss: 0.055, Accuracy: 0.8983, F1 Micro: 0.8983, F1 Macro: 0.8687\n",
      "Epoch 8/10, Train Loss: 0.0521, Accuracy: 0.8983, F1 Micro: 0.8983, F1 Macro: 0.8707\n",
      "Epoch 9/10, Train Loss: 0.0699, Accuracy: 0.8974, F1 Micro: 0.8974, F1 Macro: 0.8655\n",
      "Epoch 10/10, Train Loss: 0.0297, Accuracy: 0.8965, F1 Micro: 0.8965, F1 Macro: 0.8648\n",
      "\n",
      "Sentiment analysis accuracy: 0.9002, F1 Micro: 0.9002, F1 Macro: 0.8711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       761\n",
      "    positive       0.93      0.72      0.81       321\n",
      "\n",
      "    accuracy                           0.90      1082\n",
      "   macro avg       0.91      0.85      0.87      1082\n",
      "weighted avg       0.90      0.90      0.90      1082\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9525, F1 Micro: 0.9525, F1 Macro: 0.8185\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.88        86\n",
      "     neutral       0.98      0.98      0.98       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.79      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.78      0.79        78\n",
      "     neutral       0.96      0.97      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.58      0.58       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.82      0.72      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.57      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.84      0.93      0.88        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.77      0.82       162\n",
      "     neutral       0.89      0.97      0.93       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.86      0.70      0.75       571\n",
      "weighted avg       0.89      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.52      0.61        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.68      0.76      0.72        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.76      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 262.18255496025085 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.012761712074279785\n",
      "Samples above threshold: 103\n",
      "Acquired samples: 103\n",
      "Sampling duration: 9.376165866851807 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4921, Accuracy: 0.8208, F1 Micro: 0.8988, F1 Macro: 0.8932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3569, Accuracy: 0.9172, F1 Micro: 0.9499, F1 Macro: 0.9455\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.246, Accuracy: 0.9359, F1 Micro: 0.9612, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1984, Accuracy: 0.9441, F1 Micro: 0.9658, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1603, Accuracy: 0.9491, F1 Micro: 0.9687, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1404, Accuracy: 0.9573, F1 Micro: 0.9736, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.118, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9723\n",
      "Epoch 8/10, Train Loss: 0.0991, Accuracy: 0.9587, F1 Micro: 0.9744, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0888, Accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.9731\n",
      "Epoch 10/10, Train Loss: 0.0762, Accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.9712\n",
      "\n",
      "Aspect detection accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.9731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.96      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.89      0.97      0.93       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4224, Accuracy: 0.8554, F1 Micro: 0.8554, F1 Macro: 0.8131\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.243, Accuracy: 0.861, F1 Micro: 0.861, F1 Macro: 0.8108\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1776, Accuracy: 0.8978, F1 Micro: 0.8978, F1 Macro: 0.8704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1171, Accuracy: 0.8978, F1 Micro: 0.8978, F1 Macro: 0.8699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0974, Accuracy: 0.8987, F1 Micro: 0.8987, F1 Macro: 0.8703\n",
      "Epoch 6/10, Train Loss: 0.0676, Accuracy: 0.8877, F1 Micro: 0.8877, F1 Macro: 0.862\n",
      "Epoch 7/10, Train Loss: 0.0677, Accuracy: 0.8978, F1 Micro: 0.8978, F1 Macro: 0.866\n",
      "Epoch 8/10, Train Loss: 0.0467, Accuracy: 0.8969, F1 Micro: 0.8969, F1 Macro: 0.8708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0284, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0339, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8768\n",
      "\n",
      "Sentiment analysis accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.99      0.94       762\n",
      "    positive       0.96      0.71      0.82       324\n",
      "\n",
      "    accuracy                           0.91      1086\n",
      "   macro avg       0.92      0.85      0.88      1086\n",
      "weighted avg       0.91      0.91      0.90      1086\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.8726\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.82      0.80        78\n",
      "     neutral       0.97      0.96      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.83      0.72      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.61      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.76      0.81       162\n",
      "     neutral       0.89      0.97      0.93       387\n",
      "    positive       1.00      0.32      0.48        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.92      0.68      0.74       571\n",
      "weighted avg       0.89      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.69      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 270.350613117218 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.010384255647659301\n",
      "Samples above threshold: 92\n",
      "Acquired samples: 62\n",
      "Sampling duration: 8.649563789367676 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4905, Accuracy: 0.8266, F1 Micro: 0.9017, F1 Macro: 0.8964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3478, Accuracy: 0.9198, F1 Micro: 0.9515, F1 Macro: 0.9476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2424, Accuracy: 0.9418, F1 Micro: 0.9645, F1 Macro: 0.9621\n",
      "Epoch 4/10, Train Loss: 0.1925, Accuracy: 0.9415, F1 Micro: 0.9642, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1638, Accuracy: 0.954, F1 Micro: 0.9716, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.136, Accuracy: 0.9547, F1 Micro: 0.972, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1144, Accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.9725\n",
      "Epoch 8/10, Train Loss: 0.0943, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0827, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0709, Accuracy: 0.9611, F1 Micro: 0.9758, F1 Macro: 0.9734\n",
      "\n",
      "Aspect detection accuracy: 0.9611, F1 Micro: 0.9758, F1 Macro: 0.9734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.96      0.91      0.93       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4, Accuracy: 0.8371, F1 Micro: 0.8371, F1 Macro: 0.7718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.272, Accuracy: 0.871, F1 Micro: 0.871, F1 Macro: 0.8289\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1875, Accuracy: 0.8838, F1 Micro: 0.8838, F1 Macro: 0.8455\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1385, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.8762\n",
      "Epoch 5/10, Train Loss: 0.0867, Accuracy: 0.8948, F1 Micro: 0.8948, F1 Macro: 0.8669\n",
      "Epoch 6/10, Train Loss: 0.0782, Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.8738\n",
      "Epoch 7/10, Train Loss: 0.0602, Accuracy: 0.9003, F1 Micro: 0.9003, F1 Macro: 0.8687\n",
      "Epoch 8/10, Train Loss: 0.032, Accuracy: 0.9003, F1 Micro: 0.9003, F1 Macro: 0.8705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0467, Accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.875\n",
      "Epoch 10/10, Train Loss: 0.0333, Accuracy: 0.8783, F1 Micro: 0.8783, F1 Macro: 0.8507\n",
      "\n",
      "Sentiment analysis accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.94       771\n",
      "    positive       0.94      0.72      0.81       322\n",
      "\n",
      "    accuracy                           0.90      1093\n",
      "   macro avg       0.92      0.85      0.87      1093\n",
      "weighted avg       0.91      0.90      0.90      1093\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.8626\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.79      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.75      0.81       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.66      0.74        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.60      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89       200\n",
      "     neutral       0.96      0.90      0.93       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.73      0.36      0.48        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.84      0.71      0.76       571\n",
      "weighted avg       0.90      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.62      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 275.74993324279785 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.008542567491531372\n",
      "Samples above threshold: 86\n",
      "Acquired samples: 86\n",
      "Sampling duration: 8.00882077217102 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4781, Accuracy: 0.8377, F1 Micro: 0.9075, F1 Macro: 0.9026\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3247, Accuracy: 0.9243, F1 Micro: 0.954, F1 Macro: 0.9499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2312, Accuracy: 0.9438, F1 Micro: 0.9654, F1 Macro: 0.9624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1855, Accuracy: 0.9476, F1 Micro: 0.9678, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1546, Accuracy: 0.9505, F1 Micro: 0.9696, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1299, Accuracy: 0.9589, F1 Micro: 0.9745, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1074, Accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.9721\n",
      "Epoch 8/10, Train Loss: 0.0922, Accuracy: 0.9573, F1 Micro: 0.9735, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0768, Accuracy: 0.9599, F1 Micro: 0.9751, F1 Macro: 0.9727\n",
      "Epoch 10/10, Train Loss: 0.0636, Accuracy: 0.9589, F1 Micro: 0.9745, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9599, F1 Micro: 0.9751, F1 Macro: 0.9727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.92      0.93       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4135, Accuracy: 0.8555, F1 Micro: 0.8555, F1 Macro: 0.8155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2459, Accuracy: 0.8919, F1 Micro: 0.8919, F1 Macro: 0.8579\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1514, Accuracy: 0.9021, F1 Micro: 0.9021, F1 Macro: 0.8756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1173, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8784\n",
      "Epoch 5/10, Train Loss: 0.0697, Accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.8747\n",
      "Epoch 6/10, Train Loss: 0.0608, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8683\n",
      "Epoch 7/10, Train Loss: 0.0576, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0303, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.878\n",
      "Epoch 9/10, Train Loss: 0.0456, Accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.8756\n",
      "Epoch 10/10, Train Loss: 0.0328, Accuracy: 0.9021, F1 Micro: 0.9021, F1 Macro: 0.8699\n",
      "\n",
      "Sentiment analysis accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.99      0.94       763\n",
      "    positive       0.95      0.72      0.82       310\n",
      "\n",
      "    accuracy                           0.91      1073\n",
      "   macro avg       0.92      0.85      0.88      1073\n",
      "weighted avg       0.91      0.91      0.90      1073\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9543, F1 Micro: 0.9543, F1 Macro: 0.8495\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.85      0.89        86\n",
      "     neutral       0.97      1.00      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.78      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.65      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.54      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.87       200\n",
      "     neutral       0.93      0.92      0.93       315\n",
      "    positive       0.88      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.90      0.90       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.73      0.77       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.95      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 288.65245962142944 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.008112633228302002\n",
      "Samples above threshold: 77\n",
      "Acquired samples: 77\n",
      "Sampling duration: 7.270477294921875 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4748, Accuracy: 0.8436, F1 Micro: 0.9103, F1 Macro: 0.9052\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3242, Accuracy: 0.9214, F1 Micro: 0.9526, F1 Macro: 0.9493\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.226, Accuracy: 0.946, F1 Micro: 0.9667, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1805, Accuracy: 0.9512, F1 Micro: 0.9699, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1464, Accuracy: 0.9543, F1 Micro: 0.9719, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1259, Accuracy: 0.9589, F1 Micro: 0.9745, F1 Macro: 0.9717\n",
      "Epoch 7/10, Train Loss: 0.1045, Accuracy: 0.9585, F1 Micro: 0.9743, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0928, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9741\n",
      "Epoch 9/10, Train Loss: 0.0785, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9733\n",
      "Epoch 10/10, Train Loss: 0.0667, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9735\n",
      "\n",
      "Aspect detection accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.98      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4009, Accuracy: 0.862, F1 Micro: 0.862, F1 Macro: 0.8217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2307, Accuracy: 0.8859, F1 Micro: 0.8859, F1 Macro: 0.8498\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.179, Accuracy: 0.8979, F1 Micro: 0.8979, F1 Macro: 0.8724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1214, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8798\n",
      "Epoch 5/10, Train Loss: 0.1142, Accuracy: 0.8979, F1 Micro: 0.8979, F1 Macro: 0.8716\n",
      "Epoch 6/10, Train Loss: 0.076, Accuracy: 0.8997, F1 Micro: 0.8997, F1 Macro: 0.8691\n",
      "Epoch 7/10, Train Loss: 0.0476, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.8728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0536, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0349, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8811\n",
      "Epoch 10/10, Train Loss: 0.0223, Accuracy: 0.8997, F1 Micro: 0.8997, F1 Macro: 0.8691\n",
      "\n",
      "Sentiment analysis accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       766\n",
      "    positive       0.94      0.73      0.82       321\n",
      "\n",
      "    accuracy                           0.91      1087\n",
      "   macro avg       0.92      0.86      0.88      1087\n",
      "weighted avg       0.91      0.91      0.90      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9555, F1 Micro: 0.9555, F1 Macro: 0.8556\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87        86\n",
      "     neutral       0.98      0.98      0.98       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.78      0.80       571\n",
      "weighted avg       0.95      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.81      0.80        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.76      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.80      0.71      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.58      0.56      0.57       571\n",
      "weighted avg       0.92      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       1.00      0.32      0.48        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.94      0.71      0.76       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.85        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 294.8178291320801 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.009250926971435551\n",
      "Samples above threshold: 70\n",
      "Acquired samples: 70\n",
      "Sampling duration: 6.627072334289551 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4649, Accuracy: 0.8573, F1 Micro: 0.9169, F1 Macro: 0.9109\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3038, Accuracy: 0.9281, F1 Micro: 0.9562, F1 Macro: 0.953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2184, Accuracy: 0.9439, F1 Micro: 0.9657, F1 Macro: 0.9632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1753, Accuracy: 0.9476, F1 Micro: 0.9678, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1467, Accuracy: 0.9542, F1 Micro: 0.9717, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1218, Accuracy: 0.9568, F1 Micro: 0.9733, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0993, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9741\n",
      "Epoch 8/10, Train Loss: 0.085, Accuracy: 0.9611, F1 Micro: 0.9758, F1 Macro: 0.9735\n",
      "Epoch 9/10, Train Loss: 0.0719, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9731\n",
      "Epoch 10/10, Train Loss: 0.0626, Accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.9729\n",
      "\n",
      "Aspect detection accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.93      0.93       317\n",
      "       linen       0.94      0.95      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4074, Accuracy: 0.8496, F1 Micro: 0.8496, F1 Macro: 0.8157\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2505, Accuracy: 0.8822, F1 Micro: 0.8822, F1 Macro: 0.8522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.184, Accuracy: 0.8949, F1 Micro: 0.8949, F1 Macro: 0.8656\n",
      "Epoch 4/10, Train Loss: 0.1348, Accuracy: 0.8877, F1 Micro: 0.8877, F1 Macro: 0.8537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1095, Accuracy: 0.8958, F1 Micro: 0.8958, F1 Macro: 0.8626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0784, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8735\n",
      "Epoch 7/10, Train Loss: 0.0631, Accuracy: 0.8859, F1 Micro: 0.8859, F1 Macro: 0.8524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.049, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8748\n",
      "Epoch 9/10, Train Loss: 0.0233, Accuracy: 0.8986, F1 Micro: 0.8986, F1 Macro: 0.8685\n",
      "Epoch 10/10, Train Loss: 0.0305, Accuracy: 0.8895, F1 Micro: 0.8895, F1 Macro: 0.853\n",
      "\n",
      "Sentiment analysis accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       777\n",
      "    positive       0.94      0.72      0.82       327\n",
      "\n",
      "    accuracy                           0.90      1104\n",
      "   macro avg       0.91      0.85      0.87      1104\n",
      "weighted avg       0.91      0.90      0.90      1104\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9564, F1 Micro: 0.9564, F1 Macro: 0.8656\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.79      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.79      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.85      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.55      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.90      0.87       162\n",
      "     neutral       0.94      0.95      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.77      0.81       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.52      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.78      0.80       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 304.5241026878357 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.011792778968811039\n",
      "Samples above threshold: 63\n",
      "Acquired samples: 52\n",
      "Sampling duration: 6.073502779006958 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4679, Accuracy: 0.8701, F1 Micro: 0.9234, F1 Macro: 0.9173\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3013, Accuracy: 0.929, F1 Micro: 0.957, F1 Macro: 0.9542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2111, Accuracy: 0.9427, F1 Micro: 0.965, F1 Macro: 0.9626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1704, Accuracy: 0.9526, F1 Micro: 0.9707, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1397, Accuracy: 0.9542, F1 Micro: 0.9717, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1212, Accuracy: 0.958, F1 Micro: 0.974, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0986, Accuracy: 0.959, F1 Micro: 0.9747, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0861, Accuracy: 0.962, F1 Micro: 0.9763, F1 Macro: 0.9738\n",
      "Epoch 9/10, Train Loss: 0.0691, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0605, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.93       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3806, Accuracy: 0.8678, F1 Micro: 0.8678, F1 Macro: 0.8225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2512, Accuracy: 0.8937, F1 Micro: 0.8937, F1 Macro: 0.8607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1539, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.122, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0853, Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.8927\n",
      "Epoch 6/10, Train Loss: 0.0581, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0434, Accuracy: 0.9168, F1 Micro: 0.9168, F1 Macro: 0.8942\n",
      "Epoch 8/10, Train Loss: 0.0387, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.883\n",
      "Epoch 9/10, Train Loss: 0.0293, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8891\n",
      "Epoch 10/10, Train Loss: 0.017, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8822\n",
      "\n",
      "Sentiment analysis accuracy: 0.9168, F1 Micro: 0.9168, F1 Macro: 0.8942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94       767\n",
      "    positive       0.92      0.78      0.85       315\n",
      "\n",
      "    accuracy                           0.92      1082\n",
      "   macro avg       0.92      0.88      0.89      1082\n",
      "weighted avg       0.92      0.92      0.91      1082\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.8832\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.50      0.50      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.81      0.79      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.29      0.40         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.75      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.82      0.67      0.72       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.88       200\n",
      "     neutral       0.92      0.94      0.93       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.85       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.76      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.84      0.94      0.89        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 318.27215480804443 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0062223076820373535\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 58\n",
      "Sampling duration: 5.712435245513916 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.465, Accuracy: 0.8722, F1 Micro: 0.925, F1 Macro: 0.9194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2976, Accuracy: 0.9321, F1 Micro: 0.9586, F1 Macro: 0.9557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2091, Accuracy: 0.9425, F1 Micro: 0.9649, F1 Macro: 0.9629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1737, Accuracy: 0.9538, F1 Micro: 0.9716, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1332, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1127, Accuracy: 0.9599, F1 Micro: 0.9751, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0951, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0818, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.0689, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9742\n",
      "Epoch 10/10, Train Loss: 0.0596, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.974\n",
      "\n",
      "Aspect detection accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.91      0.94      0.93       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3738, Accuracy: 0.8594, F1 Micro: 0.8594, F1 Macro: 0.8073\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2162, Accuracy: 0.896, F1 Micro: 0.896, F1 Macro: 0.8616\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1372, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1052, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.88\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0873, Accuracy: 0.9166, F1 Micro: 0.9166, F1 Macro: 0.8934\n",
      "Epoch 6/10, Train Loss: 0.0537, Accuracy: 0.9007, F1 Micro: 0.9007, F1 Macro: 0.8686\n",
      "Epoch 7/10, Train Loss: 0.0536, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8838\n",
      "Epoch 8/10, Train Loss: 0.046, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8884\n",
      "Epoch 9/10, Train Loss: 0.0148, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8895\n",
      "Epoch 10/10, Train Loss: 0.0264, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8789\n",
      "\n",
      "Sentiment analysis accuracy: 0.9166, F1 Micro: 0.9166, F1 Macro: 0.8934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94       760\n",
      "    positive       0.92      0.78      0.84       307\n",
      "\n",
      "    accuracy                           0.92      1067\n",
      "   macro avg       0.92      0.88      0.89      1067\n",
      "weighted avg       0.92      0.92      0.91      1067\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9564, F1 Micro: 0.9564, F1 Macro: 0.8696\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.78      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.71      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.61      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87       200\n",
      "     neutral       0.91      0.94      0.93       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.85       162\n",
      "     neutral       0.93      0.96      0.94       387\n",
      "    positive       0.67      0.55      0.60        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.82      0.78      0.80       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.84      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.95      0.97        74\n",
      "     neutral       0.99      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.98      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 321.0429193973541 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.008355402946472168\n",
      "Samples above threshold: 52\n",
      "Acquired samples: 52\n",
      "Sampling duration: 5.16734504699707 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4654, Accuracy: 0.8759, F1 Micro: 0.9271, F1 Macro: 0.9221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2943, Accuracy: 0.9356, F1 Micro: 0.9607, F1 Macro: 0.9575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2101, Accuracy: 0.9446, F1 Micro: 0.9661, F1 Macro: 0.9639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1677, Accuracy: 0.9514, F1 Micro: 0.9701, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1351, Accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1155, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0974, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.082, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.067, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9754\n",
      "Epoch 10/10, Train Loss: 0.0582, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3683, Accuracy: 0.8434, F1 Micro: 0.8434, F1 Macro: 0.7821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2242, Accuracy: 0.8971, F1 Micro: 0.8971, F1 Macro: 0.866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1817, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8732\n",
      "Epoch 4/10, Train Loss: 0.1047, Accuracy: 0.8934, F1 Micro: 0.8934, F1 Macro: 0.8663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1056, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0847, Accuracy: 0.9044, F1 Micro: 0.9044, F1 Macro: 0.8757\n",
      "Epoch 7/10, Train Loss: 0.057, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0603, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8849\n",
      "Epoch 9/10, Train Loss: 0.03, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8808\n",
      "Epoch 10/10, Train Loss: 0.0445, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8852\n",
      "\n",
      "Sentiment analysis accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       774\n",
      "    positive       0.94      0.74      0.83       324\n",
      "\n",
      "    accuracy                           0.91      1098\n",
      "   macro avg       0.92      0.86      0.88      1098\n",
      "weighted avg       0.91      0.91      0.91      1098\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9587, F1 Micro: 0.9587, F1 Macro: 0.8829\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.79      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.75      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.72      0.62      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.89       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.90      0.95      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.86       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.94      0.77      0.82       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.96      0.94      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 330.701642036438 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0070798397064208984\n",
      "Samples above threshold: 47\n",
      "Acquired samples: 50\n",
      "Sampling duration: 5.017628192901611 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4602, Accuracy: 0.8708, F1 Micro: 0.9241, F1 Macro: 0.9176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2842, Accuracy: 0.9354, F1 Micro: 0.9606, F1 Macro: 0.9575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2046, Accuracy: 0.946, F1 Micro: 0.967, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1626, Accuracy: 0.9484, F1 Micro: 0.9684, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.135, Accuracy: 0.9576, F1 Micro: 0.9738, F1 Macro: 0.9713\n",
      "Epoch 6/10, Train Loss: 0.1097, Accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.091, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0778, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0633, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0557, Accuracy: 0.9642, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9642, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3739, Accuracy: 0.8454, F1 Micro: 0.8454, F1 Macro: 0.8098\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2245, Accuracy: 0.8856, F1 Micro: 0.8856, F1 Macro: 0.85\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1606, Accuracy: 0.8963, F1 Micro: 0.8963, F1 Macro: 0.8659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1054, Accuracy: 0.899, F1 Micro: 0.899, F1 Macro: 0.8704\n",
      "Epoch 5/10, Train Loss: 0.0875, Accuracy: 0.8981, F1 Micro: 0.8981, F1 Macro: 0.8682\n",
      "Epoch 6/10, Train Loss: 0.0691, Accuracy: 0.8963, F1 Micro: 0.8963, F1 Macro: 0.8653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0522, Accuracy: 0.8999, F1 Micro: 0.8999, F1 Macro: 0.8694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0472, Accuracy: 0.8999, F1 Micro: 0.8999, F1 Macro: 0.87\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0195, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8723\n",
      "Epoch 10/10, Train Loss: 0.0274, Accuracy: 0.8937, F1 Micro: 0.8937, F1 Macro: 0.8644\n",
      "\n",
      "Sentiment analysis accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       788\n",
      "    positive       0.94      0.71      0.81       331\n",
      "\n",
      "    accuracy                           0.90      1119\n",
      "   macro avg       0.92      0.85      0.87      1119\n",
      "weighted avg       0.91      0.90      0.90      1119\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9581, F1 Micro: 0.9581, F1 Macro: 0.8724\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.61      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.89      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       1.00      0.36      0.53        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.93      0.74      0.79       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.89      0.87        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.52      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      1.00      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.84      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 345.27642846107483 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.005409598350524902\n",
      "Samples above threshold: 42\n",
      "Acquired samples: 50\n",
      "Sampling duration: 4.48318886756897 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4616, Accuracy: 0.8774, F1 Micro: 0.9275, F1 Macro: 0.9215\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2784, Accuracy: 0.937, F1 Micro: 0.9615, F1 Macro: 0.9589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1981, Accuracy: 0.9464, F1 Micro: 0.9672, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1574, Accuracy: 0.9559, F1 Micro: 0.9727, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1346, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9732\n",
      "Epoch 6/10, Train Loss: 0.1054, Accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0885, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9738\n",
      "Epoch 8/10, Train Loss: 0.0748, Accuracy: 0.9608, F1 Micro: 0.9758, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0656, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.054, Accuracy: 0.9637, F1 Micro: 0.9774, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9637, F1 Micro: 0.9774, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3701, Accuracy: 0.859, F1 Micro: 0.859, F1 Macro: 0.8099\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2115, Accuracy: 0.8897, F1 Micro: 0.8897, F1 Macro: 0.8548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1487, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8746\n",
      "Epoch 4/10, Train Loss: 0.1046, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8748\n",
      "Epoch 5/10, Train Loss: 0.0761, Accuracy: 0.896, F1 Micro: 0.896, F1 Macro: 0.8624\n",
      "Epoch 6/10, Train Loss: 0.0615, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0559, Accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.8826\n",
      "Epoch 8/10, Train Loss: 0.0355, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8758\n",
      "Epoch 9/10, Train Loss: 0.0325, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0217, Accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.8837\n",
      "\n",
      "Sentiment analysis accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.8837\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       782\n",
      "    positive       0.93      0.75      0.83       324\n",
      "\n",
      "    accuracy                           0.91      1106\n",
      "   macro avg       0.92      0.86      0.88      1106\n",
      "weighted avg       0.91      0.91      0.91      1106\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9581, F1 Micro: 0.9581, F1 Macro: 0.8663\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.86      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.81      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.84      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.76      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.83      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 345.5234432220459 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0049256086349487305\n",
      "Samples above threshold: 37\n",
      "Acquired samples: 50\n",
      "Sampling duration: 4.000333309173584 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4489, Accuracy: 0.8837, F1 Micro: 0.9309, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2766, Accuracy: 0.9368, F1 Micro: 0.9616, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2013, Accuracy: 0.9443, F1 Micro: 0.966, F1 Macro: 0.9638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1605, Accuracy: 0.9514, F1 Micro: 0.9702, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1294, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1045, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0893, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9759\n",
      "Epoch 8/10, Train Loss: 0.0731, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9727\n",
      "Epoch 9/10, Train Loss: 0.0622, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9759\n",
      "Epoch 10/10, Train Loss: 0.0516, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9748\n",
      "\n",
      "Aspect detection accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3739, Accuracy: 0.8626, F1 Micro: 0.8626, F1 Macro: 0.8186\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2147, Accuracy: 0.8864, F1 Micro: 0.8864, F1 Macro: 0.8482\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.155, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1149, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8781\n",
      "Epoch 5/10, Train Loss: 0.0962, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0613, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0455, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8918\n",
      "Epoch 8/10, Train Loss: 0.0487, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8887\n",
      "Epoch 9/10, Train Loss: 0.0344, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8845\n",
      "Epoch 10/10, Train Loss: 0.0363, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8866\n",
      "\n",
      "Sentiment analysis accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8918\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       775\n",
      "    positive       0.93      0.77      0.84       317\n",
      "\n",
      "    accuracy                           0.92      1092\n",
      "   macro avg       0.92      0.87      0.89      1092\n",
      "weighted avg       0.92      0.92      0.91      1092\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8741\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.75      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.62      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.71      0.45      0.56        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.85      0.76      0.79       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 344.019992351532 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.008088469505310059\n",
      "Samples above threshold: 32\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.7394604682922363 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4504, Accuracy: 0.878, F1 Micro: 0.9281, F1 Macro: 0.923\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2636, Accuracy: 0.9417, F1 Micro: 0.9644, F1 Macro: 0.9622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1916, Accuracy: 0.9465, F1 Micro: 0.9674, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1558, Accuracy: 0.9545, F1 Micro: 0.972, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1275, Accuracy: 0.959, F1 Micro: 0.9747, F1 Macro: 0.9725\n",
      "Epoch 6/10, Train Loss: 0.1033, Accuracy: 0.9587, F1 Micro: 0.9745, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0918, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9748\n",
      "Epoch 8/10, Train Loss: 0.0729, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9748\n",
      "Epoch 9/10, Train Loss: 0.0615, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0511, Accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.97      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3822, Accuracy: 0.8473, F1 Micro: 0.8473, F1 Macro: 0.7844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2007, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.8634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1417, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.888\n",
      "Epoch 4/10, Train Loss: 0.0983, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8781\n",
      "Epoch 5/10, Train Loss: 0.0718, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.052, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0353, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8892\n",
      "Epoch 8/10, Train Loss: 0.0334, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0211, Accuracy: 0.9178, F1 Micro: 0.9178, F1 Macro: 0.8938\n",
      "Epoch 10/10, Train Loss: 0.0163, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8892\n",
      "\n",
      "Sentiment analysis accuracy: 0.9178, F1 Micro: 0.9178, F1 Macro: 0.8938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       785\n",
      "    positive       0.95      0.76      0.84       322\n",
      "\n",
      "    accuracy                           0.92      1107\n",
      "   macro avg       0.93      0.87      0.89      1107\n",
      "weighted avg       0.92      0.92      0.91      1107\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9604, F1 Micro: 0.9604, F1 Macro: 0.856\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.61      0.60      0.60       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.43      0.55         7\n",
      "     neutral       0.96      0.97      0.97       496\n",
      "    positive       0.80      0.76      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.84      0.72      0.76       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.71      0.45      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.84      0.76      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.85      0.89        85\n",
      "     neutral       0.97      0.99      0.98       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 350.6447649002075 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.004226952791213989\n",
      "Samples above threshold: 29\n",
      "Acquired samples: 50\n",
      "Sampling duration: 3.4575490951538086 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4445, Accuracy: 0.8832, F1 Micro: 0.9305, F1 Macro: 0.9236\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2701, Accuracy: 0.9392, F1 Micro: 0.9628, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1933, Accuracy: 0.9493, F1 Micro: 0.9689, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1577, Accuracy: 0.9533, F1 Micro: 0.9713, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1221, Accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1049, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0862, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0719, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0616, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9745\n",
      "Epoch 10/10, Train Loss: 0.0525, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9738\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.91      0.95      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3868, Accuracy: 0.8664, F1 Micro: 0.8664, F1 Macro: 0.8307\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2159, Accuracy: 0.8949, F1 Micro: 0.8949, F1 Macro: 0.8618\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1324, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0986, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0683, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8889\n",
      "Epoch 6/10, Train Loss: 0.0468, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8818\n",
      "Epoch 7/10, Train Loss: 0.0368, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8834\n",
      "Epoch 8/10, Train Loss: 0.0404, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0283, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8877\n",
      "Epoch 10/10, Train Loss: 0.0163, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8818\n",
      "\n",
      "Sentiment analysis accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       770\n",
      "    positive       0.94      0.75      0.83       315\n",
      "\n",
      "    accuracy                           0.91      1085\n",
      "   macro avg       0.92      0.86      0.89      1085\n",
      "weighted avg       0.92      0.91      0.91      1085\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9573, F1 Micro: 0.9573, F1 Macro: 0.8764\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.77      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.80      0.71      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.61      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.84      0.88       200\n",
      "     neutral       0.91      0.95      0.93       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.91      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.73      0.77       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.80      0.86        85\n",
      "     neutral       0.96      0.99      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 354.3121314048767 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.005762308835983276\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 50\n",
      "Sampling duration: 3.0461320877075195 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4462, Accuracy: 0.8865, F1 Micro: 0.933, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2571, Accuracy: 0.9396, F1 Micro: 0.9631, F1 Macro: 0.9609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.185, Accuracy: 0.9505, F1 Micro: 0.9696, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1456, Accuracy: 0.9549, F1 Micro: 0.9723, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1213, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.095, Accuracy: 0.9611, F1 Micro: 0.976, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.085, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "Epoch 8/10, Train Loss: 0.0681, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0594, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0494, Accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.95      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3643, Accuracy: 0.859, F1 Micro: 0.859, F1 Macro: 0.821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2215, Accuracy: 0.8972, F1 Micro: 0.8972, F1 Macro: 0.869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1503, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1096, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0777, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8874\n",
      "Epoch 6/10, Train Loss: 0.056, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0365, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8863\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0342, Accuracy: 0.9199, F1 Micro: 0.9199, F1 Macro: 0.8953\n",
      "Epoch 9/10, Train Loss: 0.0264, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8837\n",
      "Epoch 10/10, Train Loss: 0.0306, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8792\n",
      "\n",
      "Sentiment analysis accuracy: 0.9199, F1 Micro: 0.9199, F1 Macro: 0.8953\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       786\n",
      "    positive       0.94      0.76      0.84       313\n",
      "\n",
      "    accuracy                           0.92      1099\n",
      "   macro avg       0.93      0.87      0.90      1099\n",
      "weighted avg       0.92      0.92      0.92      1099\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9613, F1 Micro: 0.9613, F1 Macro: 0.8814\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.55      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.89      0.88       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.92      0.55      0.69        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.80      0.84       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.83      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 370.1190276145935 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.003707408905029297\n",
      "Samples above threshold: 19\n",
      "Acquired samples: 50\n",
      "Sampling duration: 2.6771273612976074 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4418, Accuracy: 0.888, F1 Micro: 0.9338, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2579, Accuracy: 0.9417, F1 Micro: 0.9643, F1 Macro: 0.9616\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1836, Accuracy: 0.9498, F1 Micro: 0.9692, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1487, Accuracy: 0.9552, F1 Micro: 0.9723, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1213, Accuracy: 0.9575, F1 Micro: 0.9738, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0998, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9751\n",
      "Epoch 7/10, Train Loss: 0.0803, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0672, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0548, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0483, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3501, Accuracy: 0.8738, F1 Micro: 0.8738, F1 Macro: 0.835\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1916, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8794\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1223, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0989, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8845\n",
      "Epoch 5/10, Train Loss: 0.0759, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0553, Accuracy: 0.9217, F1 Micro: 0.9217, F1 Macro: 0.8979\n",
      "Epoch 7/10, Train Loss: 0.0414, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.8928\n",
      "Epoch 8/10, Train Loss: 0.0198, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.8908\n",
      "Epoch 9/10, Train Loss: 0.0347, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8893\n",
      "Epoch 10/10, Train Loss: 0.0248, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8818\n",
      "\n",
      "Sentiment analysis accuracy: 0.9217, F1 Micro: 0.9217, F1 Macro: 0.8979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.99      0.95       774\n",
      "    positive       0.96      0.76      0.85       312\n",
      "\n",
      "    accuracy                           0.92      1086\n",
      "   macro avg       0.93      0.87      0.90      1086\n",
      "weighted avg       0.92      0.92      0.92      1086\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9594, F1 Micro: 0.9594, F1 Macro: 0.8812\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.83      0.86       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.74      0.79       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 375.5622684955597 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0037559568881988525\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 50\n",
      "Sampling duration: 2.4232842922210693 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4335, Accuracy: 0.8896, F1 Micro: 0.934, F1 Macro: 0.9283\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2551, Accuracy: 0.9385, F1 Micro: 0.9625, F1 Macro: 0.9598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1796, Accuracy: 0.9509, F1 Micro: 0.9698, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1454, Accuracy: 0.9564, F1 Micro: 0.9731, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1151, Accuracy: 0.9578, F1 Micro: 0.974, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0929, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9754\n",
      "Epoch 7/10, Train Loss: 0.0798, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0678, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.054, Accuracy: 0.9661, F1 Micro: 0.9789, F1 Macro: 0.9768\n",
      "Epoch 10/10, Train Loss: 0.046, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.9661, F1 Micro: 0.9789, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3409, Accuracy: 0.8637, F1 Micro: 0.8637, F1 Macro: 0.8185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2222, Accuracy: 0.8953, F1 Micro: 0.8953, F1 Macro: 0.8621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1367, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1082, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8847\n",
      "Epoch 5/10, Train Loss: 0.0724, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0567, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8845\n",
      "Epoch 7/10, Train Loss: 0.0473, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8817\n",
      "Epoch 8/10, Train Loss: 0.0338, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8817\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0342, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0191, Accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.891\n",
      "\n",
      "Sentiment analysis accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       785\n",
      "    positive       0.94      0.76      0.84       323\n",
      "\n",
      "    accuracy                           0.92      1108\n",
      "   macro avg       0.92      0.87      0.89      1108\n",
      "weighted avg       0.92      0.92      0.91      1108\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9611, F1 Micro: 0.9611, F1 Macro: 0.8927\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.86      0.87       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.86      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.96      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.75      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.62      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.86      0.55      0.67        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.79      0.83       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        85\n",
      "     neutral       0.97      0.99      0.98       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.84      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 388.37208127975464 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0031566321849823\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 50\n",
      "Sampling duration: 1.9736518859863281 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4283, Accuracy: 0.8941, F1 Micro: 0.9368, F1 Macro: 0.9315\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2453, Accuracy: 0.9432, F1 Micro: 0.9653, F1 Macro: 0.9629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1768, Accuracy: 0.9535, F1 Micro: 0.9714, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.139, Accuracy: 0.958, F1 Micro: 0.9741, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1136, Accuracy: 0.9637, F1 Micro: 0.9776, F1 Macro: 0.9757\n",
      "Epoch 6/10, Train Loss: 0.0938, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9751\n",
      "Epoch 7/10, Train Loss: 0.0785, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0651, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0536, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0441, Accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3525, Accuracy: 0.8751, F1 Micro: 0.8751, F1 Macro: 0.8393\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1929, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8776\n",
      "Epoch 3/10, Train Loss: 0.1269, Accuracy: 0.9034, F1 Micro: 0.9034, F1 Macro: 0.8711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0898, Accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.8897\n",
      "Epoch 5/10, Train Loss: 0.0718, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8815\n",
      "Epoch 6/10, Train Loss: 0.0521, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.886\n",
      "Epoch 7/10, Train Loss: 0.0456, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0275, Accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.8902\n",
      "Epoch 9/10, Train Loss: 0.0212, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8836\n",
      "Epoch 10/10, Train Loss: 0.038, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8809\n",
      "\n",
      "Sentiment analysis accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.8902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       782\n",
      "    positive       0.93      0.76      0.84       315\n",
      "\n",
      "    accuracy                           0.92      1097\n",
      "   macro avg       0.92      0.87      0.89      1097\n",
      "weighted avg       0.92      0.92      0.91      1097\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.8798\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.55      0.60      0.57        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.83      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.74      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.81      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 388.22058844566345 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.003092169761657715\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 36\n",
      "Sampling duration: 1.6022307872772217 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4299, Accuracy: 0.8958, F1 Micro: 0.9379, F1 Macro: 0.9329\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2461, Accuracy: 0.9425, F1 Micro: 0.9649, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1744, Accuracy: 0.9497, F1 Micro: 0.9691, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1401, Accuracy: 0.955, F1 Micro: 0.9723, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1188, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0953, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0807, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9762\n",
      "Epoch 8/10, Train Loss: 0.065, Accuracy: 0.962, F1 Micro: 0.9765, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0562, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "Epoch 10/10, Train Loss: 0.0477, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3543, Accuracy: 0.8794, F1 Micro: 0.8794, F1 Macro: 0.8411\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2026, Accuracy: 0.8987, F1 Micro: 0.8987, F1 Macro: 0.8709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1263, Accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8927\n",
      "Epoch 4/10, Train Loss: 0.0885, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8782\n",
      "Epoch 5/10, Train Loss: 0.0656, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8688\n",
      "Epoch 6/10, Train Loss: 0.0688, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8832\n",
      "Epoch 7/10, Train Loss: 0.0369, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8853\n",
      "Epoch 8/10, Train Loss: 0.026, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8815\n",
      "Epoch 9/10, Train Loss: 0.0229, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.888\n",
      "Epoch 10/10, Train Loss: 0.0258, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8758\n",
      "\n",
      "Sentiment analysis accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8927\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94       780\n",
      "    positive       0.91      0.78      0.84       306\n",
      "\n",
      "    accuracy                           0.92      1086\n",
      "   macro avg       0.92      0.88      0.89      1086\n",
      "weighted avg       0.92      0.92      0.92      1086\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.8675\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.87      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.86      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.68      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.55      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.73      0.50      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.77      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        85\n",
      "     neutral       0.98      0.97      0.98       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.84      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 393.1504421234131 s\n",
      "Total runtime: 7923.910138368607 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6416b4a",
   "metadata": {
    "papermill": {
     "duration": 0.185625,
     "end_time": "2025-03-29T17:11:25.460234",
     "exception": false,
     "start_time": "2025-03-29T17:11:25.274609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f163212d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6222, Accuracy: 0.7984, F1 Micro: 0.8875, F1 Macro: 0.8819\n",
      "Epoch 2/10, Train Loss: 0.4944, Accuracy: 0.7981, F1 Micro: 0.8873, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4566, Accuracy: 0.7997, F1 Micro: 0.8881, F1 Macro: 0.8821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4288, Accuracy: 0.8017, F1 Micro: 0.8893, F1 Macro: 0.8836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4243, Accuracy: 0.804, F1 Micro: 0.8907, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4161, Accuracy: 0.8135, F1 Micro: 0.8944, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4005, Accuracy: 0.8179, F1 Micro: 0.8965, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3794, Accuracy: 0.8247, F1 Micro: 0.9001, F1 Macro: 0.8939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3213, Accuracy: 0.8417, F1 Micro: 0.9083, F1 Macro: 0.9019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3264, Accuracy: 0.8519, F1 Micro: 0.9131, F1 Macro: 0.9062\n",
      "\n",
      "Aspect detection accuracy: 0.8519, F1 Micro: 0.9131, F1 Macro: 0.9062\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.88      1.00      0.94       462\n",
      "   air_panas       0.83      1.00      0.91       480\n",
      "         bau       0.87      0.98      0.92       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.78      0.78      0.78       317\n",
      "       linen       0.79      0.92      0.85       392\n",
      "     service       0.87      0.96      0.91       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.86      1.00      0.93       498\n",
      "\n",
      "   micro avg       0.86      0.97      0.91      4614\n",
      "   macro avg       0.86      0.96      0.91      4614\n",
      "weighted avg       0.86      0.97      0.91      4614\n",
      " samples avg       0.86      0.97      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5506, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4796, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4879, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4287, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3515, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3279, Accuracy: 0.7, F1 Micro: 0.7, F1 Macro: 0.6242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2793, Accuracy: 0.7073, F1 Micro: 0.7073, F1 Macro: 0.6432\n",
      "Epoch 8/10, Train Loss: 0.202, Accuracy: 0.6873, F1 Micro: 0.6873, F1 Macro: 0.6008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2003, Accuracy: 0.7309, F1 Micro: 0.7309, F1 Macro: 0.6829\n",
      "Epoch 10/10, Train Loss: 0.1315, Accuracy: 0.7109, F1 Micro: 0.7109, F1 Macro: 0.649\n",
      "\n",
      "Sentiment analysis accuracy: 0.7309, F1 Micro: 0.7309, F1 Macro: 0.6829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.93      0.81       332\n",
      "    positive       0.80      0.43      0.56       218\n",
      "\n",
      "    accuracy                           0.73       550\n",
      "   macro avg       0.75      0.68      0.68       550\n",
      "weighted avg       0.75      0.73      0.71       550\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8433, F1 Micro: 0.8433, F1 Macro: 0.4292\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.46      0.61        97\n",
      "     neutral       0.88      1.00      0.94       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.59      0.49      0.51       571\n",
      "weighted avg       0.86      0.88      0.86       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.28      0.33      0.30       571\n",
      "weighted avg       0.69      0.83      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.35      0.08      0.13        78\n",
      "     neutral       0.87      0.98      0.92       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.41      0.35      0.35       571\n",
      "weighted avg       0.79      0.85      0.81       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.69      0.71       200\n",
      "     neutral       0.78      0.77      0.78       315\n",
      "    positive       0.39      0.46      0.42        56\n",
      "\n",
      "    accuracy                           0.71       571\n",
      "   macro avg       0.63      0.64      0.64       571\n",
      "weighted avg       0.72      0.71      0.72       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.48      0.56       162\n",
      "     neutral       0.78      0.92      0.85       387\n",
      "    positive       0.50      0.09      0.15        22\n",
      "\n",
      "    accuracy                           0.76       571\n",
      "   macro avg       0.66      0.50      0.52       571\n",
      "weighted avg       0.75      0.76      0.74       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.49      0.57        85\n",
      "     neutral       0.87      0.96      0.91       418\n",
      "    positive       0.83      0.56      0.67        68\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.79      0.67      0.72       571\n",
      "weighted avg       0.83      0.84      0.83       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        74\n",
      "     neutral       0.87      1.00      0.93       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.80       571\n",
      "\n",
      "Total train time: 87.62715125083923 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.9259019494056702\n",
      "Samples above threshold: 215\n",
      "Acquired samples: 215\n",
      "Sampling duration: 14.03033185005188 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5516, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4382, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4022, Accuracy: 0.8016, F1 Micro: 0.8898, F1 Macro: 0.8854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3732, Accuracy: 0.8276, F1 Micro: 0.9025, F1 Macro: 0.8984\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3234, Accuracy: 0.8502, F1 Micro: 0.9138, F1 Macro: 0.9092\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2787, Accuracy: 0.8714, F1 Micro: 0.9251, F1 Macro: 0.9202\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2274, Accuracy: 0.9076, F1 Micro: 0.9446, F1 Macro: 0.9401\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2025, Accuracy: 0.9177, F1 Micro: 0.9502, F1 Macro: 0.946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1812, Accuracy: 0.9238, F1 Micro: 0.9536, F1 Macro: 0.9488\n",
      "Epoch 10/10, Train Loss: 0.1598, Accuracy: 0.922, F1 Micro: 0.9527, F1 Macro: 0.9489\n",
      "\n",
      "Aspect detection accuracy: 0.9238, F1 Micro: 0.9536, F1 Macro: 0.9488\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.92      0.99      0.96       480\n",
      "         bau       0.94      0.98      0.96       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.89      0.81      0.85       317\n",
      "       linen       0.87      0.97      0.92       392\n",
      "     service       0.93      0.98      0.95       423\n",
      "sunrise_meal       0.93      1.00      0.96       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.98      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.93      0.98      0.95      4614\n",
      "   macro avg       0.93      0.97      0.95      4614\n",
      "weighted avg       0.93      0.98      0.95      4614\n",
      " samples avg       0.93      0.98      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4196, Accuracy: 0.7218, F1 Micro: 0.7218, F1 Macro: 0.4192\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3402, Accuracy: 0.7218, F1 Micro: 0.7218, F1 Macro: 0.4192\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2607, Accuracy: 0.805, F1 Micro: 0.805, F1 Macro: 0.7076\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1821, Accuracy: 0.8171, F1 Micro: 0.8171, F1 Macro: 0.7252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1367, Accuracy: 0.8324, F1 Micro: 0.8324, F1 Macro: 0.7654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1295, Accuracy: 0.8401, F1 Micro: 0.8401, F1 Macro: 0.7743\n",
      "Epoch 7/10, Train Loss: 0.0938, Accuracy: 0.8313, F1 Micro: 0.8313, F1 Macro: 0.7603\n",
      "Epoch 8/10, Train Loss: 0.0775, Accuracy: 0.8072, F1 Micro: 0.8072, F1 Macro: 0.6834\n",
      "Epoch 9/10, Train Loss: 0.0773, Accuracy: 0.8346, F1 Micro: 0.8346, F1 Macro: 0.7587\n",
      "Epoch 10/10, Train Loss: 0.0852, Accuracy: 0.839, F1 Micro: 0.839, F1 Macro: 0.7746\n",
      "\n",
      "Sentiment analysis accuracy: 0.8401, F1 Micro: 0.8401, F1 Macro: 0.7743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.96      0.90       659\n",
      "    positive       0.83      0.54      0.65       254\n",
      "\n",
      "    accuracy                           0.84       913\n",
      "   macro avg       0.83      0.75      0.77       913\n",
      "weighted avg       0.84      0.84      0.83       913\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.5956\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.94      0.90        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       1.00      0.07      0.12        15\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.67      0.67       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.63      0.74        86\n",
      "     neutral       0.92      0.99      0.96       475\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.61      0.54      0.57       571\n",
      "weighted avg       0.90      0.92      0.91       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.62      0.69        78\n",
      "     neutral       0.94      0.98      0.96       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.58      0.53      0.55       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       1.00      0.01      0.03        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.62      0.34      0.32       571\n",
      "weighted avg       0.87      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.77      0.78       200\n",
      "     neutral       0.89      0.81      0.85       315\n",
      "    positive       0.49      0.80      0.61        56\n",
      "\n",
      "    accuracy                           0.79       571\n",
      "   macro avg       0.73      0.79      0.75       571\n",
      "weighted avg       0.82      0.79      0.80       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.72      0.77       162\n",
      "     neutral       0.87      0.97      0.92       387\n",
      "    positive       1.00      0.09      0.17        22\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.90      0.59      0.62       571\n",
      "weighted avg       0.87      0.86      0.85       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.61      0.71        85\n",
      "     neutral       0.93      0.98      0.95       418\n",
      "    positive       0.84      0.84      0.84        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.81      0.83       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.07      0.12        29\n",
      "     neutral       0.93      1.00      0.96       525\n",
      "    positive       0.50      0.06      0.11        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.70      0.38      0.40       571\n",
      "weighted avg       0.90      0.92      0.89       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.62      0.63      0.63       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.86      0.90        74\n",
      "     neutral       0.98      1.00      0.99       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.64      0.62      0.63       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Total train time: 115.68809056282043 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.09480521082878113\n",
      "Samples above threshold: 193\n",
      "Acquired samples: 193\n",
      "Sampling duration: 17.64249324798584 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5169, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4429, Accuracy: 0.8118, F1 Micro: 0.8927, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3956, Accuracy: 0.8361, F1 Micro: 0.9054, F1 Macro: 0.8993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3251, Accuracy: 0.8687, F1 Micro: 0.9224, F1 Macro: 0.9161\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2889, Accuracy: 0.9042, F1 Micro: 0.9421, F1 Macro: 0.9372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2425, Accuracy: 0.9226, F1 Micro: 0.9531, F1 Macro: 0.9498\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1988, Accuracy: 0.9233, F1 Micro: 0.9536, F1 Macro: 0.9503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1844, Accuracy: 0.9354, F1 Micro: 0.9604, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1533, Accuracy: 0.9387, F1 Micro: 0.9625, F1 Macro: 0.959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1356, Accuracy: 0.9391, F1 Micro: 0.9627, F1 Macro: 0.9596\n",
      "\n",
      "Aspect detection accuracy: 0.9391, F1 Micro: 0.9627, F1 Macro: 0.9596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.94      0.99      0.96       480\n",
      "         bau       0.95      0.98      0.96       496\n",
      "     general       0.90      0.99      0.94       500\n",
      "  kebersihan       0.89      0.91      0.90       317\n",
      "       linen       0.87      0.98      0.92       392\n",
      "     service       0.94      0.97      0.96       423\n",
      "sunrise_meal       0.97      0.99      0.98       530\n",
      "          tv       0.98      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      4614\n",
      "   macro avg       0.94      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.96      4614\n",
      " samples avg       0.94      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5812, Accuracy: 0.7226, F1 Micro: 0.7226, F1 Macro: 0.4687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3755, Accuracy: 0.8092, F1 Micro: 0.8092, F1 Macro: 0.7104\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3051, Accuracy: 0.8457, F1 Micro: 0.8457, F1 Macro: 0.7914\n",
      "Epoch 4/10, Train Loss: 0.2563, Accuracy: 0.8436, F1 Micro: 0.8436, F1 Macro: 0.8035\n",
      "Epoch 5/10, Train Loss: 0.1834, Accuracy: 0.8436, F1 Micro: 0.8436, F1 Macro: 0.7766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1425, Accuracy: 0.854, F1 Micro: 0.854, F1 Macro: 0.7942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1244, Accuracy: 0.854, F1 Micro: 0.854, F1 Macro: 0.7961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1326, Accuracy: 0.8592, F1 Micro: 0.8592, F1 Macro: 0.8043\n",
      "Epoch 9/10, Train Loss: 0.0909, Accuracy: 0.8551, F1 Micro: 0.8551, F1 Macro: 0.796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1045, Accuracy: 0.8738, F1 Micro: 0.8738, F1 Macro: 0.8288\n",
      "\n",
      "Sentiment analysis accuracy: 0.8738, F1 Micro: 0.8738, F1 Macro: 0.8288\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.98      0.92       680\n",
      "    positive       0.92      0.62      0.74       279\n",
      "\n",
      "    accuracy                           0.87       959\n",
      "   macro avg       0.89      0.80      0.83       959\n",
      "weighted avg       0.88      0.87      0.87       959\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9303, F1 Micro: 0.9303, F1 Macro: 0.7546\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.92      0.92        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.91      0.67      0.77        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.94      0.86      0.89       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.65      0.77        86\n",
      "     neutral       0.94      0.99      0.96       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.81      0.68      0.73       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.71      0.75        78\n",
      "     neutral       0.95      0.98      0.96       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.56      0.57       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.90      0.99      0.94       496\n",
      "    positive       0.81      0.32      0.46        68\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.57      0.44      0.47       571\n",
      "weighted avg       0.88      0.90      0.88       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.80      0.81       200\n",
      "     neutral       0.89      0.90      0.90       315\n",
      "    positive       0.83      0.80      0.82        56\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.85      0.84      0.84       571\n",
      "weighted avg       0.86      0.86      0.86       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.72      0.79       162\n",
      "     neutral       0.87      0.98      0.92       387\n",
      "    positive       0.60      0.14      0.22        22\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.78      0.61      0.64       571\n",
      "weighted avg       0.86      0.87      0.86       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.78      0.79        85\n",
      "     neutral       0.94      0.97      0.96       418\n",
      "    positive       0.97      0.82      0.89        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.86      0.88       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.45      0.54        29\n",
      "     neutral       0.97      0.99      0.98       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.75      0.77       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.85        54\n",
      "     neutral       0.98      1.00      0.99       511\n",
      "    positive       0.75      0.50      0.60         6\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.77      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.89      0.93        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.96      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 151.96565985679626 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.032882559299469\n",
      "Samples above threshold: 174\n",
      "Acquired samples: 174\n",
      "Sampling duration: 16.426979303359985 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5181, Accuracy: 0.8007, F1 Micro: 0.8892, F1 Macro: 0.8845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4459, Accuracy: 0.8201, F1 Micro: 0.8974, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3862, Accuracy: 0.8554, F1 Micro: 0.9154, F1 Macro: 0.9095\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3288, Accuracy: 0.9083, F1 Micro: 0.9452, F1 Macro: 0.9414\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2657, Accuracy: 0.9156, F1 Micro: 0.9494, F1 Macro: 0.9461\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2207, Accuracy: 0.9325, F1 Micro: 0.9587, F1 Macro: 0.9548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1842, Accuracy: 0.9418, F1 Micro: 0.9645, F1 Macro: 0.9619\n",
      "Epoch 8/10, Train Loss: 0.1601, Accuracy: 0.9385, F1 Micro: 0.9626, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1397, Accuracy: 0.9444, F1 Micro: 0.966, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1263, Accuracy: 0.9507, F1 Micro: 0.9697, F1 Macro: 0.9672\n",
      "\n",
      "Aspect detection accuracy: 0.9507, F1 Micro: 0.9697, F1 Macro: 0.9672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.95      0.99      0.97       480\n",
      "         bau       0.95      0.98      0.97       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.89      0.94      0.91       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.96      1.00      0.98       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      4614\n",
      "   macro avg       0.95      0.98      0.97      4614\n",
      "weighted avg       0.96      0.99      0.97      4614\n",
      " samples avg       0.95      0.99      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5253, Accuracy: 0.7852, F1 Micro: 0.7852, F1 Macro: 0.7541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3758, Accuracy: 0.846, F1 Micro: 0.846, F1 Macro: 0.7709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2857, Accuracy: 0.8551, F1 Micro: 0.8551, F1 Macro: 0.8158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2364, Accuracy: 0.8875, F1 Micro: 0.8875, F1 Macro: 0.847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.217, Accuracy: 0.8977, F1 Micro: 0.8977, F1 Macro: 0.8596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1378, Accuracy: 0.8997, F1 Micro: 0.8997, F1 Macro: 0.8616\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0982, Accuracy: 0.9007, F1 Micro: 0.9007, F1 Macro: 0.8636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.095, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8714\n",
      "Epoch 9/10, Train Loss: 0.086, Accuracy: 0.8987, F1 Micro: 0.8987, F1 Macro: 0.8616\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0543, Accuracy: 0.9037, F1 Micro: 0.9037, F1 Macro: 0.8702\n",
      "\n",
      "Sentiment analysis accuracy: 0.9037, F1 Micro: 0.9037, F1 Macro: 0.8702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       717\n",
      "    positive       0.91      0.72      0.80       270\n",
      "\n",
      "    accuracy                           0.90       987\n",
      "   macro avg       0.90      0.85      0.87       987\n",
      "weighted avg       0.90      0.90      0.90       987\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9441, F1 Micro: 0.9441, F1 Macro: 0.8161\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.72      0.81        86\n",
      "     neutral       0.95      0.99      0.97       475\n",
      "    positive       0.50      0.30      0.37        10\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.79      0.67      0.72       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.69      0.77        78\n",
      "     neutral       0.95      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.73      0.80       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.96       496\n",
      "    positive       0.91      0.47      0.62        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.61      0.49      0.53       571\n",
      "weighted avg       0.91      0.92      0.90       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.80      0.84       200\n",
      "     neutral       0.89      0.94      0.91       315\n",
      "    positive       0.86      0.86      0.86        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.88      0.87      0.87       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.78      0.84       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.62      0.45      0.53        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.81      0.74      0.77       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.87      0.86        85\n",
      "     neutral       0.96      0.97      0.97       418\n",
      "    positive       0.95      0.88      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.34      0.49        29\n",
      "     neutral       0.96      1.00      0.98       525\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.68      0.74       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.97      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 181.678142786026 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0222365140914917\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 156\n",
      "Sampling duration: 14.83829665184021 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5212, Accuracy: 0.801, F1 Micro: 0.8894, F1 Macro: 0.8849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4444, Accuracy: 0.8368, F1 Micro: 0.9057, F1 Macro: 0.8993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3553, Accuracy: 0.8941, F1 Micro: 0.937, F1 Macro: 0.9321\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2853, Accuracy: 0.9274, F1 Micro: 0.9561, F1 Macro: 0.9527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2185, Accuracy: 0.9352, F1 Micro: 0.9607, F1 Macro: 0.9576\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1915, Accuracy: 0.9436, F1 Micro: 0.9655, F1 Macro: 0.9626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.165, Accuracy: 0.9474, F1 Micro: 0.9678, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1364, Accuracy: 0.951, F1 Micro: 0.9699, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1139, Accuracy: 0.955, F1 Micro: 0.9722, F1 Macro: 0.9697\n",
      "Epoch 10/10, Train Loss: 0.1059, Accuracy: 0.9538, F1 Micro: 0.9715, F1 Macro: 0.9686\n",
      "\n",
      "Aspect detection accuracy: 0.955, F1 Micro: 0.9722, F1 Macro: 0.9697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.96      1.00      0.98       480\n",
      "         bau       0.95      0.98      0.96       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.91      0.93      0.92       317\n",
      "       linen       0.93      0.95      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4957, Accuracy: 0.8111, F1 Micro: 0.8111, F1 Macro: 0.7158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3534, Accuracy: 0.8581, F1 Micro: 0.8581, F1 Macro: 0.8037\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2774, Accuracy: 0.8869, F1 Micro: 0.8869, F1 Macro: 0.8536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2209, Accuracy: 0.8907, F1 Micro: 0.8907, F1 Macro: 0.8572\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.163, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8743\n",
      "Epoch 6/10, Train Loss: 0.1147, Accuracy: 0.8936, F1 Micro: 0.8936, F1 Macro: 0.8591\n",
      "Epoch 7/10, Train Loss: 0.0864, Accuracy: 0.8897, F1 Micro: 0.8897, F1 Macro: 0.8517\n",
      "Epoch 8/10, Train Loss: 0.0879, Accuracy: 0.884, F1 Micro: 0.884, F1 Macro: 0.8415\n",
      "Epoch 9/10, Train Loss: 0.0605, Accuracy: 0.8955, F1 Micro: 0.8955, F1 Macro: 0.8646\n",
      "Epoch 10/10, Train Loss: 0.043, Accuracy: 0.8907, F1 Micro: 0.8907, F1 Macro: 0.8551\n",
      "\n",
      "Sentiment analysis accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       740\n",
      "    positive       0.92      0.73      0.81       303\n",
      "\n",
      "    accuracy                           0.90      1043\n",
      "   macro avg       0.91      0.85      0.87      1043\n",
      "weighted avg       0.90      0.90      0.90      1043\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.8315\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.79      0.86        86\n",
      "     neutral       0.96      1.00      0.98       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.73      0.78       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.71      0.76        78\n",
      "     neutral       0.95      0.98      0.96       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.73      0.80       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.87      0.60      0.71        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.53      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86       200\n",
      "     neutral       0.91      0.93      0.92       315\n",
      "    positive       0.80      0.95      0.87        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.87      0.90      0.88       571\n",
      "weighted avg       0.90      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.84      0.84       162\n",
      "     neutral       0.93      0.95      0.94       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.85      0.75      0.79       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.88      0.74      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.86      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.98      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 199.55348539352417 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.022836816310882566\n",
      "Samples above threshold: 141\n",
      "Acquired samples: 141\n",
      "Sampling duration: 13.578568696975708 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5205, Accuracy: 0.8026, F1 Micro: 0.8901, F1 Macro: 0.8854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4258, Accuracy: 0.8599, F1 Micro: 0.9183, F1 Macro: 0.9119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3303, Accuracy: 0.9189, F1 Micro: 0.9508, F1 Macro: 0.9462\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2575, Accuracy: 0.9342, F1 Micro: 0.96, F1 Macro: 0.9567\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2057, Accuracy: 0.9403, F1 Micro: 0.9636, F1 Macro: 0.9604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1729, Accuracy: 0.9438, F1 Micro: 0.9657, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1473, Accuracy: 0.9523, F1 Micro: 0.9706, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1329, Accuracy: 0.9533, F1 Micro: 0.9712, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1109, Accuracy: 0.9547, F1 Micro: 0.972, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.097, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9714\n",
      "\n",
      "Aspect detection accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.95      0.99      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.95      0.91      0.93       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5154, Accuracy: 0.8487, F1 Micro: 0.8487, F1 Macro: 0.8051\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3357, Accuracy: 0.8684, F1 Micro: 0.8684, F1 Macro: 0.8219\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2309, Accuracy: 0.8919, F1 Micro: 0.8919, F1 Macro: 0.8575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1859, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8731\n",
      "Epoch 5/10, Train Loss: 0.1441, Accuracy: 0.8919, F1 Micro: 0.8919, F1 Macro: 0.8557\n",
      "Epoch 6/10, Train Loss: 0.1126, Accuracy: 0.89, F1 Micro: 0.89, F1 Macro: 0.8501\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0853, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0539, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8791\n",
      "Epoch 9/10, Train Loss: 0.0601, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0519, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8815\n",
      "\n",
      "Sentiment analysis accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       756\n",
      "    positive       0.95      0.73      0.82       308\n",
      "\n",
      "    accuracy                           0.91      1064\n",
      "   macro avg       0.92      0.86      0.88      1064\n",
      "weighted avg       0.91      0.91      0.91      1064\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.854\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.86      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.78      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.69      0.78        78\n",
      "     neutral       0.95      0.99      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.95      0.73      0.80       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.65      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.76      0.59      0.64       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.90      0.88       200\n",
      "     neutral       0.95      0.91      0.93       315\n",
      "    positive       0.82      0.89      0.85        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.88      0.90      0.89       571\n",
      "weighted avg       0.91      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.80      0.84       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.70      0.32      0.44        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.83      0.70      0.74       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.85      0.65      0.73        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.88      0.74      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 232.1781144142151 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.01518511772155762\n",
      "Samples above threshold: 127\n",
      "Acquired samples: 127\n",
      "Sampling duration: 11.9324369430542 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5156, Accuracy: 0.8083, F1 Micro: 0.8924, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4089, Accuracy: 0.8934, F1 Micro: 0.9358, F1 Macro: 0.9277\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3013, Accuracy: 0.9285, F1 Micro: 0.9567, F1 Macro: 0.9532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2368, Accuracy: 0.9394, F1 Micro: 0.9631, F1 Macro: 0.9604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.192, Accuracy: 0.9484, F1 Micro: 0.9683, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1569, Accuracy: 0.9545, F1 Micro: 0.9719, F1 Macro: 0.9691\n",
      "Epoch 7/10, Train Loss: 0.1344, Accuracy: 0.9479, F1 Micro: 0.9681, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1173, Accuracy: 0.9585, F1 Micro: 0.9743, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1029, Accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0901, Accuracy: 0.9604, F1 Micro: 0.9754, F1 Macro: 0.973\n",
      "\n",
      "Aspect detection accuracy: 0.9604, F1 Micro: 0.9754, F1 Macro: 0.973\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.93      0.94      0.93       317\n",
      "       linen       0.93      0.94      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4569, Accuracy: 0.8037, F1 Micro: 0.8037, F1 Macro: 0.7038\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3402, Accuracy: 0.8645, F1 Micro: 0.8645, F1 Macro: 0.8208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2376, Accuracy: 0.8737, F1 Micro: 0.8737, F1 Macro: 0.8292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1688, Accuracy: 0.894, F1 Micro: 0.894, F1 Macro: 0.8624\n",
      "Epoch 5/10, Train Loss: 0.124, Accuracy: 0.8857, F1 Micro: 0.8857, F1 Macro: 0.8479\n",
      "Epoch 6/10, Train Loss: 0.1162, Accuracy: 0.8857, F1 Micro: 0.8857, F1 Macro: 0.8483\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0977, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8684\n",
      "Epoch 8/10, Train Loss: 0.0522, Accuracy: 0.8959, F1 Micro: 0.8959, F1 Macro: 0.8632\n",
      "Epoch 9/10, Train Loss: 0.0475, Accuracy: 0.8949, F1 Micro: 0.8949, F1 Macro: 0.8605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0464, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8765\n",
      "\n",
      "Sentiment analysis accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.94       766\n",
      "    positive       0.94      0.72      0.82       319\n",
      "\n",
      "    accuracy                           0.91      1085\n",
      "   macro avg       0.92      0.85      0.88      1085\n",
      "weighted avg       0.91      0.91      0.90      1085\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9546, F1 Micro: 0.9546, F1 Macro: 0.8611\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.79      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.89      0.71      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.95      0.61      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87       200\n",
      "     neutral       0.92      0.94      0.93       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85       162\n",
      "     neutral       0.93      0.94      0.94       387\n",
      "    positive       0.69      0.41      0.51        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.82      0.74      0.77       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.91      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.45      0.58        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.75      0.71      0.73        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.72      0.76       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 244.2336311340332 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.012516486644744874\n",
      "Samples above threshold: 114\n",
      "Acquired samples: 114\n",
      "Sampling duration: 10.818077802658081 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5073, Accuracy: 0.8191, F1 Micro: 0.8972, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3948, Accuracy: 0.9024, F1 Micro: 0.9417, F1 Macro: 0.9368\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2831, Accuracy: 0.9349, F1 Micro: 0.9603, F1 Macro: 0.957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2139, Accuracy: 0.9444, F1 Micro: 0.966, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1788, Accuracy: 0.9469, F1 Micro: 0.9675, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1491, Accuracy: 0.954, F1 Micro: 0.9716, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1333, Accuracy: 0.9583, F1 Micro: 0.9743, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1143, Accuracy: 0.9589, F1 Micro: 0.9745, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.097, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9731\n",
      "Epoch 10/10, Train Loss: 0.0825, Accuracy: 0.9585, F1 Micro: 0.9743, F1 Macro: 0.972\n",
      "\n",
      "Aspect detection accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.99       480\n",
      "         bau       0.96      0.97      0.96       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.92      0.96      0.94       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4436, Accuracy: 0.8673, F1 Micro: 0.8673, F1 Macro: 0.8262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2682, Accuracy: 0.8796, F1 Micro: 0.8796, F1 Macro: 0.8394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2315, Accuracy: 0.8948, F1 Micro: 0.8948, F1 Macro: 0.8596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1295, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8828\n",
      "Epoch 5/10, Train Loss: 0.1091, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8753\n",
      "Epoch 6/10, Train Loss: 0.0702, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8704\n",
      "Epoch 7/10, Train Loss: 0.0604, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8726\n",
      "Epoch 8/10, Train Loss: 0.0524, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0373, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8803\n",
      "Epoch 10/10, Train Loss: 0.0447, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8632\n",
      "\n",
      "Sentiment analysis accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       752\n",
      "    positive       0.92      0.74      0.82       303\n",
      "\n",
      "    accuracy                           0.91      1055\n",
      "   macro avg       0.91      0.86      0.88      1055\n",
      "weighted avg       0.91      0.91      0.90      1055\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9532, F1 Micro: 0.9532, F1 Macro: 0.8685\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.86      0.91        86\n",
      "     neutral       0.97      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.76      0.77        78\n",
      "     neutral       0.96      0.97      0.96       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.88      0.68      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.60      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88       200\n",
      "     neutral       0.91      0.96      0.93       315\n",
      "    positive       0.88      0.88      0.88        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.89      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.80      0.83       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.61      0.50      0.55        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.80      0.75      0.77       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.95      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.45      0.58        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.82      0.74        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.76      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 254.21128845214844 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.011407971382141113\n",
      "Samples above threshold: 103\n",
      "Acquired samples: 103\n",
      "Sampling duration: 9.655101537704468 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5004, Accuracy: 0.8118, F1 Micro: 0.8944, F1 Macro: 0.889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3722, Accuracy: 0.901, F1 Micro: 0.9414, F1 Macro: 0.9375\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2435, Accuracy: 0.9363, F1 Micro: 0.9613, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2049, Accuracy: 0.9453, F1 Micro: 0.9664, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1578, Accuracy: 0.9514, F1 Micro: 0.9701, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1424, Accuracy: 0.9557, F1 Micro: 0.9726, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1203, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9729\n",
      "Epoch 8/10, Train Loss: 0.1037, Accuracy: 0.9587, F1 Micro: 0.9744, F1 Macro: 0.9719\n",
      "Epoch 9/10, Train Loss: 0.0866, Accuracy: 0.9601, F1 Micro: 0.9751, F1 Macro: 0.9723\n",
      "Epoch 10/10, Train Loss: 0.0763, Accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.9729\n",
      "\n",
      "Aspect detection accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.95      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.93      0.92      0.93       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4464, Accuracy: 0.8407, F1 Micro: 0.8407, F1 Macro: 0.808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.273, Accuracy: 0.8878, F1 Micro: 0.8878, F1 Macro: 0.8545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1965, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8676\n",
      "Epoch 4/10, Train Loss: 0.1229, Accuracy: 0.8907, F1 Micro: 0.8907, F1 Macro: 0.853\n",
      "Epoch 5/10, Train Loss: 0.0989, Accuracy: 0.8963, F1 Micro: 0.8963, F1 Macro: 0.8624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0631, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0552, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8841\n",
      "Epoch 8/10, Train Loss: 0.0505, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8808\n",
      "Epoch 9/10, Train Loss: 0.0491, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8753\n",
      "Epoch 10/10, Train Loss: 0.039, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8816\n",
      "\n",
      "Sentiment analysis accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8841\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       753\n",
      "    positive       0.95      0.73      0.83       308\n",
      "\n",
      "    accuracy                           0.91      1061\n",
      "   macro avg       0.92      0.86      0.88      1061\n",
      "weighted avg       0.91      0.91      0.91      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9546, F1 Micro: 0.9546, F1 Macro: 0.8604\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.86      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.72      0.78        78\n",
      "     neutral       0.95      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.73      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.89      0.71      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.95      0.61      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.87       200\n",
      "     neutral       0.93      0.92      0.93       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.83      0.84       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.73      0.78       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.84      0.88        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.59      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.76      0.80       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 270.272691488266 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.014164423942565918\n",
      "Samples above threshold: 92\n",
      "Acquired samples: 62\n",
      "Sampling duration: 9.066980123519897 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4974, Accuracy: 0.8189, F1 Micro: 0.8979, F1 Macro: 0.8924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3694, Accuracy: 0.9108, F1 Micro: 0.9467, F1 Macro: 0.943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2483, Accuracy: 0.9358, F1 Micro: 0.9607, F1 Macro: 0.9564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1959, Accuracy: 0.9484, F1 Micro: 0.9684, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1623, Accuracy: 0.9507, F1 Micro: 0.9697, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1368, Accuracy: 0.9559, F1 Micro: 0.9728, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.119, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1006, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0868, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0741, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4406, Accuracy: 0.8665, F1 Micro: 0.8665, F1 Macro: 0.8299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2861, Accuracy: 0.8842, F1 Micro: 0.8842, F1 Macro: 0.8488\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1979, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8773\n",
      "Epoch 4/10, Train Loss: 0.1273, Accuracy: 0.9018, F1 Micro: 0.9018, F1 Macro: 0.8734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1219, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.065, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8837\n",
      "Epoch 7/10, Train Loss: 0.063, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0567, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0421, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8898\n",
      "Epoch 10/10, Train Loss: 0.0385, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8845\n",
      "\n",
      "Sentiment analysis accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       767\n",
      "    positive       0.92      0.77      0.84       312\n",
      "\n",
      "    accuracy                           0.91      1079\n",
      "   macro avg       0.91      0.87      0.89      1079\n",
      "weighted avg       0.91      0.91      0.91      1079\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9573, F1 Micro: 0.9573, F1 Macro: 0.8713\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.73      0.79        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.74      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.29      0.40         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.88      0.74      0.80        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.83      0.67      0.72       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.83      0.96      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.79      0.83       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.64      0.41      0.50        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.81      0.72      0.76       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.94      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.81      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 284.6783092021942 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.00875866413116455\n",
      "Samples above threshold: 86\n",
      "Acquired samples: 86\n",
      "Sampling duration: 8.649420976638794 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4906, Accuracy: 0.8203, F1 Micro: 0.8984, F1 Macro: 0.8933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.354, Accuracy: 0.9226, F1 Micro: 0.9531, F1 Macro: 0.9489\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2375, Accuracy: 0.9425, F1 Micro: 0.9649, F1 Macro: 0.9622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1873, Accuracy: 0.9495, F1 Micro: 0.9689, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1579, Accuracy: 0.9568, F1 Micro: 0.9733, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1394, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9722\n",
      "Epoch 7/10, Train Loss: 0.111, Accuracy: 0.9589, F1 Micro: 0.9746, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0914, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0826, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0742, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9748\n",
      "\n",
      "Aspect detection accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.94      0.94       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       0.99      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4154, Accuracy: 0.8619, F1 Micro: 0.8619, F1 Macro: 0.8139\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2382, Accuracy: 0.8897, F1 Micro: 0.8897, F1 Macro: 0.8614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1723, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1368, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8751\n",
      "Epoch 5/10, Train Loss: 0.0904, Accuracy: 0.9018, F1 Micro: 0.9018, F1 Macro: 0.8691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0743, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8824\n",
      "Epoch 7/10, Train Loss: 0.0582, Accuracy: 0.8999, F1 Micro: 0.8999, F1 Macro: 0.8679\n",
      "Epoch 8/10, Train Loss: 0.0351, Accuracy: 0.899, F1 Micro: 0.899, F1 Macro: 0.8665\n",
      "Epoch 9/10, Train Loss: 0.0423, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8811\n",
      "Epoch 10/10, Train Loss: 0.0268, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8792\n",
      "\n",
      "Sentiment analysis accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       766\n",
      "    positive       0.93      0.74      0.83       313\n",
      "\n",
      "    accuracy                           0.91      1079\n",
      "   macro avg       0.92      0.86      0.88      1079\n",
      "weighted avg       0.91      0.91      0.91      1079\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.8724\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.76      0.78        78\n",
      "     neutral       0.96      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.91      0.92       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.87      0.69      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.61      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91       200\n",
      "     neutral       0.95      0.94      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.64      0.41      0.50        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.80      0.73      0.76       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.55      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.75      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.96      0.97        74\n",
      "     neutral       0.99      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 292.10133242607117 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.008106225728988647\n",
      "Samples above threshold: 77\n",
      "Acquired samples: 77\n",
      "Sampling duration: 7.602010488510132 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4843, Accuracy: 0.8313, F1 Micro: 0.9027, F1 Macro: 0.8942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3361, Accuracy: 0.9241, F1 Micro: 0.954, F1 Macro: 0.95\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2274, Accuracy: 0.9444, F1 Micro: 0.966, F1 Macro: 0.9632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1831, Accuracy: 0.9491, F1 Micro: 0.9688, F1 Macro: 0.9664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1515, Accuracy: 0.958, F1 Micro: 0.974, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1282, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9733\n",
      "Epoch 7/10, Train Loss: 0.1062, Accuracy: 0.9601, F1 Micro: 0.9752, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0915, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9734\n",
      "Epoch 9/10, Train Loss: 0.0784, Accuracy: 0.9583, F1 Micro: 0.9743, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0663, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.95      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       0.99      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4289, Accuracy: 0.8561, F1 Micro: 0.8561, F1 Macro: 0.81\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2455, Accuracy: 0.8801, F1 Micro: 0.8801, F1 Macro: 0.8449\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1746, Accuracy: 0.8884, F1 Micro: 0.8884, F1 Macro: 0.8517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.119, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.87\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0883, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0621, Accuracy: 0.9022, F1 Micro: 0.9022, F1 Macro: 0.8712\n",
      "Epoch 7/10, Train Loss: 0.0573, Accuracy: 0.8994, F1 Micro: 0.8994, F1 Macro: 0.8692\n",
      "Epoch 8/10, Train Loss: 0.0486, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8697\n",
      "Epoch 9/10, Train Loss: 0.0254, Accuracy: 0.8994, F1 Micro: 0.8994, F1 Macro: 0.8671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0329, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8749\n",
      "\n",
      "Sentiment analysis accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       768\n",
      "    positive       0.92      0.73      0.82       316\n",
      "\n",
      "    accuracy                           0.90      1084\n",
      "   macro avg       0.91      0.85      0.87      1084\n",
      "weighted avg       0.90      0.90      0.90      1084\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9548, F1 Micro: 0.9548, F1 Macro: 0.8611\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.58      0.70      0.64        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.85      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.71      0.77        78\n",
      "     neutral       0.95      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.90      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.86      0.65      0.74        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.59      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.83      0.84       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.78      0.32      0.45        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.85      0.70      0.74       571\n",
      "weighted avg       0.90      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.89      0.88        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.48      0.60        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.82      0.74        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.77      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.95      0.97        74\n",
      "     neutral       0.99      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.98      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 305.59789204597473 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.007796096801757813\n",
      "Samples above threshold: 70\n",
      "Acquired samples: 70\n",
      "Sampling duration: 7.0232093334198 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.482, Accuracy: 0.8293, F1 Micro: 0.9031, F1 Macro: 0.899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3324, Accuracy: 0.9219, F1 Micro: 0.953, F1 Macro: 0.9499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.223, Accuracy: 0.9429, F1 Micro: 0.9652, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.178, Accuracy: 0.9533, F1 Micro: 0.9712, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1423, Accuracy: 0.9576, F1 Micro: 0.9738, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1219, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9729\n",
      "Epoch 7/10, Train Loss: 0.1035, Accuracy: 0.9594, F1 Micro: 0.9748, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0901, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0774, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "Epoch 10/10, Train Loss: 0.0666, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3944, Accuracy: 0.8566, F1 Micro: 0.8566, F1 Macro: 0.8205\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.24, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1694, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1153, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8792\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0988, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8811\n",
      "Epoch 6/10, Train Loss: 0.0778, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0572, Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0434, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8899\n",
      "Epoch 9/10, Train Loss: 0.0299, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.887\n",
      "Epoch 10/10, Train Loss: 0.0299, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8822\n",
      "\n",
      "Sentiment analysis accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       774\n",
      "    positive       0.94      0.75      0.84       314\n",
      "\n",
      "    accuracy                           0.92      1088\n",
      "   macro avg       0.93      0.87      0.89      1088\n",
      "weighted avg       0.92      0.92      0.91      1088\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.8783\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.88      0.72      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.94      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.75      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.55      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.77      0.80       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 312.8909249305725 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.007847809791564941\n",
      "Samples above threshold: 63\n",
      "Acquired samples: 52\n",
      "Sampling duration: 6.4488561153411865 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4798, Accuracy: 0.8313, F1 Micro: 0.9039, F1 Macro: 0.8989\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3216, Accuracy: 0.9278, F1 Micro: 0.9564, F1 Macro: 0.9531\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2143, Accuracy: 0.9443, F1 Micro: 0.9659, F1 Macro: 0.9638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1763, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1423, Accuracy: 0.9566, F1 Micro: 0.9732, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1184, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1028, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0849, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.0718, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0634, Accuracy: 0.9649, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3996, Accuracy: 0.8606, F1 Micro: 0.8606, F1 Macro: 0.8204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.225, Accuracy: 0.899, F1 Micro: 0.899, F1 Macro: 0.8736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1684, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1134, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0853, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.8978\n",
      "Epoch 6/10, Train Loss: 0.0726, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8931\n",
      "Epoch 7/10, Train Loss: 0.0563, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8886\n",
      "Epoch 8/10, Train Loss: 0.0398, Accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.8927\n",
      "Epoch 9/10, Train Loss: 0.0454, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.8946\n",
      "Epoch 10/10, Train Loss: 0.0298, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8898\n",
      "\n",
      "Sentiment analysis accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.8978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       763\n",
      "    positive       0.93      0.78      0.85       306\n",
      "\n",
      "    accuracy                           0.92      1069\n",
      "   macro avg       0.92      0.88      0.90      1069\n",
      "weighted avg       0.92      0.92      0.92      1069\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.8688\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.85      0.90        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.78      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.76      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.91      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.76      0.80        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.60      0.58      0.59       571\n",
      "weighted avg       0.93      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.85      0.93      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.91      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.80      0.84       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.73      0.50      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.76      0.79       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.90        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 319.804283618927 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.006881058216094971\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 58\n",
      "Sampling duration: 5.919281959533691 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4728, Accuracy: 0.8457, F1 Micro: 0.9112, F1 Macro: 0.9066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3045, Accuracy: 0.9321, F1 Micro: 0.9589, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2121, Accuracy: 0.9434, F1 Micro: 0.9653, F1 Macro: 0.9624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1663, Accuracy: 0.9516, F1 Micro: 0.9703, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1351, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1155, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9748\n",
      "Epoch 7/10, Train Loss: 0.0988, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0844, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0709, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0623, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.93       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4017, Accuracy: 0.8626, F1 Micro: 0.8626, F1 Macro: 0.8162\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.249, Accuracy: 0.8935, F1 Micro: 0.8935, F1 Macro: 0.861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1713, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8743\n",
      "Epoch 4/10, Train Loss: 0.1016, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0699, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8865\n",
      "Epoch 6/10, Train Loss: 0.0539, Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8829\n",
      "Epoch 7/10, Train Loss: 0.0337, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8795\n",
      "Epoch 8/10, Train Loss: 0.0571, Accuracy: 0.8999, F1 Micro: 0.8999, F1 Macro: 0.8697\n",
      "Epoch 9/10, Train Loss: 0.0325, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8728\n",
      "Epoch 10/10, Train Loss: 0.0349, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8774\n",
      "\n",
      "Sentiment analysis accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       776\n",
      "    positive       0.94      0.75      0.83       323\n",
      "\n",
      "    accuracy                           0.91      1099\n",
      "   macro avg       0.92      0.86      0.89      1099\n",
      "weighted avg       0.91      0.91      0.91      1099\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.8652\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.82       571\n",
      "weighted avg       0.96      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.77      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.85      0.76      0.81        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.63      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90       200\n",
      "     neutral       0.95      0.92      0.93       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.86       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.74      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 326.49408626556396 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.006831729412078858\n",
      "Samples above threshold: 52\n",
      "Acquired samples: 52\n",
      "Sampling duration: 5.66582989692688 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.481, Accuracy: 0.8425, F1 Micro: 0.9097, F1 Macro: 0.9052\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.312, Accuracy: 0.9356, F1 Micro: 0.9607, F1 Macro: 0.958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2117, Accuracy: 0.9469, F1 Micro: 0.9674, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1669, Accuracy: 0.9556, F1 Micro: 0.9725, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1414, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1145, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9756\n",
      "Epoch 7/10, Train Loss: 0.1003, Accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0824, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0708, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0609, Accuracy: 0.9668, F1 Micro: 0.9794, F1 Macro: 0.9774\n",
      "\n",
      "Aspect detection accuracy: 0.9668, F1 Micro: 0.9794, F1 Macro: 0.9774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.94      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3839, Accuracy: 0.859, F1 Micro: 0.859, F1 Macro: 0.8074\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2356, Accuracy: 0.8924, F1 Micro: 0.8924, F1 Macro: 0.8638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.168, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1258, Accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.8832\n",
      "Epoch 5/10, Train Loss: 0.0892, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0611, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0408, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.8906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0424, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.891\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0303, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0277, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.8975\n",
      "\n",
      "Sentiment analysis accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.8975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       782\n",
      "    positive       0.94      0.78      0.85       324\n",
      "\n",
      "    accuracy                           0.92      1106\n",
      "   macro avg       0.93      0.88      0.90      1106\n",
      "weighted avg       0.92      0.92      0.92      1106\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9615, F1 Micro: 0.9615, F1 Macro: 0.9012\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.86      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.85      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.43      0.55         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.78      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.85      0.73      0.78       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.91       200\n",
      "     neutral       0.95      0.94      0.94       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.67      0.55      0.60        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.83      0.78      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.89      0.88        85\n",
      "     neutral       0.98      0.97      0.98       418\n",
      "    positive       0.96      0.94      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 341.5023226737976 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.005720198154449463\n",
      "Samples above threshold: 47\n",
      "Acquired samples: 50\n",
      "Sampling duration: 5.28979229927063 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4705, Accuracy: 0.8398, F1 Micro: 0.9085, F1 Macro: 0.9036\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2994, Accuracy: 0.9387, F1 Micro: 0.9626, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2009, Accuracy: 0.9457, F1 Micro: 0.9667, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1569, Accuracy: 0.9543, F1 Micro: 0.9718, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1304, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9735\n",
      "Epoch 6/10, Train Loss: 0.1126, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0917, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0808, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0687, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0576, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.95      0.91      0.93       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3835, Accuracy: 0.8562, F1 Micro: 0.8562, F1 Macro: 0.8061\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2298, Accuracy: 0.8899, F1 Micro: 0.8899, F1 Macro: 0.8531\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1478, Accuracy: 0.8899, F1 Micro: 0.8899, F1 Macro: 0.8517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1095, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0841, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8834\n",
      "Epoch 6/10, Train Loss: 0.0632, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8733\n",
      "Epoch 7/10, Train Loss: 0.0484, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8821\n",
      "Epoch 8/10, Train Loss: 0.0378, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8716\n",
      "Epoch 9/10, Train Loss: 0.0416, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8797\n",
      "Epoch 10/10, Train Loss: 0.0344, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8782\n",
      "\n",
      "Sentiment analysis accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8834\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       781\n",
      "    positive       0.93      0.75      0.83       318\n",
      "\n",
      "    accuracy                           0.91      1099\n",
      "   macro avg       0.92      0.86      0.88      1099\n",
      "weighted avg       0.91      0.91      0.91      1099\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.8745\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.73      0.80        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.90      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.88      0.72      0.79        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.62      0.67       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.92      0.89       200\n",
      "     neutral       0.95      0.91      0.93       315\n",
      "    positive       0.87      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.76      0.80       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.78      0.80       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 342.80103635787964 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.006514191627502441\n",
      "Samples above threshold: 42\n",
      "Acquired samples: 50\n",
      "Sampling duration: 4.702049016952515 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4697, Accuracy: 0.8635, F1 Micro: 0.9202, F1 Macro: 0.9146\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.288, Accuracy: 0.9368, F1 Micro: 0.9614, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1987, Accuracy: 0.9507, F1 Micro: 0.9697, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1555, Accuracy: 0.9519, F1 Micro: 0.9704, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1306, Accuracy: 0.9543, F1 Micro: 0.9718, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1129, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9765\n",
      "Epoch 7/10, Train Loss: 0.0901, Accuracy: 0.9637, F1 Micro: 0.9774, F1 Macro: 0.975\n",
      "Epoch 8/10, Train Loss: 0.0747, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0641, Accuracy: 0.9672, F1 Micro: 0.9796, F1 Macro: 0.9778\n",
      "Epoch 10/10, Train Loss: 0.0558, Accuracy: 0.9668, F1 Micro: 0.9794, F1 Macro: 0.9774\n",
      "\n",
      "Aspect detection accuracy: 0.9672, F1 Micro: 0.9796, F1 Macro: 0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.99      0.97       496\n",
      "     general       0.96      0.97      0.97       500\n",
      "  kebersihan       0.95      0.95      0.95       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3549, Accuracy: 0.8686, F1 Micro: 0.8686, F1 Macro: 0.8323\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1982, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1472, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1006, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.071, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8884\n",
      "Epoch 6/10, Train Loss: 0.0607, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0591, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.043, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.8944\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0182, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.8952\n",
      "Epoch 10/10, Train Loss: 0.0262, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.887\n",
      "\n",
      "Sentiment analysis accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.8952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       781\n",
      "    positive       0.95      0.76      0.84       315\n",
      "\n",
      "    accuracy                           0.92      1096\n",
      "   macro avg       0.93      0.87      0.90      1096\n",
      "weighted avg       0.92      0.92      0.92      1096\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9609, F1 Micro: 0.9609, F1 Macro: 0.8813\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.73      0.80        78\n",
      "     neutral       0.96      0.99      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.74      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.96      0.97      0.97       496\n",
      "    positive       0.78      0.75      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.67      0.73       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.90       200\n",
      "     neutral       0.95      0.95      0.95       315\n",
      "    positive       0.88      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.77      0.81       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.89        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.69      0.77        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.86      0.88       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 349.102441072464 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.005248665809631348\n",
      "Samples above threshold: 37\n",
      "Acquired samples: 50\n",
      "Sampling duration: 4.2703857421875 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4628, Accuracy: 0.866, F1 Micro: 0.9212, F1 Macro: 0.9151\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2791, Accuracy: 0.9352, F1 Micro: 0.9606, F1 Macro: 0.9581\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1936, Accuracy: 0.9472, F1 Micro: 0.9677, F1 Macro: 0.9657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1521, Accuracy: 0.9526, F1 Micro: 0.9708, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1252, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9739\n",
      "Epoch 6/10, Train Loss: 0.1004, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0868, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0736, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0613, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "Epoch 10/10, Train Loss: 0.0536, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.95      0.95      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3599, Accuracy: 0.8567, F1 Micro: 0.8567, F1 Macro: 0.8003\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2233, Accuracy: 0.8871, F1 Micro: 0.8871, F1 Macro: 0.8464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.145, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0947, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0753, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8859\n",
      "Epoch 6/10, Train Loss: 0.0499, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8862\n",
      "Epoch 7/10, Train Loss: 0.0388, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8801\n",
      "Epoch 8/10, Train Loss: 0.0347, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8801\n",
      "Epoch 9/10, Train Loss: 0.028, Accuracy: 0.899, F1 Micro: 0.899, F1 Macro: 0.8632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0287, Accuracy: 0.9155, F1 Micro: 0.9155, F1 Macro: 0.8884\n",
      "\n",
      "Sentiment analysis accuracy: 0.9155, F1 Micro: 0.9155, F1 Macro: 0.8884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.99      0.94       778\n",
      "    positive       0.95      0.74      0.83       311\n",
      "\n",
      "    accuracy                           0.92      1089\n",
      "   macro avg       0.93      0.86      0.89      1089\n",
      "weighted avg       0.92      0.92      0.91      1089\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9594, F1 Micro: 0.9594, F1 Macro: 0.8841\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.85      0.80      0.83       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.72      0.78        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.90      0.92       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.88      0.65      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.59      0.65       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.88      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.88      0.86       162\n",
      "     neutral       0.95      0.95      0.95       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.76      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.96      0.94      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.83      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 350.10986375808716 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.005631387233734131\n",
      "Samples above threshold: 32\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.9092893600463867 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4625, Accuracy: 0.8755, F1 Micro: 0.9258, F1 Macro: 0.9176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2766, Accuracy: 0.9352, F1 Micro: 0.9606, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1952, Accuracy: 0.9476, F1 Micro: 0.9679, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1577, Accuracy: 0.9517, F1 Micro: 0.9704, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.131, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.105, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0887, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0763, Accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.9772\n",
      "Epoch 9/10, Train Loss: 0.0644, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9758\n",
      "Epoch 10/10, Train Loss: 0.0554, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.96      0.99      0.97       500\n",
      "  kebersihan       0.94      0.96      0.95       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3504, Accuracy: 0.8699, F1 Micro: 0.8699, F1 Macro: 0.8268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2234, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.145, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8903\n",
      "Epoch 4/10, Train Loss: 0.0848, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0813, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.8951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0581, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.8937\n",
      "Epoch 7/10, Train Loss: 0.0476, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8855\n",
      "Epoch 8/10, Train Loss: 0.0539, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8815\n",
      "Epoch 9/10, Train Loss: 0.0294, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8852\n",
      "Epoch 10/10, Train Loss: 0.0342, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8807\n",
      "\n",
      "Sentiment analysis accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.8937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.94       775\n",
      "    positive       0.93      0.77      0.84       309\n",
      "\n",
      "    accuracy                           0.92      1084\n",
      "   macro avg       0.92      0.87      0.89      1084\n",
      "weighted avg       0.92      0.92      0.92      1084\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.8777\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.74      0.80        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.99      0.97       496\n",
      "    positive       0.88      0.75      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.63      0.68       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91       200\n",
      "     neutral       0.94      0.96      0.95       315\n",
      "    positive       0.84      0.93      0.88        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.87      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.78      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.88        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.78      0.80       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 356.5707938671112 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.006635516881942749\n",
      "Samples above threshold: 29\n",
      "Acquired samples: 50\n",
      "Sampling duration: 3.7328760623931885 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.457, Accuracy: 0.8623, F1 Micro: 0.9201, F1 Macro: 0.9161\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2735, Accuracy: 0.938, F1 Micro: 0.9621, F1 Macro: 0.9597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1937, Accuracy: 0.949, F1 Micro: 0.9687, F1 Macro: 0.9664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1533, Accuracy: 0.9559, F1 Micro: 0.9728, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1222, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1027, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9759\n",
      "Epoch 7/10, Train Loss: 0.0874, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0721, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9763\n",
      "Epoch 9/10, Train Loss: 0.0604, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.976\n",
      "Epoch 10/10, Train Loss: 0.0538, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3437, Accuracy: 0.8631, F1 Micro: 0.8631, F1 Macro: 0.8185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2031, Accuracy: 0.8928, F1 Micro: 0.8928, F1 Macro: 0.8604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.152, Accuracy: 0.8955, F1 Micro: 0.8955, F1 Macro: 0.8643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1068, Accuracy: 0.8982, F1 Micro: 0.8982, F1 Macro: 0.8705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0806, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8781\n",
      "Epoch 6/10, Train Loss: 0.0656, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0444, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8818\n",
      "Epoch 8/10, Train Loss: 0.0399, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8745\n",
      "Epoch 9/10, Train Loss: 0.0419, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.8791\n",
      "Epoch 10/10, Train Loss: 0.0333, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.883\n",
      "\n",
      "Sentiment analysis accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       783\n",
      "    positive       0.93      0.74      0.83       327\n",
      "\n",
      "    accuracy                           0.91      1110\n",
      "   macro avg       0.92      0.86      0.88      1110\n",
      "weighted avg       0.91      0.91      0.90      1110\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.8779\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.81      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.83      0.78      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.63      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.67      0.45      0.54        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.82      0.75      0.78       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.89      0.86        85\n",
      "     neutral       0.97      0.96      0.97       418\n",
      "    positive       0.94      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 357.37195086479187 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.00630420446395874\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 50\n",
      "Sampling duration: 3.3273379802703857 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4543, Accuracy: 0.8753, F1 Micro: 0.9261, F1 Macro: 0.9195\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2663, Accuracy: 0.9418, F1 Micro: 0.9645, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.189, Accuracy: 0.9502, F1 Micro: 0.9694, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1478, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1181, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1043, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0848, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9758\n",
      "Epoch 8/10, Train Loss: 0.0724, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9756\n",
      "Epoch 9/10, Train Loss: 0.0607, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0494, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3564, Accuracy: 0.8429, F1 Micro: 0.8429, F1 Macro: 0.8166\n",
      "Epoch 2/10, Train Loss: 0.2131, Accuracy: 0.8393, F1 Micro: 0.8393, F1 Macro: 0.7631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.161, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.87\n",
      "Epoch 4/10, Train Loss: 0.1217, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0725, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.8806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0605, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.878\n",
      "Epoch 7/10, Train Loss: 0.0503, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0334, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8822\n",
      "Epoch 9/10, Train Loss: 0.0236, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8704\n",
      "Epoch 10/10, Train Loss: 0.0278, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.878\n",
      "\n",
      "Sentiment analysis accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       775\n",
      "    positive       0.91      0.76      0.83       320\n",
      "\n",
      "    accuracy                           0.91      1095\n",
      "   macro avg       0.91      0.86      0.88      1095\n",
      "weighted avg       0.91      0.91      0.91      1095\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.8718\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.86      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.81      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.83      0.96      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.85       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.72      0.59      0.65        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.84      0.79      0.82       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 366.1953070163727 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.003939628601074219\n",
      "Samples above threshold: 19\n",
      "Acquired samples: 50\n",
      "Sampling duration: 2.8258590698242188 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4459, Accuracy: 0.8774, F1 Micro: 0.9271, F1 Macro: 0.9203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2617, Accuracy: 0.9413, F1 Micro: 0.9641, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1829, Accuracy: 0.951, F1 Micro: 0.9699, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1489, Accuracy: 0.9559, F1 Micro: 0.9728, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1186, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0984, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "Epoch 7/10, Train Loss: 0.0825, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0692, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0578, Accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9772\n",
      "Epoch 10/10, Train Loss: 0.0508, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.96      0.95       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3619, Accuracy: 0.873, F1 Micro: 0.873, F1 Macro: 0.8276\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.202, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1267, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0971, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.8966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.06, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.8971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0649, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9009\n",
      "Epoch 7/10, Train Loss: 0.0377, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8893\n",
      "Epoch 8/10, Train Loss: 0.0351, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0315, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.8991\n",
      "Epoch 10/10, Train Loss: 0.0064, Accuracy: 0.9212, F1 Micro: 0.9212, F1 Macro: 0.8967\n",
      "\n",
      "Sentiment analysis accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.8991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       773\n",
      "    positive       0.95      0.77      0.85       306\n",
      "\n",
      "    accuracy                           0.92      1079\n",
      "   macro avg       0.93      0.88      0.90      1079\n",
      "weighted avg       0.93      0.92      0.92      1079\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.8819\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.89      0.74      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.62      0.68       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90       200\n",
      "     neutral       0.93      0.96      0.95       315\n",
      "    positive       0.88      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.74      0.79       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.89        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.48      0.61        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.77      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 373.74833631515503 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.004035532474517822\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 50\n",
      "Sampling duration: 2.4467368125915527 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4473, Accuracy: 0.8804, F1 Micro: 0.929, F1 Macro: 0.9222\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2617, Accuracy: 0.9384, F1 Micro: 0.9624, F1 Macro: 0.9598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1822, Accuracy: 0.9507, F1 Micro: 0.9697, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1497, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1186, Accuracy: 0.9632, F1 Micro: 0.9773, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.103, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0861, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9765\n",
      "Epoch 8/10, Train Loss: 0.0721, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9758\n",
      "Epoch 9/10, Train Loss: 0.0574, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9754\n",
      "Epoch 10/10, Train Loss: 0.0498, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.95      0.95      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3446, Accuracy: 0.8733, F1 Micro: 0.8733, F1 Macro: 0.836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1958, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1335, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1027, Accuracy: 0.9041, F1 Micro: 0.9041, F1 Macro: 0.875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0711, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8836\n",
      "Epoch 6/10, Train Loss: 0.0578, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8751\n",
      "Epoch 7/10, Train Loss: 0.0644, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8697\n",
      "Epoch 8/10, Train Loss: 0.0489, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.88\n",
      "Epoch 9/10, Train Loss: 0.0356, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8821\n",
      "Epoch 10/10, Train Loss: 0.031, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8789\n",
      "\n",
      "Sentiment analysis accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       784\n",
      "    positive       0.90      0.77      0.83       321\n",
      "\n",
      "    accuracy                           0.91      1105\n",
      "   macro avg       0.91      0.87      0.88      1105\n",
      "weighted avg       0.91      0.91      0.91      1105\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.876\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.90      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.75      1.00      0.86        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.96      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.86      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.71      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.61      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.87       162\n",
      "     neutral       0.95      0.95      0.95       387\n",
      "    positive       0.65      0.59      0.62        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.82      0.80      0.81       571\n",
      "weighted avg       0.91      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.89      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.97      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 373.4371998310089 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.009859681129455566\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 50\n",
      "Sampling duration: 2.100088119506836 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4374, Accuracy: 0.8832, F1 Micro: 0.9306, F1 Macro: 0.9247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2493, Accuracy: 0.9439, F1 Micro: 0.9657, F1 Macro: 0.9637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1768, Accuracy: 0.9524, F1 Micro: 0.9708, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1376, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1177, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0941, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0788, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9762\n",
      "Epoch 8/10, Train Loss: 0.0661, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0557, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.048, Accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.9773\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.96      0.95       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3406, Accuracy: 0.872, F1 Micro: 0.872, F1 Macro: 0.8334\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2047, Accuracy: 0.8923, F1 Micro: 0.8923, F1 Macro: 0.8538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1448, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1025, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8845\n",
      "Epoch 5/10, Train Loss: 0.0728, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0499, Accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.891\n",
      "Epoch 7/10, Train Loss: 0.0484, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8855\n",
      "Epoch 8/10, Train Loss: 0.036, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.027, Accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8915\n",
      "Epoch 10/10, Train Loss: 0.0234, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.884\n",
      "\n",
      "Sentiment analysis accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       781\n",
      "    positive       0.92      0.77      0.84       305\n",
      "\n",
      "    accuracy                           0.92      1086\n",
      "   macro avg       0.92      0.87      0.89      1086\n",
      "weighted avg       0.92      0.92      0.91      1086\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.8761\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.90      0.93        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.86      0.60      0.71        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.83      0.88       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.83      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.71      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.91       200\n",
      "     neutral       0.93      0.96      0.95       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.75      0.55      0.63        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.78      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.88      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.94      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 389.36036252975464 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0033065378665924072\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 36\n",
      "Sampling duration: 1.5460708141326904 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4442, Accuracy: 0.8786, F1 Micro: 0.9286, F1 Macro: 0.9245\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2545, Accuracy: 0.9411, F1 Micro: 0.964, F1 Macro: 0.9615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1744, Accuracy: 0.9519, F1 Micro: 0.9705, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1382, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1147, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9732\n",
      "Epoch 6/10, Train Loss: 0.0952, Accuracy: 0.9602, F1 Micro: 0.9755, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0807, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0655, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9762\n",
      "Epoch 9/10, Train Loss: 0.0554, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9755\n",
      "Epoch 10/10, Train Loss: 0.0464, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3442, Accuracy: 0.8763, F1 Micro: 0.8763, F1 Macro: 0.8351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1674, Accuracy: 0.8999, F1 Micro: 0.8999, F1 Macro: 0.8682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1208, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8886\n",
      "Epoch 4/10, Train Loss: 0.0909, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8808\n",
      "Epoch 5/10, Train Loss: 0.0599, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.88\n",
      "Epoch 6/10, Train Loss: 0.0552, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.8786\n",
      "Epoch 7/10, Train Loss: 0.0582, Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8818\n",
      "Epoch 8/10, Train Loss: 0.029, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8823\n",
      "Epoch 9/10, Train Loss: 0.0308, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8823\n",
      "Epoch 10/10, Train Loss: 0.0247, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8847\n",
      "\n",
      "Sentiment analysis accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       781\n",
      "    positive       0.91      0.77      0.84       318\n",
      "\n",
      "    accuracy                           0.91      1099\n",
      "   macro avg       0.91      0.87      0.89      1099\n",
      "weighted avg       0.91      0.91      0.91      1099\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8719\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.81      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.82      0.93      0.86       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.62      0.66       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.83      0.96      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.67      0.55      0.60        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.83      0.79      0.81       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.94      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.82      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 382.536746263504 s\n",
      "Total runtime: 7954.7986097335815 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6765788,
     "sourceId": 10888066,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6980.806919,
   "end_time": "2025-03-29T17:11:28.937730",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-29T15:15:08.130811",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0612d49c91ba40bd9dfb7740be070774": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "099ae6298c814cfaa3014728959c9bb5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ff2c53ab21c34d1c9f603aa215033155",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d0b761eeb7354d89a460ee18e902df69",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "103f89fa97c34766b6903f8abe25819b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1de4b82285a14fe8a5d55b1d17676205",
       "placeholder": "",
       "style": "IPY_MODEL_cbbba70ef54d48699bf9c84ee454020d",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt:100%"
      }
     },
     "1361358a888e461d87321f43239f5bb3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1721c29117664ad68692c854f7c47b31": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bc8240b5848c4608bf228bd1c0b340cb",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1d7181b6d0464bf6a72f8327c891e557",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "1d7181b6d0464bf6a72f8327c891e557": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1de4b82285a14fe8a5d55b1d17676205": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1f90cc946cc24b1c9654bb58534ad9c3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "235f32adb00d46f08037512c965ba2ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0612d49c91ba40bd9dfb7740be070774",
       "placeholder": "",
       "style": "IPY_MODEL_1361358a888e461d87321f43239f5bb3",
       "tabbable": null,
       "tooltip": null,
       "value": "1.53k/1.53k[00:00&lt;00:00,177kB/s]"
      }
     },
     "256d6dfda28148efa0fbc4a602de9d5a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1f90cc946cc24b1c9654bb58534ad9c3",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2eb5643c355e423ba5bc4e69f3ffb660",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "2eb5643c355e423ba5bc4e69f3ffb660": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2ee9dc34708c4d8ca949dac8793d6804": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "40528780367e4aee833779435a9cd5fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_41dc50de8bf4458d979828bf47b42f1f",
       "placeholder": "",
       "style": "IPY_MODEL_79ad741e6868429287129a5e70b6da8a",
       "tabbable": null,
       "tooltip": null,
       "value": "112/112[00:00&lt;00:00,12.7kB/s]"
      }
     },
     "41dc50de8bf4458d979828bf47b42f1f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4ac41cb7e82d4638bdbfbc523f7f4eef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4cb0d371d0db4fdd9d91e6d573b25ac8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_103f89fa97c34766b6903f8abe25819b",
        "IPY_MODEL_099ae6298c814cfaa3014728959c9bb5",
        "IPY_MODEL_d132eb5a72394c00849824d1ce6ed50d"
       ],
       "layout": "IPY_MODEL_e4c9c66954e44add8b729dea8c326c7a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "598b5d7c59c84337bb31a81ef4406f2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8980af4e3b0649d1bb07b50ce2501a14",
       "placeholder": "",
       "style": "IPY_MODEL_9f999bef8f4c45e8b662c192d8ac8191",
       "tabbable": null,
       "tooltip": null,
       "value": "2.00/2.00[00:00&lt;00:00,168B/s]"
      }
     },
     "5a12f5a590e740e592ead71df0aa4883": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6c4abeaff4274198aefc44bcb0138570": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_93a74c7ffbd54d1c91737f67b8b2f108",
        "IPY_MODEL_822c961ca1c44c1fabebb910d006c4aa",
        "IPY_MODEL_235f32adb00d46f08037512c965ba2ab"
       ],
       "layout": "IPY_MODEL_773c0bc690884a77a2538ca90748bde0",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6d17dc3e389b4984b9aa3ba6c5d93817": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7243fad603fd446e869f085ec3c8f518": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "72e92c1b381244a887d787487c006ca8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "773c0bc690884a77a2538ca90748bde0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "79ad741e6868429287129a5e70b6da8a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8057f70d2ad9426caedd28ca72a19607": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "822c961ca1c44c1fabebb910d006c4aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4ac41cb7e82d4638bdbfbc523f7f4eef",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8057f70d2ad9426caedd28ca72a19607",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     },
     "8980af4e3b0649d1bb07b50ce2501a14": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8e893165964b4f2fbb9cd866c9be5eb2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d49cd83e652a4c64902e8c328276011c",
       "placeholder": "",
       "style": "IPY_MODEL_72e92c1b381244a887d787487c006ca8",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json:100%"
      }
     },
     "8fde79624924403fbaad7660ff63d355": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "93a74c7ffbd54d1c91737f67b8b2f108": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5a12f5a590e740e592ead71df0aa4883",
       "placeholder": "",
       "style": "IPY_MODEL_6d17dc3e389b4984b9aa3ba6c5d93817",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:100%"
      }
     },
     "9f999bef8f4c45e8b662c192d8ac8191": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ab53e199a78a49878671acc7670aa1f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7243fad603fd446e869f085ec3c8f518",
       "placeholder": "",
       "style": "IPY_MODEL_e3c1469b004e4f2b9e937e71948864ff",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:100%"
      }
     },
     "b253f3e0f0aa4b2b9811ab39d9d17896": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8e893165964b4f2fbb9cd866c9be5eb2",
        "IPY_MODEL_256d6dfda28148efa0fbc4a602de9d5a",
        "IPY_MODEL_40528780367e4aee833779435a9cd5fe"
       ],
       "layout": "IPY_MODEL_e841af94577f470cb27119c79c6f83c6",
       "tabbable": null,
       "tooltip": null
      }
     },
     "bc8240b5848c4608bf228bd1c0b340cb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cbbba70ef54d48699bf9c84ee454020d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d0b761eeb7354d89a460ee18e902df69": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d132eb5a72394c00849824d1ce6ed50d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8fde79624924403fbaad7660ff63d355",
       "placeholder": "",
       "style": "IPY_MODEL_d31c3d2090c64f3389df7464e3a635af",
       "tabbable": null,
       "tooltip": null,
       "value": "229k/229k[00:00&lt;00:00,6.68MB/s]"
      }
     },
     "d31c3d2090c64f3389df7464e3a635af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d49cd83e652a4c64902e8c328276011c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d58e2ef3a1dc459285f9a961b22b316e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ab53e199a78a49878671acc7670aa1f4",
        "IPY_MODEL_1721c29117664ad68692c854f7c47b31",
        "IPY_MODEL_598b5d7c59c84337bb31a81ef4406f2c"
       ],
       "layout": "IPY_MODEL_2ee9dc34708c4d8ca949dac8793d6804",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e3c1469b004e4f2b9e937e71948864ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e4c9c66954e44add8b729dea8c326c7a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e841af94577f470cb27119c79c6f83c6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ff2c53ab21c34d1c9f603aa215033155": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
