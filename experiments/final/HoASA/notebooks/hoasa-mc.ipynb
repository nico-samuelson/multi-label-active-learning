{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d330890a",
   "metadata": {
    "papermill": {
     "duration": 0.01213,
     "end_time": "2025-03-30T07:57:23.750477",
     "exception": false,
     "start_time": "2025-03-30T07:57:23.738347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "702a61c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:57:23.773172Z",
     "iopub.status.busy": "2025-03-30T07:57:23.772919Z",
     "iopub.status.idle": "2025-03-30T07:57:47.890157Z",
     "shell.execute_reply": "2025-03-30T07:57:47.889491Z"
    },
    "papermill": {
     "duration": 24.130119,
     "end_time": "2025-03-30T07:57:47.891642",
     "exception": false,
     "start_time": "2025-03-30T07:57:23.761523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8c831f",
   "metadata": {
    "papermill": {
     "duration": 0.010831,
     "end_time": "2025-03-30T07:57:47.914056",
     "exception": false,
     "start_time": "2025-03-30T07:57:47.903225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7507e1c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:57:47.937516Z",
     "iopub.status.busy": "2025-03-30T07:57:47.937009Z",
     "iopub.status.idle": "2025-03-30T07:57:47.940336Z",
     "shell.execute_reply": "2025-03-30T07:57:47.939727Z"
    },
    "papermill": {
     "duration": 0.016537,
     "end_time": "2025-03-30T07:57:47.941665",
     "exception": false,
     "start_time": "2025-03-30T07:57:47.925128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "326b25a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:57:47.964755Z",
     "iopub.status.busy": "2025-03-30T07:57:47.964503Z",
     "iopub.status.idle": "2025-03-30T07:57:47.968238Z",
     "shell.execute_reply": "2025-03-30T07:57:47.967480Z"
    },
    "papermill": {
     "duration": 0.016696,
     "end_time": "2025-03-30T07:57:47.969520",
     "exception": false,
     "start_time": "2025-03-30T07:57:47.952824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1d5a3f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:57:47.992845Z",
     "iopub.status.busy": "2025-03-30T07:57:47.992641Z",
     "iopub.status.idle": "2025-03-30T07:57:48.001738Z",
     "shell.execute_reply": "2025-03-30T07:57:48.001094Z"
    },
    "papermill": {
     "duration": 0.02204,
     "end_time": "2025-03-30T07:57:48.002913",
     "exception": false,
     "start_time": "2025-03-30T07:57:47.980873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddeab79",
   "metadata": {
    "papermill": {
     "duration": 0.011381,
     "end_time": "2025-03-30T07:57:48.025588",
     "exception": false,
     "start_time": "2025-03-30T07:57:48.014207",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "613da2d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:57:48.047946Z",
     "iopub.status.busy": "2025-03-30T07:57:48.047748Z",
     "iopub.status.idle": "2025-03-30T07:57:48.107230Z",
     "shell.execute_reply": "2025-03-30T07:57:48.105909Z"
    },
    "papermill": {
     "duration": 0.072624,
     "end_time": "2025-03-30T07:57:48.108995",
     "exception": false,
     "start_time": "2025-03-30T07:57:48.036371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "aspect_accuracies = manager.list()\n",
    "aspect_f1_micros = manager.list()\n",
    "aspect_f1_macros = manager.list()\n",
    "sentiment_accuracies = manager.list()\n",
    "sentiment_f1_micros = manager.list()\n",
    "sentiment_f1_macros = manager.list()\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'hoasa-mc'\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "sequence_length = 48\n",
    "\n",
    "aspect_list = ['ac', 'air_panas', 'bau', 'general', 'kebersihan', 'linen', 'service', 'sunrise_meal', 'tv', 'wifi']\n",
    "aspect_mapping = {'ac': 0, 'air_panas': 1, 'bau': 2, 'general': 3, 'kebersihan': 4, 'linen': 5, 'service': 6, 'sunrise_meal': 7, 'tv': 8, 'wifi': 9}\n",
    "label_mapping = {\"neg\": 0, \"neut\": 1, 'neg_pos': 1, 'pos': 2}\n",
    "ignored_keys = ['labels', 'ori_text', 'ori_label', 'ori_indices', 'aspect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d0cc57",
   "metadata": {
    "papermill": {
     "duration": 0.010584,
     "end_time": "2025-03-30T07:57:48.130789",
     "exception": false,
     "start_time": "2025-03-30T07:57:48.120205",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06762f78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:57:48.153687Z",
     "iopub.status.busy": "2025-03-30T07:57:48.153384Z",
     "iopub.status.idle": "2025-03-30T07:57:48.258723Z",
     "shell.execute_reply": "2025-03-30T07:57:48.257794Z"
    },
    "papermill": {
     "duration": 0.11837,
     "end_time": "2025-03-30T07:57:48.260149",
     "exception": false,
     "start_time": "2025-03-30T07:57:48.141779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>ac</th>\n",
       "      <th>air_panas</th>\n",
       "      <th>bau</th>\n",
       "      <th>general</th>\n",
       "      <th>kebersihan</th>\n",
       "      <th>linen</th>\n",
       "      <th>service</th>\n",
       "      <th>sunrise_meal</th>\n",
       "      <th>tv</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kebersihan kurang...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sangat mengecewakan... hotel bad image, kebers...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tempat nyaman bersih tapi tv terlalu tinggi ti...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>pos</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>semuanya bagus sesuai profile,dan harga promo ...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>pos</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tempat tidur sangat keras, bantal besar dan ke...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review    ac air_panas   bau  \\\n",
       "0                               kebersihan kurang...  neut      neut  neut   \n",
       "1  sangat mengecewakan... hotel bad image, kebers...  neut      neut  neut   \n",
       "2  Tempat nyaman bersih tapi tv terlalu tinggi ti...  neut      neut  neut   \n",
       "3  semuanya bagus sesuai profile,dan harga promo ...  neut       neg  neut   \n",
       "4  Tempat tidur sangat keras, bantal besar dan ke...   neg       neg  neut   \n",
       "\n",
       "  general kebersihan linen service sunrise_meal    tv  wifi  \n",
       "0    neut        neg  neut    neut         neut  neut  neut  \n",
       "1    neut        neg  neut    neut         neut  neut  neut  \n",
       "2    neut        pos  neut    neut         neut   neg  neut  \n",
       "3     pos       neut  neut    neut         neut  neut  neut  \n",
       "4    neut       neut   neg    neut         neut  neut  neut  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/hoasa-dataset/train_preprocess.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/hoasa-dataset/valid_preprocess.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('/kaggle/input/hoasa-dataset/test_preprocess.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data, test_data], ignore_index=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4771277",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:57:48.284028Z",
     "iopub.status.busy": "2025-03-30T07:57:48.283764Z",
     "iopub.status.idle": "2025-03-30T07:57:48.292246Z",
     "shell.execute_reply": "2025-03-30T07:57:48.291468Z"
    },
    "papermill": {
     "duration": 0.021839,
     "end_time": "2025-03-30T07:57:48.293491",
     "exception": false,
     "start_time": "2025-03-30T07:57:48.271652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c60ce372",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:57:48.316314Z",
     "iopub.status.busy": "2025-03-30T07:57:48.316085Z",
     "iopub.status.idle": "2025-03-30T07:57:48.328016Z",
     "shell.execute_reply": "2025-03-30T07:57:48.326870Z"
    },
    "papermill": {
     "duration": 0.024991,
     "end_time": "2025-03-30T07:57:48.329485",
     "exception": false,
     "start_time": "2025-03-30T07:57:48.304494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2283,) (2283, 10)\n",
      "(571,) (571, 10)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[1:]\n",
    "val_labels = val_data.columns[1:]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['review'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['review'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4143c4",
   "metadata": {
    "papermill": {
     "duration": 0.011243,
     "end_time": "2025-03-30T07:57:48.352635",
     "exception": false,
     "start_time": "2025-03-30T07:57:48.341392",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55cda53c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:57:48.375493Z",
     "iopub.status.busy": "2025-03-30T07:57:48.375239Z",
     "iopub.status.idle": "2025-03-30T07:57:48.381051Z",
     "shell.execute_reply": "2025-03-30T07:57:48.380392Z"
    },
    "papermill": {
     "duration": 0.018659,
     "end_time": "2025-03-30T07:57:48.382314",
     "exception": false,
     "start_time": "2025-03-30T07:57:48.363655",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AspectDetectionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, label_mapping, tokenizer, max_length=sequence_length, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        \n",
    "        original_labels = [self.label_mapping[label] for label in self.labels[idx]]\n",
    "        encoded_labels = [1 if label == 1 else 0 for label in original_labels]\n",
    "        \n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['ori_indices'] = idx\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(original_labels, dtype=torch.float)\n",
    "        item['labels'] = torch.tensor(encoded_labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e87b5f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:57:48.405200Z",
     "iopub.status.busy": "2025-03-30T07:57:48.405001Z",
     "iopub.status.idle": "2025-03-30T07:57:48.411298Z",
     "shell.execute_reply": "2025-03-30T07:57:48.410711Z"
    },
    "papermill": {
     "duration": 0.019185,
     "end_time": "2025-03-30T07:57:48.412517",
     "exception": false,
     "start_time": "2025-03-30T07:57:48.393332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, texts, labels, aspects, indices, label_mapping, tokenizer, max_length=96, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.aspects = aspects\n",
    "        self.indices = indices\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = aspect_token + ' ' + self.aspects[idx] + ' ' + review_token + ' ' + self.texts[idx] \n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        if isinstance(self.labels[idx], str):\n",
    "            self.labels[idx] = self.label_mapping[self.labels[idx]]\n",
    "        elif torch.is_tensor(self.labels[idx]):\n",
    "            self.labels[idx] = int(self.labels[idx].item())\n",
    "\n",
    "        encoded_label = 1 if self.labels[idx] == 2 else self.labels[idx]\n",
    "        one_hot_label = F.one_hot(torch.tensor(encoded_label, dtype=torch.long), num_classes=2).float()\n",
    "\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['aspect'] = self.aspects[idx]\n",
    "        item['labels'] = one_hot_label\n",
    "        item['ori_indices'] = self.indices[idx]\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e3eee0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:57:48.435178Z",
     "iopub.status.busy": "2025-03-30T07:57:48.434977Z",
     "iopub.status.idle": "2025-03-30T07:57:49.221642Z",
     "shell.execute_reply": "2025-03-30T07:57:49.220681Z"
    },
    "papermill": {
     "duration": 0.799755,
     "end_time": "2025-03-30T07:57:49.223315",
     "exception": false,
     "start_time": "2025-03-30T07:57:48.423560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420f577222a2440f98c72ecdb4a2d100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885e9426347c4779960f2191a74c1ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb98bcd14ad495c9d07993f530abf44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dedb86a1fbe4b5380792b324c24912e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "review_token = '[REVIEW]'\n",
    "aspect_token = '[ASPECT]'\n",
    "special_tokens_dict = {'additional_special_tokens': [review_token, aspect_token]}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbf60a19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:57:49.249439Z",
     "iopub.status.busy": "2025-03-30T07:57:49.249125Z",
     "iopub.status.idle": "2025-03-30T07:57:49.253928Z",
     "shell.execute_reply": "2025-03-30T07:57:49.253093Z"
    },
    "papermill": {
     "duration": 0.019057,
     "end_time": "2025-03-30T07:57:49.255150",
     "exception": false,
     "start_time": "2025-03-30T07:57:49.236093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_aspect_dataset(X_train, y_train, X_val, y_val, sequence_length, num_workers=4):\n",
    "    train_dataset = AspectDetectionDataset(X_train, y_train, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = AspectDetectionDataset(X_val, y_val, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc39e2f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:57:49.281728Z",
     "iopub.status.busy": "2025-03-30T07:57:49.281473Z",
     "iopub.status.idle": "2025-03-30T07:57:49.292633Z",
     "shell.execute_reply": "2025-03-30T07:57:49.291871Z"
    },
    "papermill": {
     "duration": 0.026317,
     "end_time": "2025-03-30T07:57:49.293922",
     "exception": false,
     "start_time": "2025-03-30T07:57:49.267605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sentiment_dataset(device, train_dataset, val_dataset, aspect_detection_model, tokenizer, max_length=sequence_length):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    aspect_detection_model.to(device)\n",
    "    aspect_detection_model.eval()\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    train_aspects = []\n",
    "    train_indices = []\n",
    "\n",
    "    val_data = []\n",
    "    val_labels = []\n",
    "    val_aspects = []\n",
    "    val_indices = []\n",
    "\n",
    "    # Transform train set\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        train_aspects.append(aspect_list[j])\n",
    "                        train_data.append(batch['ori_text'][i])\n",
    "                        train_labels.append(batch['ori_label'][i][j])\n",
    "                        train_indices.append(batch['ori_indices'][i])\n",
    "            \n",
    "        # Transform validation set\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        val_aspects.append(aspect_list[j])\n",
    "                        val_data.append(batch['ori_text'][i])\n",
    "                        val_labels.append(batch['ori_label'][i][j])\n",
    "                        val_indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    train_dataset = SentimentAnalysisDataset(train_data, train_labels, train_aspects, train_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "    val_dataset = SentimentAnalysisDataset(val_data, val_labels, val_aspects, val_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d271c628",
   "metadata": {
    "papermill": {
     "duration": 0.012027,
     "end_time": "2025-03-30T07:57:49.318151",
     "exception": false,
     "start_time": "2025-03-30T07:57:49.306124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4941e951",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:57:49.345079Z",
     "iopub.status.busy": "2025-03-30T07:57:49.344839Z",
     "iopub.status.idle": "2025-03-30T07:57:49.348750Z",
     "shell.execute_reply": "2025-03-30T07:57:49.348005Z"
    },
    "papermill": {
     "duration": 0.019362,
     "end_time": "2025-03-30T07:57:49.349947",
     "exception": false,
     "start_time": "2025-03-30T07:57:49.330585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a4485fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:57:49.375773Z",
     "iopub.status.busy": "2025-03-30T07:57:49.375520Z",
     "iopub.status.idle": "2025-03-30T07:57:49.380581Z",
     "shell.execute_reply": "2025-03-30T07:57:49.379829Z"
    },
    "papermill": {
     "duration": 0.019854,
     "end_time": "2025-03-30T07:57:49.381786",
     "exception": false,
     "start_time": "2025-03-30T07:57:49.361932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p, label, classes):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        labels=label,\n",
    "        target_names=classes,\n",
    "        zero_division=0\n",
    "    ) \n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c64195e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:57:49.406652Z",
     "iopub.status.busy": "2025-03-30T07:57:49.406394Z",
     "iopub.status.idle": "2025-03-30T07:57:49.413223Z",
     "shell.execute_reply": "2025-03-30T07:57:49.412494Z"
    },
    "papermill": {
     "duration": 0.02047,
     "end_time": "2025-03-30T07:57:49.414423",
     "exception": false,
     "start_time": "2025-03-30T07:57:49.393953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics_overall(p, classes):\n",
    "    preds = torch.tensor(p.predictions)\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Ensure it's in the correct shape\n",
    "    if preds.shape != labels.shape:\n",
    "        raise ValueError(\"Shape mismatch: predictions and labels must have the same shape.\")\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Compute per-label (column-wise) precision, recall, F1\n",
    "    precision_list, recall_list, f1_micro_list, f1_macro_list = [], [], [], []\n",
    "    \n",
    "    for i in range(labels.shape[1]):  # Loop through each column (multi-output)\n",
    "        prec, rec, f1_micro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='micro', zero_division=0\n",
    "        )\n",
    "        _, _, f1_macro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='macro', zero_division=0\n",
    "        )\n",
    "\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        f1_micro_list.append(f1_micro)\n",
    "        f1_macro_list.append(f1_macro)\n",
    "\n",
    "    # Compute average metrics across all outputs\n",
    "    precision = sum(precision_list) / len(precision_list)\n",
    "    recall = sum(recall_list) / len(recall_list)\n",
    "    f1_micro = sum(f1_micro_list) / len(f1_micro_list)\n",
    "    f1_macro = sum(f1_macro_list) / len(f1_macro_list)\n",
    "\n",
    "    # Generate classification report per output\n",
    "    reports = [classification_report(labels[:, i], preds[:, i], target_names=classes, zero_division=0) for i in range(labels.shape[1])]\n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'reports': reports \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a51e9b67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:57:49.438804Z",
     "iopub.status.busy": "2025-03-30T07:57:49.438547Z",
     "iopub.status.idle": "2025-03-30T07:57:49.467758Z",
     "shell.execute_reply": "2025-03-30T07:57:49.467101Z"
    },
    "papermill": {
     "duration": 0.042862,
     "end_time": "2025-03-30T07:57:49.469116",
     "exception": false,
     "start_time": "2025-03-30T07:57:49.426254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, aspect_metrics, sentiment_metrics, metrics, trials, seed):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in aspect_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    aspect_optimizer = torch.optim.AdamW(aspect_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    aspect_train_loader, aspect_val_loader, aspect_train_dataset, aspect_val_dataset = build_aspect_dataset(current_X_train, current_y_train, X_val, y_val, sequence_length)\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader = accelerator.prepare(\n",
    "        aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader\n",
    "    )\n",
    "\n",
    "    aspect_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ASPECT DETECTION\n",
    "    accelerator.print(\"ASPECT DETECTION\")\n",
    "    for epoch in range(epochs):\n",
    "        aspect_model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in aspect_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            aspect_optimizer.zero_grad()\n",
    "            outputs = aspect_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            aspect_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        aspect_model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in aspect_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = aspect_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}),\n",
    "            None,\n",
    "            aspect_list,\n",
    "        )\n",
    "\n",
    "        if aspect_result is None or result['f1_micro'] >= aspect_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(aspect_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-aspect-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            aspect_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(aspect_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"\\nAspect detection accuracy: {round(aspect_result['accuracy'], 4)}, F1 Micro: {round(aspect_result['f1_micro'], 4)}, F1 Macro: {round(aspect_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(aspect_result['report'])\n",
    "\n",
    "    best_aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{trials + 1}-model')\n",
    "    best_aspect_model = accelerator.prepare(best_aspect_model)\n",
    "\n",
    "    # SENTIMENT ANALYSIS ON NON NEUTRAL ASPECTS\n",
    "    accelerator.print(\"--------------------------------------------------\")\n",
    "    accelerator.print(\"SENTIMENT ANALYSIS\")\n",
    "\n",
    "    sentiment_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=2,\n",
    "    )\n",
    "    sentiment_optimizer = torch.optim.AdamW(sentiment_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "    for name, param in sentiment_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    sentiment_train_loader, sentiment_val_loader, sentiment_train_dataset, sentiment_val_dataset = build_sentiment_dataset(\n",
    "        device, aspect_train_dataset, aspect_val_dataset, best_aspect_model, tokenizer, max_length=sequence_length\n",
    "    )\n",
    "    sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader = accelerator.prepare(\n",
    "        sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader\n",
    "    )\n",
    "    sentiment_result = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sentiment_model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in sentiment_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            sentiment_optimizer.zero_grad()\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            sentiment_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        sentiment_model.eval()\n",
    "        sentiment_val_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in sentiment_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                \n",
    "                outputs = sentiment_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                for i in range(len(preds)):\n",
    "                    val_output = {\n",
    "                        'label': batch['labels'][i],\n",
    "                        'aspect': batch['aspect'][i],\n",
    "                        'ori_indices': batch['ori_indices'][i],\n",
    "                        'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                    }\n",
    "                    sentiment_val_outputs.append(val_output)\n",
    "\n",
    "        sentiment_val_outputs = accelerator.gather_for_metrics(sentiment_val_outputs)\n",
    "        unique_val_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_val_outputs}\n",
    "        sentiment_val_outputs = list(unique_val_outputs.values())\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': [item['pred'] for item in sentiment_val_outputs], 'label_ids': [np.argmax(item['label'].cpu().numpy()) for item in sentiment_val_outputs]}),\n",
    "            [0, 1],\n",
    "            ['negative', 'positive']\n",
    "        )\n",
    "\n",
    "        if sentiment_result is None or result['f1_micro'] >= sentiment_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            sentiment_result = result\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(sentiment_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                 f'{filename}-sentiment-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(sentiment_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    accelerator.print(f\"\\nSentiment analysis accuracy: {round(sentiment_result['accuracy'], 4)}, F1 Micro: {round(sentiment_result['f1_micro'], 4)}, F1 Macro: {round(sentiment_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(sentiment_result['report'])\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    best_sentiment_model = BertForSequenceClassification.from_pretrained( f'{filename}-sentiment-{trials + 1}-model')\n",
    "    best_sentiment_model = accelerator.prepare(best_sentiment_model)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    aspect_labels = []\n",
    "    aspect_indices = []\n",
    "    aspect_preds = []\n",
    "\n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = []\n",
    "    \n",
    "    best_aspect_model.eval()\n",
    "    best_sentiment_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in aspect_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_aspect_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            aspect_indices.append(accelerator.gather(batch['ori_indices']))\n",
    "            aspect_labels.append(accelerator.gather(batch['ori_label']))\n",
    "            aspect_preds.append(accelerator.gather(preds))\n",
    "\n",
    "        aspect_indices = torch.cat(aspect_indices).cpu().numpy()\n",
    "        aspect_labels = torch.cat(aspect_labels).cpu().numpy()\n",
    "        aspect_preds = torch.cat(aspect_preds).cpu().numpy()\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        aspect_outputs = [\n",
    "            {'ori_indices': aspect_indices[i], \n",
    "             'ori_labels': aspect_labels[i], \n",
    "             'pred': aspect_preds[i]}\n",
    "            for i in range(len(aspect_preds))\n",
    "        ]\n",
    "        aspect_outputs = {x['ori_indices'].item(): x for x in aspect_outputs}\n",
    "    \n",
    "        for batch in sentiment_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_sentiment_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "    \n",
    "            for i in range(len(preds)):\n",
    "                output = {\n",
    "                    'aspect': batch['aspect'][i],\n",
    "                    'ori_indices': batch['ori_indices'][i],\n",
    "                    'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                }\n",
    "                sentiment_outputs.append(output)\n",
    "\n",
    "        sentiment_outputs = accelerator.gather_for_metrics(sentiment_outputs)\n",
    "        sentiment_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_outputs}\n",
    "\n",
    "    # Replcae non neutral aspect to its predicted sentiment\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        i = -1\n",
    "        for (ori_index, aspect), value in sentiment_outputs.items():\n",
    "            aspect = aspect_mapping[aspect]\n",
    "            aspect_outputs[ori_index]['pred'][aspect] = 2 if value['pred'] == 1.0 else value['pred']\n",
    "\n",
    "        result = compute_metrics_overall(\n",
    "            type('EvalOutput', (object,), {'predictions': [output['pred'] for output in aspect_outputs.values()], 'label_ids': [output['ori_labels'] for output in aspect_outputs.values()]}),\n",
    "            ['negative', 'neutral', 'positive'],\n",
    "        )\n",
    "\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        for i in range(len(train_labels)):\n",
    "            accelerator.print(f\"Aspect {aspect_list[i]} report:\")\n",
    "            accelerator.print(result['reports'][i])\n",
    "       \n",
    "        \n",
    "        aspect_metrics[0].append(aspect_result['accuracy'])\n",
    "        aspect_metrics[1].append(aspect_result['f1_micro'])\n",
    "        aspect_metrics[2].append(aspect_result['f1_macro'])\n",
    "        sentiment_metrics[0].append(sentiment_result['accuracy'])\n",
    "        sentiment_metrics[1].append(sentiment_result['f1_micro'])\n",
    "        sentiment_metrics[2].append(sentiment_result['f1_macro'])\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(result['accuracy'])\n",
    "        metrics[2].append(result['f1_micro'])\n",
    "        metrics[3].append(result['f1_macro'])\n",
    "        \n",
    "    accelerator.print(f\"Total train time: {duration} s\")\n",
    "    accelerator.end_training()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88bf58c",
   "metadata": {
    "papermill": {
     "duration": 0.012041,
     "end_time": "2025-03-30T07:57:49.493956",
     "exception": false,
     "start_time": "2025-03-30T07:57:49.481915",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5115e6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:57:49.518730Z",
     "iopub.status.busy": "2025-03-30T07:57:49.518507Z",
     "iopub.status.idle": "2025-03-30T07:57:49.523761Z",
     "shell.execute_reply": "2025-03-30T07:57:49.523057Z"
    },
    "papermill": {
     "duration": 0.019255,
     "end_time": "2025-03-30T07:57:49.524996",
     "exception": false,
     "start_time": "2025-03-30T07:57:49.505741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783916bd",
   "metadata": {
    "papermill": {
     "duration": 0.013707,
     "end_time": "2025-03-30T07:57:49.550293",
     "exception": false,
     "start_time": "2025-03-30T07:57:49.536586",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c018e38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:57:49.575901Z",
     "iopub.status.busy": "2025-03-30T07:57:49.575522Z",
     "iopub.status.idle": "2025-03-30T07:57:49.599535Z",
     "shell.execute_reply": "2025-03-30T07:57:49.598403Z"
    },
    "papermill": {
     "duration": 0.039206,
     "end_time": "2025-03-30T07:57:49.601334",
     "exception": false,
     "start_time": "2025-03-30T07:57:49.562128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def monte_carlo_dropout_sampling(aspect_model, sentiment_model, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, mc_passes=3, n_samples=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model.to(device)\n",
    "    aspect_model.train()\n",
    "    sentiment_model.to(device)\n",
    "    sentiment_model.train()\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    aspect_dataset = AspectDetectionDataset(\n",
    "        X_pool, \n",
    "        [['neut' for i in range(len(train_labels))] for x in range(len(X_pool))], \n",
    "        label_mapping, \n",
    "        tokenizer, \n",
    "        max_length=sequence_length\n",
    "    )\n",
    "    aspect_loader = DataLoader(\n",
    "        aspect_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = {}\n",
    "\n",
    "    aspects = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    indices = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    aspect_uncertainties = []\n",
    "\n",
    "    # Pass through aspect detction model\n",
    "    for batch in aspect_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "\n",
    "        batch_probs = []\n",
    "        \n",
    "        for i in range(mc_passes):\n",
    "            with torch.no_grad():\n",
    "                outputs = aspect_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
    "                probs = torch.sigmoid(outputs).cpu().numpy()  # Shape: (batch_size, num_classes)\n",
    "                batch_probs.append(probs)\n",
    "                \n",
    "        # Stack the probabilities from multiple MC passes\n",
    "        batch_probs = np.stack(batch_probs, axis=0)  # Shape: (mc_passes, batch_size, num_classes)\n",
    "\n",
    "        # Calculate mean probability and uncertainty for each sample in the batch\n",
    "        mean_probs = np.mean(batch_probs, axis=0)  # Shape: (batch_size, num_classes)\n",
    "        uncertainties = np.mean(np.var(batch_probs, axis=0), axis=1)  # Shape: (batch_size,)\n",
    "        aspect_uncertainties.extend(uncertainties)\n",
    "\n",
    "        for i in range(len(mean_probs)):\n",
    "            aspect_outputs[batch['ori_indices'][i].item()] = [np.max(torch.sigmoid(outputs[i]).cpu().numpy())]\n",
    "            \n",
    "            for j in range(len(mean_probs[i])):\n",
    "                if int(mean_probs[i][j].round()) != 1:\n",
    "                    aspects.append(aspect_list[j])\n",
    "                    data.append(batch['ori_text'][i])\n",
    "                    labels.append(batch['ori_label'][i][j])\n",
    "                    indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    aspect_outputs = {i: aspect_uncertainties[i] for i in range(len(aspect_uncertainties))}\n",
    "    sentiment_dataset = SentimentAnalysisDataset(data, labels, aspects, indices, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    sentiment_loader = torch.utils.data.DataLoader(\n",
    "        sentiment_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4,\n",
    "    )\n",
    "\n",
    "    # Pass through sentiment analysis model\n",
    "    for batch in sentiment_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "\n",
    "        batch_probs = []\n",
    "        for i in range(mc_passes):\n",
    "            with torch.no_grad():\n",
    "                outputs = sentiment_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "                preds = torch.sigmoid(outputs.logits)\n",
    "\n",
    "                for j in range(len(preds)):\n",
    "                    ori_index = batch['ori_indices'][j].item()\n",
    "                    if ori_index in sentiment_outputs.keys():\n",
    "                        sentiment_outputs[ori_index].append(preds[j].cpu().numpy())\n",
    "                    else:\n",
    "                        sentiment_outputs[ori_index] = [preds[j].cpu().numpy()]\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    for indices, probs in sentiment_outputs.items():\n",
    "        sentiment_outputs[indices] = [[probs[i], probs[i+1], probs[i+2]] for i in range(int(len(probs) / 3))]\n",
    "        \n",
    "        variance = np.var(sentiment_outputs[indices], axis=1)\n",
    "        mean_aspect_variance = np.mean(variance, axis=1)\n",
    "        mean_data_variance = np.mean(mean_aspect_variance)\n",
    "        \n",
    "        sentiment_outputs[indices] = np.mean(np.mean(np.var(sentiment_outputs[indices], axis=0), axis=0), axis=0)\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        aspect_outputs = dict(sorted(aspect_outputs.items()))\n",
    "\n",
    "        if len(data) > 0:\n",
    "            for key, val in sentiment_outputs.items():\n",
    "                aspect_outputs[key] = (val + aspect_outputs[key]) / 2\n",
    "\n",
    "        uncertainties = np.array(list(aspect_outputs.values()))\n",
    "        sorted_unc = np.argsort(uncertainties)\n",
    "        sorted_unc = sorted_unc[::-1]\n",
    "\n",
    "        threshold = np.percentile(uncertainties, 90)\n",
    "        items_greater_than_average = uncertainties[uncertainties >= threshold]\n",
    "        num_of_candidates = len(items_greater_than_average)\n",
    "        \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "        \n",
    "        if num_of_candidates <= n_samples and n_samples < nearest_cp - current_train_size:\n",
    "            least_confident_indices = sorted_unc[:n_samples]\n",
    "        elif num_of_candidates > n_samples and num_of_candidates < nearest_cp - current_train_size:\n",
    "            least_confident_indices = sorted_unc[:max(n_samples, min(math.ceil(0.1*len(sorted_unc)), num_of_candidates))]\n",
    "        else:\n",
    "            least_confident_indices = sorted_unc[:nearest_cp - current_train_size]\n",
    "    \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend([remaining_indices[i] for i in least_confident_indices])\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                'fuel': [y_train[i][0] for i in temp],\n",
    "                'machine': [y_train[i][1] for i in temp],\n",
    "                'others': [y_train[i][2] for i in temp],\n",
    "                'part': [y_train[i][3] for i in temp],\n",
    "                'price': [y_train[i][4] for i in temp],\n",
    "                'service': [y_train[i][5] for i in temp],\n",
    "            })\n",
    "    \n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "    \n",
    "        end_time = time.time() \n",
    "        duration = end_time - start_time\n",
    "    \n",
    "        sampling_dur.append(duration)\n",
    "        for i in least_confident_indices:\n",
    "            new_samples.append(remaining_indices[i])\n",
    "            \n",
    "        print(\"Nearest checkpoint:\", nearest_cp)\n",
    "        print(\"Threshold:\", threshold)\n",
    "        print(\"Samples above threshold:\", num_of_candidates)\n",
    "        print(\"Acquired samples:\", len(least_confident_indices))\n",
    "        print(f\"Sampling duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e50360",
   "metadata": {
    "papermill": {
     "duration": 0.013563,
     "end_time": "2025-03-30T07:57:49.633976",
     "exception": false,
     "start_time": "2025-03-30T07:57:49.620413",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8875c46a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:57:49.665812Z",
     "iopub.status.busy": "2025-03-30T07:57:49.665383Z",
     "iopub.status.idle": "2025-03-30T07:57:49.681357Z",
     "shell.execute_reply": "2025-03-30T07:57:49.680524Z"
    },
    "papermill": {
     "duration": 0.032988,
     "end_time": "2025-03-30T07:57:49.682909",
     "exception": false,
     "start_time": "2025-03-30T07:57:49.649921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    aspect_accuracies = manager.list()\n",
    "    aspect_f1_micros = manager.list()\n",
    "    aspect_f1_macros = manager.list()\n",
    "    sentiment_accuracies = manager.list()\n",
    "    sentiment_f1_micros = manager.list()\n",
    "    sentiment_f1_macros = manager.list()\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        # Train the model\n",
    "        args = (\n",
    "            current_train_size, \n",
    "            train_indices, \n",
    "            (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "            (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "            (data_used, accuracies, f1_micros, f1_macros), \n",
    "            i,\n",
    "            seed\n",
    "        )\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{i+1}-model')\n",
    "        sentiment_model = BertForSequenceClassification.from_pretrained(f'{filename}-sentiment-{i+1}-model')\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (\n",
    "            aspect_model, \n",
    "            sentiment_model, \n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices, \n",
    "            remaining_indices, \n",
    "            sampling_dur, \n",
    "            new_samples, \n",
    "            i\n",
    "        )\n",
    "        notebook_launcher(monte_carlo_dropout_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    args = (\n",
    "        current_train_size, \n",
    "        train_indices, \n",
    "        (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "        (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "        (data_used, accuracies, f1_micros, f1_macros), \n",
    "        i,\n",
    "        seed\n",
    "    )\n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    aspect_accuracies, aspect_f1_micros, aspect_f1_macros = list(aspect_accuracies), list(aspect_f1_micros), list(aspect_f1_macros)\n",
    "    sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros = list(sentiment_accuracies), list(sentiment_f1_micros), list(sentiment_f1_macros)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Aspect Accuracy': aspect_accuracies,\n",
    "        'Aspect F1 Micro': aspect_f1_micros,\n",
    "        'Aspect F1 Macro': aspect_f1_macros,\n",
    "        'Sentiment Accuracy': sentiment_accuracies,\n",
    "        'Sentiment F1 Micro': sentiment_f1_micros,\n",
    "        'Sentiment F1 Macro': sentiment_f1_macros,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "655f0c86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:57:49.710549Z",
     "iopub.status.busy": "2025-03-30T07:57:49.710167Z",
     "iopub.status.idle": "2025-03-30T07:57:49.714172Z",
     "shell.execute_reply": "2025-03-30T07:57:49.713376Z"
    },
    "papermill": {
     "duration": 0.019682,
     "end_time": "2025-03-30T07:57:49.715553",
     "exception": false,
     "start_time": "2025-03-30T07:57:49.695871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b89321b",
   "metadata": {
    "papermill": {
     "duration": 0.022092,
     "end_time": "2025-03-30T07:57:49.752151",
     "exception": false,
     "start_time": "2025-03-30T07:57:49.730059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b82242b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T07:57:49.779021Z",
     "iopub.status.busy": "2025-03-30T07:57:49.778745Z",
     "iopub.status.idle": "2025-03-30T10:00:54.397328Z",
     "shell.execute_reply": "2025-03-30T10:00:54.396385Z"
    },
    "papermill": {
     "duration": 7384.633387,
     "end_time": "2025-03-30T10:00:54.398751",
     "exception": false,
     "start_time": "2025-03-30T07:57:49.765364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5865, Accuracy: 0.7995, F1 Micro: 0.8876, F1 Macro: 0.8805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4747, Accuracy: 0.801, F1 Micro: 0.8892, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4337, Accuracy: 0.8007, F1 Micro: 0.8893, F1 Macro: 0.8848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.425, Accuracy: 0.8033, F1 Micro: 0.8905, F1 Macro: 0.8856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4065, Accuracy: 0.8064, F1 Micro: 0.8916, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4121, Accuracy: 0.8101, F1 Micro: 0.8933, F1 Macro: 0.8874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3857, Accuracy: 0.8177, F1 Micro: 0.8971, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3725, Accuracy: 0.8321, F1 Micro: 0.9044, F1 Macro: 0.8994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3428, Accuracy: 0.841, F1 Micro: 0.9088, F1 Macro: 0.9042\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3197, Accuracy: 0.8507, F1 Micro: 0.9137, F1 Macro: 0.9092\n",
      "\n",
      "Aspect detection accuracy: 0.8507, F1 Micro: 0.9137, F1 Macro: 0.9092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.84      1.00      0.91       462\n",
      "   air_panas       0.84      1.00      0.91       480\n",
      "         bau       0.86      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.80      0.85      0.83       317\n",
      "       linen       0.71      0.99      0.83       392\n",
      "     service       0.88      0.97      0.93       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.86      1.00      0.93       498\n",
      "\n",
      "   micro avg       0.85      0.99      0.91      4614\n",
      "   macro avg       0.85      0.98      0.91      4614\n",
      "weighted avg       0.85      0.99      0.91      4614\n",
      " samples avg       0.85      0.99      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6014, Accuracy: 0.6293, F1 Micro: 0.6293, F1 Macro: 0.3862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5503, Accuracy: 0.6293, F1 Micro: 0.6293, F1 Macro: 0.3862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4934, Accuracy: 0.6293, F1 Micro: 0.6293, F1 Macro: 0.3862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3898, Accuracy: 0.6878, F1 Micro: 0.6878, F1 Macro: 0.5444\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3441, Accuracy: 0.7488, F1 Micro: 0.7488, F1 Macro: 0.6959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2311, Accuracy: 0.7634, F1 Micro: 0.7634, F1 Macro: 0.719\n",
      "Epoch 7/10, Train Loss: 0.181, Accuracy: 0.7439, F1 Micro: 0.7439, F1 Macro: 0.6915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2402, Accuracy: 0.7756, F1 Micro: 0.7756, F1 Macro: 0.7399\n",
      "Epoch 9/10, Train Loss: 0.1526, Accuracy: 0.7512, F1 Micro: 0.7512, F1 Macro: 0.6996\n",
      "Epoch 10/10, Train Loss: 0.1164, Accuracy: 0.7537, F1 Micro: 0.7537, F1 Macro: 0.7047\n",
      "\n",
      "Sentiment analysis accuracy: 0.7756, F1 Micro: 0.7756, F1 Macro: 0.7399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.91      0.84       258\n",
      "    positive       0.78      0.55      0.64       152\n",
      "\n",
      "    accuracy                           0.78       410\n",
      "   macro avg       0.78      0.73      0.74       410\n",
      "weighted avg       0.78      0.78      0.76       410\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8419, F1 Micro: 0.8419, F1 Macro: 0.4131\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.27      0.42        97\n",
      "     neutral       0.84      1.00      0.91       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.59      0.42      0.44       571\n",
      "weighted avg       0.84      0.85      0.81       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.01      0.02        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       1.00      0.10      0.18        10\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.94      0.37      0.37       571\n",
      "weighted avg       0.86      0.84      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        78\n",
      "     neutral       0.86      1.00      0.92       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.74      0.86      0.80       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.69      0.71       200\n",
      "     neutral       0.80      0.85      0.83       315\n",
      "    positive       0.43      0.38      0.40        56\n",
      "\n",
      "    accuracy                           0.75       571\n",
      "   macro avg       0.66      0.64      0.65       571\n",
      "weighted avg       0.74      0.75      0.75       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.18      0.30       162\n",
      "     neutral       0.71      0.99      0.83       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.72       571\n",
      "   macro avg       0.52      0.39      0.37       571\n",
      "weighted avg       0.72      0.72      0.64       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.48      0.59        85\n",
      "     neutral       0.88      0.98      0.93       418\n",
      "    positive       0.76      0.62      0.68        68\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.80      0.69      0.73       571\n",
      "weighted avg       0.85      0.86      0.85       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        74\n",
      "     neutral       0.87      1.00      0.93       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.80       571\n",
      "\n",
      "Total train time: 79.86495995521545 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0010121086379513144\n",
      "Samples above threshold: 215\n",
      "Acquired samples: 215\n",
      "Sampling duration: 31.95566463470459 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5575, Accuracy: 0.8005, F1 Micro: 0.8892, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5007, Accuracy: 0.8038, F1 Micro: 0.8907, F1 Macro: 0.8859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4811, Accuracy: 0.8175, F1 Micro: 0.897, F1 Macro: 0.8923\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4307, Accuracy: 0.8434, F1 Micro: 0.9103, F1 Macro: 0.9058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3942, Accuracy: 0.867, F1 Micro: 0.9225, F1 Macro: 0.9182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3326, Accuracy: 0.8856, F1 Micro: 0.9323, F1 Macro: 0.9279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2935, Accuracy: 0.9016, F1 Micro: 0.9414, F1 Macro: 0.9388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.25, Accuracy: 0.9106, F1 Micro: 0.9459, F1 Macro: 0.9412\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2306, Accuracy: 0.9207, F1 Micro: 0.9519, F1 Macro: 0.9483\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1974, Accuracy: 0.9285, F1 Micro: 0.9565, F1 Macro: 0.9533\n",
      "\n",
      "Aspect detection accuracy: 0.9285, F1 Micro: 0.9565, F1 Macro: 0.9533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.98       462\n",
      "   air_panas       0.91      1.00      0.95       480\n",
      "         bau       0.96      0.97      0.97       496\n",
      "     general       0.88      1.00      0.93       500\n",
      "  kebersihan       0.87      0.90      0.88       317\n",
      "       linen       0.85      0.96      0.90       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.94      1.00      0.97       530\n",
      "          tv       0.98      1.00      0.99       516\n",
      "        wifi       0.98      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.93      0.98      0.96      4614\n",
      "   macro avg       0.93      0.98      0.95      4614\n",
      "weighted avg       0.93      0.98      0.96      4614\n",
      " samples avg       0.93      0.98      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5696, Accuracy: 0.7864, F1 Micro: 0.7864, F1 Macro: 0.6486\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4061, Accuracy: 0.8242, F1 Micro: 0.8242, F1 Macro: 0.746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3551, Accuracy: 0.832, F1 Micro: 0.832, F1 Macro: 0.7594\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2876, Accuracy: 0.842, F1 Micro: 0.842, F1 Macro: 0.7816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.242, Accuracy: 0.8532, F1 Micro: 0.8532, F1 Macro: 0.8055\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.223, Accuracy: 0.8587, F1 Micro: 0.8587, F1 Macro: 0.8056\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1531, Accuracy: 0.861, F1 Micro: 0.861, F1 Macro: 0.8105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1457, Accuracy: 0.8632, F1 Micro: 0.8632, F1 Macro: 0.804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1027, Accuracy: 0.8687, F1 Micro: 0.8687, F1 Macro: 0.8123\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1126, Accuracy: 0.8799, F1 Micro: 0.8799, F1 Macro: 0.8404\n",
      "\n",
      "Sentiment analysis accuracy: 0.8799, F1 Micro: 0.8799, F1 Macro: 0.8404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92       650\n",
      "    positive       0.85      0.69      0.76       249\n",
      "\n",
      "    accuracy                           0.88       899\n",
      "   macro avg       0.87      0.82      0.84       899\n",
      "weighted avg       0.88      0.88      0.88       899\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.921, F1 Micro: 0.921, F1 Macro: 0.696\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.89      0.92        97\n",
      "     neutral       0.98      0.99      0.98       459\n",
      "    positive       0.87      0.87      0.87        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.50      0.66        86\n",
      "     neutral       0.91      1.00      0.95       475\n",
      "    positive       0.25      0.10      0.14        10\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.70      0.53      0.58       571\n",
      "weighted avg       0.90      0.91      0.89       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.76      0.78        78\n",
      "     neutral       0.96      0.97      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.58      0.58       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.88      1.00      0.93       496\n",
      "    positive       0.88      0.10      0.18        68\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.58      0.37      0.37       571\n",
      "weighted avg       0.87      0.88      0.83       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.75      0.80       200\n",
      "     neutral       0.88      0.90      0.89       315\n",
      "    positive       0.68      0.93      0.79        56\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.81      0.86      0.83       571\n",
      "weighted avg       0.85      0.85      0.85       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.66      0.74       162\n",
      "     neutral       0.84      0.97      0.90       387\n",
      "    positive       0.50      0.05      0.08        22\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.73      0.56      0.58       571\n",
      "weighted avg       0.83      0.84      0.82       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.76      0.81        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.84      0.97      0.90        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.89      0.90      0.89       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.94      1.00      0.97       525\n",
      "    positive       0.73      0.47      0.57        17\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.55      0.49      0.51       571\n",
      "weighted avg       0.88      0.93      0.91       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.81      0.87        54\n",
      "     neutral       0.98      1.00      0.99       511\n",
      "    positive       0.50      0.50      0.50         6\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.81      0.77      0.79       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.88      0.92        74\n",
      "     neutral       0.98      1.00      0.99       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.85      0.90       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 123.50765776634216 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.07998066022992134\n",
      "Samples above threshold: 193\n",
      "Acquired samples: 193\n",
      "Sampling duration: 48.43165850639343 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5441, Accuracy: 0.8076, F1 Micro: 0.8924, F1 Macro: 0.8879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4936, Accuracy: 0.8342, F1 Micro: 0.9052, F1 Macro: 0.9002\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4366, Accuracy: 0.866, F1 Micro: 0.9214, F1 Macro: 0.916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3633, Accuracy: 0.8948, F1 Micro: 0.9374, F1 Macro: 0.9345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3024, Accuracy: 0.9248, F1 Micro: 0.9544, F1 Macro: 0.9513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.243, Accuracy: 0.9335, F1 Micro: 0.9596, F1 Macro: 0.9571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2055, Accuracy: 0.9339, F1 Micro: 0.9597, F1 Macro: 0.9569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1773, Accuracy: 0.9382, F1 Micro: 0.9623, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.16, Accuracy: 0.9429, F1 Micro: 0.965, F1 Macro: 0.9626\n",
      "Epoch 10/10, Train Loss: 0.1379, Accuracy: 0.9424, F1 Micro: 0.9646, F1 Macro: 0.9616\n",
      "\n",
      "Aspect detection accuracy: 0.9429, F1 Micro: 0.965, F1 Macro: 0.9626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.94      0.99      0.97       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.89      0.99      0.94       500\n",
      "  kebersihan       0.90      0.93      0.91       317\n",
      "       linen       0.88      0.97      0.92       392\n",
      "     service       0.96      0.96      0.96       423\n",
      "sunrise_meal       0.95      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.97      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.585, Accuracy: 0.8285, F1 Micro: 0.8285, F1 Macro: 0.7719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3848, Accuracy: 0.8545, F1 Micro: 0.8545, F1 Macro: 0.7957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3029, Accuracy: 0.869, F1 Micro: 0.869, F1 Macro: 0.8205\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1984, Accuracy: 0.8846, F1 Micro: 0.8846, F1 Macro: 0.8402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.153, Accuracy: 0.894, F1 Micro: 0.894, F1 Macro: 0.8543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1093, Accuracy: 0.894, F1 Micro: 0.894, F1 Macro: 0.8534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0773, Accuracy: 0.896, F1 Micro: 0.896, F1 Macro: 0.8572\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0814, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0613, Accuracy: 0.9075, F1 Micro: 0.9075, F1 Macro: 0.876\n",
      "Epoch 10/10, Train Loss: 0.0446, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8754\n",
      "\n",
      "Sentiment analysis accuracy: 0.9075, F1 Micro: 0.9075, F1 Macro: 0.876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       695\n",
      "    positive       0.92      0.73      0.81       267\n",
      "\n",
      "    accuracy                           0.91       962\n",
      "   macro avg       0.91      0.85      0.88       962\n",
      "weighted avg       0.91      0.91      0.90       962\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.8\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.70      0.78        86\n",
      "     neutral       0.94      0.99      0.97       475\n",
      "    positive       0.50      0.20      0.29        10\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.77      0.63      0.68       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.77      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.89      0.99      0.94       496\n",
      "    positive       0.88      0.22      0.35        68\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.59      0.40      0.43       571\n",
      "weighted avg       0.88      0.89      0.86       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.85       200\n",
      "     neutral       0.90      0.93      0.91       315\n",
      "    positive       0.81      0.96      0.88        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.87      0.90      0.88       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.72      0.80       162\n",
      "     neutral       0.87      0.97      0.92       387\n",
      "    positive       0.70      0.32      0.44        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.82      0.67      0.72       571\n",
      "weighted avg       0.87      0.88      0.87       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.80      0.82        85\n",
      "     neutral       0.96      0.96      0.96       418\n",
      "    positive       0.89      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.90      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.21      0.33        29\n",
      "     neutral       0.95      1.00      0.98       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.89      0.66      0.71       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 149.40449929237366 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.02188113257288927\n",
      "Samples above threshold: 174\n",
      "Acquired samples: 174\n",
      "Sampling duration: 42.933464765548706 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5492, Accuracy: 0.8118, F1 Micro: 0.8939, F1 Macro: 0.8895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4873, Accuracy: 0.8519, F1 Micro: 0.9144, F1 Macro: 0.9103\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4103, Accuracy: 0.8931, F1 Micro: 0.9364, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3114, Accuracy: 0.9253, F1 Micro: 0.9548, F1 Macro: 0.9517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2428, Accuracy: 0.938, F1 Micro: 0.9621, F1 Macro: 0.9595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2064, Accuracy: 0.9469, F1 Micro: 0.9673, F1 Macro: 0.9647\n",
      "Epoch 7/10, Train Loss: 0.1803, Accuracy: 0.9441, F1 Micro: 0.9658, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1585, Accuracy: 0.9503, F1 Micro: 0.9694, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1371, Accuracy: 0.9524, F1 Micro: 0.9706, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.123, Accuracy: 0.954, F1 Micro: 0.9716, F1 Macro: 0.969\n",
      "\n",
      "Aspect detection accuracy: 0.954, F1 Micro: 0.9716, F1 Macro: 0.969\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.96      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.91      0.93      0.92       317\n",
      "       linen       0.90      0.96      0.93       392\n",
      "     service       0.95      0.98      0.96       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.58, Accuracy: 0.8467, F1 Micro: 0.8467, F1 Macro: 0.793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3903, Accuracy: 0.8679, F1 Micro: 0.8679, F1 Macro: 0.8303\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2135, Accuracy: 0.8997, F1 Micro: 0.8997, F1 Macro: 0.8716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1506, Accuracy: 0.9007, F1 Micro: 0.9007, F1 Macro: 0.8715\n",
      "Epoch 5/10, Train Loss: 0.1261, Accuracy: 0.8987, F1 Micro: 0.8987, F1 Macro: 0.8745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1039, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8834\n",
      "Epoch 7/10, Train Loss: 0.0627, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8734\n",
      "Epoch 8/10, Train Loss: 0.0472, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8784\n",
      "Epoch 9/10, Train Loss: 0.0462, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.034, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8834\n",
      "\n",
      "Sentiment analysis accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8834\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       731\n",
      "    positive       0.94      0.74      0.83       306\n",
      "\n",
      "    accuracy                           0.91      1037\n",
      "   macro avg       0.92      0.86      0.88      1037\n",
      "weighted avg       0.91      0.91      0.91      1037\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.8438\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.80      0.84        86\n",
      "     neutral       0.96      0.99      0.98       475\n",
      "    positive       0.75      0.30      0.43        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.87      0.70      0.75       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.77      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.82      0.62      0.71        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.75      0.58      0.63       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.87       200\n",
      "     neutral       0.91      0.93      0.92       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.80      0.83       162\n",
      "     neutral       0.90      0.96      0.93       387\n",
      "    positive       0.78      0.32      0.45        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.85      0.69      0.74       571\n",
      "weighted avg       0.89      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        85\n",
      "     neutral       0.95      0.98      0.97       418\n",
      "    positive       0.89      0.93      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.89      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.41      0.53        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.74      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 168.70063304901123 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0019015478901565077\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 156\n",
      "Sampling duration: 38.65107583999634 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5384, Accuracy: 0.8146, F1 Micro: 0.8926, F1 Macro: 0.8748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4699, Accuracy: 0.8661, F1 Micro: 0.9214, F1 Macro: 0.9156\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.36, Accuracy: 0.9104, F1 Micro: 0.9463, F1 Macro: 0.943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2799, Accuracy: 0.9361, F1 Micro: 0.9611, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2327, Accuracy: 0.9427, F1 Micro: 0.9648, F1 Macro: 0.9619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1956, Accuracy: 0.951, F1 Micro: 0.9698, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1642, Accuracy: 0.9531, F1 Micro: 0.9711, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1442, Accuracy: 0.9542, F1 Micro: 0.9718, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1255, Accuracy: 0.955, F1 Micro: 0.9723, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1124, Accuracy: 0.9589, F1 Micro: 0.9746, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9589, F1 Micro: 0.9746, F1 Macro: 0.9721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.93      0.99      0.96       500\n",
      "  kebersihan       0.91      0.94      0.92       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5368, Accuracy: 0.845, F1 Micro: 0.845, F1 Macro: 0.7777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3297, Accuracy: 0.8842, F1 Micro: 0.8842, F1 Macro: 0.8526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.219, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.144, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1124, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.8818\n",
      "Epoch 6/10, Train Loss: 0.0726, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0715, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8837\n",
      "Epoch 8/10, Train Loss: 0.0583, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0803, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0394, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8899\n",
      "\n",
      "Sentiment analysis accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       749\n",
      "    positive       0.93      0.76      0.84       296\n",
      "\n",
      "    accuracy                           0.92      1045\n",
      "   macro avg       0.92      0.87      0.89      1045\n",
      "weighted avg       0.92      0.92      0.91      1045\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9532, F1 Micro: 0.9532, F1 Macro: 0.849\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.85      0.89        86\n",
      "     neutral       0.97      1.00      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.78      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.76      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.99      0.96       496\n",
      "    positive       0.86      0.54      0.67        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.60      0.51      0.54       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.82      0.86       200\n",
      "     neutral       0.91      0.94      0.92       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86       162\n",
      "     neutral       0.93      0.96      0.94       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.75      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        85\n",
      "     neutral       0.96      0.97      0.97       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.52      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.78      0.80       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 196.5365867614746 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.001239701895974576\n",
      "Samples above threshold: 141\n",
      "Acquired samples: 141\n",
      "Sampling duration: 34.4837121963501 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5382, Accuracy: 0.8241, F1 Micro: 0.8997, F1 Macro: 0.8926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4587, Accuracy: 0.8809, F1 Micro: 0.9292, F1 Macro: 0.9227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3441, Accuracy: 0.9295, F1 Micro: 0.9571, F1 Macro: 0.9539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2654, Accuracy: 0.9398, F1 Micro: 0.9631, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2201, Accuracy: 0.9493, F1 Micro: 0.9688, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1852, Accuracy: 0.9521, F1 Micro: 0.9704, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1541, Accuracy: 0.9528, F1 Micro: 0.9709, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1343, Accuracy: 0.9554, F1 Micro: 0.9725, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1212, Accuracy: 0.9561, F1 Micro: 0.9729, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1054, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9712\n",
      "\n",
      "Aspect detection accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.93      0.99      0.96       500\n",
      "  kebersihan       0.92      0.92      0.92       317\n",
      "       linen       0.90      0.97      0.93       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5013, Accuracy: 0.8553, F1 Micro: 0.8553, F1 Macro: 0.8014\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3309, Accuracy: 0.8796, F1 Micro: 0.8796, F1 Macro: 0.8405\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2248, Accuracy: 0.8908, F1 Micro: 0.8908, F1 Macro: 0.8641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1589, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8788\n",
      "Epoch 5/10, Train Loss: 0.1069, Accuracy: 0.8926, F1 Micro: 0.8926, F1 Macro: 0.8621\n",
      "Epoch 6/10, Train Loss: 0.0886, Accuracy: 0.901, F1 Micro: 0.901, F1 Macro: 0.8707\n",
      "Epoch 7/10, Train Loss: 0.0696, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0467, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8785\n",
      "Epoch 9/10, Train Loss: 0.0258, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8726\n",
      "Epoch 10/10, Train Loss: 0.0488, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8717\n",
      "\n",
      "Sentiment analysis accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       759\n",
      "    positive       0.93      0.73      0.82       312\n",
      "\n",
      "    accuracy                           0.91      1071\n",
      "   macro avg       0.92      0.85      0.88      1071\n",
      "weighted avg       0.91      0.91      0.90      1071\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9527, F1 Micro: 0.9527, F1 Macro: 0.8512\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.82       571\n",
      "weighted avg       0.96      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.99      0.96       496\n",
      "    positive       0.85      0.57      0.68        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.52      0.55       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       200\n",
      "     neutral       0.92      0.92      0.92       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.80      0.83       162\n",
      "     neutral       0.90      0.97      0.93       387\n",
      "    positive       0.89      0.36      0.52        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.89      0.71      0.76       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        85\n",
      "     neutral       0.97      0.96      0.97       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.84      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 216.08768677711487 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0011058745905756955\n",
      "Samples above threshold: 127\n",
      "Acquired samples: 127\n",
      "Sampling duration: 30.81414771080017 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.529, Accuracy: 0.8165, F1 Micro: 0.8971, F1 Macro: 0.8931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4328, Accuracy: 0.8962, F1 Micro: 0.9377, F1 Macro: 0.9331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.323, Accuracy: 0.9316, F1 Micro: 0.9583, F1 Macro: 0.955\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2538, Accuracy: 0.9453, F1 Micro: 0.9664, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2046, Accuracy: 0.9521, F1 Micro: 0.9705, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1763, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1463, Accuracy: 0.9573, F1 Micro: 0.9736, F1 Macro: 0.9708\n",
      "Epoch 8/10, Train Loss: 0.1305, Accuracy: 0.9563, F1 Micro: 0.973, F1 Macro: 0.9701\n",
      "Epoch 9/10, Train Loss: 0.1082, Accuracy: 0.9568, F1 Micro: 0.9733, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0973, Accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.9721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.93      0.98      0.96       500\n",
      "  kebersihan       0.95      0.91      0.93       317\n",
      "       linen       0.91      0.96      0.93       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4825, Accuracy: 0.8441, F1 Micro: 0.8441, F1 Macro: 0.7977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2997, Accuracy: 0.8893, F1 Micro: 0.8893, F1 Macro: 0.8585\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1978, Accuracy: 0.8948, F1 Micro: 0.8948, F1 Macro: 0.8646\n",
      "Epoch 4/10, Train Loss: 0.1361, Accuracy: 0.893, F1 Micro: 0.893, F1 Macro: 0.8566\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1105, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8752\n",
      "Epoch 6/10, Train Loss: 0.0772, Accuracy: 0.8967, F1 Micro: 0.8967, F1 Macro: 0.8652\n",
      "Epoch 7/10, Train Loss: 0.0795, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8597\n",
      "Epoch 8/10, Train Loss: 0.0732, Accuracy: 0.8948, F1 Micro: 0.8948, F1 Macro: 0.8634\n",
      "Epoch 9/10, Train Loss: 0.051, Accuracy: 0.8985, F1 Micro: 0.8985, F1 Macro: 0.8676\n",
      "Epoch 10/10, Train Loss: 0.0384, Accuracy: 0.8948, F1 Micro: 0.8948, F1 Macro: 0.8631\n",
      "\n",
      "Sentiment analysis accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       767\n",
      "    positive       0.92      0.74      0.82       317\n",
      "\n",
      "    accuracy                           0.90      1084\n",
      "   macro avg       0.91      0.85      0.88      1084\n",
      "weighted avg       0.90      0.90      0.90      1084\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9527, F1 Micro: 0.9527, F1 Macro: 0.8518\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.86      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.78      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.83      0.56      0.67        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.51      0.54       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.95      0.91      0.93       315\n",
      "    positive       0.79      0.96      0.87        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.79      0.83       162\n",
      "     neutral       0.91      0.96      0.93       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.85      0.75      0.79       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.78      0.83        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.90      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.83      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 230.48390126228333 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0007821739884093404\n",
      "Samples above threshold: 114\n",
      "Acquired samples: 114\n",
      "Sampling duration: 27.249758005142212 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5293, Accuracy: 0.8398, F1 Micro: 0.9064, F1 Macro: 0.8955\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4147, Accuracy: 0.9087, F1 Micro: 0.9446, F1 Macro: 0.9396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3005, Accuracy: 0.9392, F1 Micro: 0.9629, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2272, Accuracy: 0.9495, F1 Micro: 0.9689, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1876, Accuracy: 0.9528, F1 Micro: 0.9709, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1613, Accuracy: 0.9573, F1 Micro: 0.9736, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1364, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1171, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1017, Accuracy: 0.9611, F1 Micro: 0.9758, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0845, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4429, Accuracy: 0.8668, F1 Micro: 0.8668, F1 Macro: 0.8303\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2884, Accuracy: 0.8841, F1 Micro: 0.8841, F1 Macro: 0.8464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2076, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1467, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1126, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8815\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0823, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8857\n",
      "Epoch 7/10, Train Loss: 0.0703, Accuracy: 0.8942, F1 Micro: 0.8942, F1 Macro: 0.868\n",
      "Epoch 8/10, Train Loss: 0.0642, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8732\n",
      "Epoch 9/10, Train Loss: 0.0331, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8856\n",
      "Epoch 10/10, Train Loss: 0.037, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8851\n",
      "\n",
      "Sentiment analysis accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       775\n",
      "    positive       0.94      0.74      0.83       321\n",
      "\n",
      "    accuracy                           0.91      1096\n",
      "   macro avg       0.92      0.86      0.89      1096\n",
      "weighted avg       0.91      0.91      0.91      1096\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.8718\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.80      0.84       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.75      0.41      0.53        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.85      0.73      0.77       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.93      0.97      0.95        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.69      0.78        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.84      0.94      0.89        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.88      0.89       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 241.36856889724731 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0007661901181563735\n",
      "Samples above threshold: 103\n",
      "Acquired samples: 103\n",
      "Sampling duration: 23.985726356506348 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5158, Accuracy: 0.8443, F1 Micro: 0.9091, F1 Macro: 0.8996\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4028, Accuracy: 0.9165, F1 Micro: 0.9496, F1 Macro: 0.946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2772, Accuracy: 0.9401, F1 Micro: 0.9635, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2211, Accuracy: 0.9479, F1 Micro: 0.9681, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1812, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1505, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1298, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9738\n",
      "Epoch 8/10, Train Loss: 0.1147, Accuracy: 0.9585, F1 Micro: 0.9743, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0969, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9751\n",
      "Epoch 10/10, Train Loss: 0.0835, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.95      0.94      0.94       317\n",
      "       linen       0.90      0.98      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4412, Accuracy: 0.8765, F1 Micro: 0.8765, F1 Macro: 0.8402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2444, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.88\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1599, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8765\n",
      "Epoch 4/10, Train Loss: 0.1206, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0895, Accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.8879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.075, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.8964\n",
      "Epoch 7/10, Train Loss: 0.0543, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.8915\n",
      "Epoch 8/10, Train Loss: 0.0346, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.8926\n",
      "Epoch 9/10, Train Loss: 0.0207, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.8913\n",
      "Epoch 10/10, Train Loss: 0.0269, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8924\n",
      "\n",
      "Sentiment analysis accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.8964\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       761\n",
      "    positive       0.94      0.77      0.85       300\n",
      "\n",
      "    accuracy                           0.92      1061\n",
      "   macro avg       0.93      0.88      0.90      1061\n",
      "weighted avg       0.92      0.92      0.92      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9574, F1 Micro: 0.9574, F1 Macro: 0.8614\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.85      0.90        86\n",
      "     neutral       0.97      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.78      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.85      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.60      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.94      0.94       315\n",
      "    positive       0.88      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.78      0.84       162\n",
      "     neutral       0.90      0.98      0.94       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.88      0.72      0.78       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.96      0.96      0.96        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.82      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 257.27816891670227 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0006039466243237265\n",
      "Samples above threshold: 92\n",
      "Acquired samples: 62\n",
      "Sampling duration: 21.177802801132202 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5141, Accuracy: 0.8361, F1 Micro: 0.9068, F1 Macro: 0.9027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3867, Accuracy: 0.9187, F1 Micro: 0.9506, F1 Macro: 0.9455\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2653, Accuracy: 0.9411, F1 Micro: 0.964, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2148, Accuracy: 0.9521, F1 Micro: 0.9705, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1777, Accuracy: 0.9582, F1 Micro: 0.9741, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1471, Accuracy: 0.9589, F1 Micro: 0.9745, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1258, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9742\n",
      "Epoch 8/10, Train Loss: 0.1148, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9729\n",
      "Epoch 9/10, Train Loss: 0.0946, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0836, Accuracy: 0.9642, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.9642, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.93      0.99      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.92      0.98      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.99      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4386, Accuracy: 0.8691, F1 Micro: 0.8691, F1 Macro: 0.8272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2694, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.177, Accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8894\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1197, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.8932\n",
      "Epoch 5/10, Train Loss: 0.0907, Accuracy: 0.9162, F1 Micro: 0.9162, F1 Macro: 0.8885\n",
      "Epoch 6/10, Train Loss: 0.0428, Accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.046, Accuracy: 0.9218, F1 Micro: 0.9218, F1 Macro: 0.8961\n",
      "Epoch 8/10, Train Loss: 0.0519, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0321, Accuracy: 0.9256, F1 Micro: 0.9256, F1 Macro: 0.9008\n",
      "Epoch 10/10, Train Loss: 0.036, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.8974\n",
      "\n",
      "Sentiment analysis accuracy: 0.9256, F1 Micro: 0.9256, F1 Macro: 0.9008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       772\n",
      "    positive       0.94      0.78      0.85       290\n",
      "\n",
      "    accuracy                           0.93      1062\n",
      "   macro avg       0.93      0.88      0.90      1062\n",
      "weighted avg       0.93      0.93      0.92      1062\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.8547\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.86      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.85        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.79      0.76      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.99      0.96       496\n",
      "    positive       0.84      0.54      0.66        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.51      0.54       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.84      0.95      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.77      0.82       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 254.27434754371643 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.000428370971349068\n",
      "Samples above threshold: 86\n",
      "Acquired samples: 86\n",
      "Sampling duration: 19.50300431251526 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5054, Accuracy: 0.8455, F1 Micro: 0.9108, F1 Macro: 0.9056\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3656, Accuracy: 0.9238, F1 Micro: 0.9541, F1 Macro: 0.9515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2542, Accuracy: 0.9453, F1 Micro: 0.9665, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2029, Accuracy: 0.953, F1 Micro: 0.971, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1702, Accuracy: 0.9608, F1 Micro: 0.9756, F1 Macro: 0.9734\n",
      "Epoch 6/10, Train Loss: 0.1449, Accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.9723\n",
      "Epoch 7/10, Train Loss: 0.1194, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1036, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0904, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0769, Accuracy: 0.9651, F1 Micro: 0.9784, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9651, F1 Micro: 0.9784, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3881, Accuracy: 0.8686, F1 Micro: 0.8686, F1 Macro: 0.8273\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2272, Accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.8763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1417, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8918\n",
      "Epoch 4/10, Train Loss: 0.1079, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8814\n",
      "Epoch 5/10, Train Loss: 0.0905, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8856\n",
      "Epoch 6/10, Train Loss: 0.0591, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8859\n",
      "Epoch 7/10, Train Loss: 0.0467, Accuracy: 0.9075, F1 Micro: 0.9075, F1 Macro: 0.8757\n",
      "Epoch 8/10, Train Loss: 0.042, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8841\n",
      "Epoch 9/10, Train Loss: 0.0297, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8728\n",
      "Epoch 10/10, Train Loss: 0.0262, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8843\n",
      "\n",
      "Sentiment analysis accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8918\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       774\n",
      "    positive       0.93      0.77      0.84       307\n",
      "\n",
      "    accuracy                           0.92      1081\n",
      "   macro avg       0.92      0.87      0.89      1081\n",
      "weighted avg       0.92      0.92      0.91      1081\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8633\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.77      0.83       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.68      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.60      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.86      0.55      0.67        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.79      0.83       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.94      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.79       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.93      0.96       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.96      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 263.81634616851807 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.0004427792417118328\n",
      "Samples above threshold: 77\n",
      "Acquired samples: 77\n",
      "Sampling duration: 17.304234266281128 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4997, Accuracy: 0.8557, F1 Micro: 0.9165, F1 Macro: 0.9116\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3541, Accuracy: 0.9266, F1 Micro: 0.9553, F1 Macro: 0.9514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2466, Accuracy: 0.9493, F1 Micro: 0.9688, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1995, Accuracy: 0.9557, F1 Micro: 0.9727, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1672, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "Epoch 6/10, Train Loss: 0.137, Accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1186, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9745\n",
      "Epoch 8/10, Train Loss: 0.1016, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0877, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "Epoch 10/10, Train Loss: 0.076, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3968, Accuracy: 0.8612, F1 Micro: 0.8612, F1 Macro: 0.8062\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2284, Accuracy: 0.9029, F1 Micro: 0.9029, F1 Macro: 0.8755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1632, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8843\n",
      "Epoch 4/10, Train Loss: 0.1105, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0817, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8877\n",
      "Epoch 6/10, Train Loss: 0.0629, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0561, Accuracy: 0.9156, F1 Micro: 0.9156, F1 Macro: 0.8908\n",
      "Epoch 8/10, Train Loss: 0.0296, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8848\n",
      "Epoch 9/10, Train Loss: 0.0354, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8872\n",
      "Epoch 10/10, Train Loss: 0.0258, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8811\n",
      "\n",
      "Sentiment analysis accuracy: 0.9156, F1 Micro: 0.9156, F1 Macro: 0.8908\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       784\n",
      "    positive       0.93      0.76      0.84       318\n",
      "\n",
      "    accuracy                           0.92      1102\n",
      "   macro avg       0.92      0.87      0.89      1102\n",
      "weighted avg       0.92      0.92      0.91      1102\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8675\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.85      0.84        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.56      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.90       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.86      0.55      0.67        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.79      0.83       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.97      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 267.8373656272888 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.0003014625399373476\n",
      "Samples above threshold: 70\n",
      "Acquired samples: 70\n",
      "Sampling duration: 15.409927129745483 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4942, Accuracy: 0.854, F1 Micro: 0.9158, F1 Macro: 0.9117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3431, Accuracy: 0.9281, F1 Micro: 0.9566, F1 Macro: 0.9542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2388, Accuracy: 0.9503, F1 Micro: 0.9695, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1965, Accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.159, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1356, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9747\n",
      "Epoch 7/10, Train Loss: 0.1161, Accuracy: 0.9622, F1 Micro: 0.9766, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0994, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0837, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9763\n",
      "Epoch 10/10, Train Loss: 0.0689, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9754\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3867, Accuracy: 0.8639, F1 Micro: 0.8639, F1 Macro: 0.82\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2422, Accuracy: 0.8875, F1 Micro: 0.8875, F1 Macro: 0.8502\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1549, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1125, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8905\n",
      "Epoch 5/10, Train Loss: 0.0811, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8848\n",
      "Epoch 6/10, Train Loss: 0.0638, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8836\n",
      "Epoch 7/10, Train Loss: 0.0641, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8904\n",
      "Epoch 8/10, Train Loss: 0.0398, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8858\n",
      "Epoch 9/10, Train Loss: 0.0412, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8884\n",
      "Epoch 10/10, Train Loss: 0.0267, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8887\n",
      "\n",
      "Sentiment analysis accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       778\n",
      "    positive       0.94      0.76      0.84       324\n",
      "\n",
      "    accuracy                           0.91      1102\n",
      "   macro avg       0.92      0.87      0.89      1102\n",
      "weighted avg       0.92      0.91      0.91      1102\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8828\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.85      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.78      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.87      0.76      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.63      0.68       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.75      0.79       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.97      0.96        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 275.57961893081665 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.00024202353670261801\n",
      "Samples above threshold: 63\n",
      "Acquired samples: 52\n",
      "Sampling duration: 13.982055187225342 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4889, Accuracy: 0.8587, F1 Micro: 0.9179, F1 Macro: 0.913\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3267, Accuracy: 0.9342, F1 Micro: 0.96, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2348, Accuracy: 0.9484, F1 Micro: 0.9683, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.181, Accuracy: 0.955, F1 Micro: 0.9722, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1534, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1288, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "Epoch 7/10, Train Loss: 0.1119, Accuracy: 0.9608, F1 Micro: 0.9758, F1 Macro: 0.9736\n",
      "Epoch 8/10, Train Loss: 0.0901, Accuracy: 0.9622, F1 Micro: 0.9766, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0775, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0663, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3763, Accuracy: 0.8676, F1 Micro: 0.8676, F1 Macro: 0.8304\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2086, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.8761\n",
      "Epoch 3/10, Train Loss: 0.1512, Accuracy: 0.9003, F1 Micro: 0.9003, F1 Macro: 0.8681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1092, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0806, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0528, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8833\n",
      "Epoch 7/10, Train Loss: 0.037, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8807\n",
      "Epoch 8/10, Train Loss: 0.036, Accuracy: 0.8985, F1 Micro: 0.8985, F1 Macro: 0.8721\n",
      "Epoch 9/10, Train Loss: 0.0228, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8817\n",
      "Epoch 10/10, Train Loss: 0.0188, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8815\n",
      "\n",
      "Sentiment analysis accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8833\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       782\n",
      "    positive       0.94      0.74      0.83       321\n",
      "\n",
      "    accuracy                           0.91      1103\n",
      "   macro avg       0.92      0.86      0.88      1103\n",
      "weighted avg       0.91      0.91      0.91      1103\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.8496\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.60      0.61      0.61       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.88       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.77      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 289.1205966472626 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0001746230263961479\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 58\n",
      "Sampling duration: 12.65981149673462 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4773, Accuracy: 0.8684, F1 Micro: 0.9227, F1 Macro: 0.9169\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3162, Accuracy: 0.93, F1 Micro: 0.9575, F1 Macro: 0.9552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.227, Accuracy: 0.9479, F1 Micro: 0.9681, F1 Macro: 0.9657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1817, Accuracy: 0.9563, F1 Micro: 0.973, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1462, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1238, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1071, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9764\n",
      "Epoch 8/10, Train Loss: 0.0874, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0748, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9747\n",
      "Epoch 10/10, Train Loss: 0.0636, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3709, Accuracy: 0.8692, F1 Micro: 0.8692, F1 Macro: 0.8239\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2379, Accuracy: 0.8884, F1 Micro: 0.8884, F1 Macro: 0.8645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1393, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1072, Accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.8908\n",
      "Epoch 5/10, Train Loss: 0.0835, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8848\n",
      "Epoch 6/10, Train Loss: 0.0763, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0488, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0449, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.8934\n",
      "Epoch 9/10, Train Loss: 0.0457, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8834\n",
      "Epoch 10/10, Train Loss: 0.0296, Accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.8882\n",
      "\n",
      "Sentiment analysis accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.8934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       778\n",
      "    positive       0.94      0.77      0.84       315\n",
      "\n",
      "    accuracy                           0.92      1093\n",
      "   macro avg       0.92      0.87      0.89      1093\n",
      "weighted avg       0.92      0.92      0.91      1093\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8758\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.88      0.93        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.78      0.70      0.74        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.86      0.89       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.93      0.87       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.83      0.76      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.63      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.93      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       1.00      0.32      0.48        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.93      0.72      0.77       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 287.64279317855835 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0001983141526579858\n",
      "Samples above threshold: 52\n",
      "Acquired samples: 52\n",
      "Sampling duration: 11.473140716552734 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.482, Accuracy: 0.8595, F1 Micro: 0.9183, F1 Macro: 0.9128\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3174, Accuracy: 0.9349, F1 Micro: 0.9605, F1 Macro: 0.9583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2236, Accuracy: 0.9495, F1 Micro: 0.969, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1734, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.145, Accuracy: 0.9576, F1 Micro: 0.9739, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1217, Accuracy: 0.9641, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1049, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0888, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9764\n",
      "Epoch 9/10, Train Loss: 0.0774, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Epoch 10/10, Train Loss: 0.0644, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.96      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3715, Accuracy: 0.8718, F1 Micro: 0.8718, F1 Macro: 0.8321\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2038, Accuracy: 0.8936, F1 Micro: 0.8936, F1 Macro: 0.8607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1454, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1051, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8832\n",
      "Epoch 5/10, Train Loss: 0.0767, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8808\n",
      "Epoch 6/10, Train Loss: 0.0571, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8783\n",
      "Epoch 7/10, Train Loss: 0.0465, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0356, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.885\n",
      "Epoch 9/10, Train Loss: 0.0216, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8816\n",
      "Epoch 10/10, Train Loss: 0.0214, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8816\n",
      "\n",
      "Sentiment analysis accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       784\n",
      "    positive       0.95      0.73      0.83       316\n",
      "\n",
      "    accuracy                           0.91      1100\n",
      "   macro avg       0.93      0.86      0.89      1100\n",
      "weighted avg       0.92      0.91      0.91      1100\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9594, F1 Micro: 0.9594, F1 Macro: 0.8582\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.79      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.87      0.82        78\n",
      "     neutral       0.98      0.96      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.78      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.84      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.90      0.96      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.75      0.80       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.88        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.88      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 288.9648084640503 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.00015208132390398532\n",
      "Samples above threshold: 47\n",
      "Acquired samples: 50\n",
      "Sampling duration: 10.223914623260498 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4718, Accuracy: 0.8717, F1 Micro: 0.9247, F1 Macro: 0.9201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2997, Accuracy: 0.9365, F1 Micro: 0.9612, F1 Macro: 0.9589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2173, Accuracy: 0.9543, F1 Micro: 0.9718, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1682, Accuracy: 0.9575, F1 Micro: 0.9738, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1421, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1165, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0993, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9763\n",
      "Epoch 8/10, Train Loss: 0.0847, Accuracy: 0.9644, F1 Micro: 0.9778, F1 Macro: 0.9754\n",
      "Epoch 9/10, Train Loss: 0.0708, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0618, Accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3743, Accuracy: 0.8561, F1 Micro: 0.8561, F1 Macro: 0.803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2117, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1394, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8883\n",
      "Epoch 4/10, Train Loss: 0.1038, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0691, Accuracy: 0.9162, F1 Micro: 0.9162, F1 Macro: 0.8922\n",
      "Epoch 6/10, Train Loss: 0.0614, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8829\n",
      "Epoch 7/10, Train Loss: 0.0422, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8878\n",
      "Epoch 8/10, Train Loss: 0.0328, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8906\n",
      "Epoch 9/10, Train Loss: 0.0308, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8761\n",
      "Epoch 10/10, Train Loss: 0.0212, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8815\n",
      "\n",
      "Sentiment analysis accuracy: 0.9162, F1 Micro: 0.9162, F1 Macro: 0.8922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       778\n",
      "    positive       0.94      0.76      0.84       320\n",
      "\n",
      "    accuracy                           0.92      1098\n",
      "   macro avg       0.92      0.87      0.89      1098\n",
      "weighted avg       0.92      0.92      0.91      1098\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9604, F1 Micro: 0.9604, F1 Macro: 0.8847\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.87      0.76      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.63      0.68       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.76      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.82      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 293.296621799469 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 7.853226270526648e-05\n",
      "Samples above threshold: 42\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.464118003845215 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.468, Accuracy: 0.8698, F1 Micro: 0.9237, F1 Macro: 0.9189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2969, Accuracy: 0.9377, F1 Micro: 0.962, F1 Macro: 0.9597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.211, Accuracy: 0.9521, F1 Micro: 0.9706, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1583, Accuracy: 0.9571, F1 Micro: 0.9734, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1373, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1116, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9756\n",
      "Epoch 7/10, Train Loss: 0.0966, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0803, Accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.977\n",
      "Epoch 9/10, Train Loss: 0.0694, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "Epoch 10/10, Train Loss: 0.0552, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.92      0.97      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3615, Accuracy: 0.8792, F1 Micro: 0.8792, F1 Macro: 0.8397\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2102, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1421, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1078, Accuracy: 0.9229, F1 Micro: 0.9229, F1 Macro: 0.899\n",
      "Epoch 5/10, Train Loss: 0.0648, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8866\n",
      "Epoch 6/10, Train Loss: 0.0543, Accuracy: 0.9201, F1 Micro: 0.9201, F1 Macro: 0.8957\n",
      "Epoch 7/10, Train Loss: 0.0406, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8876\n",
      "Epoch 8/10, Train Loss: 0.0477, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8885\n",
      "Epoch 9/10, Train Loss: 0.0301, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0184, Accuracy: 0.9247, F1 Micro: 0.9247, F1 Macro: 0.903\n",
      "\n",
      "Sentiment analysis accuracy: 0.9247, F1 Micro: 0.9247, F1 Macro: 0.903\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       771\n",
      "    positive       0.93      0.80      0.86       305\n",
      "\n",
      "    accuracy                           0.92      1076\n",
      "   macro avg       0.93      0.89      0.90      1076\n",
      "weighted avg       0.92      0.92      0.92      1076\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9604, F1 Micro: 0.9604, F1 Macro: 0.8744\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.87      0.83      0.85       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.56      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.84      0.89       200\n",
      "     neutral       0.92      0.97      0.94       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.77      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.83      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.98      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 295.253835439682 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 7.676214590901509e-05\n",
      "Samples above threshold: 37\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.203439235687256 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4689, Accuracy: 0.8778, F1 Micro: 0.9278, F1 Macro: 0.9229\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2896, Accuracy: 0.9385, F1 Micro: 0.9624, F1 Macro: 0.9596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2085, Accuracy: 0.9521, F1 Micro: 0.9705, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1672, Accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1317, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1152, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0945, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9752\n",
      "Epoch 8/10, Train Loss: 0.0774, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Epoch 9/10, Train Loss: 0.0666, Accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0586, Accuracy: 0.9641, F1 Micro: 0.9776, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.9641, F1 Micro: 0.9776, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.96      0.90      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.35, Accuracy: 0.8654, F1 Micro: 0.8654, F1 Macro: 0.8265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2225, Accuracy: 0.8961, F1 Micro: 0.8961, F1 Macro: 0.8652\n",
      "Epoch 3/10, Train Loss: 0.1402, Accuracy: 0.8934, F1 Micro: 0.8934, F1 Macro: 0.8615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1011, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0681, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8753\n",
      "Epoch 6/10, Train Loss: 0.0454, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8708\n",
      "Epoch 7/10, Train Loss: 0.0363, Accuracy: 0.8997, F1 Micro: 0.8997, F1 Macro: 0.8675\n",
      "Epoch 8/10, Train Loss: 0.0306, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8708\n",
      "Epoch 9/10, Train Loss: 0.0348, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0256, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8747\n",
      "\n",
      "Sentiment analysis accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.99      0.94       784\n",
      "    positive       0.96      0.71      0.81       323\n",
      "\n",
      "    accuracy                           0.91      1107\n",
      "   macro avg       0.92      0.85      0.87      1107\n",
      "weighted avg       0.91      0.91      0.90      1107\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.8685\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.86      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.88      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.95      0.94       571\n",
      "weighted avg       0.96      0.95      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.85      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.93      0.89       200\n",
      "     neutral       0.96      0.90      0.93       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       1.00      0.32      0.48        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.71      0.76       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.96      0.94      0.95        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.66      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 303.6033215522766 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 4.271158832125366e-05\n",
      "Samples above threshold: 32\n",
      "Acquired samples: 25\n",
      "Sampling duration: 7.289448976516724 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4579, Accuracy: 0.8839, F1 Micro: 0.9313, F1 Macro: 0.9273\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2832, Accuracy: 0.9354, F1 Micro: 0.9607, F1 Macro: 0.9583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1961, Accuracy: 0.9545, F1 Micro: 0.972, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1619, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.132, Accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1133, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0917, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0814, Accuracy: 0.9653, F1 Micro: 0.9785, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0643, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9764\n",
      "Epoch 10/10, Train Loss: 0.0551, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9735\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.93       317\n",
      "       linen       0.95      0.95      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3528, Accuracy: 0.8584, F1 Micro: 0.8584, F1 Macro: 0.8208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.198, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1433, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.108, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8861\n",
      "Epoch 5/10, Train Loss: 0.0712, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8794\n",
      "Epoch 6/10, Train Loss: 0.0481, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8784\n",
      "Epoch 7/10, Train Loss: 0.0561, Accuracy: 0.9044, F1 Micro: 0.9044, F1 Macro: 0.8779\n",
      "Epoch 8/10, Train Loss: 0.0415, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8869\n",
      "Epoch 9/10, Train Loss: 0.025, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0279, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8879\n",
      "\n",
      "Sentiment analysis accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       783\n",
      "    positive       0.94      0.75      0.84       326\n",
      "\n",
      "    accuracy                           0.91      1109\n",
      "   macro avg       0.92      0.87      0.89      1109\n",
      "weighted avg       0.91      0.91      0.91      1109\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.8855\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.86      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.76      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.63      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.89       200\n",
      "     neutral       0.93      0.94      0.93       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.87      0.86       162\n",
      "     neutral       0.95      0.95      0.95       387\n",
      "    positive       0.67      0.55      0.60        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.82      0.79      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.69      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 305.3738498687744 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 5.7886974900611676e-05\n",
      "Samples above threshold: 29\n",
      "Acquired samples: 50\n",
      "Sampling duration: 6.905956029891968 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4554, Accuracy: 0.8795, F1 Micro: 0.9293, F1 Macro: 0.9255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2786, Accuracy: 0.9368, F1 Micro: 0.9616, F1 Macro: 0.9595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1984, Accuracy: 0.9521, F1 Micro: 0.9705, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1576, Accuracy: 0.9576, F1 Micro: 0.9739, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1319, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9754\n",
      "Epoch 6/10, Train Loss: 0.106, Accuracy: 0.9622, F1 Micro: 0.9766, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0909, Accuracy: 0.9642, F1 Micro: 0.9777, F1 Macro: 0.9753\n",
      "Epoch 8/10, Train Loss: 0.077, Accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9747\n",
      "Epoch 9/10, Train Loss: 0.0649, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9751\n",
      "Epoch 10/10, Train Loss: 0.0551, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9642, F1 Micro: 0.9777, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.91      0.93       317\n",
      "       linen       0.92      0.98      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3633, Accuracy: 0.8514, F1 Micro: 0.8514, F1 Macro: 0.7931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2097, Accuracy: 0.8991, F1 Micro: 0.8991, F1 Macro: 0.8721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1444, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1006, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.881\n",
      "Epoch 5/10, Train Loss: 0.0704, Accuracy: 0.8991, F1 Micro: 0.8991, F1 Macro: 0.871\n",
      "Epoch 6/10, Train Loss: 0.0752, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8792\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0438, Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0442, Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8836\n",
      "Epoch 9/10, Train Loss: 0.0228, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8772\n",
      "Epoch 10/10, Train Loss: 0.0185, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8797\n",
      "\n",
      "Sentiment analysis accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       781\n",
      "    positive       0.94      0.74      0.83       329\n",
      "\n",
      "    accuracy                           0.91      1110\n",
      "   macro avg       0.92      0.86      0.88      1110\n",
      "weighted avg       0.91      0.91      0.91      1110\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.8832\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.81      0.75      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.62      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.90      0.89       200\n",
      "     neutral       0.95      0.91      0.93       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.93      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.86       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.74      0.79       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.91      0.86        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.96      0.94      0.95        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.85      0.86       571\n",
      "weighted avg       0.98      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 306.01564049720764 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 6.568843309651129e-05\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 50\n",
      "Sampling duration: 5.905622482299805 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4513, Accuracy: 0.8847, F1 Micro: 0.932, F1 Macro: 0.9286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2693, Accuracy: 0.9389, F1 Micro: 0.9627, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.198, Accuracy: 0.949, F1 Micro: 0.9687, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1527, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1226, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.104, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0881, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0747, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9764\n",
      "Epoch 9/10, Train Loss: 0.0621, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.051, Accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.977\n",
      "\n",
      "Aspect detection accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3395, Accuracy: 0.877, F1 Micro: 0.877, F1 Macro: 0.8354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1967, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1334, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8786\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0838, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0749, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8835\n",
      "Epoch 6/10, Train Loss: 0.0421, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0401, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8849\n",
      "Epoch 8/10, Train Loss: 0.0386, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0295, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0223, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8878\n",
      "\n",
      "Sentiment analysis accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       779\n",
      "    positive       0.94      0.75      0.83       310\n",
      "\n",
      "    accuracy                           0.91      1089\n",
      "   macro avg       0.92      0.86      0.89      1089\n",
      "weighted avg       0.92      0.91      0.91      1089\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.8773\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.87      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.95      0.94       571\n",
      "weighted avg       0.96      0.95      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.86      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.90       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.90      0.95      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.85       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.72      0.77       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 320.4917833805084 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 2.3345772206084803e-05\n",
      "Samples above threshold: 19\n",
      "Acquired samples: 50\n",
      "Sampling duration: 4.872024059295654 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4392, Accuracy: 0.8892, F1 Micro: 0.9344, F1 Macro: 0.931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2612, Accuracy: 0.9417, F1 Micro: 0.9644, F1 Macro: 0.9625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1833, Accuracy: 0.9533, F1 Micro: 0.9714, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.15, Accuracy: 0.9554, F1 Micro: 0.9726, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1207, Accuracy: 0.9613, F1 Micro: 0.9761, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1027, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9757\n",
      "Epoch 7/10, Train Loss: 0.0855, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0706, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9765\n",
      "Epoch 9/10, Train Loss: 0.061, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9748\n",
      "Epoch 10/10, Train Loss: 0.0502, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9748\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.98       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3491, Accuracy: 0.8581, F1 Micro: 0.8581, F1 Macro: 0.7993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.19, Accuracy: 0.8974, F1 Micro: 0.8974, F1 Macro: 0.8619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1261, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0922, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8863\n",
      "Epoch 5/10, Train Loss: 0.0625, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.886\n",
      "Epoch 6/10, Train Loss: 0.0403, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0396, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9001\n",
      "Epoch 8/10, Train Loss: 0.0339, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8804\n",
      "Epoch 9/10, Train Loss: 0.0166, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8809\n",
      "Epoch 10/10, Train Loss: 0.0145, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8906\n",
      "\n",
      "Sentiment analysis accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       781\n",
      "    positive       0.94      0.78      0.85       311\n",
      "\n",
      "    accuracy                           0.92      1092\n",
      "   macro avg       0.93      0.88      0.90      1092\n",
      "weighted avg       0.92      0.92      0.92      1092\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.8731\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85        78\n",
      "     neutral       0.98      0.97      0.98       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.94      0.88       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.85      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.75      0.55      0.63        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.78      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.88        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.96      0.94      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 322.3737459182739 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 3.0003718165971804e-05\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 50\n",
      "Sampling duration: 3.924461603164673 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4399, Accuracy: 0.8873, F1 Micro: 0.9331, F1 Macro: 0.9284\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2637, Accuracy: 0.9372, F1 Micro: 0.9618, F1 Macro: 0.9596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1876, Accuracy: 0.9498, F1 Micro: 0.9692, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1478, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1219, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9755\n",
      "Epoch 6/10, Train Loss: 0.1016, Accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.9745\n",
      "Epoch 7/10, Train Loss: 0.0793, Accuracy: 0.9611, F1 Micro: 0.976, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.071, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9764\n",
      "Epoch 9/10, Train Loss: 0.0563, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0515, Accuracy: 0.9674, F1 Micro: 0.9797, F1 Macro: 0.9777\n",
      "\n",
      "Aspect detection accuracy: 0.9674, F1 Micro: 0.9797, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3358, Accuracy: 0.8777, F1 Micro: 0.8777, F1 Macro: 0.8354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2019, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1307, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.895\n",
      "Epoch 4/10, Train Loss: 0.0942, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8914\n",
      "Epoch 5/10, Train Loss: 0.0683, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8894\n",
      "Epoch 6/10, Train Loss: 0.0559, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0312, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.8949\n",
      "Epoch 8/10, Train Loss: 0.0379, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8891\n",
      "Epoch 9/10, Train Loss: 0.0245, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8907\n",
      "Epoch 10/10, Train Loss: 0.0347, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8854\n",
      "\n",
      "Sentiment analysis accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.8949\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       783\n",
      "    positive       0.93      0.77      0.84       313\n",
      "\n",
      "    accuracy                           0.92      1096\n",
      "   macro avg       0.92      0.88      0.89      1096\n",
      "weighted avg       0.92      0.92      0.92      1096\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9615, F1 Micro: 0.9615, F1 Macro: 0.8894\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.90      0.93        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.85      0.75      0.80        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.67      0.74       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.73      0.50      0.59        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.85      0.78      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.55      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.72      0.76      0.74        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.77      0.79       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 317.77837657928467 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 1.6929195226111915e-05\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 50\n",
      "Sampling duration: 2.8259670734405518 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4277, Accuracy: 0.8852, F1 Micro: 0.9323, F1 Macro: 0.9286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2512, Accuracy: 0.9391, F1 Micro: 0.963, F1 Macro: 0.9609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1819, Accuracy: 0.9531, F1 Micro: 0.9711, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.143, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1177, Accuracy: 0.9609, F1 Micro: 0.9759, F1 Macro: 0.9737\n",
      "Epoch 6/10, Train Loss: 0.0985, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0825, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0673, Accuracy: 0.9644, F1 Micro: 0.978, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.055, Accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9768\n",
      "Epoch 10/10, Train Loss: 0.048, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9754\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3262, Accuracy: 0.8625, F1 Micro: 0.8625, F1 Macro: 0.807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1826, Accuracy: 0.8983, F1 Micro: 0.8983, F1 Macro: 0.8619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1322, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0993, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0648, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8914\n",
      "Epoch 6/10, Train Loss: 0.0523, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8882\n",
      "Epoch 7/10, Train Loss: 0.0359, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8892\n",
      "Epoch 8/10, Train Loss: 0.0355, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8894\n",
      "Epoch 9/10, Train Loss: 0.0207, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8882\n",
      "Epoch 10/10, Train Loss: 0.0188, Accuracy: 0.9166, F1 Micro: 0.9166, F1 Macro: 0.889\n",
      "\n",
      "Sentiment analysis accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       782\n",
      "    positive       0.94      0.75      0.84       309\n",
      "\n",
      "    accuracy                           0.92      1091\n",
      "   macro avg       0.93      0.87      0.89      1091\n",
      "weighted avg       0.92      0.92      0.91      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.8703\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.85      0.80      0.83       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.84      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.88      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.87       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.73      0.36      0.48        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.73      0.77       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.72      0.76      0.74        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.78      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 327.2867887020111 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 1.6087697986222338e-05\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 36\n",
      "Sampling duration: 1.8961217403411865 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4239, Accuracy: 0.8898, F1 Micro: 0.9348, F1 Macro: 0.9321\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2527, Accuracy: 0.9408, F1 Micro: 0.9638, F1 Macro: 0.9615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1789, Accuracy: 0.9465, F1 Micro: 0.9673, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1398, Accuracy: 0.9585, F1 Micro: 0.9743, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1115, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0962, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.975\n",
      "Epoch 7/10, Train Loss: 0.0772, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0642, Accuracy: 0.9646, F1 Micro: 0.9781, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0545, Accuracy: 0.9667, F1 Micro: 0.9793, F1 Macro: 0.9771\n",
      "Epoch 10/10, Train Loss: 0.0467, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9667, F1 Micro: 0.9793, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3403, Accuracy: 0.8715, F1 Micro: 0.8715, F1 Macro: 0.8235\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1846, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1335, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0931, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.063, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0501, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.8933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0393, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.8967\n",
      "Epoch 8/10, Train Loss: 0.0283, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8841\n",
      "Epoch 9/10, Train Loss: 0.0233, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8852\n",
      "Epoch 10/10, Train Loss: 0.0284, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8786\n",
      "\n",
      "Sentiment analysis accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.8967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.99      0.95       784\n",
      "    positive       0.96      0.75      0.85       313\n",
      "\n",
      "    accuracy                           0.92      1097\n",
      "   macro avg       0.94      0.87      0.90      1097\n",
      "weighted avg       0.92      0.92      0.92      1097\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.8888\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.80      0.85       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.88      0.72      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.90       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.90      0.96      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.86      0.76      0.80       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.96      0.96      0.96        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.81      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 336.9292070865631 s\n",
      "Total runtime: 7383.690388441086 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1602e60",
   "metadata": {
    "papermill": {
     "duration": 0.180795,
     "end_time": "2025-03-30T10:00:54.766998",
     "exception": false,
     "start_time": "2025-03-30T10:00:54.586203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fdaa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6846, Accuracy: 0.7771, F1 Micro: 0.873, F1 Macro: 0.8661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5356, Accuracy: 0.8012, F1 Micro: 0.8896, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4856, Accuracy: 0.8019, F1 Micro: 0.8899, F1 Macro: 0.8853\n",
      "Epoch 4/10, Train Loss: 0.4451, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Epoch 5/10, Train Loss: 0.447, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4104, Accuracy: 0.8038, F1 Micro: 0.8908, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4062, Accuracy: 0.8099, F1 Micro: 0.893, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4023, Accuracy: 0.8189, F1 Micro: 0.8974, F1 Macro: 0.8906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3668, Accuracy: 0.8349, F1 Micro: 0.9047, F1 Macro: 0.8978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3363, Accuracy: 0.8422, F1 Micro: 0.9091, F1 Macro: 0.9034\n",
      "\n",
      "Aspect detection accuracy: 0.8422, F1 Micro: 0.9091, F1 Macro: 0.9034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.80      1.00      0.89       462\n",
      "   air_panas       0.83      1.00      0.91       480\n",
      "         bau       0.86      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.66      0.86      0.75       317\n",
      "       linen       0.73      0.99      0.84       392\n",
      "     service       0.92      0.96      0.94       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.91      1.00      0.95       498\n",
      "\n",
      "   micro avg       0.84      0.99      0.91      4614\n",
      "   macro avg       0.84      0.98      0.90      4614\n",
      "weighted avg       0.85      0.99      0.91      4614\n",
      " samples avg       0.84      0.99      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6158, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4961, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4198, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4426, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3147, Accuracy: 0.7391, F1 Micro: 0.7391, F1 Macro: 0.6783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2361, Accuracy: 0.7636, F1 Micro: 0.7636, F1 Macro: 0.7349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2395, Accuracy: 0.7663, F1 Micro: 0.7663, F1 Macro: 0.7452\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2328, Accuracy: 0.7935, F1 Micro: 0.7935, F1 Macro: 0.781\n",
      "Epoch 9/10, Train Loss: 0.1405, Accuracy: 0.7799, F1 Micro: 0.7799, F1 Macro: 0.7604\n",
      "Epoch 10/10, Train Loss: 0.0903, Accuracy: 0.7745, F1 Micro: 0.7745, F1 Macro: 0.7461\n",
      "\n",
      "Sentiment analysis accuracy: 0.7935, F1 Micro: 0.7935, F1 Macro: 0.781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.84      0.83       226\n",
      "    positive       0.74      0.72      0.73       142\n",
      "\n",
      "    accuracy                           0.79       368\n",
      "   macro avg       0.78      0.78      0.78       368\n",
      "weighted avg       0.79      0.79      0.79       368\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8343, F1 Micro: 0.8343, F1 Macro: 0.4065\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        97\n",
      "     neutral       0.80      1.00      0.89       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.80       571\n",
      "   macro avg       0.27      0.33      0.30       571\n",
      "weighted avg       0.65      0.80      0.72       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.28      0.33      0.30       571\n",
      "weighted avg       0.69      0.83      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.03      0.05        78\n",
      "     neutral       0.86      1.00      0.93       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.51      0.34      0.32       571\n",
      "weighted avg       0.83      0.86      0.80       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.36      0.49       200\n",
      "     neutral       0.66      0.86      0.75       315\n",
      "    positive       0.27      0.32      0.30        56\n",
      "\n",
      "    accuracy                           0.63       571\n",
      "   macro avg       0.56      0.51      0.51       571\n",
      "weighted avg       0.65      0.63      0.61       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.23      0.37       162\n",
      "     neutral       0.72      0.99      0.84       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.74       571\n",
      "   macro avg       0.55      0.41      0.40       571\n",
      "weighted avg       0.75      0.74      0.67       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.61      0.71        85\n",
      "     neutral       0.92      0.96      0.94       418\n",
      "    positive       0.72      0.75      0.73        68\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.83      0.78      0.79       571\n",
      "weighted avg       0.88      0.89      0.88       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.36      0.52        74\n",
      "     neutral       0.91      1.00      0.95       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.61      0.45      0.49       571\n",
      "weighted avg       0.91      0.91      0.89       571\n",
      "\n",
      "Total train time: 81.10176730155945 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0007218016544356942\n",
      "Samples above threshold: 215\n",
      "Acquired samples: 215\n",
      "Sampling duration: 28.3151957988739 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5902, Accuracy: 0.8021, F1 Micro: 0.8893, F1 Macro: 0.8833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4828, Accuracy: 0.803, F1 Micro: 0.8901, F1 Macro: 0.8847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4616, Accuracy: 0.8215, F1 Micro: 0.8965, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4294, Accuracy: 0.8392, F1 Micro: 0.9074, F1 Macro: 0.9016\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3712, Accuracy: 0.8719, F1 Micro: 0.9239, F1 Macro: 0.9163\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3278, Accuracy: 0.8845, F1 Micro: 0.9304, F1 Macro: 0.9222\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2923, Accuracy: 0.8917, F1 Micro: 0.9352, F1 Macro: 0.9293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2629, Accuracy: 0.9028, F1 Micro: 0.9417, F1 Macro: 0.9378\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2269, Accuracy: 0.9168, F1 Micro: 0.9494, F1 Macro: 0.9446\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2016, Accuracy: 0.9267, F1 Micro: 0.9552, F1 Macro: 0.9512\n",
      "\n",
      "Aspect detection accuracy: 0.9267, F1 Micro: 0.9552, F1 Macro: 0.9512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.95      0.99      0.97       480\n",
      "         bau       0.95      0.97      0.96       496\n",
      "     general       0.87      0.99      0.93       500\n",
      "  kebersihan       0.85      0.87      0.86       317\n",
      "       linen       0.87      0.97      0.91       392\n",
      "     service       0.97      0.93      0.95       423\n",
      "sunrise_meal       0.94      1.00      0.97       530\n",
      "          tv       0.98      1.00      0.99       516\n",
      "        wifi       0.99      0.99      0.99       498\n",
      "\n",
      "   micro avg       0.94      0.97      0.96      4614\n",
      "   macro avg       0.93      0.97      0.95      4614\n",
      "weighted avg       0.94      0.97      0.96      4614\n",
      " samples avg       0.94      0.97      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5452, Accuracy: 0.7209, F1 Micro: 0.7209, F1 Macro: 0.4261\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4303, Accuracy: 0.7817, F1 Micro: 0.7817, F1 Macro: 0.7354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3222, Accuracy: 0.8206, F1 Micro: 0.8206, F1 Macro: 0.7375\n",
      "Epoch 4/10, Train Loss: 0.2765, Accuracy: 0.8195, F1 Micro: 0.8195, F1 Macro: 0.7279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1842, Accuracy: 0.8426, F1 Micro: 0.8426, F1 Macro: 0.7762\n",
      "Epoch 6/10, Train Loss: 0.1785, Accuracy: 0.8405, F1 Micro: 0.8405, F1 Macro: 0.7803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1365, Accuracy: 0.8552, F1 Micro: 0.8552, F1 Macro: 0.8079\n",
      "Epoch 8/10, Train Loss: 0.1089, Accuracy: 0.8468, F1 Micro: 0.8468, F1 Macro: 0.7747\n",
      "Epoch 9/10, Train Loss: 0.1097, Accuracy: 0.8353, F1 Micro: 0.8353, F1 Macro: 0.7931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0929, Accuracy: 0.8615, F1 Micro: 0.8615, F1 Macro: 0.8056\n",
      "\n",
      "Sentiment analysis accuracy: 0.8615, F1 Micro: 0.8615, F1 Macro: 0.8056\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.97      0.91       685\n",
      "    positive       0.89      0.58      0.70       268\n",
      "\n",
      "    accuracy                           0.86       953\n",
      "   macro avg       0.87      0.78      0.81       953\n",
      "weighted avg       0.87      0.86      0.85       953\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9196, F1 Micro: 0.9196, F1 Macro: 0.6848\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.85      0.73      0.79        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.87      0.90       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.74      0.83        86\n",
      "     neutral       0.95      0.99      0.97       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.83      0.74      0.78       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.71      0.75        78\n",
      "     neutral       0.95      0.97      0.96       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.58      0.56      0.57       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      0.99      0.93       496\n",
      "    positive       0.50      0.03      0.06        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.46      0.34      0.33       571\n",
      "weighted avg       0.82      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.75      0.79       200\n",
      "     neutral       0.85      0.87      0.86       315\n",
      "    positive       0.68      0.86      0.76        56\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.79      0.83      0.80       571\n",
      "weighted avg       0.83      0.83      0.83       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.73      0.80       162\n",
      "     neutral       0.86      0.97      0.91       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.58      0.57      0.57       571\n",
      "weighted avg       0.83      0.87      0.84       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.88      0.81        85\n",
      "     neutral       0.97      0.93      0.95       418\n",
      "    positive       0.86      0.87      0.86        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.86      0.89      0.87       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.17      0.28        29\n",
      "     neutral       0.94      1.00      0.97       525\n",
      "    positive       0.67      0.12      0.20        17\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.77      0.43      0.48       571\n",
      "weighted avg       0.92      0.93      0.91       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.81      0.86        54\n",
      "     neutral       0.98      1.00      0.99       511\n",
      "    positive       0.33      0.17      0.22         6\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.74      0.66      0.69       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90        74\n",
      "     neutral       0.99      0.99      0.99       494\n",
      "    positive       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.85      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Total train time: 127.6776556968689 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.05189027078449726\n",
      "Samples above threshold: 193\n",
      "Acquired samples: 193\n",
      "Sampling duration: 47.64686584472656 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5712, Accuracy: 0.8016, F1 Micro: 0.8851, F1 Macro: 0.8597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4994, Accuracy: 0.8196, F1 Micro: 0.8964, F1 Macro: 0.8865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4644, Accuracy: 0.8438, F1 Micro: 0.9071, F1 Macro: 0.8883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3872, Accuracy: 0.8898, F1 Micro: 0.9332, F1 Macro: 0.9232\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.305, Accuracy: 0.9073, F1 Micro: 0.944, F1 Macro: 0.9392\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2601, Accuracy: 0.9281, F1 Micro: 0.9559, F1 Macro: 0.95\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2157, Accuracy: 0.9385, F1 Micro: 0.9625, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1935, Accuracy: 0.9411, F1 Micro: 0.9639, F1 Macro: 0.9605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1669, Accuracy: 0.9432, F1 Micro: 0.9652, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1558, Accuracy: 0.9441, F1 Micro: 0.9656, F1 Macro: 0.9625\n",
      "\n",
      "Aspect detection accuracy: 0.9441, F1 Micro: 0.9656, F1 Macro: 0.9625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.97      0.96       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.91      0.88      0.89       317\n",
      "       linen       0.89      0.97      0.93       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.97      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5974, Accuracy: 0.7904, F1 Micro: 0.7904, F1 Macro: 0.6505\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4088, Accuracy: 0.8413, F1 Micro: 0.8413, F1 Macro: 0.7732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3, Accuracy: 0.8523, F1 Micro: 0.8523, F1 Macro: 0.8017\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2198, Accuracy: 0.8842, F1 Micro: 0.8842, F1 Macro: 0.842\n",
      "Epoch 5/10, Train Loss: 0.1715, Accuracy: 0.8762, F1 Micro: 0.8762, F1 Macro: 0.8218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1147, Accuracy: 0.8872, F1 Micro: 0.8872, F1 Macro: 0.8413\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1149, Accuracy: 0.8892, F1 Micro: 0.8892, F1 Macro: 0.846\n",
      "Epoch 8/10, Train Loss: 0.0848, Accuracy: 0.8772, F1 Micro: 0.8772, F1 Macro: 0.824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0544, Accuracy: 0.8892, F1 Micro: 0.8892, F1 Macro: 0.8486\n",
      "Epoch 10/10, Train Loss: 0.0503, Accuracy: 0.8812, F1 Micro: 0.8812, F1 Macro: 0.8344\n",
      "\n",
      "Sentiment analysis accuracy: 0.8892, F1 Micro: 0.8892, F1 Macro: 0.8486\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93       730\n",
      "    positive       0.88      0.68      0.77       272\n",
      "\n",
      "    accuracy                           0.89      1002\n",
      "   macro avg       0.89      0.82      0.85      1002\n",
      "weighted avg       0.89      0.89      0.88      1002\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.8039\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.81      0.86        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.83      0.80      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.74      0.77        78\n",
      "     neutral       0.96      0.97      0.96       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.74      0.80       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       1.00      0.03      0.06        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.62      0.34      0.33       571\n",
      "weighted avg       0.88      0.87      0.82       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83       200\n",
      "     neutral       0.91      0.88      0.89       315\n",
      "    positive       0.77      0.98      0.87        56\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.84      0.89      0.86       571\n",
      "weighted avg       0.87      0.87      0.87       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.75      0.82       162\n",
      "     neutral       0.88      0.97      0.93       387\n",
      "    positive       0.55      0.27      0.36        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.78      0.67      0.71       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.45      0.58        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.76      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.91      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.97      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 166.11164164543152 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0033167603891342875\n",
      "Samples above threshold: 174\n",
      "Acquired samples: 174\n",
      "Sampling duration: 41.53303027153015 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5659, Accuracy: 0.7957, F1 Micro: 0.8803, F1 Macro: 0.8322\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4895, Accuracy: 0.83, F1 Micro: 0.8989, F1 Macro: 0.8726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4212, Accuracy: 0.8755, F1 Micro: 0.9244, F1 Macro: 0.9066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3349, Accuracy: 0.9082, F1 Micro: 0.944, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2678, Accuracy: 0.9351, F1 Micro: 0.9603, F1 Macro: 0.9569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2331, Accuracy: 0.9453, F1 Micro: 0.9663, F1 Macro: 0.9632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1959, Accuracy: 0.9462, F1 Micro: 0.9669, F1 Macro: 0.9636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1734, Accuracy: 0.9514, F1 Micro: 0.97, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1535, Accuracy: 0.9517, F1 Micro: 0.9702, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1389, Accuracy: 0.9521, F1 Micro: 0.9704, F1 Macro: 0.9677\n",
      "\n",
      "Aspect detection accuracy: 0.9521, F1 Micro: 0.9704, F1 Macro: 0.9677\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.97      0.97       496\n",
      "     general       0.89      0.99      0.94       500\n",
      "  kebersihan       0.91      0.90      0.91       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5696, Accuracy: 0.814, F1 Micro: 0.814, F1 Macro: 0.7637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3993, Accuracy: 0.8627, F1 Micro: 0.8627, F1 Macro: 0.8139\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2862, Accuracy: 0.8958, F1 Micro: 0.8958, F1 Macro: 0.861\n",
      "Epoch 4/10, Train Loss: 0.1776, Accuracy: 0.8948, F1 Micro: 0.8948, F1 Macro: 0.8557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1269, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8696\n",
      "Epoch 6/10, Train Loss: 0.1226, Accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.8621\n",
      "Epoch 7/10, Train Loss: 0.1122, Accuracy: 0.8958, F1 Micro: 0.8958, F1 Macro: 0.8552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0774, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8705\n",
      "Epoch 9/10, Train Loss: 0.0756, Accuracy: 0.8997, F1 Micro: 0.8997, F1 Macro: 0.8651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.05, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8712\n",
      "\n",
      "Sentiment analysis accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       746\n",
      "    positive       0.91      0.72      0.81       281\n",
      "\n",
      "    accuracy                           0.90      1027\n",
      "   macro avg       0.91      0.85      0.87      1027\n",
      "weighted avg       0.90      0.90      0.90      1027\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9461, F1 Micro: 0.9461, F1 Macro: 0.8345\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.83      0.88        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.77      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.78      0.80        78\n",
      "     neutral       0.96      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.75      0.81       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.89      0.99      0.94       496\n",
      "    positive       0.76      0.24      0.36        68\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.55      0.41      0.43       571\n",
      "weighted avg       0.87      0.89      0.86       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86       200\n",
      "     neutral       0.91      0.90      0.91       315\n",
      "    positive       0.83      0.96      0.89        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.87      0.91      0.89       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.79      0.84       162\n",
      "     neutral       0.90      0.97      0.94       387\n",
      "    positive       0.70      0.32      0.44        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.83      0.69      0.74       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.75      0.82        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.88      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.89      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.97      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 195.35421586036682 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0017171945888549093\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 156\n",
      "Sampling duration: 36.4737012386322 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5647, Accuracy: 0.8059, F1 Micro: 0.8902, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4957, Accuracy: 0.8521, F1 Micro: 0.9131, F1 Macro: 0.9021\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3937, Accuracy: 0.8976, F1 Micro: 0.9388, F1 Macro: 0.9347\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3051, Accuracy: 0.9276, F1 Micro: 0.9561, F1 Macro: 0.9529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2421, Accuracy: 0.9401, F1 Micro: 0.9632, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.205, Accuracy: 0.9498, F1 Micro: 0.9692, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1758, Accuracy: 0.9526, F1 Micro: 0.9708, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1582, Accuracy: 0.9552, F1 Micro: 0.9722, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1389, Accuracy: 0.9563, F1 Micro: 0.9729, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1189, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9709\n",
      "\n",
      "Aspect detection accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.91      0.92      0.92       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5602, Accuracy: 0.8519, F1 Micro: 0.8519, F1 Macro: 0.7965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3105, Accuracy: 0.8813, F1 Micro: 0.8813, F1 Macro: 0.8385\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2087, Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.8711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1645, Accuracy: 0.9022, F1 Micro: 0.9022, F1 Macro: 0.8751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.107, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8816\n",
      "Epoch 6/10, Train Loss: 0.0868, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0663, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8805\n",
      "Epoch 8/10, Train Loss: 0.0726, Accuracy: 0.9041, F1 Micro: 0.9041, F1 Macro: 0.875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0569, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8799\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0349, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8807\n",
      "\n",
      "Sentiment analysis accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       751\n",
      "    positive       0.93      0.74      0.82       302\n",
      "\n",
      "    accuracy                           0.91      1053\n",
      "   macro avg       0.92      0.86      0.88      1053\n",
      "weighted avg       0.91      0.91      0.91      1053\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.8573\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.78      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.78      0.82        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.20      0.14      0.17         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.86      0.56      0.68        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.67      0.56      0.60       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.86       200\n",
      "     neutral       0.91      0.92      0.92       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.88      0.90      0.89       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.80      0.85       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.67      0.36      0.47        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.83      0.71      0.75       571\n",
      "weighted avg       0.90      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.84      0.87       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 223.3156988620758 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0013850039802491658\n",
      "Samples above threshold: 141\n",
      "Acquired samples: 141\n",
      "Sampling duration: 32.292163372039795 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5567, Accuracy: 0.8083, F1 Micro: 0.889, F1 Macro: 0.8687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4778, Accuracy: 0.8724, F1 Micro: 0.9245, F1 Macro: 0.9167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3591, Accuracy: 0.9184, F1 Micro: 0.9507, F1 Macro: 0.9469\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.276, Accuracy: 0.9392, F1 Micro: 0.9628, F1 Macro: 0.9597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2243, Accuracy: 0.95, F1 Micro: 0.9692, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1874, Accuracy: 0.9535, F1 Micro: 0.9713, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1652, Accuracy: 0.9543, F1 Micro: 0.9719, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1395, Accuracy: 0.9554, F1 Micro: 0.9723, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1224, Accuracy: 0.9576, F1 Micro: 0.9738, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1089, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.972\n",
      "\n",
      "Aspect detection accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.92      0.92      0.92       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4904, Accuracy: 0.8355, F1 Micro: 0.8355, F1 Macro: 0.7961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3178, Accuracy: 0.8838, F1 Micro: 0.8838, F1 Macro: 0.8526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2223, Accuracy: 0.895, F1 Micro: 0.895, F1 Macro: 0.8615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1427, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8734\n",
      "Epoch 5/10, Train Loss: 0.1012, Accuracy: 0.8931, F1 Micro: 0.8931, F1 Macro: 0.8577\n",
      "Epoch 6/10, Train Loss: 0.1114, Accuracy: 0.8959, F1 Micro: 0.8959, F1 Macro: 0.8632\n",
      "Epoch 7/10, Train Loss: 0.0777, Accuracy: 0.8987, F1 Micro: 0.8987, F1 Macro: 0.8661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.042, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8779\n",
      "Epoch 9/10, Train Loss: 0.0336, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0473, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8793\n",
      "\n",
      "Sentiment analysis accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       764\n",
      "    positive       0.93      0.74      0.82       312\n",
      "\n",
      "    accuracy                           0.91      1076\n",
      "   macro avg       0.91      0.86      0.88      1076\n",
      "weighted avg       0.91      0.91      0.90      1076\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9536, F1 Micro: 0.9536, F1 Macro: 0.8583\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.82      0.84       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.85      0.84        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.86      0.62      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.77      0.58      0.63       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.88       200\n",
      "     neutral       0.92      0.92      0.92       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85       162\n",
      "     neutral       0.93      0.96      0.94       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.74      0.78       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.76      0.83        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.89      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.90      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.68      0.76      0.72        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.76      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 241.82923102378845 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0011019074125215413\n",
      "Samples above threshold: 127\n",
      "Acquired samples: 127\n",
      "Sampling duration: 29.063190698623657 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5492, Accuracy: 0.8036, F1 Micro: 0.8907, F1 Macro: 0.8863\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4487, Accuracy: 0.8847, F1 Micro: 0.9313, F1 Macro: 0.925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3302, Accuracy: 0.9306, F1 Micro: 0.9574, F1 Macro: 0.9532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2546, Accuracy: 0.9481, F1 Micro: 0.968, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2094, Accuracy: 0.9526, F1 Micro: 0.9708, F1 Macro: 0.9678\n",
      "Epoch 6/10, Train Loss: 0.1737, Accuracy: 0.9524, F1 Micro: 0.9706, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1504, Accuracy: 0.9575, F1 Micro: 0.9736, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1311, Accuracy: 0.959, F1 Micro: 0.9747, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.113, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1016, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9739\n",
      "\n",
      "Aspect detection accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.92      0.94      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.471, Accuracy: 0.8508, F1 Micro: 0.8508, F1 Macro: 0.8131\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.297, Accuracy: 0.8941, F1 Micro: 0.8941, F1 Macro: 0.864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1847, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1379, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8852\n",
      "Epoch 5/10, Train Loss: 0.1231, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8776\n",
      "Epoch 6/10, Train Loss: 0.076, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0607, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8834\n",
      "Epoch 8/10, Train Loss: 0.0502, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8792\n",
      "Epoch 9/10, Train Loss: 0.0476, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8782\n",
      "Epoch 10/10, Train Loss: 0.0541, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8829\n",
      "\n",
      "Sentiment analysis accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8834\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       770\n",
      "    positive       0.93      0.75      0.83       316\n",
      "\n",
      "    accuracy                           0.91      1086\n",
      "   macro avg       0.92      0.86      0.88      1086\n",
      "weighted avg       0.91      0.91      0.91      1086\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9557, F1 Micro: 0.9557, F1 Macro: 0.8553\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.79      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.81      0.68      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.58      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.88       200\n",
      "     neutral       0.92      0.94      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.84      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.69      0.41      0.51        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.84      0.74      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.86      0.84        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.65      0.88      0.75        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.80      0.79       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 257.0185377597809 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0010299650020897388\n",
      "Samples above threshold: 114\n",
      "Acquired samples: 114\n",
      "Sampling duration: 25.616477251052856 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5488, Accuracy: 0.8087, F1 Micro: 0.892, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4372, Accuracy: 0.8887, F1 Micro: 0.9328, F1 Macro: 0.9232\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3163, Accuracy: 0.9318, F1 Micro: 0.9581, F1 Macro: 0.9536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2462, Accuracy: 0.9477, F1 Micro: 0.9678, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2016, Accuracy: 0.9545, F1 Micro: 0.9718, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1674, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1434, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1225, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.1078, Accuracy: 0.9589, F1 Micro: 0.9746, F1 Macro: 0.9723\n",
      "Epoch 10/10, Train Loss: 0.0926, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9728\n",
      "\n",
      "Aspect detection accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.92      0.96      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4552, Accuracy: 0.8593, F1 Micro: 0.8593, F1 Macro: 0.8212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2808, Accuracy: 0.8931, F1 Micro: 0.8931, F1 Macro: 0.861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1771, Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1504, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1061, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8886\n",
      "Epoch 6/10, Train Loss: 0.0782, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0559, Accuracy: 0.9212, F1 Micro: 0.9212, F1 Macro: 0.8987\n",
      "Epoch 8/10, Train Loss: 0.0456, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8865\n",
      "Epoch 9/10, Train Loss: 0.0479, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8873\n",
      "Epoch 10/10, Train Loss: 0.0453, Accuracy: 0.9165, F1 Micro: 0.9165, F1 Macro: 0.8903\n",
      "\n",
      "Sentiment analysis accuracy: 0.9212, F1 Micro: 0.9212, F1 Macro: 0.8987\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       761\n",
      "    positive       0.93      0.79      0.85       305\n",
      "\n",
      "    accuracy                           0.92      1066\n",
      "   macro avg       0.92      0.88      0.90      1066\n",
      "weighted avg       0.92      0.92      0.92      1066\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9562, F1 Micro: 0.9562, F1 Macro: 0.8603\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.80      0.83       571\n",
      "weighted avg       0.95      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.82      0.68      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.83      0.88       200\n",
      "     neutral       0.92      0.96      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.69      0.50      0.58        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.85      0.78      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.78      0.81       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 280.5134828090668 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.000687361229211092\n",
      "Samples above threshold: 103\n",
      "Acquired samples: 103\n",
      "Sampling duration: 22.493101835250854 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5366, Accuracy: 0.8134, F1 Micro: 0.8931, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4187, Accuracy: 0.901, F1 Micro: 0.9406, F1 Macro: 0.9351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2974, Accuracy: 0.9399, F1 Micro: 0.9631, F1 Macro: 0.9598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2382, Accuracy: 0.9465, F1 Micro: 0.967, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1956, Accuracy: 0.951, F1 Micro: 0.9698, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1659, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1405, Accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1199, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9746\n",
      "Epoch 9/10, Train Loss: 0.1013, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9736\n",
      "Epoch 10/10, Train Loss: 0.0886, Accuracy: 0.9618, F1 Micro: 0.9764, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.92      0.94      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4315, Accuracy: 0.8554, F1 Micro: 0.8554, F1 Macro: 0.807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.251, Accuracy: 0.8862, F1 Micro: 0.8862, F1 Macro: 0.8439\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1705, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8891\n",
      "Epoch 4/10, Train Loss: 0.1197, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.87\n",
      "Epoch 5/10, Train Loss: 0.0928, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8784\n",
      "Epoch 6/10, Train Loss: 0.0796, Accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0643, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.8932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0352, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.895\n",
      "Epoch 9/10, Train Loss: 0.028, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8837\n",
      "Epoch 10/10, Train Loss: 0.0289, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.8944\n",
      "\n",
      "Sentiment analysis accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       766\n",
      "    positive       0.93      0.77      0.84       306\n",
      "\n",
      "    accuracy                           0.92      1072\n",
      "   macro avg       0.92      0.88      0.89      1072\n",
      "weighted avg       0.92      0.92      0.92      1072\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.8599\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.83      0.88        86\n",
      "     neutral       0.97      1.00      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.77      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.83      0.65      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.54      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.89       200\n",
      "     neutral       0.92      0.94      0.93       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.67      0.45      0.54        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.83      0.76      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.90      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 283.5396740436554 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0005364808544982227\n",
      "Samples above threshold: 92\n",
      "Acquired samples: 62\n",
      "Sampling duration: 19.889581203460693 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5313, Accuracy: 0.803, F1 Micro: 0.8905, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4118, Accuracy: 0.9062, F1 Micro: 0.9433, F1 Macro: 0.9378\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2907, Accuracy: 0.9394, F1 Micro: 0.963, F1 Macro: 0.9605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2177, Accuracy: 0.953, F1 Micro: 0.9711, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1757, Accuracy: 0.9573, F1 Micro: 0.9734, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1504, Accuracy: 0.959, F1 Micro: 0.9747, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1317, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1121, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0979, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.085, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.95      0.95       317\n",
      "       linen       0.93      0.98      0.95       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4372, Accuracy: 0.8533, F1 Micro: 0.8533, F1 Macro: 0.7925\n",
      "Epoch 2/10, Train Loss: 0.2532, Accuracy: 0.8478, F1 Micro: 0.8478, F1 Macro: 0.7769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1842, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1407, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8825\n",
      "Epoch 5/10, Train Loss: 0.105, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8801\n",
      "Epoch 6/10, Train Loss: 0.0806, Accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0612, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8911\n",
      "Epoch 8/10, Train Loss: 0.042, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8841\n",
      "Epoch 9/10, Train Loss: 0.0274, Accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.8809\n",
      "Epoch 10/10, Train Loss: 0.0454, Accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.8795\n",
      "\n",
      "Sentiment analysis accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8911\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94       778\n",
      "    positive       0.92      0.77      0.84       306\n",
      "\n",
      "    accuracy                           0.92      1084\n",
      "   macro avg       0.92      0.87      0.89      1084\n",
      "weighted avg       0.92      0.92      0.91      1084\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.8662\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.86      0.87       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.78      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.65      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.71      0.59      0.63       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90       200\n",
      "     neutral       0.94      0.95      0.94       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.76      0.80       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.84      0.84        85\n",
      "     neutral       0.97      0.96      0.97       418\n",
      "    positive       0.89      0.96      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.55      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.79      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 296.6119999885559 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.0004873908910667524\n",
      "Samples above threshold: 86\n",
      "Acquired samples: 86\n",
      "Sampling duration: 18.475477695465088 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5294, Accuracy: 0.825, F1 Micro: 0.9013, F1 Macro: 0.8968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3912, Accuracy: 0.9208, F1 Micro: 0.9519, F1 Macro: 0.9476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2666, Accuracy: 0.9411, F1 Micro: 0.964, F1 Macro: 0.9618\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2076, Accuracy: 0.9535, F1 Micro: 0.9713, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1725, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1392, Accuracy: 0.9606, F1 Micro: 0.9755, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1273, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1073, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0926, Accuracy: 0.9609, F1 Micro: 0.9757, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.081, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9748\n",
      "\n",
      "Aspect detection accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.93      0.94      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4338, Accuracy: 0.8662, F1 Micro: 0.8662, F1 Macro: 0.824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.248, Accuracy: 0.8856, F1 Micro: 0.8856, F1 Macro: 0.8448\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1651, Accuracy: 0.8921, F1 Micro: 0.8921, F1 Macro: 0.8545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1135, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0991, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8836\n",
      "Epoch 6/10, Train Loss: 0.0729, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8802\n",
      "Epoch 7/10, Train Loss: 0.059, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8694\n",
      "Epoch 8/10, Train Loss: 0.0481, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8807\n",
      "Epoch 9/10, Train Loss: 0.0377, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.048, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8839\n",
      "\n",
      "Sentiment analysis accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8839\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.99      0.94       774\n",
      "    positive       0.95      0.73      0.83       310\n",
      "\n",
      "    accuracy                           0.91      1084\n",
      "   macro avg       0.93      0.86      0.88      1084\n",
      "weighted avg       0.92      0.91      0.91      1084\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.8508\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.40      0.20      0.27        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.76      0.69      0.72       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.77      0.83       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.71      0.60      0.64       571\n",
      "weighted avg       0.92      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.89       200\n",
      "     neutral       0.93      0.94      0.93       315\n",
      "    positive       0.88      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.73      0.36      0.48        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.73      0.77       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.86      0.84        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 308.7110800743103 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.0003467640752205626\n",
      "Samples above threshold: 77\n",
      "Acquired samples: 77\n",
      "Sampling duration: 16.329474925994873 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5194, Accuracy: 0.8306, F1 Micro: 0.9031, F1 Macro: 0.8969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3734, Accuracy: 0.917, F1 Micro: 0.9496, F1 Macro: 0.9449\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2666, Accuracy: 0.946, F1 Micro: 0.9668, F1 Macro: 0.9639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2115, Accuracy: 0.9542, F1 Micro: 0.9717, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1763, Accuracy: 0.9573, F1 Micro: 0.9736, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1476, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1229, Accuracy: 0.9615, F1 Micro: 0.9762, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.108, Accuracy: 0.9615, F1 Micro: 0.9762, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0925, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0771, Accuracy: 0.9642, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9642, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.95      0.95      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4061, Accuracy: 0.8573, F1 Micro: 0.8573, F1 Macro: 0.8223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2324, Accuracy: 0.8934, F1 Micro: 0.8934, F1 Macro: 0.8622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1546, Accuracy: 0.8979, F1 Micro: 0.8979, F1 Macro: 0.8648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1131, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8887\n",
      "Epoch 5/10, Train Loss: 0.0801, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8832\n",
      "Epoch 6/10, Train Loss: 0.0753, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8791\n",
      "Epoch 7/10, Train Loss: 0.0539, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8796\n",
      "Epoch 8/10, Train Loss: 0.0441, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8788\n",
      "Epoch 9/10, Train Loss: 0.0328, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8765\n",
      "Epoch 10/10, Train Loss: 0.0356, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8816\n",
      "\n",
      "Sentiment analysis accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       782\n",
      "    positive       0.90      0.78      0.84       325\n",
      "\n",
      "    accuracy                           0.91      1107\n",
      "   macro avg       0.91      0.87      0.89      1107\n",
      "weighted avg       0.91      0.91      0.91      1107\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9574, F1 Micro: 0.9574, F1 Macro: 0.8543\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.97      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.83      0.88        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.42      0.50      0.45        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.78      0.77      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.82      0.72      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.57      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       162\n",
      "     neutral       0.95      0.95      0.95       387\n",
      "    positive       0.65      0.59      0.62        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.83      0.81      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.94      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.79       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 322.0506989955902 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.00030333629110828046\n",
      "Samples above threshold: 70\n",
      "Acquired samples: 70\n",
      "Sampling duration: 14.660605430603027 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.518, Accuracy: 0.8276, F1 Micro: 0.9015, F1 Macro: 0.8939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3607, Accuracy: 0.9278, F1 Micro: 0.956, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2501, Accuracy: 0.9415, F1 Micro: 0.9644, F1 Macro: 0.962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2034, Accuracy: 0.9491, F1 Micro: 0.9689, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1647, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1386, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1177, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "Epoch 8/10, Train Loss: 0.1058, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0866, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9755\n",
      "Epoch 10/10, Train Loss: 0.0751, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3702, Accuracy: 0.8602, F1 Micro: 0.8602, F1 Macro: 0.8272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2344, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8795\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1516, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1437, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8891\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0926, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0764, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8931\n",
      "Epoch 7/10, Train Loss: 0.0533, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0578, Accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8933\n",
      "Epoch 9/10, Train Loss: 0.0349, Accuracy: 0.9172, F1 Micro: 0.9172, F1 Macro: 0.8935\n",
      "Epoch 10/10, Train Loss: 0.0332, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8924\n",
      "\n",
      "Sentiment analysis accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       775\n",
      "    positive       0.94      0.76      0.84       312\n",
      "\n",
      "    accuracy                           0.92      1087\n",
      "   macro avg       0.93      0.87      0.89      1087\n",
      "weighted avg       0.92      0.92      0.92      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.8809\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.61      0.66       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86       162\n",
      "     neutral       0.93      0.98      0.95       387\n",
      "    positive       0.88      0.32      0.47        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.71      0.76       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.84      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 324.58800768852234 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.00026995236403308813\n",
      "Samples above threshold: 63\n",
      "Acquired samples: 52\n",
      "Sampling duration: 13.086901664733887 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5107, Accuracy: 0.8368, F1 Micro: 0.9066, F1 Macro: 0.9004\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3528, Accuracy: 0.9288, F1 Micro: 0.9567, F1 Macro: 0.9536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2451, Accuracy: 0.9486, F1 Micro: 0.9685, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.193, Accuracy: 0.9538, F1 Micro: 0.9716, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1555, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1338, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1127, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9759\n",
      "Epoch 8/10, Train Loss: 0.0949, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0806, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0707, Accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3702, Accuracy: 0.8607, F1 Micro: 0.8607, F1 Macro: 0.8125\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2121, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.144, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1103, Accuracy: 0.9166, F1 Micro: 0.9166, F1 Macro: 0.8923\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0933, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8936\n",
      "Epoch 6/10, Train Loss: 0.0606, Accuracy: 0.9166, F1 Micro: 0.9166, F1 Macro: 0.8921\n",
      "Epoch 7/10, Train Loss: 0.0534, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0435, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8936\n",
      "Epoch 9/10, Train Loss: 0.0312, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8884\n",
      "Epoch 10/10, Train Loss: 0.0333, Accuracy: 0.9019, F1 Micro: 0.9019, F1 Macro: 0.8675\n",
      "\n",
      "Sentiment analysis accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94       779\n",
      "    positive       0.92      0.78      0.84       312\n",
      "\n",
      "    accuracy                           0.92      1091\n",
      "   macro avg       0.92      0.87      0.89      1091\n",
      "weighted avg       0.92      0.92      0.92      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.8706\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.86      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.50      0.50      0.50        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.80      0.78      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.95      0.88       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.62      0.66       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.74      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.79      0.83        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.89      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.90      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.84      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 338.0292880535126 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0001656289241509512\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 58\n",
      "Sampling duration: 12.030551671981812 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.498, Accuracy: 0.8486, F1 Micro: 0.9114, F1 Macro: 0.9019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3453, Accuracy: 0.9316, F1 Micro: 0.9582, F1 Macro: 0.954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.239, Accuracy: 0.9476, F1 Micro: 0.9678, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1907, Accuracy: 0.9545, F1 Micro: 0.972, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1598, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9734\n",
      "Epoch 6/10, Train Loss: 0.1329, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1094, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "Epoch 8/10, Train Loss: 0.0935, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9744\n",
      "Epoch 9/10, Train Loss: 0.0811, Accuracy: 0.9623, F1 Micro: 0.9765, F1 Macro: 0.9737\n",
      "Epoch 10/10, Train Loss: 0.0713, Accuracy: 0.9649, F1 Micro: 0.9783, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.98       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3759, Accuracy: 0.8705, F1 Micro: 0.8705, F1 Macro: 0.8266\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2192, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1481, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1294, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8908\n",
      "Epoch 5/10, Train Loss: 0.0914, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0613, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.8923\n",
      "Epoch 7/10, Train Loss: 0.0661, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8728\n",
      "Epoch 8/10, Train Loss: 0.0391, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8841\n",
      "Epoch 9/10, Train Loss: 0.0409, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8838\n",
      "Epoch 10/10, Train Loss: 0.0436, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8865\n",
      "\n",
      "Sentiment analysis accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.8923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       779\n",
      "    positive       0.93      0.76      0.84       310\n",
      "\n",
      "    accuracy                           0.92      1089\n",
      "   macro avg       0.92      0.87      0.89      1089\n",
      "weighted avg       0.92      0.92      0.91      1089\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8747\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.92      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85        78\n",
      "     neutral       0.98      0.97      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.87      0.69      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.89       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.77      0.82       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.83      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 333.96715784072876 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.000154804639169015\n",
      "Samples above threshold: 52\n",
      "Acquired samples: 52\n",
      "Sampling duration: 10.833458185195923 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5044, Accuracy: 0.8283, F1 Micro: 0.9027, F1 Macro: 0.8973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3395, Accuracy: 0.9285, F1 Micro: 0.9567, F1 Macro: 0.9534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2401, Accuracy: 0.9443, F1 Micro: 0.966, F1 Macro: 0.9637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1847, Accuracy: 0.9559, F1 Micro: 0.9728, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1561, Accuracy: 0.9599, F1 Micro: 0.9751, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1326, Accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1087, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0926, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9761\n",
      "Epoch 9/10, Train Loss: 0.0773, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9748\n",
      "Epoch 10/10, Train Loss: 0.0685, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9741\n",
      "\n",
      "Aspect detection accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.91      0.95      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3964, Accuracy: 0.8732, F1 Micro: 0.8732, F1 Macro: 0.8296\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2139, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.8787\n",
      "Epoch 3/10, Train Loss: 0.1436, Accuracy: 0.8952, F1 Micro: 0.8952, F1 Macro: 0.86\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1085, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8888\n",
      "Epoch 5/10, Train Loss: 0.0843, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8869\n",
      "Epoch 6/10, Train Loss: 0.0802, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8843\n",
      "Epoch 7/10, Train Loss: 0.0538, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0387, Accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.8949\n",
      "Epoch 9/10, Train Loss: 0.0343, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8903\n",
      "Epoch 10/10, Train Loss: 0.0379, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8873\n",
      "\n",
      "Sentiment analysis accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.8949\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       777\n",
      "    positive       0.94      0.77      0.84       311\n",
      "\n",
      "    accuracy                           0.92      1088\n",
      "   macro avg       0.93      0.87      0.89      1088\n",
      "weighted avg       0.92      0.92      0.92      1088\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9592, F1 Micro: 0.9592, F1 Macro: 0.8643\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.83      0.71      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.89       200\n",
      "     neutral       0.91      0.95      0.93       315\n",
      "    positive       0.87      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.67      0.45      0.54        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.83      0.76      0.79       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.82      0.86        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 335.66939759254456 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.00013482310168910772\n",
      "Samples above threshold: 47\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.806490182876587 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4913, Accuracy: 0.8675, F1 Micro: 0.922, F1 Macro: 0.9149\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3188, Accuracy: 0.9361, F1 Micro: 0.9611, F1 Macro: 0.9579\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.22, Accuracy: 0.9434, F1 Micro: 0.9654, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1722, Accuracy: 0.9554, F1 Micro: 0.9725, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1465, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1219, Accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1037, Accuracy: 0.9653, F1 Micro: 0.9785, F1 Macro: 0.9764\n",
      "Epoch 8/10, Train Loss: 0.0906, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0725, Accuracy: 0.9667, F1 Micro: 0.9793, F1 Macro: 0.9771\n",
      "Epoch 10/10, Train Loss: 0.0625, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9667, F1 Micro: 0.9793, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3578, Accuracy: 0.8742, F1 Micro: 0.8742, F1 Macro: 0.8363\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2086, Accuracy: 0.8905, F1 Micro: 0.8905, F1 Macro: 0.8609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1435, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0958, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8834\n",
      "Epoch 5/10, Train Loss: 0.0858, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.879\n",
      "Epoch 6/10, Train Loss: 0.0599, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0462, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.047, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8917\n",
      "Epoch 9/10, Train Loss: 0.0426, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8844\n",
      "Epoch 10/10, Train Loss: 0.0253, Accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.8906\n",
      "\n",
      "Sentiment analysis accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8917\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       787\n",
      "    positive       0.92      0.77      0.84       318\n",
      "\n",
      "    accuracy                           0.92      1105\n",
      "   macro avg       0.92      0.87      0.89      1105\n",
      "weighted avg       0.92      0.92      0.91      1105\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9609, F1 Micro: 0.9609, F1 Macro: 0.8825\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.86      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.86      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.62      0.66       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.94      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.87      0.79      0.82       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 353.30758261680603 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.00010265685705235228\n",
      "Samples above threshold: 42\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.726047277450562 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4895, Accuracy: 0.8665, F1 Micro: 0.9212, F1 Macro: 0.9122\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3148, Accuracy: 0.9382, F1 Micro: 0.9623, F1 Macro: 0.9595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.221, Accuracy: 0.9488, F1 Micro: 0.9687, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.176, Accuracy: 0.9568, F1 Micro: 0.9733, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1429, Accuracy: 0.9589, F1 Micro: 0.9746, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1195, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1005, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9755\n",
      "Epoch 8/10, Train Loss: 0.0864, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0706, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9765\n",
      "Epoch 10/10, Train Loss: 0.0617, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9754\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.92      0.95      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3607, Accuracy: 0.8592, F1 Micro: 0.8592, F1 Macro: 0.7982\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2094, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1277, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1083, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0669, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.8978\n",
      "Epoch 6/10, Train Loss: 0.0521, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8909\n",
      "Epoch 7/10, Train Loss: 0.0436, Accuracy: 0.9172, F1 Micro: 0.9172, F1 Macro: 0.8923\n",
      "Epoch 8/10, Train Loss: 0.0419, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8763\n",
      "Epoch 9/10, Train Loss: 0.0288, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8905\n",
      "Epoch 10/10, Train Loss: 0.033, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8787\n",
      "\n",
      "Sentiment analysis accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.8978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       776\n",
      "    positive       0.93      0.78      0.85       311\n",
      "\n",
      "    accuracy                           0.92      1087\n",
      "   macro avg       0.93      0.88      0.90      1087\n",
      "weighted avg       0.92      0.92      0.92      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.8709\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.75      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.58      0.59       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.89       200\n",
      "     neutral       0.92      0.95      0.94       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.71      0.45      0.56        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.85      0.76      0.79       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 355.54831171035767 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 7.49701721360907e-05\n",
      "Samples above threshold: 37\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.776854991912842 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4871, Accuracy: 0.8747, F1 Micro: 0.9259, F1 Macro: 0.9186\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3081, Accuracy: 0.9325, F1 Micro: 0.9589, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2133, Accuracy: 0.9503, F1 Micro: 0.9695, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1716, Accuracy: 0.9587, F1 Micro: 0.9745, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1387, Accuracy: 0.962, F1 Micro: 0.9765, F1 Macro: 0.9744\n",
      "Epoch 6/10, Train Loss: 0.1173, Accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.974\n",
      "Epoch 7/10, Train Loss: 0.1002, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0846, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0701, Accuracy: 0.967, F1 Micro: 0.9794, F1 Macro: 0.9772\n",
      "Epoch 10/10, Train Loss: 0.0607, Accuracy: 0.9667, F1 Micro: 0.9793, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.967, F1 Micro: 0.9794, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.96      0.91      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.98      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3518, Accuracy: 0.8642, F1 Micro: 0.8642, F1 Macro: 0.8257\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2171, Accuracy: 0.8997, F1 Micro: 0.8997, F1 Macro: 0.871\n",
      "Epoch 3/10, Train Loss: 0.1338, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1085, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8786\n",
      "Epoch 5/10, Train Loss: 0.0776, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8751\n",
      "Epoch 6/10, Train Loss: 0.0662, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8697\n",
      "Epoch 7/10, Train Loss: 0.0524, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8773\n",
      "Epoch 8/10, Train Loss: 0.0436, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8774\n",
      "Epoch 9/10, Train Loss: 0.0424, Accuracy: 0.8997, F1 Micro: 0.8997, F1 Macro: 0.8715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0268, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8793\n",
      "\n",
      "Sentiment analysis accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       795\n",
      "    positive       0.94      0.73      0.82       332\n",
      "\n",
      "    accuracy                           0.91      1127\n",
      "   macro avg       0.92      0.86      0.88      1127\n",
      "weighted avg       0.91      0.91      0.90      1127\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9613, F1 Micro: 0.9613, F1 Macro: 0.8741\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.78      0.70      0.74        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.87      0.88       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.82      0.94      0.87       571\n",
      "weighted avg       0.96      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.75      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.58      0.59       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90       200\n",
      "     neutral       0.96      0.91      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.75      0.41      0.53        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.85      0.75      0.78       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.93      0.97      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.69      0.75        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 354.409943819046 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 6.945512723177671e-05\n",
      "Samples above threshold: 32\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.868149757385254 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.483, Accuracy: 0.8661, F1 Micro: 0.9217, F1 Macro: 0.9158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3085, Accuracy: 0.9332, F1 Micro: 0.9594, F1 Macro: 0.957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2145, Accuracy: 0.9467, F1 Micro: 0.9674, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1654, Accuracy: 0.9543, F1 Micro: 0.9718, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1384, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9747\n",
      "Epoch 6/10, Train Loss: 0.1156, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0997, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9767\n",
      "Epoch 8/10, Train Loss: 0.0829, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9748\n",
      "Epoch 9/10, Train Loss: 0.0673, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "Epoch 10/10, Train Loss: 0.0595, Accuracy: 0.9653, F1 Micro: 0.9785, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3602, Accuracy: 0.8713, F1 Micro: 0.8713, F1 Macro: 0.8407\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2252, Accuracy: 0.8948, F1 Micro: 0.8948, F1 Macro: 0.8609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1599, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1049, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0917, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.89\n",
      "Epoch 6/10, Train Loss: 0.0756, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8761\n",
      "Epoch 7/10, Train Loss: 0.0508, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0423, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8901\n",
      "Epoch 9/10, Train Loss: 0.0294, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8867\n",
      "Epoch 10/10, Train Loss: 0.0336, Accuracy: 0.9003, F1 Micro: 0.9003, F1 Macro: 0.8693\n",
      "\n",
      "Sentiment analysis accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8901\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       782\n",
      "    positive       0.94      0.76      0.84       321\n",
      "\n",
      "    accuracy                           0.91      1103\n",
      "   macro avg       0.92      0.87      0.89      1103\n",
      "weighted avg       0.92      0.91      0.91      1103\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8825\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.29      0.40         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.76      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.82      0.68      0.72       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.78      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 358.9480628967285 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 6.622421278734691e-05\n",
      "Samples above threshold: 29\n",
      "Acquired samples: 50\n",
      "Sampling duration: 6.373679161071777 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4772, Accuracy: 0.8694, F1 Micro: 0.9227, F1 Macro: 0.9145\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2993, Accuracy: 0.9396, F1 Micro: 0.9631, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.209, Accuracy: 0.9493, F1 Micro: 0.969, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1682, Accuracy: 0.9559, F1 Micro: 0.9727, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1357, Accuracy: 0.9564, F1 Micro: 0.9731, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1138, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0954, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9768\n",
      "Epoch 8/10, Train Loss: 0.0839, Accuracy: 0.9648, F1 Micro: 0.978, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.07, Accuracy: 0.9663, F1 Micro: 0.979, F1 Macro: 0.9768\n",
      "Epoch 10/10, Train Loss: 0.0617, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9663, F1 Micro: 0.979, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3443, Accuracy: 0.8645, F1 Micro: 0.8645, F1 Macro: 0.8125\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1994, Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1347, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0891, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0838, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8887\n",
      "Epoch 6/10, Train Loss: 0.0553, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8744\n",
      "Epoch 7/10, Train Loss: 0.0398, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8796\n",
      "Epoch 8/10, Train Loss: 0.0467, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8814\n",
      "Epoch 9/10, Train Loss: 0.0344, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8829\n",
      "Epoch 10/10, Train Loss: 0.0188, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8845\n",
      "\n",
      "Sentiment analysis accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       786\n",
      "    positive       0.94      0.75      0.84       321\n",
      "\n",
      "    accuracy                           0.91      1107\n",
      "   macro avg       0.92      0.87      0.89      1107\n",
      "weighted avg       0.92      0.91      0.91      1107\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.8818\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.86      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.82      0.75      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.62      0.66       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.75      0.80       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.84      0.87        85\n",
      "     neutral       0.97      0.99      0.98       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.85      0.86       571\n",
      "weighted avg       0.98      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 365.52278327941895 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 4.077869925822597e-05\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 50\n",
      "Sampling duration: 5.618517160415649 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4753, Accuracy: 0.8714, F1 Micro: 0.9252, F1 Macro: 0.9206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2911, Accuracy: 0.9382, F1 Micro: 0.9623, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2033, Accuracy: 0.9486, F1 Micro: 0.9685, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1634, Accuracy: 0.9559, F1 Micro: 0.9729, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1348, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Epoch 6/10, Train Loss: 0.1109, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9753\n",
      "Epoch 7/10, Train Loss: 0.0906, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Epoch 8/10, Train Loss: 0.0781, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0647, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.055, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.92      0.96      0.94       317\n",
      "       linen       0.92      0.98      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3461, Accuracy: 0.877, F1 Micro: 0.877, F1 Macro: 0.8386\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.205, Accuracy: 0.8966, F1 Micro: 0.8966, F1 Macro: 0.8611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1295, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1036, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.896\n",
      "Epoch 5/10, Train Loss: 0.0599, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0571, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9013\n",
      "Epoch 7/10, Train Loss: 0.0521, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8837\n",
      "Epoch 8/10, Train Loss: 0.0358, Accuracy: 0.9199, F1 Micro: 0.9199, F1 Macro: 0.897\n",
      "Epoch 9/10, Train Loss: 0.0321, Accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.8873\n",
      "Epoch 10/10, Train Loss: 0.0186, Accuracy: 0.9199, F1 Micro: 0.9199, F1 Macro: 0.8941\n",
      "\n",
      "Sentiment analysis accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       771\n",
      "    positive       0.94      0.78      0.85       302\n",
      "\n",
      "    accuracy                           0.92      1073\n",
      "   macro avg       0.93      0.88      0.90      1073\n",
      "weighted avg       0.93      0.92      0.92      1073\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8837\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.86      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.86      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.96      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.29      0.36         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.88      0.75      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.78      0.67      0.71       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.86      0.90       200\n",
      "     neutral       0.92      0.96      0.94       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.86       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.67      0.36      0.47        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.83      0.72      0.76       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        85\n",
      "     neutral       0.97      0.99      0.98       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.77      0.81       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 370.3446261882782 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 2.713120738917496e-05\n",
      "Samples above threshold: 19\n",
      "Acquired samples: 50\n",
      "Sampling duration: 4.665951728820801 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4629, Accuracy: 0.8778, F1 Micro: 0.9274, F1 Macro: 0.9203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.279, Accuracy: 0.9429, F1 Micro: 0.965, F1 Macro: 0.9629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1949, Accuracy: 0.9505, F1 Micro: 0.9695, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1593, Accuracy: 0.9549, F1 Micro: 0.9722, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1311, Accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1116, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0906, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0757, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0641, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9762\n",
      "Epoch 10/10, Train Loss: 0.0557, Accuracy: 0.9648, F1 Micro: 0.9782, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3505, Accuracy: 0.8637, F1 Micro: 0.8637, F1 Macro: 0.8183\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1939, Accuracy: 0.9021, F1 Micro: 0.9021, F1 Macro: 0.8754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1218, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8863\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0968, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8911\n",
      "Epoch 5/10, Train Loss: 0.0649, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8869\n",
      "Epoch 6/10, Train Loss: 0.0515, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8858\n",
      "Epoch 7/10, Train Loss: 0.0536, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8821\n",
      "Epoch 8/10, Train Loss: 0.0442, Accuracy: 0.9085, F1 Micro: 0.9085, F1 Macro: 0.8844\n",
      "Epoch 9/10, Train Loss: 0.0232, Accuracy: 0.9131, F1 Micro: 0.9131, F1 Macro: 0.8879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0346, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.8934\n",
      "\n",
      "Sentiment analysis accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.8934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       777\n",
      "    positive       0.94      0.76      0.84       316\n",
      "\n",
      "    accuracy                           0.92      1093\n",
      "   macro avg       0.93      0.87      0.89      1093\n",
      "weighted avg       0.92      0.92      0.91      1093\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9594, F1 Micro: 0.9594, F1 Macro: 0.8731\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.86      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.67      0.36      0.47        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.83      0.73      0.76       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 378.3675434589386 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 2.669053901627194e-05\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 50\n",
      "Sampling duration: 3.73494029045105 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4641, Accuracy: 0.8769, F1 Micro: 0.9275, F1 Macro: 0.9215\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2748, Accuracy: 0.9398, F1 Micro: 0.9633, F1 Macro: 0.9608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1925, Accuracy: 0.9497, F1 Micro: 0.969, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1573, Accuracy: 0.9554, F1 Micro: 0.9725, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1325, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1078, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "Epoch 7/10, Train Loss: 0.0882, Accuracy: 0.9639, F1 Micro: 0.9775, F1 Macro: 0.9752\n",
      "Epoch 8/10, Train Loss: 0.0726, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "Epoch 9/10, Train Loss: 0.062, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9758\n",
      "Epoch 10/10, Train Loss: 0.0533, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3496, Accuracy: 0.8716, F1 Micro: 0.8716, F1 Macro: 0.8326\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1997, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1518, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8815\n",
      "Epoch 4/10, Train Loss: 0.1084, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0833, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.07, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8909\n",
      "Epoch 7/10, Train Loss: 0.0431, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8868\n",
      "Epoch 8/10, Train Loss: 0.0461, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.888\n",
      "Epoch 9/10, Train Loss: 0.0311, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.037, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.8979\n",
      "\n",
      "Sentiment analysis accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.8979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       775\n",
      "    positive       0.95      0.77      0.85       315\n",
      "\n",
      "    accuracy                           0.92      1090\n",
      "   macro avg       0.93      0.88      0.90      1090\n",
      "weighted avg       0.92      0.92      0.92      1090\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8858\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.86      0.89        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.82       571\n",
      "weighted avg       0.96      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.86      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.96      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.82      0.72      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.61      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.90       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.75      0.41      0.53        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.86      0.74      0.78       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.84      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.84      0.87       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 375.0934889316559 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 3.744497553270776e-05\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 50\n",
      "Sampling duration: 2.7427356243133545 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4489, Accuracy: 0.884, F1 Micro: 0.9313, F1 Macro: 0.9259\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2651, Accuracy: 0.9413, F1 Micro: 0.9641, F1 Macro: 0.9618\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1887, Accuracy: 0.9519, F1 Micro: 0.9705, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1489, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1247, Accuracy: 0.9592, F1 Micro: 0.9749, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1028, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0842, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0677, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0616, Accuracy: 0.9651, F1 Micro: 0.9784, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0502, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.96      0.90      0.93       317\n",
      "       linen       0.94      0.97      0.96       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.98      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3485, Accuracy: 0.8601, F1 Micro: 0.8601, F1 Macro: 0.8311\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1874, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8697\n",
      "Epoch 3/10, Train Loss: 0.1343, Accuracy: 0.8975, F1 Micro: 0.8975, F1 Macro: 0.864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0874, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8804\n",
      "Epoch 5/10, Train Loss: 0.0767, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8612\n",
      "Epoch 6/10, Train Loss: 0.0648, Accuracy: 0.9037, F1 Micro: 0.9037, F1 Macro: 0.8758\n",
      "Epoch 7/10, Train Loss: 0.0417, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0382, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8832\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0289, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8822\n",
      "Epoch 10/10, Train Loss: 0.0306, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8799\n",
      "\n",
      "Sentiment analysis accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       790\n",
      "    positive       0.95      0.73      0.83       332\n",
      "\n",
      "    accuracy                           0.91      1122\n",
      "   macro avg       0.92      0.86      0.88      1122\n",
      "weighted avg       0.91      0.91      0.91      1122\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.8753\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.29      0.40         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.85      0.78      0.82        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.83      0.68      0.73       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.93      0.89       200\n",
      "     neutral       0.96      0.90      0.93       315\n",
      "    positive       0.88      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88       162\n",
      "     neutral       0.94      0.98      0.96       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.75      0.80       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.66      0.76        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.86      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 389.42946195602417 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 7.385368917312007e-06\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 36\n",
      "Sampling duration: 1.8758594989776611 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4456, Accuracy: 0.8868, F1 Micro: 0.9331, F1 Macro: 0.9281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2567, Accuracy: 0.9432, F1 Micro: 0.9653, F1 Macro: 0.9631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.183, Accuracy: 0.9481, F1 Micro: 0.9682, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1467, Accuracy: 0.9543, F1 Micro: 0.9719, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1218, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1011, Accuracy: 0.9649, F1 Micro: 0.9783, F1 Macro: 0.9761\n",
      "Epoch 7/10, Train Loss: 0.08, Accuracy: 0.9648, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "Epoch 8/10, Train Loss: 0.0694, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "Epoch 9/10, Train Loss: 0.0579, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0489, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3436, Accuracy: 0.8675, F1 Micro: 0.8675, F1 Macro: 0.8241\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1863, Accuracy: 0.8949, F1 Micro: 0.8949, F1 Macro: 0.8598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1294, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0952, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8811\n",
      "Epoch 5/10, Train Loss: 0.0732, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0624, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0498, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.8875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0323, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.893\n",
      "Epoch 9/10, Train Loss: 0.0338, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.8888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0189, Accuracy: 0.9214, F1 Micro: 0.9214, F1 Macro: 0.8975\n",
      "\n",
      "Sentiment analysis accuracy: 0.9214, F1 Micro: 0.9214, F1 Macro: 0.8975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       781\n",
      "    positive       0.95      0.77      0.85       313\n",
      "\n",
      "    accuracy                           0.92      1094\n",
      "   macro avg       0.93      0.88      0.90      1094\n",
      "weighted avg       0.92      0.92      0.92      1094\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.877\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.86      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.87      0.86        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.87      0.69      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.77      0.81       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.66      0.76        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.86      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 392.096355676651 s\n",
      "Total runtime: 8451.37600684166 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0ffdb9",
   "metadata": {
    "papermill": {
     "duration": 0.186054,
     "end_time": "2025-03-30T10:00:55.498031",
     "exception": false,
     "start_time": "2025-03-30T10:00:55.311977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d98685d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6341, Accuracy: 0.7974, F1 Micro: 0.8859, F1 Macro: 0.8768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5134, Accuracy: 0.8014, F1 Micro: 0.8897, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4829, Accuracy: 0.8017, F1 Micro: 0.8897, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4632, Accuracy: 0.8045, F1 Micro: 0.8906, F1 Macro: 0.8847\n",
      "Epoch 5/10, Train Loss: 0.4642, Accuracy: 0.8047, F1 Micro: 0.8903, F1 Macro: 0.8835\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4501, Accuracy: 0.8075, F1 Micro: 0.891, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.451, Accuracy: 0.8149, F1 Micro: 0.8947, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4034, Accuracy: 0.8273, F1 Micro: 0.9007, F1 Macro: 0.892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3957, Accuracy: 0.8345, F1 Micro: 0.9041, F1 Macro: 0.8954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3562, Accuracy: 0.8448, F1 Micro: 0.9097, F1 Macro: 0.9016\n",
      "\n",
      "Aspect detection accuracy: 0.8448, F1 Micro: 0.9097, F1 Macro: 0.9016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.83      1.00      0.90       462\n",
      "   air_panas       0.83      1.00      0.91       480\n",
      "         bau       0.86      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.70      0.75      0.73       317\n",
      "       linen       0.77      0.94      0.85       392\n",
      "     service       0.90      0.98      0.94       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.88      1.00      0.94       498\n",
      "\n",
      "   micro avg       0.85      0.98      0.91      4614\n",
      "   macro avg       0.85      0.97      0.90      4614\n",
      "weighted avg       0.85      0.98      0.91      4614\n",
      " samples avg       0.85      0.97      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7316, Accuracy: 0.5412, F1 Micro: 0.5412, F1 Macro: 0.3512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.612, Accuracy: 0.5412, F1 Micro: 0.5412, F1 Macro: 0.3512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5437, Accuracy: 0.5645, F1 Micro: 0.5645, F1 Macro: 0.4185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5596, Accuracy: 0.5751, F1 Micro: 0.5751, F1 Macro: 0.4522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4998, Accuracy: 0.5877, F1 Micro: 0.5877, F1 Macro: 0.5659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.478, Accuracy: 0.6025, F1 Micro: 0.6025, F1 Macro: 0.5626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3806, Accuracy: 0.666, F1 Micro: 0.666, F1 Macro: 0.6564\n",
      "Epoch 8/10, Train Loss: 0.3522, Accuracy: 0.6195, F1 Micro: 0.6195, F1 Macro: 0.5823\n",
      "Epoch 9/10, Train Loss: 0.3548, Accuracy: 0.6575, F1 Micro: 0.6575, F1 Macro: 0.6482\n",
      "Epoch 10/10, Train Loss: 0.3088, Accuracy: 0.6237, F1 Micro: 0.6237, F1 Macro: 0.6009\n",
      "\n",
      "Sentiment analysis accuracy: 0.666, F1 Micro: 0.666, F1 Macro: 0.6564\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.77      0.71       256\n",
      "    positive       0.67      0.54      0.60       217\n",
      "\n",
      "    accuracy                           0.67       473\n",
      "   macro avg       0.67      0.66      0.66       473\n",
      "weighted avg       0.67      0.67      0.66       473\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8285, F1 Micro: 0.8285, F1 Macro: 0.4061\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.16      0.28        97\n",
      "     neutral       0.83      1.00      0.91       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.61      0.39      0.40       571\n",
      "weighted avg       0.83      0.83      0.78       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.28      0.33      0.30       571\n",
      "weighted avg       0.69      0.83      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        78\n",
      "     neutral       0.86      1.00      0.92       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.74      0.86      0.80       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.43      0.50       200\n",
      "     neutral       0.70      0.75      0.73       315\n",
      "    positive       0.28      0.45      0.34        56\n",
      "\n",
      "    accuracy                           0.61       571\n",
      "   macro avg       0.53      0.54      0.52       571\n",
      "weighted avg       0.62      0.61      0.61       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.30      0.42       162\n",
      "     neutral       0.76      0.94      0.84       387\n",
      "    positive       0.17      0.18      0.18        22\n",
      "\n",
      "    accuracy                           0.73       571\n",
      "   macro avg       0.54      0.47      0.48       571\n",
      "weighted avg       0.72      0.73      0.70       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.41      0.51        85\n",
      "     neutral       0.90      0.98      0.93       418\n",
      "    positive       0.72      0.68      0.70        68\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.76      0.69      0.71       571\n",
      "weighted avg       0.84      0.86      0.84       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.24        74\n",
      "     neutral       0.88      1.00      0.94       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.63      0.38      0.39       571\n",
      "weighted avg       0.89      0.88      0.84       571\n",
      "\n",
      "Total train time: 84.26201009750366 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0010259365662932396\n",
      "Samples above threshold: 215\n",
      "Acquired samples: 215\n",
      "Sampling duration: 30.784592151641846 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5693, Accuracy: 0.8017, F1 Micro: 0.8896, F1 Macro: 0.8848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4791, Accuracy: 0.8064, F1 Micro: 0.8901, F1 Macro: 0.8797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4611, Accuracy: 0.8269, F1 Micro: 0.9007, F1 Macro: 0.8932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4498, Accuracy: 0.8366, F1 Micro: 0.9051, F1 Macro: 0.8964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4257, Accuracy: 0.8493, F1 Micro: 0.9125, F1 Macro: 0.9065\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3525, Accuracy: 0.8776, F1 Micro: 0.9277, F1 Macro: 0.922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3306, Accuracy: 0.8915, F1 Micro: 0.9357, F1 Macro: 0.9318\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2789, Accuracy: 0.9042, F1 Micro: 0.9427, F1 Macro: 0.9391\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2484, Accuracy: 0.9073, F1 Micro: 0.9445, F1 Macro: 0.9413\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2185, Accuracy: 0.9189, F1 Micro: 0.951, F1 Macro: 0.9475\n",
      "\n",
      "Aspect detection accuracy: 0.9189, F1 Micro: 0.951, F1 Macro: 0.9475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.96      0.99      0.98       462\n",
      "   air_panas       0.91      1.00      0.95       480\n",
      "         bau       0.91      0.99      0.95       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.88      0.86      0.87       317\n",
      "       linen       0.85      0.97      0.90       392\n",
      "     service       0.95      0.98      0.96       423\n",
      "sunrise_meal       0.93      1.00      0.97       530\n",
      "          tv       0.96      1.00      0.98       516\n",
      "        wifi       0.97      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.92      0.98      0.95      4614\n",
      "   macro avg       0.92      0.98      0.95      4614\n",
      "weighted avg       0.92      0.98      0.95      4614\n",
      " samples avg       0.92      0.98      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5393, Accuracy: 0.7231, F1 Micro: 0.7231, F1 Macro: 0.4196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4395, Accuracy: 0.7908, F1 Micro: 0.7908, F1 Macro: 0.6718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4216, Accuracy: 0.815, F1 Micro: 0.815, F1 Macro: 0.7372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.334, Accuracy: 0.8392, F1 Micro: 0.8392, F1 Macro: 0.7932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2945, Accuracy: 0.8501, F1 Micro: 0.8501, F1 Macro: 0.792\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2391, Accuracy: 0.8597, F1 Micro: 0.8597, F1 Macro: 0.8094\n",
      "Epoch 7/10, Train Loss: 0.2104, Accuracy: 0.8513, F1 Micro: 0.8513, F1 Macro: 0.8135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1771, Accuracy: 0.8767, F1 Micro: 0.8767, F1 Macro: 0.8324\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1133, Accuracy: 0.8803, F1 Micro: 0.8803, F1 Macro: 0.8381\n",
      "Epoch 10/10, Train Loss: 0.1111, Accuracy: 0.8791, F1 Micro: 0.8791, F1 Macro: 0.8389\n",
      "\n",
      "Sentiment analysis accuracy: 0.8803, F1 Micro: 0.8803, F1 Macro: 0.8381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92       598\n",
      "    positive       0.87      0.67      0.76       229\n",
      "\n",
      "    accuracy                           0.88       827\n",
      "   macro avg       0.88      0.81      0.84       827\n",
      "weighted avg       0.88      0.88      0.87       827\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.6587\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.86      0.90        97\n",
      "     neutral       0.96      0.99      0.98       459\n",
      "    positive       0.91      0.67      0.77        15\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.84      0.88       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.51      0.65        86\n",
      "     neutral       0.91      1.00      0.95       475\n",
      "    positive       0.67      0.20      0.31        10\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.83      0.57      0.64       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.38      0.53        78\n",
      "     neutral       0.91      0.99      0.95       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.59      0.46      0.49       571\n",
      "weighted avg       0.90      0.90      0.89       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.77      0.80       200\n",
      "     neutral       0.88      0.86      0.87       315\n",
      "    positive       0.65      0.91      0.76        56\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.79      0.85      0.81       571\n",
      "weighted avg       0.84      0.83      0.83       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.66      0.74       162\n",
      "     neutral       0.85      0.97      0.90       387\n",
      "    positive       0.50      0.05      0.08        22\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.73      0.56      0.58       571\n",
      "weighted avg       0.83      0.85      0.83       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.68      0.77        85\n",
      "     neutral       0.95      0.98      0.96       418\n",
      "    positive       0.86      0.93      0.89        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.90      0.86      0.88       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.10      0.19        29\n",
      "     neutral       0.93      1.00      0.97       525\n",
      "    positive       0.83      0.29      0.43        17\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.47      0.53       571\n",
      "weighted avg       0.93      0.93      0.91       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.67      0.76        54\n",
      "     neutral       0.96      1.00      0.98       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.61      0.55      0.58       571\n",
      "weighted avg       0.94      0.95      0.95       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.82      0.90        74\n",
      "     neutral       0.97      1.00      0.99       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.99      0.83      0.89       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Total train time: 129.04159545898438 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.03109887521713972\n",
      "Samples above threshold: 193\n",
      "Acquired samples: 193\n",
      "Sampling duration: 42.81668782234192 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5453, Accuracy: 0.7953, F1 Micro: 0.8804, F1 Macro: 0.8373\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4917, Accuracy: 0.8247, F1 Micro: 0.8963, F1 Macro: 0.8759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4554, Accuracy: 0.8415, F1 Micro: 0.908, F1 Macro: 0.9007\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3916, Accuracy: 0.8809, F1 Micro: 0.9294, F1 Macro: 0.9238\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3406, Accuracy: 0.8913, F1 Micro: 0.935, F1 Macro: 0.9294\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2813, Accuracy: 0.921, F1 Micro: 0.9521, F1 Macro: 0.9486\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2391, Accuracy: 0.9337, F1 Micro: 0.9594, F1 Macro: 0.9557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2066, Accuracy: 0.9352, F1 Micro: 0.9605, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1753, Accuracy: 0.9377, F1 Micro: 0.9619, F1 Macro: 0.9585\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.164, Accuracy: 0.9408, F1 Micro: 0.9638, F1 Macro: 0.9607\n",
      "\n",
      "Aspect detection accuracy: 0.9408, F1 Micro: 0.9638, F1 Macro: 0.9607\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.96      0.99      0.97       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.87      0.91      0.89       317\n",
      "       linen       0.88      0.97      0.92       392\n",
      "     service       0.95      0.98      0.97       423\n",
      "sunrise_meal       0.97      0.99      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      4614\n",
      "   macro avg       0.94      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.96      4614\n",
      " samples avg       0.94      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6068, Accuracy: 0.8084, F1 Micro: 0.8084, F1 Macro: 0.7319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4439, Accuracy: 0.8482, F1 Micro: 0.8482, F1 Macro: 0.7876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3349, Accuracy: 0.8607, F1 Micro: 0.8607, F1 Macro: 0.8172\n",
      "Epoch 4/10, Train Loss: 0.2987, Accuracy: 0.8492, F1 Micro: 0.8492, F1 Macro: 0.7817\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.235, Accuracy: 0.8869, F1 Micro: 0.8869, F1 Macro: 0.8435\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1605, Accuracy: 0.888, F1 Micro: 0.888, F1 Macro: 0.8479\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1255, Accuracy: 0.8942, F1 Micro: 0.8942, F1 Macro: 0.8556\n",
      "Epoch 8/10, Train Loss: 0.0842, Accuracy: 0.888, F1 Micro: 0.888, F1 Macro: 0.8418\n",
      "Epoch 9/10, Train Loss: 0.0904, Accuracy: 0.8827, F1 Micro: 0.8827, F1 Macro: 0.833\n",
      "Epoch 10/10, Train Loss: 0.0624, Accuracy: 0.8921, F1 Micro: 0.8921, F1 Macro: 0.8467\n",
      "\n",
      "Sentiment analysis accuracy: 0.8942, F1 Micro: 0.8942, F1 Macro: 0.8556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       697\n",
      "    positive       0.89      0.70      0.78       258\n",
      "\n",
      "    accuracy                           0.89       955\n",
      "   macro avg       0.89      0.83      0.86       955\n",
      "weighted avg       0.89      0.89      0.89       955\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.7869\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.87      0.87      0.87        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.76      0.81        86\n",
      "     neutral       0.96      0.99      0.97       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.82      0.75      0.78       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.74      0.79        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.74      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.50      0.01      0.03        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.46      0.34      0.32       571\n",
      "weighted avg       0.82      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.76      0.81       200\n",
      "     neutral       0.87      0.91      0.89       315\n",
      "    positive       0.83      0.98      0.90        56\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.86      0.88      0.87       571\n",
      "weighted avg       0.87      0.87      0.86       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.70      0.78       162\n",
      "     neutral       0.87      0.97      0.92       387\n",
      "    positive       0.50      0.36      0.42        22\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.76      0.68      0.71       571\n",
      "weighted avg       0.87      0.87      0.86       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.75      0.82        85\n",
      "     neutral       0.95      0.98      0.97       418\n",
      "    positive       0.90      0.90      0.90        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.88      0.89       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.41      0.55        29\n",
      "     neutral       0.97      0.99      0.98       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.74      0.76       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.81      0.87       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.98      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 169.6706793308258 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.003537310380488632\n",
      "Samples above threshold: 174\n",
      "Acquired samples: 174\n",
      "Sampling duration: 39.286810636520386 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.554, Accuracy: 0.8111, F1 Micro: 0.8895, F1 Macro: 0.8609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4971, Accuracy: 0.838, F1 Micro: 0.9064, F1 Macro: 0.8994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4251, Accuracy: 0.8799, F1 Micro: 0.9285, F1 Macro: 0.9214\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3444, Accuracy: 0.9071, F1 Micro: 0.9442, F1 Macro: 0.9397\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2893, Accuracy: 0.9285, F1 Micro: 0.9564, F1 Macro: 0.9527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2404, Accuracy: 0.9347, F1 Micro: 0.96, F1 Macro: 0.9562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1969, Accuracy: 0.9455, F1 Micro: 0.9665, F1 Macro: 0.9638\n",
      "Epoch 8/10, Train Loss: 0.1819, Accuracy: 0.9448, F1 Micro: 0.9661, F1 Macro: 0.9638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1562, Accuracy: 0.9465, F1 Micro: 0.9671, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1379, Accuracy: 0.9488, F1 Micro: 0.9685, F1 Macro: 0.9659\n",
      "\n",
      "Aspect detection accuracy: 0.9488, F1 Micro: 0.9685, F1 Macro: 0.9659\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.95      0.99      0.97       496\n",
      "     general       0.90      0.99      0.94       500\n",
      "  kebersihan       0.90      0.92      0.91       317\n",
      "       linen       0.87      0.98      0.92       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      0.99      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.97      4614\n",
      "weighted avg       0.95      0.98      0.97      4614\n",
      " samples avg       0.95      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5905, Accuracy: 0.831, F1 Micro: 0.831, F1 Macro: 0.7652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4281, Accuracy: 0.8583, F1 Micro: 0.8583, F1 Macro: 0.8199\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2887, Accuracy: 0.8957, F1 Micro: 0.8957, F1 Macro: 0.8569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1813, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1179, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.8893\n",
      "Epoch 6/10, Train Loss: 0.0992, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8821\n",
      "Epoch 7/10, Train Loss: 0.0972, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8846\n",
      "Epoch 8/10, Train Loss: 0.0568, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8827\n",
      "Epoch 9/10, Train Loss: 0.0444, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8762\n",
      "Epoch 10/10, Train Loss: 0.035, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8816\n",
      "\n",
      "Sentiment analysis accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.8893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       714\n",
      "    positive       0.94      0.75      0.83       274\n",
      "\n",
      "    accuracy                           0.92       988\n",
      "   macro avg       0.92      0.87      0.89       988\n",
      "weighted avg       0.92      0.92      0.91       988\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.8332\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.80      0.84        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.82      0.76      0.79       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.69      0.78        78\n",
      "     neutral       0.95      0.99      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.95      0.73      0.80       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.90      0.99      0.94       496\n",
      "    positive       0.83      0.29      0.43        68\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.58      0.43      0.46       571\n",
      "weighted avg       0.88      0.89      0.87       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86       200\n",
      "     neutral       0.90      0.92      0.91       315\n",
      "    positive       0.82      0.96      0.89        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.87      0.90      0.89       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.70      0.79       162\n",
      "     neutral       0.87      0.98      0.92       387\n",
      "    positive       0.58      0.32      0.41        22\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.79      0.67      0.71       571\n",
      "weighted avg       0.87      0.87      0.87       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.79      0.84        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.90      0.91       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      0.99      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 192.74747323989868 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0016295885201543573\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 156\n",
      "Sampling duration: 35.06882309913635 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5483, Accuracy: 0.8201, F1 Micro: 0.8977, F1 Macro: 0.8901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4745, Accuracy: 0.8523, F1 Micro: 0.9134, F1 Macro: 0.9042\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.388, Accuracy: 0.9016, F1 Micro: 0.9407, F1 Macro: 0.9354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3044, Accuracy: 0.9316, F1 Micro: 0.9582, F1 Macro: 0.9542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2414, Accuracy: 0.9427, F1 Micro: 0.9649, F1 Macro: 0.9623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2087, Accuracy: 0.9484, F1 Micro: 0.9683, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.171, Accuracy: 0.949, F1 Micro: 0.9686, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1462, Accuracy: 0.9547, F1 Micro: 0.972, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1284, Accuracy: 0.9552, F1 Micro: 0.9724, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1136, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.9707\n",
      "\n",
      "Aspect detection accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.9707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.93      0.98      0.96       500\n",
      "  kebersihan       0.94      0.91      0.92       317\n",
      "       linen       0.90      0.97      0.94       392\n",
      "     service       0.95      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5716, Accuracy: 0.8387, F1 Micro: 0.8387, F1 Macro: 0.7986\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3787, Accuracy: 0.8736, F1 Micro: 0.8736, F1 Macro: 0.8392\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2587, Accuracy: 0.8981, F1 Micro: 0.8981, F1 Macro: 0.8713\n",
      "Epoch 4/10, Train Loss: 0.1881, Accuracy: 0.8953, F1 Micro: 0.8953, F1 Macro: 0.8623\n",
      "Epoch 5/10, Train Loss: 0.153, Accuracy: 0.8962, F1 Micro: 0.8962, F1 Macro: 0.8692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0984, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0777, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8748\n",
      "Epoch 8/10, Train Loss: 0.0485, Accuracy: 0.8991, F1 Micro: 0.8991, F1 Macro: 0.8688\n",
      "Epoch 9/10, Train Loss: 0.0408, Accuracy: 0.8981, F1 Micro: 0.8981, F1 Macro: 0.8693\n",
      "Epoch 10/10, Train Loss: 0.0385, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8702\n",
      "\n",
      "Sentiment analysis accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       750\n",
      "    positive       0.93      0.72      0.81       310\n",
      "\n",
      "    accuracy                           0.90      1060\n",
      "   macro avg       0.91      0.85      0.87      1060\n",
      "weighted avg       0.91      0.90      0.90      1060\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.8436\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.79      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.78      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.84      0.56      0.67        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.51      0.54       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       200\n",
      "     neutral       0.94      0.91      0.92       315\n",
      "    positive       0.82      0.98      0.89        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.88      0.92      0.90       571\n",
      "weighted avg       0.91      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.77      0.83       162\n",
      "     neutral       0.90      0.97      0.93       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.90      0.73      0.79       571\n",
      "weighted avg       0.90      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.79      0.83        85\n",
      "     neutral       0.95      0.98      0.97       418\n",
      "    positive       0.95      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.89      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 227.0289821624756 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0013399307848885654\n",
      "Samples above threshold: 141\n",
      "Acquired samples: 141\n",
      "Sampling duration: 31.647292375564575 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5415, Accuracy: 0.8043, F1 Micro: 0.8865, F1 Macro: 0.8612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4623, Accuracy: 0.8684, F1 Micro: 0.9224, F1 Macro: 0.9157\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3681, Accuracy: 0.9132, F1 Micro: 0.9475, F1 Macro: 0.9432\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2796, Accuracy: 0.9347, F1 Micro: 0.9601, F1 Macro: 0.9568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2263, Accuracy: 0.9458, F1 Micro: 0.9667, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1834, Accuracy: 0.9523, F1 Micro: 0.9706, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1659, Accuracy: 0.9547, F1 Micro: 0.9721, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1401, Accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.12, Accuracy: 0.9597, F1 Micro: 0.975, F1 Macro: 0.9726\n",
      "Epoch 10/10, Train Loss: 0.1072, Accuracy: 0.9594, F1 Micro: 0.9748, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9597, F1 Micro: 0.975, F1 Macro: 0.9726\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      0.99      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.539, Accuracy: 0.8454, F1 Micro: 0.8454, F1 Macro: 0.7893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3319, Accuracy: 0.8796, F1 Micro: 0.8796, F1 Macro: 0.8418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2241, Accuracy: 0.8991, F1 Micro: 0.8991, F1 Macro: 0.87\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1719, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0998, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0936, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8814\n",
      "Epoch 7/10, Train Loss: 0.0793, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8806\n",
      "Epoch 8/10, Train Loss: 0.0551, Accuracy: 0.8981, F1 Micro: 0.8981, F1 Macro: 0.8658\n",
      "Epoch 9/10, Train Loss: 0.0518, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8707\n",
      "Epoch 10/10, Train Loss: 0.0387, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8747\n",
      "\n",
      "Sentiment analysis accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8814\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       762\n",
      "    positive       0.93      0.75      0.83       318\n",
      "\n",
      "    accuracy                           0.91      1080\n",
      "   macro avg       0.91      0.86      0.88      1080\n",
      "weighted avg       0.91      0.91      0.90      1080\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.86\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.75      0.77       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.81      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.60      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.80      0.84       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.86      0.74      0.78       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.80      0.84        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.90      0.91       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      1.00      0.97        74\n",
      "     neutral       1.00      0.99      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      1.00      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 247.7229130268097 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0011117975111119456\n",
      "Samples above threshold: 127\n",
      "Acquired samples: 127\n",
      "Sampling duration: 28.456788539886475 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5338, Accuracy: 0.8139, F1 Micro: 0.895, F1 Macro: 0.8885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4466, Accuracy: 0.88, F1 Micro: 0.9286, F1 Macro: 0.9216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3484, Accuracy: 0.9262, F1 Micro: 0.955, F1 Macro: 0.9508\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2568, Accuracy: 0.9458, F1 Micro: 0.9668, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2118, Accuracy: 0.9533, F1 Micro: 0.9712, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.177, Accuracy: 0.958, F1 Micro: 0.974, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1485, Accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1348, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9728\n",
      "Epoch 9/10, Train Loss: 0.1128, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0998, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.974\n",
      "\n",
      "Aspect detection accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5215, Accuracy: 0.8499, F1 Micro: 0.8499, F1 Macro: 0.7969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.294, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2097, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1532, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8824\n",
      "Epoch 5/10, Train Loss: 0.0901, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0878, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8811\n",
      "Epoch 7/10, Train Loss: 0.0548, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.871\n",
      "Epoch 8/10, Train Loss: 0.0521, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.036, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0309, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8858\n",
      "\n",
      "Sentiment analysis accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8858\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       769\n",
      "    positive       0.94      0.75      0.83       317\n",
      "\n",
      "    accuracy                           0.91      1086\n",
      "   macro avg       0.92      0.86      0.89      1086\n",
      "weighted avg       0.91      0.91      0.91      1086\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9559, F1 Micro: 0.9559, F1 Macro: 0.8684\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.85      0.89        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.78      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.65      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.54      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.83      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.75      0.55      0.63        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.78      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 264.28874373435974 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0009289885405451059\n",
      "Samples above threshold: 114\n",
      "Acquired samples: 114\n",
      "Sampling duration: 25.57074785232544 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5312, Accuracy: 0.8236, F1 Micro: 0.8999, F1 Macro: 0.8944\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4298, Accuracy: 0.8887, F1 Micro: 0.933, F1 Macro: 0.926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3174, Accuracy: 0.9332, F1 Micro: 0.9589, F1 Macro: 0.9546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2452, Accuracy: 0.9481, F1 Micro: 0.9681, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1971, Accuracy: 0.9533, F1 Micro: 0.9711, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1658, Accuracy: 0.9576, F1 Micro: 0.9738, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1426, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1224, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1074, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9747\n",
      "Epoch 10/10, Train Loss: 0.0949, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9733\n",
      "\n",
      "Aspect detection accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.93      0.92      0.93       317\n",
      "       linen       0.93      0.98      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4626, Accuracy: 0.8611, F1 Micro: 0.8611, F1 Macro: 0.8054\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2838, Accuracy: 0.8944, F1 Micro: 0.8944, F1 Macro: 0.8623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2021, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8777\n",
      "Epoch 4/10, Train Loss: 0.1191, Accuracy: 0.9037, F1 Micro: 0.9037, F1 Macro: 0.8706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0919, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.8944\n",
      "Epoch 6/10, Train Loss: 0.0772, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.884\n",
      "Epoch 7/10, Train Loss: 0.0769, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8894\n",
      "Epoch 8/10, Train Loss: 0.0522, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8829\n",
      "Epoch 9/10, Train Loss: 0.0484, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0293, Accuracy: 0.9204, F1 Micro: 0.9204, F1 Macro: 0.8971\n",
      "\n",
      "Sentiment analysis accuracy: 0.9204, F1 Micro: 0.9204, F1 Macro: 0.8971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       770\n",
      "    positive       0.94      0.77      0.85       310\n",
      "\n",
      "    accuracy                           0.92      1080\n",
      "   macro avg       0.93      0.88      0.90      1080\n",
      "weighted avg       0.92      0.92      0.92      1080\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.8688\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.81      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.76      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.60      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.88       200\n",
      "     neutral       0.93      0.92      0.93       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.84      0.87       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.76      0.81       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 277.68719267845154 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0006924386252649128\n",
      "Samples above threshold: 103\n",
      "Acquired samples: 103\n",
      "Sampling duration: 22.285070180892944 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5234, Accuracy: 0.8342, F1 Micro: 0.9048, F1 Macro: 0.8982\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4147, Accuracy: 0.899, F1 Micro: 0.94, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2886, Accuracy: 0.9405, F1 Micro: 0.9636, F1 Macro: 0.9608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2313, Accuracy: 0.951, F1 Micro: 0.97, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1843, Accuracy: 0.9582, F1 Micro: 0.9741, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1529, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.127, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1127, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "Epoch 9/10, Train Loss: 0.0968, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0851, Accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.93      0.98      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.467, Accuracy: 0.8522, F1 Micro: 0.8522, F1 Macro: 0.7989\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2806, Accuracy: 0.8894, F1 Micro: 0.8894, F1 Macro: 0.8615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1832, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1367, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8822\n",
      "Epoch 5/10, Train Loss: 0.0864, Accuracy: 0.8903, F1 Micro: 0.8903, F1 Macro: 0.8529\n",
      "Epoch 6/10, Train Loss: 0.0816, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8789\n",
      "Epoch 7/10, Train Loss: 0.0547, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.8739\n",
      "Epoch 8/10, Train Loss: 0.0408, Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.8724\n",
      "Epoch 9/10, Train Loss: 0.0258, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0281, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8817\n",
      "\n",
      "Sentiment analysis accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       779\n",
      "    positive       0.90      0.76      0.83       324\n",
      "\n",
      "    accuracy                           0.91      1103\n",
      "   macro avg       0.91      0.86      0.88      1103\n",
      "weighted avg       0.91      0.91      0.90      1103\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9562, F1 Micro: 0.9562, F1 Macro: 0.8701\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.75      1.00      0.86        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.97      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.83      0.84       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.79      0.68      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.60      0.65       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.71      0.45      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.75      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.88      0.87        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.89      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.64      0.94      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.80      0.78       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 292.7753179073334 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0006860510620754212\n",
      "Samples above threshold: 92\n",
      "Acquired samples: 62\n",
      "Sampling duration: 19.995985746383667 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5198, Accuracy: 0.8293, F1 Micro: 0.903, F1 Macro: 0.8978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4029, Accuracy: 0.9059, F1 Micro: 0.9434, F1 Macro: 0.9388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2901, Accuracy: 0.9389, F1 Micro: 0.9628, F1 Macro: 0.9604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2227, Accuracy: 0.9509, F1 Micro: 0.9698, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1846, Accuracy: 0.9583, F1 Micro: 0.9743, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.155, Accuracy: 0.9599, F1 Micro: 0.9751, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.136, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9737\n",
      "Epoch 8/10, Train Loss: 0.1151, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0986, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9756\n",
      "Epoch 10/10, Train Loss: 0.0865, Accuracy: 0.9642, F1 Micro: 0.9777, F1 Macro: 0.9754\n",
      "\n",
      "Aspect detection accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.91      0.93       317\n",
      "       linen       0.92      0.98      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4552, Accuracy: 0.8528, F1 Micro: 0.8528, F1 Macro: 0.8232\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2647, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1943, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8835\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1205, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0997, Accuracy: 0.9172, F1 Micro: 0.9172, F1 Macro: 0.8937\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0781, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.8968\n",
      "Epoch 7/10, Train Loss: 0.0543, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8915\n",
      "Epoch 8/10, Train Loss: 0.032, Accuracy: 0.9172, F1 Micro: 0.9172, F1 Macro: 0.8946\n",
      "Epoch 9/10, Train Loss: 0.0363, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8874\n",
      "Epoch 10/10, Train Loss: 0.042, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8941\n",
      "\n",
      "Sentiment analysis accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.8968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.94       771\n",
      "    positive       0.93      0.78      0.85       316\n",
      "\n",
      "    accuracy                           0.92      1087\n",
      "   macro avg       0.92      0.88      0.90      1087\n",
      "weighted avg       0.92      0.92      0.92      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8819\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.85      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.78      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.83      0.74      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       200\n",
      "     neutral       0.94      0.91      0.93       315\n",
      "    positive       0.83      0.98      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.86       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.75      0.81       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.83      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 304.4999885559082 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.0004961638915119693\n",
      "Samples above threshold: 86\n",
      "Acquired samples: 86\n",
      "Sampling duration: 18.50954556465149 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5075, Accuracy: 0.8273, F1 Micro: 0.9021, F1 Macro: 0.8976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3843, Accuracy: 0.9194, F1 Micro: 0.951, F1 Macro: 0.9458\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2656, Accuracy: 0.9429, F1 Micro: 0.965, F1 Macro: 0.9626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2124, Accuracy: 0.9528, F1 Micro: 0.9709, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1742, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1444, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9736\n",
      "Epoch 7/10, Train Loss: 0.1236, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1071, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0886, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0795, Accuracy: 0.9644, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9644, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.96      0.91      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4328, Accuracy: 0.8628, F1 Micro: 0.8628, F1 Macro: 0.8258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2599, Accuracy: 0.8852, F1 Micro: 0.8852, F1 Macro: 0.8481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1783, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8718\n",
      "Epoch 4/10, Train Loss: 0.1248, Accuracy: 0.896, F1 Micro: 0.896, F1 Macro: 0.8704\n",
      "Epoch 5/10, Train Loss: 0.0934, Accuracy: 0.8942, F1 Micro: 0.8942, F1 Macro: 0.8596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0772, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8678\n",
      "Epoch 7/10, Train Loss: 0.0689, Accuracy: 0.8978, F1 Micro: 0.8978, F1 Macro: 0.8683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0572, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8773\n",
      "Epoch 9/10, Train Loss: 0.0404, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8755\n",
      "Epoch 10/10, Train Loss: 0.0238, Accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.8759\n",
      "\n",
      "Sentiment analysis accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.94       788\n",
      "    positive       0.94      0.72      0.82       327\n",
      "\n",
      "    accuracy                           0.91      1115\n",
      "   macro avg       0.92      0.85      0.88      1115\n",
      "weighted avg       0.91      0.91      0.90      1115\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.8804\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.86      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.60      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89       200\n",
      "     neutral       0.96      0.91      0.93       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.86      0.27      0.41        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.70      0.74       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.66      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 310.4962863922119 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.00041932050371542575\n",
      "Samples above threshold: 77\n",
      "Acquired samples: 77\n",
      "Sampling duration: 16.486647844314575 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.497, Accuracy: 0.8266, F1 Micro: 0.9018, F1 Macro: 0.8975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3751, Accuracy: 0.9243, F1 Micro: 0.954, F1 Macro: 0.95\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2634, Accuracy: 0.9438, F1 Micro: 0.9656, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2045, Accuracy: 0.9517, F1 Micro: 0.9702, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1695, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1442, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9739\n",
      "Epoch 7/10, Train Loss: 0.124, Accuracy: 0.9587, F1 Micro: 0.9745, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1061, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0923, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0753, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.92      0.94      0.93       317\n",
      "       linen       0.95      0.95      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4311, Accuracy: 0.8456, F1 Micro: 0.8456, F1 Macro: 0.7819\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2717, Accuracy: 0.891, F1 Micro: 0.891, F1 Macro: 0.8631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1765, Accuracy: 0.8974, F1 Micro: 0.8974, F1 Macro: 0.8652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1231, Accuracy: 0.9019, F1 Micro: 0.9019, F1 Macro: 0.8755\n",
      "Epoch 5/10, Train Loss: 0.0946, Accuracy: 0.901, F1 Micro: 0.901, F1 Macro: 0.8765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0731, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8798\n",
      "Epoch 7/10, Train Loss: 0.0585, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0387, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8856\n",
      "Epoch 9/10, Train Loss: 0.0247, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8761\n",
      "Epoch 10/10, Train Loss: 0.035, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8804\n",
      "\n",
      "Sentiment analysis accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8856\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.99      0.94       777\n",
      "    positive       0.96      0.73      0.83       324\n",
      "\n",
      "    accuracy                           0.91      1101\n",
      "   macro avg       0.93      0.86      0.89      1101\n",
      "weighted avg       0.92      0.91      0.91      1101\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9581, F1 Micro: 0.9581, F1 Macro: 0.8743\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.83      0.71      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.84      0.88       200\n",
      "     neutral       0.92      0.94      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.90      0.87       162\n",
      "     neutral       0.95      0.95      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.77      0.81       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.81      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 323.4050533771515 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.0002976429415866735\n",
      "Samples above threshold: 70\n",
      "Acquired samples: 70\n",
      "Sampling duration: 14.703339338302612 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5023, Accuracy: 0.8368, F1 Micro: 0.9058, F1 Macro: 0.8986\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3692, Accuracy: 0.9257, F1 Micro: 0.9548, F1 Macro: 0.951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2541, Accuracy: 0.9406, F1 Micro: 0.9636, F1 Macro: 0.9608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.195, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1635, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.136, Accuracy: 0.9604, F1 Micro: 0.9756, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1156, Accuracy: 0.9639, F1 Micro: 0.9775, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1011, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.085, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9759\n",
      "Epoch 10/10, Train Loss: 0.0724, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.95      0.97      0.96       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4198, Accuracy: 0.8584, F1 Micro: 0.8584, F1 Macro: 0.8077\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2156, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.8693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1808, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1184, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.883\n",
      "Epoch 5/10, Train Loss: 0.0709, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0592, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0603, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8864\n",
      "Epoch 8/10, Train Loss: 0.0477, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8843\n",
      "Epoch 9/10, Train Loss: 0.0376, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.026, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8862\n",
      "\n",
      "Sentiment analysis accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8862\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.99      0.94       780\n",
      "    positive       0.96      0.73      0.83       322\n",
      "\n",
      "    accuracy                           0.91      1102\n",
      "   macro avg       0.93      0.86      0.89      1102\n",
      "weighted avg       0.92      0.91      0.91      1102\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.8803\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.97      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.86      0.87       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.89       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.90      0.93      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.75      0.80       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.89      0.85        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.95      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.81      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 329.5176331996918 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.00020649788202717912\n",
      "Samples above threshold: 63\n",
      "Acquired samples: 52\n",
      "Sampling duration: 13.181721925735474 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4962, Accuracy: 0.838, F1 Micro: 0.9075, F1 Macro: 0.9031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3483, Accuracy: 0.9267, F1 Micro: 0.9554, F1 Macro: 0.9514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2412, Accuracy: 0.9472, F1 Micro: 0.9676, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1884, Accuracy: 0.9545, F1 Micro: 0.9719, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1611, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1332, Accuracy: 0.9606, F1 Micro: 0.9757, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.114, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9755\n",
      "Epoch 8/10, Train Loss: 0.1005, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Epoch 9/10, Train Loss: 0.0815, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.975\n",
      "Epoch 10/10, Train Loss: 0.0691, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.99      0.98       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.95      0.91      0.93       317\n",
      "       linen       0.93      0.98      0.95       392\n",
      "     service       0.98      0.95      0.96       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4128, Accuracy: 0.8526, F1 Micro: 0.8526, F1 Macro: 0.7897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2606, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.86\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1703, Accuracy: 0.9075, F1 Micro: 0.9075, F1 Macro: 0.8805\n",
      "Epoch 4/10, Train Loss: 0.1307, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0951, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8831\n",
      "Epoch 6/10, Train Loss: 0.0752, Accuracy: 0.9029, F1 Micro: 0.9029, F1 Macro: 0.8745\n",
      "Epoch 7/10, Train Loss: 0.0631, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0502, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.886\n",
      "Epoch 9/10, Train Loss: 0.0431, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8777\n",
      "Epoch 10/10, Train Loss: 0.0353, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8834\n",
      "\n",
      "Sentiment analysis accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       776\n",
      "    positive       0.92      0.76      0.83       316\n",
      "\n",
      "    accuracy                           0.91      1092\n",
      "   macro avg       0.91      0.87      0.89      1092\n",
      "weighted avg       0.91      0.91      0.91      1092\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.958, F1 Micro: 0.958, F1 Macro: 0.8635\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.84      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.85      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.78      0.84        78\n",
      "     neutral       0.96      0.99      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.76      0.83       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.90      0.88       200\n",
      "     neutral       0.95      0.91      0.93       315\n",
      "    positive       0.83      0.95      0.88        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.84      0.88       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.92      0.77      0.83       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.87      0.83        85\n",
      "     neutral       0.98      0.95      0.96       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.89      0.93      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 324.64432978630066 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.00023844462702982128\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 58\n",
      "Sampling duration: 11.835315465927124 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4932, Accuracy: 0.847, F1 Micro: 0.9116, F1 Macro: 0.9052\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3328, Accuracy: 0.9295, F1 Micro: 0.9569, F1 Macro: 0.9529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2334, Accuracy: 0.9465, F1 Micro: 0.9672, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1875, Accuracy: 0.953, F1 Micro: 0.971, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1544, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1315, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1097, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0922, Accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0778, Accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0688, Accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.977\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.92      0.96      0.94       317\n",
      "       linen       0.95      0.97      0.96       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.402, Accuracy: 0.8726, F1 Micro: 0.8726, F1 Macro: 0.8291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2311, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1523, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8863\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1068, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.8993\n",
      "Epoch 5/10, Train Loss: 0.0811, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.8957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0541, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.8996\n",
      "Epoch 7/10, Train Loss: 0.0462, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.8959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.03, Accuracy: 0.9274, F1 Micro: 0.9274, F1 Macro: 0.9049\n",
      "Epoch 9/10, Train Loss: 0.0219, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.8962\n",
      "Epoch 10/10, Train Loss: 0.0203, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.8973\n",
      "\n",
      "Sentiment analysis accuracy: 0.9274, F1 Micro: 0.9274, F1 Macro: 0.9049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       772\n",
      "    positive       0.95      0.78      0.86       303\n",
      "\n",
      "    accuracy                           0.93      1075\n",
      "   macro avg       0.94      0.88      0.90      1075\n",
      "weighted avg       0.93      0.93      0.93      1075\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9609, F1 Micro: 0.9609, F1 Macro: 0.8726\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.85      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.77      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.72      0.62      0.65       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.85      0.90       200\n",
      "     neutral       0.92      0.96      0.94       315\n",
      "    positive       0.90      0.98      0.94        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89       162\n",
      "     neutral       0.95      0.97      0.96       387\n",
      "    positive       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.79      0.83       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.89      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.81      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 342.24250316619873 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.00010671482741599907\n",
      "Samples above threshold: 52\n",
      "Acquired samples: 52\n",
      "Sampling duration: 10.74107575416565 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4897, Accuracy: 0.8512, F1 Micro: 0.9141, F1 Macro: 0.9084\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.325, Accuracy: 0.9328, F1 Micro: 0.9589, F1 Macro: 0.9559\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2405, Accuracy: 0.9457, F1 Micro: 0.9667, F1 Macro: 0.9639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.182, Accuracy: 0.9542, F1 Micro: 0.9718, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1534, Accuracy: 0.9587, F1 Micro: 0.9744, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1275, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9748\n",
      "Epoch 7/10, Train Loss: 0.1072, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "Epoch 8/10, Train Loss: 0.0895, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0776, Accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.9771\n",
      "Epoch 10/10, Train Loss: 0.0681, Accuracy: 0.9661, F1 Micro: 0.9789, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.94      0.97      0.96       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3952, Accuracy: 0.8705, F1 Micro: 0.8705, F1 Macro: 0.8244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2116, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1607, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1021, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8873\n",
      "Epoch 5/10, Train Loss: 0.086, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0535, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0495, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0313, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8908\n",
      "Epoch 9/10, Train Loss: 0.0287, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8794\n",
      "Epoch 10/10, Train Loss: 0.0294, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8857\n",
      "\n",
      "Sentiment analysis accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8908\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       777\n",
      "    positive       0.94      0.75      0.84       312\n",
      "\n",
      "    accuracy                           0.92      1089\n",
      "   macro avg       0.93      0.87      0.89      1089\n",
      "weighted avg       0.92      0.92      0.91      1089\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8705\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.86      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.62      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       1.00      0.36      0.53        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.94      0.73      0.79       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.69      0.74        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 346.6478111743927 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.00010616714280331507\n",
      "Samples above threshold: 47\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.527951002120972 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4811, Accuracy: 0.8552, F1 Micro: 0.9164, F1 Macro: 0.9115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3285, Accuracy: 0.9314, F1 Micro: 0.958, F1 Macro: 0.9539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2308, Accuracy: 0.9484, F1 Micro: 0.9684, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1804, Accuracy: 0.9568, F1 Micro: 0.9733, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1441, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1213, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1022, Accuracy: 0.9616, F1 Micro: 0.9761, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0886, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0739, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0632, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.92      0.95      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3762, Accuracy: 0.8741, F1 Micro: 0.8741, F1 Macro: 0.8399\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2132, Accuracy: 0.8934, F1 Micro: 0.8934, F1 Macro: 0.8564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1371, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.8776\n",
      "Epoch 4/10, Train Loss: 0.091, Accuracy: 0.9007, F1 Micro: 0.9007, F1 Macro: 0.8736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0903, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0515, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8902\n",
      "Epoch 7/10, Train Loss: 0.0319, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0299, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0246, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0212, Accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.8934\n",
      "\n",
      "Sentiment analysis accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.8934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       774\n",
      "    positive       0.95      0.75      0.84       314\n",
      "\n",
      "    accuracy                           0.92      1088\n",
      "   macro avg       0.93      0.87      0.89      1088\n",
      "weighted avg       0.92      0.92      0.92      1088\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8782\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.85      0.89       200\n",
      "     neutral       0.92      0.95      0.94       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.93      0.75      0.80       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.89      0.87        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.81      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 362.82831859588623 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 7.408874807879329e-05\n",
      "Samples above threshold: 42\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.66059398651123 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.478, Accuracy: 0.8592, F1 Micro: 0.9181, F1 Macro: 0.9124\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3144, Accuracy: 0.9314, F1 Micro: 0.9583, F1 Macro: 0.9557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2261, Accuracy: 0.9488, F1 Micro: 0.9685, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1718, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1453, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1225, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1016, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0831, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0714, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0597, Accuracy: 0.9668, F1 Micro: 0.9794, F1 Macro: 0.9775\n",
      "\n",
      "Aspect detection accuracy: 0.9668, F1 Micro: 0.9794, F1 Macro: 0.9775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.93      0.96      0.94       317\n",
      "       linen       0.95      0.95      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3668, Accuracy: 0.861, F1 Micro: 0.861, F1 Macro: 0.8202\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2124, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1435, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1146, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.8963\n",
      "Epoch 5/10, Train Loss: 0.0681, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8826\n",
      "Epoch 6/10, Train Loss: 0.0673, Accuracy: 0.9162, F1 Micro: 0.9162, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0468, Accuracy: 0.9236, F1 Micro: 0.9236, F1 Macro: 0.8998\n",
      "Epoch 8/10, Train Loss: 0.0417, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8871\n",
      "Epoch 9/10, Train Loss: 0.0381, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.8931\n",
      "Epoch 10/10, Train Loss: 0.045, Accuracy: 0.9199, F1 Micro: 0.9199, F1 Macro: 0.8955\n",
      "\n",
      "Sentiment analysis accuracy: 0.9236, F1 Micro: 0.9236, F1 Macro: 0.8998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       781\n",
      "    positive       0.94      0.78      0.85       305\n",
      "\n",
      "    accuracy                           0.92      1086\n",
      "   macro avg       0.93      0.88      0.90      1086\n",
      "weighted avg       0.92      0.92      0.92      1086\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9613, F1 Micro: 0.9613, F1 Macro: 0.8936\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.92      0.93        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.85      0.80      0.83       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.78      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.66      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.64      0.72       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.86      0.90       200\n",
      "     neutral       0.93      0.96      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.90      0.88       162\n",
      "     neutral       0.95      0.96      0.95       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.78      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.85      0.86       571\n",
      "weighted avg       0.98      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 357.64377665519714 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 5.803832391393371e-05\n",
      "Samples above threshold: 37\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.79259181022644 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4758, Accuracy: 0.8597, F1 Micro: 0.9184, F1 Macro: 0.9135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3068, Accuracy: 0.9314, F1 Micro: 0.9583, F1 Macro: 0.9553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2195, Accuracy: 0.947, F1 Micro: 0.9676, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1698, Accuracy: 0.9517, F1 Micro: 0.9703, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1374, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1189, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0995, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9763\n",
      "Epoch 8/10, Train Loss: 0.0832, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9751\n",
      "Epoch 9/10, Train Loss: 0.0696, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0597, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.93      0.98      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3777, Accuracy: 0.854, F1 Micro: 0.854, F1 Macro: 0.7915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.211, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1525, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1084, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0943, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0554, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0439, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.8958\n",
      "Epoch 8/10, Train Loss: 0.0408, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8873\n",
      "Epoch 9/10, Train Loss: 0.0189, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8896\n",
      "Epoch 10/10, Train Loss: 0.0166, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8761\n",
      "\n",
      "Sentiment analysis accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.8958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.99      0.95       783\n",
      "    positive       0.96      0.76      0.84       313\n",
      "\n",
      "    accuracy                           0.92      1096\n",
      "   macro avg       0.93      0.87      0.90      1096\n",
      "weighted avg       0.92      0.92      0.92      1096\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.8796\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.86      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.82      0.69      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.60      0.66       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.90       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87       162\n",
      "     neutral       0.93      0.98      0.95       387\n",
      "    positive       0.88      0.32      0.47        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.72      0.76       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.69      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 362.8411240577698 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 4.187909507891163e-05\n",
      "Samples above threshold: 32\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.873027563095093 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.472, Accuracy: 0.871, F1 Micro: 0.924, F1 Macro: 0.9172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2981, Accuracy: 0.9323, F1 Micro: 0.9587, F1 Macro: 0.9557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2055, Accuracy: 0.9526, F1 Micro: 0.9708, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1668, Accuracy: 0.9564, F1 Micro: 0.9731, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1337, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1095, Accuracy: 0.962, F1 Micro: 0.9765, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0991, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0798, Accuracy: 0.9641, F1 Micro: 0.9776, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0657, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9765\n",
      "Epoch 10/10, Train Loss: 0.0573, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.94      0.97      0.96       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3797, Accuracy: 0.8614, F1 Micro: 0.8614, F1 Macro: 0.8247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1978, Accuracy: 0.8895, F1 Micro: 0.8895, F1 Macro: 0.8557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1455, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8867\n",
      "Epoch 4/10, Train Loss: 0.1058, Accuracy: 0.9085, F1 Micro: 0.9085, F1 Macro: 0.8796\n",
      "Epoch 5/10, Train Loss: 0.0924, Accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0734, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0512, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8899\n",
      "Epoch 8/10, Train Loss: 0.0362, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8841\n",
      "Epoch 9/10, Train Loss: 0.0266, Accuracy: 0.9085, F1 Micro: 0.9085, F1 Macro: 0.8812\n",
      "Epoch 10/10, Train Loss: 0.0321, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8812\n",
      "\n",
      "Sentiment analysis accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.99      0.94       784\n",
      "    positive       0.96      0.74      0.84       320\n",
      "\n",
      "    accuracy                           0.92      1104\n",
      "   macro avg       0.93      0.86      0.89      1104\n",
      "weighted avg       0.92      0.92      0.91      1104\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.8806\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.86      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.78      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.79      0.83       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.88      0.87        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.94      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.85      0.86       571\n",
      "weighted avg       0.98      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 361.49430871009827 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 4.344511035014875e-05\n",
      "Samples above threshold: 29\n",
      "Acquired samples: 50\n",
      "Sampling duration: 6.368564605712891 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4637, Accuracy: 0.8703, F1 Micro: 0.9242, F1 Macro: 0.9191\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2983, Accuracy: 0.9326, F1 Micro: 0.9592, F1 Macro: 0.9564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2123, Accuracy: 0.9498, F1 Micro: 0.9693, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1672, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1325, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1106, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0972, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0801, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0672, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0568, Accuracy: 0.9646, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3649, Accuracy: 0.8493, F1 Micro: 0.8493, F1 Macro: 0.7916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2214, Accuracy: 0.8987, F1 Micro: 0.8987, F1 Macro: 0.871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1316, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1081, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0684, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8824\n",
      "Epoch 6/10, Train Loss: 0.071, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8747\n",
      "Epoch 7/10, Train Loss: 0.0399, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8722\n",
      "Epoch 8/10, Train Loss: 0.0381, Accuracy: 0.9022, F1 Micro: 0.9022, F1 Macro: 0.8751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0244, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8842\n",
      "Epoch 10/10, Train Loss: 0.0285, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8799\n",
      "\n",
      "Sentiment analysis accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       781\n",
      "    positive       0.95      0.74      0.83       334\n",
      "\n",
      "    accuracy                           0.91      1115\n",
      "   macro avg       0.92      0.86      0.88      1115\n",
      "weighted avg       0.91      0.91      0.91      1115\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.891\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.82      0.78      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.68      0.74       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.77      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.88      0.87        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.96      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 371.5758647918701 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 3.4718441384029575e-05\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 50\n",
      "Sampling duration: 5.578221559524536 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4574, Accuracy: 0.8755, F1 Micro: 0.9266, F1 Macro: 0.9207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2872, Accuracy: 0.9368, F1 Micro: 0.9615, F1 Macro: 0.9593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2017, Accuracy: 0.9493, F1 Micro: 0.9688, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1615, Accuracy: 0.9531, F1 Micro: 0.9712, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1323, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9747\n",
      "Epoch 6/10, Train Loss: 0.1135, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0918, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9766\n",
      "Epoch 8/10, Train Loss: 0.0765, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9758\n",
      "Epoch 9/10, Train Loss: 0.0667, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0536, Accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.977\n",
      "\n",
      "Aspect detection accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.97      0.96       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3609, Accuracy: 0.8522, F1 Micro: 0.8522, F1 Macro: 0.8232\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2009, Accuracy: 0.8914, F1 Micro: 0.8914, F1 Macro: 0.8529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1397, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1127, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.888\n",
      "Epoch 5/10, Train Loss: 0.0798, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0559, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.8918\n",
      "Epoch 7/10, Train Loss: 0.0444, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.883\n",
      "Epoch 8/10, Train Loss: 0.0351, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8901\n",
      "Epoch 9/10, Train Loss: 0.0255, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8854\n",
      "Epoch 10/10, Train Loss: 0.0195, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8902\n",
      "\n",
      "Sentiment analysis accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.8918\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       783\n",
      "    positive       0.94      0.76      0.84       313\n",
      "\n",
      "    accuracy                           0.92      1096\n",
      "   macro avg       0.92      0.87      0.89      1096\n",
      "weighted avg       0.92      0.92      0.91      1096\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9604, F1 Micro: 0.9604, F1 Macro: 0.8796\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.82      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.83      0.71      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       162\n",
      "     neutral       0.94      0.98      0.96       387\n",
      "    positive       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.94      0.75      0.80       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.84      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 368.60077953338623 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 2.4834541363816243e-05\n",
      "Samples above threshold: 19\n",
      "Acquired samples: 50\n",
      "Sampling duration: 4.559148788452148 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4505, Accuracy: 0.8788, F1 Micro: 0.9285, F1 Macro: 0.9227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2749, Accuracy: 0.9325, F1 Micro: 0.959, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1916, Accuracy: 0.9517, F1 Micro: 0.9703, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1572, Accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1239, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9735\n",
      "Epoch 6/10, Train Loss: 0.1016, Accuracy: 0.9599, F1 Micro: 0.9751, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0838, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0735, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0622, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0504, Accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.9771\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3466, Accuracy: 0.8705, F1 Micro: 0.8705, F1 Macro: 0.8355\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2177, Accuracy: 0.8877, F1 Micro: 0.8877, F1 Macro: 0.8607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1282, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8831\n",
      "Epoch 4/10, Train Loss: 0.0962, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0635, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8828\n",
      "Epoch 6/10, Train Loss: 0.059, Accuracy: 0.9085, F1 Micro: 0.9085, F1 Macro: 0.879\n",
      "Epoch 7/10, Train Loss: 0.043, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0376, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0276, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8883\n",
      "Epoch 10/10, Train Loss: 0.0265, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8859\n",
      "\n",
      "Sentiment analysis accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       786\n",
      "    positive       0.93      0.75      0.83       318\n",
      "\n",
      "    accuracy                           0.91      1104\n",
      "   macro avg       0.92      0.87      0.89      1104\n",
      "weighted avg       0.92      0.91      0.91      1104\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8759\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.95      0.95       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.83      0.74      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.54      0.32      0.40        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.78      0.71      0.73       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 379.7661192417145 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 1.955300831468776e-05\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 50\n",
      "Sampling duration: 3.693058967590332 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4468, Accuracy: 0.8837, F1 Micro: 0.931, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2669, Accuracy: 0.9363, F1 Micro: 0.9612, F1 Macro: 0.9589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1924, Accuracy: 0.9531, F1 Micro: 0.9712, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1496, Accuracy: 0.954, F1 Micro: 0.9717, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1255, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1025, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0853, Accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9771\n",
      "Epoch 8/10, Train Loss: 0.0704, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0603, Accuracy: 0.9667, F1 Micro: 0.9792, F1 Macro: 0.9771\n",
      "Epoch 10/10, Train Loss: 0.0518, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9667, F1 Micro: 0.9792, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.97      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.98      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3427, Accuracy: 0.8418, F1 Micro: 0.8418, F1 Macro: 0.7749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1873, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1276, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0834, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8914\n",
      "Epoch 5/10, Train Loss: 0.0738, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8889\n",
      "Epoch 6/10, Train Loss: 0.0522, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8858\n",
      "Epoch 7/10, Train Loss: 0.0371, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8869\n",
      "Epoch 8/10, Train Loss: 0.036, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8834\n",
      "Epoch 9/10, Train Loss: 0.029, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0337, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8917\n",
      "\n",
      "Sentiment analysis accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8917\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       785\n",
      "    positive       0.95      0.75      0.84       334\n",
      "\n",
      "    accuracy                           0.92      1119\n",
      "   macro avg       0.93      0.87      0.89      1119\n",
      "weighted avg       0.92      0.92      0.91      1119\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9609, F1 Micro: 0.9609, F1 Macro: 0.8746\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.92      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.97      0.98      0.97       496\n",
      "    positive       0.82      0.82      0.82        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.65      0.68       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.75      0.79       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.90      0.97      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 381.0326290130615 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 1.948276076291222e-05\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 50\n",
      "Sampling duration: 2.7910666465759277 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.437, Accuracy: 0.8769, F1 Micro: 0.9275, F1 Macro: 0.9221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2612, Accuracy: 0.9356, F1 Micro: 0.9608, F1 Macro: 0.9586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1871, Accuracy: 0.9488, F1 Micro: 0.9687, F1 Macro: 0.9664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1505, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1234, Accuracy: 0.9609, F1 Micro: 0.9757, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1011, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0842, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9769\n",
      "Epoch 8/10, Train Loss: 0.0706, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9763\n",
      "Epoch 9/10, Train Loss: 0.0556, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0503, Accuracy: 0.9677, F1 Micro: 0.9799, F1 Macro: 0.9782\n",
      "\n",
      "Aspect detection accuracy: 0.9677, F1 Micro: 0.9799, F1 Macro: 0.9782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.96      0.94      0.95       317\n",
      "       linen       0.95      0.97      0.96       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.98      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3576, Accuracy: 0.8649, F1 Micro: 0.8649, F1 Macro: 0.8166\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2205, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.8761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1531, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8804\n",
      "Epoch 4/10, Train Loss: 0.0887, Accuracy: 0.9075, F1 Micro: 0.9075, F1 Macro: 0.8788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0665, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.055, Accuracy: 0.9166, F1 Micro: 0.9166, F1 Macro: 0.8912\n",
      "Epoch 7/10, Train Loss: 0.026, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8806\n",
      "Epoch 8/10, Train Loss: 0.0423, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8757\n",
      "Epoch 9/10, Train Loss: 0.026, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8848\n",
      "Epoch 10/10, Train Loss: 0.0178, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8875\n",
      "\n",
      "Sentiment analysis accuracy: 0.9166, F1 Micro: 0.9166, F1 Macro: 0.8912\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       790\n",
      "    positive       0.93      0.76      0.84       313\n",
      "\n",
      "    accuracy                           0.92      1103\n",
      "   macro avg       0.92      0.87      0.89      1103\n",
      "weighted avg       0.92      0.92      0.91      1103\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9616, F1 Micro: 0.9616, F1 Macro: 0.8915\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.80      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.66      0.73       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91       200\n",
      "     neutral       0.96      0.94      0.95       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.90      0.94      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.77      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 391.9260573387146 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 8.852054634189699e-06\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 36\n",
      "Sampling duration: 1.8617908954620361 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4366, Accuracy: 0.8863, F1 Micro: 0.9326, F1 Macro: 0.9271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2622, Accuracy: 0.934, F1 Micro: 0.9597, F1 Macro: 0.9561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1829, Accuracy: 0.9502, F1 Micro: 0.9694, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1437, Accuracy: 0.9535, F1 Micro: 0.9714, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1184, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.095, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9743\n",
      "Epoch 7/10, Train Loss: 0.0803, Accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0679, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9759\n",
      "Epoch 9/10, Train Loss: 0.0588, Accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0492, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.95      0.94       317\n",
      "       linen       0.95      0.95      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3476, Accuracy: 0.85, F1 Micro: 0.85, F1 Macro: 0.7837\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1824, Accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1203, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0982, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.8953\n",
      "Epoch 5/10, Train Loss: 0.0686, Accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.8915\n",
      "Epoch 6/10, Train Loss: 0.0562, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8899\n",
      "Epoch 7/10, Train Loss: 0.0456, Accuracy: 0.9131, F1 Micro: 0.9131, F1 Macro: 0.8871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0318, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.8965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.023, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.8963\n",
      "Epoch 10/10, Train Loss: 0.0225, Accuracy: 0.9131, F1 Micro: 0.9131, F1 Macro: 0.8879\n",
      "\n",
      "Sentiment analysis accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.8963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       778\n",
      "    positive       0.93      0.77      0.85       315\n",
      "\n",
      "    accuracy                           0.92      1093\n",
      "   macro avg       0.92      0.88      0.90      1093\n",
      "weighted avg       0.92      0.92      0.92      1093\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.8607\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.78      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.75      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.58      0.59       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90       200\n",
      "     neutral       0.94      0.95      0.94       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.87       162\n",
      "     neutral       0.95      0.95      0.95       387\n",
      "    positive       0.71      0.55      0.62        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.81      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 391.1049747467041 s\n",
      "Total runtime: 8522.830321788788 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e327e6bb",
   "metadata": {
    "papermill": {
     "duration": 0.180113,
     "end_time": "2025-03-30T10:00:56.300440",
     "exception": false,
     "start_time": "2025-03-30T10:00:56.120327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978ac219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6072, Accuracy: 0.7955, F1 Micro: 0.8818, F1 Macro: 0.8546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4916, Accuracy: 0.8016, F1 Micro: 0.8877, F1 Macro: 0.8774\n",
      "Epoch 3/10, Train Loss: 0.453, Accuracy: 0.8024, F1 Micro: 0.8857, F1 Macro: 0.8609\n",
      "Epoch 4/10, Train Loss: 0.4515, Accuracy: 0.8021, F1 Micro: 0.8849, F1 Macro: 0.8543\n",
      "Epoch 5/10, Train Loss: 0.417, Accuracy: 0.8047, F1 Micro: 0.8868, F1 Macro: 0.862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4402, Accuracy: 0.8092, F1 Micro: 0.8902, F1 Macro: 0.874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3799, Accuracy: 0.8141, F1 Micro: 0.8937, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3851, Accuracy: 0.8252, F1 Micro: 0.899, F1 Macro: 0.8873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3532, Accuracy: 0.8361, F1 Micro: 0.9044, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3254, Accuracy: 0.8502, F1 Micro: 0.9121, F1 Macro: 0.9018\n",
      "\n",
      "Aspect detection accuracy: 0.8502, F1 Micro: 0.9121, F1 Macro: 0.9018\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.86      1.00      0.93       462\n",
      "   air_panas       0.90      0.99      0.94       480\n",
      "         bau       0.87      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.77      0.66      0.71       317\n",
      "       linen       0.74      0.98      0.84       392\n",
      "     service       0.82      0.98      0.89       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.89      1.00      0.94       498\n",
      "\n",
      "   micro avg       0.86      0.97      0.91      4614\n",
      "   macro avg       0.85      0.96      0.90      4614\n",
      "weighted avg       0.86      0.97      0.91      4614\n",
      " samples avg       0.86      0.97      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5988, Accuracy: 0.6204, F1 Micro: 0.6204, F1 Macro: 0.3829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5281, Accuracy: 0.6204, F1 Micro: 0.6204, F1 Macro: 0.3829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4888, Accuracy: 0.6259, F1 Micro: 0.6259, F1 Macro: 0.4027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3707, Accuracy: 0.6861, F1 Micro: 0.6861, F1 Macro: 0.5752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3492, Accuracy: 0.7336, F1 Micro: 0.7336, F1 Macro: 0.6917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2739, Accuracy: 0.7372, F1 Micro: 0.7372, F1 Macro: 0.7005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3739, Accuracy: 0.7409, F1 Micro: 0.7409, F1 Macro: 0.7103\n",
      "Epoch 8/10, Train Loss: 0.2974, Accuracy: 0.7281, F1 Micro: 0.7281, F1 Macro: 0.6718\n",
      "Epoch 9/10, Train Loss: 0.18, Accuracy: 0.7372, F1 Micro: 0.7372, F1 Macro: 0.703\n",
      "Epoch 10/10, Train Loss: 0.1429, Accuracy: 0.7281, F1 Micro: 0.7281, F1 Macro: 0.6706\n",
      "\n",
      "Sentiment analysis accuracy: 0.7409, F1 Micro: 0.7409, F1 Macro: 0.7103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.86      0.80       340\n",
      "    positive       0.70      0.55      0.62       208\n",
      "\n",
      "    accuracy                           0.74       548\n",
      "   macro avg       0.73      0.70      0.71       548\n",
      "weighted avg       0.74      0.74      0.73       548\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8385, F1 Micro: 0.8385, F1 Macro: 0.4347\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.36      0.51        97\n",
      "     neutral       0.87      1.00      0.93       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.58      0.45      0.48       571\n",
      "weighted avg       0.84      0.86      0.83       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.43      0.56        86\n",
      "     neutral       0.90      0.99      0.94       475\n",
      "    positive       0.20      0.10      0.13        10\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.63      0.51      0.54       571\n",
      "weighted avg       0.87      0.89      0.87       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.12      0.20        78\n",
      "     neutral       0.87      1.00      0.93       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.59      0.37      0.38       571\n",
      "weighted avg       0.87      0.87      0.83       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.65      0.65       200\n",
      "     neutral       0.77      0.66      0.71       315\n",
      "    positive       0.26      0.48      0.34        56\n",
      "\n",
      "    accuracy                           0.64       571\n",
      "   macro avg       0.56      0.60      0.57       571\n",
      "weighted avg       0.68      0.64      0.65       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.30      0.44       162\n",
      "     neutral       0.74      0.98      0.84       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.75       571\n",
      "   macro avg       0.53      0.43      0.43       571\n",
      "weighted avg       0.74      0.75      0.70       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.18      0.29        85\n",
      "     neutral       0.81      0.98      0.89       418\n",
      "    positive       0.60      0.44      0.51        68\n",
      "\n",
      "    accuracy                           0.80       571\n",
      "   macro avg       0.77      0.53      0.56       571\n",
      "weighted avg       0.80      0.80      0.76       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.24      0.39        74\n",
      "     neutral       0.89      1.00      0.94       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.61      0.41      0.44       571\n",
      "weighted avg       0.90      0.89      0.87       571\n",
      "\n",
      "Total train time: 77.25872898101807 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0011882658582180738\n",
      "Samples above threshold: 215\n",
      "Acquired samples: 215\n",
      "Sampling duration: 34.78522539138794 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5369, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4557, Accuracy: 0.8064, F1 Micro: 0.8917, F1 Macro: 0.8863\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4405, Accuracy: 0.8247, F1 Micro: 0.9007, F1 Macro: 0.8955\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3935, Accuracy: 0.8448, F1 Micro: 0.9101, F1 Macro: 0.9037\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3461, Accuracy: 0.8606, F1 Micro: 0.918, F1 Macro: 0.9118\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3066, Accuracy: 0.8816, F1 Micro: 0.9297, F1 Macro: 0.9243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2661, Accuracy: 0.9003, F1 Micro: 0.9403, F1 Macro: 0.9362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2377, Accuracy: 0.9099, F1 Micro: 0.9457, F1 Macro: 0.9419\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2066, Accuracy: 0.9149, F1 Micro: 0.9487, F1 Macro: 0.9451\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1778, Accuracy: 0.9205, F1 Micro: 0.9517, F1 Macro: 0.9482\n",
      "\n",
      "Aspect detection accuracy: 0.9205, F1 Micro: 0.9517, F1 Macro: 0.9482\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.96      0.99      0.97       462\n",
      "   air_panas       0.93      0.99      0.96       480\n",
      "         bau       0.95      0.98      0.96       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.90      0.84      0.87       317\n",
      "       linen       0.87      0.96      0.91       392\n",
      "     service       0.95      0.98      0.96       423\n",
      "sunrise_meal       0.95      1.00      0.97       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.98      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.93      0.98      0.95      4614\n",
      "   macro avg       0.93      0.97      0.95      4614\n",
      "weighted avg       0.93      0.98      0.95      4614\n",
      " samples avg       0.93      0.98      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5256, Accuracy: 0.7102, F1 Micro: 0.7102, F1 Macro: 0.4153\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4567, Accuracy: 0.7989, F1 Micro: 0.7989, F1 Macro: 0.7462\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3803, Accuracy: 0.8136, F1 Micro: 0.8136, F1 Macro: 0.7258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3387, Accuracy: 0.8341, F1 Micro: 0.8341, F1 Macro: 0.7795\n",
      "Epoch 5/10, Train Loss: 0.2474, Accuracy: 0.8295, F1 Micro: 0.8295, F1 Macro: 0.7639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1844, Accuracy: 0.8375, F1 Micro: 0.8375, F1 Macro: 0.7782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2114, Accuracy: 0.8534, F1 Micro: 0.8534, F1 Macro: 0.8054\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1393, Accuracy: 0.8557, F1 Micro: 0.8557, F1 Macro: 0.8107\n",
      "Epoch 9/10, Train Loss: 0.0898, Accuracy: 0.8534, F1 Micro: 0.8534, F1 Macro: 0.8012\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0647, Accuracy: 0.867, F1 Micro: 0.867, F1 Macro: 0.8251\n",
      "\n",
      "Sentiment analysis accuracy: 0.867, F1 Micro: 0.867, F1 Macro: 0.8251\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.96      0.91       625\n",
      "    positive       0.86      0.65      0.74       255\n",
      "\n",
      "    accuracy                           0.87       880\n",
      "   macro avg       0.86      0.80      0.83       880\n",
      "weighted avg       0.87      0.87      0.86       880\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.6718\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.79      0.85        97\n",
      "     neutral       0.96      0.99      0.97       459\n",
      "    positive       0.75      0.60      0.67        15\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.87      0.79      0.83       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        86\n",
      "     neutral       0.93      0.99      0.96       475\n",
      "    positive       0.60      0.30      0.40        10\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.81      0.63      0.70       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.69      0.76        78\n",
      "     neutral       0.95      0.98      0.96       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.57       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.80      0.81       200\n",
      "     neutral       0.90      0.84      0.87       315\n",
      "    positive       0.65      0.93      0.76        56\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.79      0.86      0.81       571\n",
      "weighted avg       0.85      0.84      0.84       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.73      0.78       162\n",
      "     neutral       0.87      0.96      0.91       387\n",
      "    positive       0.43      0.14      0.21        22\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.72      0.61      0.63       571\n",
      "weighted avg       0.85      0.86      0.85       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.69      0.80        85\n",
      "     neutral       0.94      0.98      0.96       418\n",
      "    positive       0.86      0.94      0.90        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.87      0.89       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.24      0.38        29\n",
      "     neutral       0.95      1.00      0.97       525\n",
      "    positive       0.55      0.35      0.43        17\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.79      0.53      0.59       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.07      0.14        54\n",
      "     neutral       0.90      1.00      0.95       511\n",
      "    positive       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.97      0.41      0.46       571\n",
      "weighted avg       0.91      0.90      0.87       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.88      0.92        74\n",
      "     neutral       0.98      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.96      0.92       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 117.02248740196228 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.06521690264344215\n",
      "Samples above threshold: 193\n",
      "Acquired samples: 193\n",
      "Sampling duration: 46.69735097885132 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5407, Accuracy: 0.7991, F1 Micro: 0.8828, F1 Macro: 0.8453\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4851, Accuracy: 0.8295, F1 Micro: 0.9011, F1 Macro: 0.8894\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4165, Accuracy: 0.862, F1 Micro: 0.9181, F1 Macro: 0.9065\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3537, Accuracy: 0.8931, F1 Micro: 0.9356, F1 Macro: 0.9279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2886, Accuracy: 0.9125, F1 Micro: 0.9467, F1 Macro: 0.9404\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2435, Accuracy: 0.9288, F1 Micro: 0.9564, F1 Macro: 0.9521\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2062, Accuracy: 0.9372, F1 Micro: 0.9616, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.186, Accuracy: 0.9384, F1 Micro: 0.9622, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1513, Accuracy: 0.9396, F1 Micro: 0.963, F1 Macro: 0.9602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1419, Accuracy: 0.945, F1 Micro: 0.9663, F1 Macro: 0.9638\n",
      "\n",
      "Aspect detection accuracy: 0.945, F1 Micro: 0.9663, F1 Macro: 0.9638\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.98      0.98      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.87      0.94      0.90       317\n",
      "       linen       0.91      0.95      0.93       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.97      1.00      0.98       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.97      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6224, Accuracy: 0.7899, F1 Micro: 0.7899, F1 Macro: 0.6164\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4298, Accuracy: 0.8476, F1 Micro: 0.8476, F1 Macro: 0.7935\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3255, Accuracy: 0.8507, F1 Micro: 0.8507, F1 Macro: 0.7678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2084, Accuracy: 0.8702, F1 Micro: 0.8702, F1 Macro: 0.8285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1746, Accuracy: 0.8764, F1 Micro: 0.8764, F1 Macro: 0.8214\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1191, Accuracy: 0.8919, F1 Micro: 0.8919, F1 Macro: 0.8484\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0937, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.8467\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0475, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8535\n",
      "Epoch 9/10, Train Loss: 0.0415, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.854\n",
      "Epoch 10/10, Train Loss: 0.053, Accuracy: 0.8888, F1 Micro: 0.8888, F1 Macro: 0.8413\n",
      "\n",
      "Sentiment analysis accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93       716\n",
      "    positive       0.87      0.70      0.78       255\n",
      "\n",
      "    accuracy                           0.89       971\n",
      "   macro avg       0.88      0.83      0.85       971\n",
      "weighted avg       0.89      0.89      0.89       971\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.7857\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.88      0.91        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.68      0.87      0.76        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.91      0.89       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        86\n",
      "     neutral       0.98      0.98      0.98       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.75      0.77       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.73      0.79        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.74      0.81       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.60      0.04      0.08        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.49      0.35      0.34       571\n",
      "weighted avg       0.83      0.87      0.82       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.77      0.83       200\n",
      "     neutral       0.87      0.94      0.90       315\n",
      "    positive       0.84      0.91      0.87        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.87      0.87      0.87       571\n",
      "weighted avg       0.88      0.88      0.87       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84       162\n",
      "     neutral       0.91      0.95      0.93       387\n",
      "    positive       0.69      0.41      0.51        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.82      0.73      0.76       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.82      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.38      0.52        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.75      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.67      0.77        54\n",
      "     neutral       0.97      1.00      0.98       511\n",
      "    positive       0.75      0.50      0.60         6\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.88      0.72      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.98      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 149.40937280654907 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.010222884081304052\n",
      "Samples above threshold: 174\n",
      "Acquired samples: 174\n",
      "Sampling duration: 42.87765836715698 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5375, Accuracy: 0.7859, F1 Micro: 0.8703, F1 Macro: 0.8139\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4776, Accuracy: 0.8436, F1 Micro: 0.9094, F1 Macro: 0.9023\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3988, Accuracy: 0.8988, F1 Micro: 0.9385, F1 Macro: 0.9311\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3039, Accuracy: 0.9198, F1 Micro: 0.9514, F1 Macro: 0.9471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2505, Accuracy: 0.9354, F1 Micro: 0.9605, F1 Macro: 0.9571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.22, Accuracy: 0.9444, F1 Micro: 0.9659, F1 Macro: 0.9631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1886, Accuracy: 0.9443, F1 Micro: 0.9659, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1581, Accuracy: 0.9464, F1 Micro: 0.9671, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1408, Accuracy: 0.9498, F1 Micro: 0.9692, F1 Macro: 0.967\n",
      "Epoch 10/10, Train Loss: 0.1226, Accuracy: 0.9495, F1 Micro: 0.9689, F1 Macro: 0.9664\n",
      "\n",
      "Aspect detection accuracy: 0.9498, F1 Micro: 0.9692, F1 Macro: 0.967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.95      0.98      0.97       496\n",
      "     general       0.88      0.99      0.93       500\n",
      "  kebersihan       0.90      0.93      0.92       317\n",
      "       linen       0.89      0.97      0.93       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      4614\n",
      "   macro avg       0.95      0.98      0.97      4614\n",
      "weighted avg       0.96      0.99      0.97      4614\n",
      " samples avg       0.95      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6052, Accuracy: 0.8296, F1 Micro: 0.8296, F1 Macro: 0.7543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4141, Accuracy: 0.8671, F1 Micro: 0.8671, F1 Macro: 0.8049\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2814, Accuracy: 0.9037, F1 Micro: 0.9037, F1 Macro: 0.8671\n",
      "Epoch 4/10, Train Loss: 0.2026, Accuracy: 0.8935, F1 Micro: 0.8935, F1 Macro: 0.8584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1226, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1064, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.074, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0682, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0543, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8756\n",
      "Epoch 10/10, Train Loss: 0.0391, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8627\n",
      "\n",
      "Sentiment analysis accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       731\n",
      "    positive       0.90      0.73      0.81       255\n",
      "\n",
      "    accuracy                           0.91       986\n",
      "   macro avg       0.91      0.85      0.88       986\n",
      "weighted avg       0.91      0.91      0.91       986\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.8091\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.50      0.50      0.50        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.80      0.79      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.72      0.78        78\n",
      "     neutral       0.95      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.73      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.88      0.99      0.93       496\n",
      "    positive       0.71      0.07      0.13        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.53      0.36      0.35       571\n",
      "weighted avg       0.85      0.87      0.82       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.85       200\n",
      "     neutral       0.90      0.93      0.92       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.88      0.90      0.89       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83       162\n",
      "     neutral       0.89      0.97      0.93       387\n",
      "    positive       0.73      0.36      0.48        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.84      0.70      0.75       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.79      0.85        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.90      0.97      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.55      0.63        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.75      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.94      0.97      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.95        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.87      0.87      0.87       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 164.27524256706238 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0014707521768286829\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 156\n",
      "Sampling duration: 37.6527943611145 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5392, Accuracy: 0.8059, F1 Micro: 0.8877, F1 Macro: 0.8651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4796, Accuracy: 0.8745, F1 Micro: 0.9252, F1 Macro: 0.9181\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3713, Accuracy: 0.917, F1 Micro: 0.9496, F1 Macro: 0.9448\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2774, Accuracy: 0.9372, F1 Micro: 0.9613, F1 Macro: 0.9576\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2309, Accuracy: 0.9444, F1 Micro: 0.966, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1987, Accuracy: 0.9483, F1 Micro: 0.9681, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1705, Accuracy: 0.9521, F1 Micro: 0.9706, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.15, Accuracy: 0.9536, F1 Micro: 0.9714, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.134, Accuracy: 0.9549, F1 Micro: 0.9721, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.117, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9703\n",
      "\n",
      "Aspect detection accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9703\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.90      0.95      0.92       317\n",
      "       linen       0.89      0.98      0.93       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.99      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5449, Accuracy: 0.8517, F1 Micro: 0.8517, F1 Macro: 0.7996\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3839, Accuracy: 0.8821, F1 Micro: 0.8821, F1 Macro: 0.836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2754, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8852\n",
      "Epoch 4/10, Train Loss: 0.1764, Accuracy: 0.9037, F1 Micro: 0.9037, F1 Macro: 0.8687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1159, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8854\n",
      "Epoch 6/10, Train Loss: 0.1083, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8852\n",
      "Epoch 7/10, Train Loss: 0.0842, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8819\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0537, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8832\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0643, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.889\n",
      "Epoch 10/10, Train Loss: 0.0446, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8822\n",
      "\n",
      "Sentiment analysis accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       737\n",
      "    positive       0.95      0.74      0.83       281\n",
      "\n",
      "    accuracy                           0.92      1018\n",
      "   macro avg       0.93      0.86      0.89      1018\n",
      "weighted avg       0.92      0.92      0.91      1018\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9503, F1 Micro: 0.9503, F1 Macro: 0.8387\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.79      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.76      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.95       496\n",
      "    positive       0.85      0.43      0.57        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.59      0.47      0.51       571\n",
      "weighted avg       0.90      0.91      0.89       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.81      0.86       200\n",
      "     neutral       0.90      0.95      0.92       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.77      0.83       162\n",
      "     neutral       0.89      0.98      0.93       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.86      0.70      0.75       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.96      0.94      0.95        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.59      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.76      0.81       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.98      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 191.8202362060547 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0017323053441941736\n",
      "Samples above threshold: 141\n",
      "Acquired samples: 141\n",
      "Sampling duration: 34.25701069831848 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5363, Accuracy: 0.813, F1 Micro: 0.8943, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4575, Accuracy: 0.8844, F1 Micro: 0.9308, F1 Macro: 0.9239\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3447, Accuracy: 0.9245, F1 Micro: 0.9537, F1 Macro: 0.9486\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2543, Accuracy: 0.9444, F1 Micro: 0.9659, F1 Macro: 0.9632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2136, Accuracy: 0.9497, F1 Micro: 0.969, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1843, Accuracy: 0.9549, F1 Micro: 0.9722, F1 Macro: 0.9696\n",
      "Epoch 7/10, Train Loss: 0.1635, Accuracy: 0.9549, F1 Micro: 0.9721, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1404, Accuracy: 0.9585, F1 Micro: 0.9743, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1198, Accuracy: 0.9601, F1 Micro: 0.9752, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1044, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9735\n",
      "\n",
      "Aspect detection accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.92      0.95      0.93       317\n",
      "       linen       0.93      0.95      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4829, Accuracy: 0.8533, F1 Micro: 0.8533, F1 Macro: 0.8085\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3478, Accuracy: 0.8839, F1 Micro: 0.8839, F1 Macro: 0.854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.22, Accuracy: 0.8877, F1 Micro: 0.8877, F1 Macro: 0.8503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1661, Accuracy: 0.9044, F1 Micro: 0.9044, F1 Macro: 0.8767\n",
      "Epoch 5/10, Train Loss: 0.1378, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.871\n",
      "Epoch 6/10, Train Loss: 0.1114, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0962, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0547, Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8818\n",
      "Epoch 9/10, Train Loss: 0.0382, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.8726\n",
      "Epoch 10/10, Train Loss: 0.0518, Accuracy: 0.9034, F1 Micro: 0.9034, F1 Macro: 0.873\n",
      "\n",
      "Sentiment analysis accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       765\n",
      "    positive       0.93      0.74      0.82       312\n",
      "\n",
      "    accuracy                           0.91      1077\n",
      "   macro avg       0.92      0.86      0.88      1077\n",
      "weighted avg       0.91      0.91      0.91      1077\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9555, F1 Micro: 0.9555, F1 Macro: 0.8645\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.82       571\n",
      "weighted avg       0.96      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.91      0.63      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.79      0.59      0.64       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.84      0.88       200\n",
      "     neutral       0.92      0.95      0.93       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85       162\n",
      "     neutral       0.93      0.95      0.94       387\n",
      "    positive       0.73      0.36      0.48        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.83      0.72      0.76       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.82      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 217.9536919593811 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0012612440739758314\n",
      "Samples above threshold: 127\n",
      "Acquired samples: 127\n",
      "Sampling duration: 30.6502685546875 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5313, Accuracy: 0.8118, F1 Micro: 0.8944, F1 Macro: 0.889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4324, Accuracy: 0.9056, F1 Micro: 0.9431, F1 Macro: 0.9378\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3188, Accuracy: 0.9333, F1 Micro: 0.9594, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2383, Accuracy: 0.9486, F1 Micro: 0.9684, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2025, Accuracy: 0.954, F1 Micro: 0.9716, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.169, Accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.143, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1287, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1067, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9742\n",
      "Epoch 10/10, Train Loss: 0.0943, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.98      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4774, Accuracy: 0.8672, F1 Micro: 0.8672, F1 Macro: 0.8266\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2941, Accuracy: 0.8887, F1 Micro: 0.8887, F1 Macro: 0.852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1964, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1414, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1136, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8841\n",
      "Epoch 6/10, Train Loss: 0.0839, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0483, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.048, Accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.89\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0388, Accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.8885\n",
      "Epoch 10/10, Train Loss: 0.0394, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8792\n",
      "\n",
      "Sentiment analysis accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.8885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       764\n",
      "    positive       0.94      0.75      0.83       305\n",
      "\n",
      "    accuracy                           0.91      1069\n",
      "   macro avg       0.92      0.87      0.89      1069\n",
      "weighted avg       0.92      0.91      0.91      1069\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9562, F1 Micro: 0.9562, F1 Macro: 0.851\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87        86\n",
      "     neutral       0.97      0.98      0.98       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.78      0.80       571\n",
      "weighted avg       0.95      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.76      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.87       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.75      0.27      0.40        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.69      0.74       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.80      0.86        85\n",
      "     neutral       0.96      0.99      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.90      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.84      0.87       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 224.86249995231628 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0009986722841858863\n",
      "Samples above threshold: 114\n",
      "Acquired samples: 114\n",
      "Sampling duration: 26.900699377059937 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5243, Accuracy: 0.825, F1 Micro: 0.8989, F1 Macro: 0.8866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4103, Accuracy: 0.9047, F1 Micro: 0.9428, F1 Macro: 0.9379\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2922, Accuracy: 0.9403, F1 Micro: 0.9634, F1 Macro: 0.9602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2296, Accuracy: 0.9498, F1 Micro: 0.9691, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1897, Accuracy: 0.9563, F1 Micro: 0.973, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1562, Accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1362, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9735\n",
      "Epoch 8/10, Train Loss: 0.117, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1044, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0864, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.90      0.97      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4419, Accuracy: 0.8596, F1 Micro: 0.8596, F1 Macro: 0.8199\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.266, Accuracy: 0.8873, F1 Micro: 0.8873, F1 Macro: 0.8597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1863, Accuracy: 0.904, F1 Micro: 0.904, F1 Macro: 0.8745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1278, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0956, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0886, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8855\n",
      "Epoch 7/10, Train Loss: 0.0605, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8794\n",
      "Epoch 8/10, Train Loss: 0.0477, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8782\n",
      "Epoch 9/10, Train Loss: 0.0349, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8769\n",
      "Epoch 10/10, Train Loss: 0.0344, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.881\n",
      "\n",
      "Sentiment analysis accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8855\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       773\n",
      "    positive       0.91      0.76      0.83       310\n",
      "\n",
      "    accuracy                           0.91      1083\n",
      "   macro avg       0.91      0.87      0.89      1083\n",
      "weighted avg       0.91      0.91      0.91      1083\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9559, F1 Micro: 0.9559, F1 Macro: 0.861\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.44      0.40      0.42        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.79      0.76      0.77       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.83      0.63      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.70      0.59      0.63       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.78      0.85       162\n",
      "     neutral       0.90      0.97      0.94       387\n",
      "    positive       0.65      0.50      0.56        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.82      0.75      0.78       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.85        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.93      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 236.7933840751648 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0008085433510132134\n",
      "Samples above threshold: 103\n",
      "Acquired samples: 103\n",
      "Sampling duration: 23.736964225769043 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5173, Accuracy: 0.8332, F1 Micro: 0.9041, F1 Macro: 0.8968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3926, Accuracy: 0.916, F1 Micro: 0.949, F1 Macro: 0.9437\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2788, Accuracy: 0.9401, F1 Micro: 0.9634, F1 Macro: 0.9609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2206, Accuracy: 0.9523, F1 Micro: 0.9706, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1754, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.152, Accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9727\n",
      "Epoch 7/10, Train Loss: 0.1306, Accuracy: 0.9587, F1 Micro: 0.9745, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1145, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0936, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9744\n",
      "Epoch 10/10, Train Loss: 0.0845, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.93      0.94      0.93       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4435, Accuracy: 0.8717, F1 Micro: 0.8717, F1 Macro: 0.8264\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2889, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1816, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1459, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1027, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8863\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0726, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8866\n",
      "Epoch 7/10, Train Loss: 0.0593, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.882\n",
      "Epoch 8/10, Train Loss: 0.0521, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.882\n",
      "Epoch 9/10, Train Loss: 0.0376, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0496, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8884\n",
      "\n",
      "Sentiment analysis accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       767\n",
      "    positive       0.92      0.76      0.84       309\n",
      "\n",
      "    accuracy                           0.91      1076\n",
      "   macro avg       0.92      0.87      0.89      1076\n",
      "weighted avg       0.91      0.91      0.91      1076\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.8793\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.78      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.60      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.83      0.87       200\n",
      "     neutral       0.93      0.94      0.93       315\n",
      "    positive       0.81      0.98      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.85       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.73      0.36      0.48        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.84      0.72      0.76       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.82      0.86        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.83      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 242.9923505783081 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0006114182237070059\n",
      "Samples above threshold: 92\n",
      "Acquired samples: 62\n",
      "Sampling duration: 21.12736225128174 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5163, Accuracy: 0.8233, F1 Micro: 0.9001, F1 Macro: 0.8948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3837, Accuracy: 0.9179, F1 Micro: 0.9503, F1 Macro: 0.9462\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2736, Accuracy: 0.9453, F1 Micro: 0.9663, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2143, Accuracy: 0.9464, F1 Micro: 0.9671, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1795, Accuracy: 0.9578, F1 Micro: 0.974, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1512, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1302, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9752\n",
      "Epoch 8/10, Train Loss: 0.1063, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9744\n",
      "Epoch 9/10, Train Loss: 0.0939, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.078, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.96      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.91      0.98      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4431, Accuracy: 0.8653, F1 Micro: 0.8653, F1 Macro: 0.8198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2437, Accuracy: 0.9001, F1 Micro: 0.9001, F1 Macro: 0.8689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1707, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1246, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0917, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0722, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0511, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8882\n",
      "Epoch 8/10, Train Loss: 0.0313, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8852\n",
      "Epoch 9/10, Train Loss: 0.0369, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8874\n",
      "Epoch 10/10, Train Loss: 0.0294, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8891\n",
      "\n",
      "Sentiment analysis accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.99      0.94       775\n",
      "    positive       0.96      0.74      0.83       316\n",
      "\n",
      "    accuracy                           0.91      1091\n",
      "   macro avg       0.93      0.86      0.89      1091\n",
      "weighted avg       0.92      0.91      0.91      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.8775\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.83        78\n",
      "     neutral       0.98      0.96      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.95      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.82      0.75      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.62      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.88      0.89      0.88        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.81      0.85       162\n",
      "     neutral       0.91      0.98      0.95       387\n",
      "    positive       1.00      0.36      0.53        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.94      0.72      0.78       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.66      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 254.95630836486816 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.0005432594625744969\n",
      "Samples above threshold: 86\n",
      "Acquired samples: 86\n",
      "Sampling duration: 19.3255136013031 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.51, Accuracy: 0.8455, F1 Micro: 0.9107, F1 Macro: 0.9043\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3602, Accuracy: 0.9255, F1 Micro: 0.9547, F1 Macro: 0.9507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.253, Accuracy: 0.9453, F1 Micro: 0.9665, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2062, Accuracy: 0.9545, F1 Micro: 0.9719, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1654, Accuracy: 0.9587, F1 Micro: 0.9745, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1431, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1222, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1006, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.0861, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9748\n",
      "Epoch 10/10, Train Loss: 0.0754, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4487, Accuracy: 0.8642, F1 Micro: 0.8642, F1 Macro: 0.8222\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.242, Accuracy: 0.8991, F1 Micro: 0.8991, F1 Macro: 0.8681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1582, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8856\n",
      "Epoch 4/10, Train Loss: 0.1154, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.097, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8863\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0522, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.8932\n",
      "Epoch 7/10, Train Loss: 0.0574, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8801\n",
      "Epoch 8/10, Train Loss: 0.0511, Accuracy: 0.9165, F1 Micro: 0.9165, F1 Macro: 0.8925\n",
      "Epoch 9/10, Train Loss: 0.046, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0392, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.8937\n",
      "\n",
      "Sentiment analysis accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.8937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       777\n",
      "    positive       0.94      0.76      0.84       313\n",
      "\n",
      "    accuracy                           0.92      1090\n",
      "   macro avg       0.93      0.87      0.89      1090\n",
      "weighted avg       0.92      0.92      0.92      1090\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.8868\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.91        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.81      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.88      0.72      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.88       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.76      0.80       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.81      0.86        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 264.47274518013 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.0004065568966325373\n",
      "Samples above threshold: 77\n",
      "Acquired samples: 77\n",
      "Sampling duration: 17.10334610939026 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4963, Accuracy: 0.8524, F1 Micro: 0.912, F1 Macro: 0.9001\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3434, Accuracy: 0.9241, F1 Micro: 0.9541, F1 Macro: 0.9502\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2518, Accuracy: 0.9451, F1 Micro: 0.9664, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1962, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1635, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9727\n",
      "Epoch 6/10, Train Loss: 0.14, Accuracy: 0.9585, F1 Micro: 0.9743, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.115, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1028, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "Epoch 9/10, Train Loss: 0.0839, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0741, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4348, Accuracy: 0.8561, F1 Micro: 0.8561, F1 Macro: 0.8071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2648, Accuracy: 0.8873, F1 Micro: 0.8873, F1 Macro: 0.8503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1675, Accuracy: 0.9019, F1 Micro: 0.9019, F1 Macro: 0.8713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.126, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1041, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0624, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8826\n",
      "Epoch 7/10, Train Loss: 0.0559, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.882\n",
      "Epoch 8/10, Train Loss: 0.0467, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8794\n",
      "Epoch 9/10, Train Loss: 0.0441, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0334, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8897\n",
      "\n",
      "Sentiment analysis accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       775\n",
      "    positive       0.94      0.76      0.84       316\n",
      "\n",
      "    accuracy                           0.91      1091\n",
      "   macro avg       0.92      0.87      0.89      1091\n",
      "weighted avg       0.92      0.91      0.91      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.8706\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.82      0.68      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.73      0.50      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.84      0.77      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 277.56000447273254 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.0002764108881819994\n",
      "Samples above threshold: 70\n",
      "Acquired samples: 70\n",
      "Sampling duration: 15.1948881149292 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4971, Accuracy: 0.8486, F1 Micro: 0.9133, F1 Macro: 0.9089\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3363, Accuracy: 0.9307, F1 Micro: 0.9578, F1 Macro: 0.9546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2404, Accuracy: 0.9483, F1 Micro: 0.9682, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1939, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1594, Accuracy: 0.9589, F1 Micro: 0.9746, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1311, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1107, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0992, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9759\n",
      "Epoch 9/10, Train Loss: 0.0855, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.07, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.92      0.98      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3905, Accuracy: 0.8657, F1 Micro: 0.8657, F1 Macro: 0.832\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2431, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.17, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.112, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0924, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0822, Accuracy: 0.9172, F1 Micro: 0.9172, F1 Macro: 0.8915\n",
      "Epoch 7/10, Train Loss: 0.0579, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8904\n",
      "Epoch 8/10, Train Loss: 0.0392, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8872\n",
      "Epoch 9/10, Train Loss: 0.0333, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8896\n",
      "Epoch 10/10, Train Loss: 0.0368, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8869\n",
      "\n",
      "Sentiment analysis accuracy: 0.9172, F1 Micro: 0.9172, F1 Macro: 0.8915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       777\n",
      "    positive       0.94      0.75      0.84       310\n",
      "\n",
      "    accuracy                           0.92      1087\n",
      "   macro avg       0.93      0.87      0.89      1087\n",
      "weighted avg       0.92      0.92      0.91      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.8795\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.87      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.95      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.61      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.83      0.86       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.94      0.74      0.80       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 277.72474670410156 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.00021759984956588603\n",
      "Samples above threshold: 63\n",
      "Acquired samples: 52\n",
      "Sampling duration: 13.745344638824463 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4903, Accuracy: 0.8536, F1 Micro: 0.9157, F1 Macro: 0.9108\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3357, Accuracy: 0.9345, F1 Micro: 0.9602, F1 Macro: 0.9571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2348, Accuracy: 0.9495, F1 Micro: 0.969, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1868, Accuracy: 0.9549, F1 Micro: 0.9722, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1565, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1272, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "Epoch 7/10, Train Loss: 0.1104, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0936, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0786, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0688, Accuracy: 0.9653, F1 Micro: 0.9785, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9653, F1 Micro: 0.9785, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3878, Accuracy: 0.8582, F1 Micro: 0.8582, F1 Macro: 0.8279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2234, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.149, Accuracy: 0.9226, F1 Micro: 0.9226, F1 Macro: 0.8986\n",
      "Epoch 4/10, Train Loss: 0.1003, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.8937\n",
      "Epoch 5/10, Train Loss: 0.0843, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.8927\n",
      "Epoch 6/10, Train Loss: 0.0531, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.8945\n",
      "Epoch 7/10, Train Loss: 0.0646, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8878\n",
      "Epoch 8/10, Train Loss: 0.0353, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.8894\n",
      "Epoch 9/10, Train Loss: 0.0236, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0276, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.8996\n",
      "\n",
      "Sentiment analysis accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.8996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       774\n",
      "    positive       0.95      0.77      0.85       298\n",
      "\n",
      "    accuracy                           0.92      1072\n",
      "   macro avg       0.93      0.88      0.90      1072\n",
      "weighted avg       0.93      0.92      0.92      1072\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.8673\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.78      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.84      0.62      0.71        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.93      0.58      0.64       571\n",
      "weighted avg       0.93      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 279.11142086982727 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0001594848872628063\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 58\n",
      "Sampling duration: 12.528849124908447 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4862, Accuracy: 0.8663, F1 Micro: 0.9217, F1 Macro: 0.9164\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3228, Accuracy: 0.9375, F1 Micro: 0.9618, F1 Macro: 0.9589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.225, Accuracy: 0.9498, F1 Micro: 0.9691, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1765, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1457, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1252, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "Epoch 7/10, Train Loss: 0.1061, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0907, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0757, Accuracy: 0.9661, F1 Micro: 0.9789, F1 Macro: 0.9767\n",
      "Epoch 10/10, Train Loss: 0.0659, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9661, F1 Micro: 0.9789, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3847, Accuracy: 0.8655, F1 Micro: 0.8655, F1 Macro: 0.8352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2292, Accuracy: 0.8908, F1 Micro: 0.8908, F1 Macro: 0.8595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1634, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.885\n",
      "Epoch 4/10, Train Loss: 0.1129, Accuracy: 0.9007, F1 Micro: 0.9007, F1 Macro: 0.8735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0743, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8832\n",
      "Epoch 6/10, Train Loss: 0.0659, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8763\n",
      "Epoch 7/10, Train Loss: 0.0584, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8822\n",
      "Epoch 8/10, Train Loss: 0.0464, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8788\n",
      "Epoch 9/10, Train Loss: 0.0326, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0315, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.8884\n",
      "\n",
      "Sentiment analysis accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.8884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.99      0.94       784\n",
      "    positive       0.96      0.74      0.83       324\n",
      "\n",
      "    accuracy                           0.91      1108\n",
      "   macro avg       0.93      0.86      0.89      1108\n",
      "weighted avg       0.92      0.91      0.91      1108\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9611, F1 Micro: 0.9611, F1 Macro: 0.8891\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.91      0.80      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.85      0.76      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.63      0.68       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.76      0.80       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.96      0.97      0.96        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.66      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 288.2295069694519 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.00015942619065754116\n",
      "Samples above threshold: 52\n",
      "Acquired samples: 52\n",
      "Sampling duration: 11.31205439567566 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4826, Accuracy: 0.8684, F1 Micro: 0.9232, F1 Macro: 0.9182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3079, Accuracy: 0.9366, F1 Micro: 0.9614, F1 Macro: 0.9586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2168, Accuracy: 0.9483, F1 Micro: 0.9682, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1771, Accuracy: 0.9561, F1 Micro: 0.9728, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1493, Accuracy: 0.9613, F1 Micro: 0.9761, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1213, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1078, Accuracy: 0.9648, F1 Micro: 0.9782, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0896, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9768\n",
      "Epoch 9/10, Train Loss: 0.0733, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.067, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.94      0.95      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.38, Accuracy: 0.8736, F1 Micro: 0.8736, F1 Macro: 0.8378\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.219, Accuracy: 0.9009, F1 Micro: 0.9009, F1 Macro: 0.8699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1438, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1253, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0804, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.884\n",
      "Epoch 6/10, Train Loss: 0.0789, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.044, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.884\n",
      "Epoch 8/10, Train Loss: 0.0477, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8771\n",
      "Epoch 9/10, Train Loss: 0.0328, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0229, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8837\n",
      "\n",
      "Sentiment analysis accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8837\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       783\n",
      "    positive       0.94      0.74      0.83       317\n",
      "\n",
      "    accuracy                           0.91      1100\n",
      "   macro avg       0.92      0.86      0.88      1100\n",
      "weighted avg       0.91      0.91      0.91      1100\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.874\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.88      0.86       162\n",
      "     neutral       0.94      0.95      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.76      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.78      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 294.39849734306335 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.00011547077156137675\n",
      "Samples above threshold: 47\n",
      "Acquired samples: 50\n",
      "Sampling duration: 10.19373083114624 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4715, Accuracy: 0.8767, F1 Micro: 0.9276, F1 Macro: 0.9224\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.302, Accuracy: 0.9368, F1 Micro: 0.9615, F1 Macro: 0.9589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2143, Accuracy: 0.9493, F1 Micro: 0.9689, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1711, Accuracy: 0.9549, F1 Micro: 0.9722, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1462, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1172, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9738\n",
      "Epoch 7/10, Train Loss: 0.1016, Accuracy: 0.9606, F1 Micro: 0.9757, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0876, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0696, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0607, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.92      0.94      0.93       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3651, Accuracy: 0.8685, F1 Micro: 0.8685, F1 Macro: 0.8281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2124, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1407, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8861\n",
      "Epoch 4/10, Train Loss: 0.0999, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0643, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8906\n",
      "Epoch 6/10, Train Loss: 0.0528, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8863\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0442, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.8919\n",
      "Epoch 8/10, Train Loss: 0.0287, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8911\n",
      "Epoch 9/10, Train Loss: 0.0196, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0222, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.8904\n",
      "\n",
      "Sentiment analysis accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.8904\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.99      0.94       775\n",
      "    positive       0.96      0.74      0.84       320\n",
      "\n",
      "    accuracy                           0.92      1095\n",
      "   macro avg       0.93      0.86      0.89      1095\n",
      "weighted avg       0.92      0.92      0.91      1095\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8785\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.91        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.87      0.76      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.77      0.63      0.67       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.88       200\n",
      "     neutral       0.92      0.94      0.93       315\n",
      "    positive       0.90      0.96      0.93        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.88      0.32      0.47        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.72      0.76       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.96      0.97      0.96        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.62      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 298.13078355789185 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 8.400894876103848e-05\n",
      "Samples above threshold: 42\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.14972186088562 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4672, Accuracy: 0.88, F1 Micro: 0.9292, F1 Macro: 0.9242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2914, Accuracy: 0.9411, F1 Micro: 0.9641, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2084, Accuracy: 0.9517, F1 Micro: 0.9702, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.165, Accuracy: 0.9568, F1 Micro: 0.9733, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1405, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9751\n",
      "Epoch 6/10, Train Loss: 0.114, Accuracy: 0.962, F1 Micro: 0.9765, F1 Macro: 0.9743\n",
      "Epoch 7/10, Train Loss: 0.0945, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9743\n",
      "Epoch 8/10, Train Loss: 0.0805, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0697, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0574, Accuracy: 0.9649, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.92      0.95      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3756, Accuracy: 0.8679, F1 Micro: 0.8679, F1 Macro: 0.819\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2054, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1361, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8852\n",
      "Epoch 4/10, Train Loss: 0.095, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0728, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0632, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.8957\n",
      "Epoch 7/10, Train Loss: 0.0535, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8873\n",
      "Epoch 8/10, Train Loss: 0.0315, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8873\n",
      "Epoch 9/10, Train Loss: 0.0422, Accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.8958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0258, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.8969\n",
      "\n",
      "Sentiment analysis accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.8969\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.99      0.95       771\n",
      "    positive       0.95      0.76      0.85       304\n",
      "\n",
      "    accuracy                           0.92      1075\n",
      "   macro avg       0.93      0.87      0.90      1075\n",
      "weighted avg       0.92      0.92      0.92      1075\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.8753\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.69      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.88       200\n",
      "     neutral       0.92      0.95      0.94       315\n",
      "    positive       0.88      0.89      0.88        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.90      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.78      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.81      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 298.37709069252014 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 6.669674621662125e-05\n",
      "Samples above threshold: 37\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.179770469665527 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4636, Accuracy: 0.88, F1 Micro: 0.9288, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2851, Accuracy: 0.9405, F1 Micro: 0.9636, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2, Accuracy: 0.9509, F1 Micro: 0.9699, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1648, Accuracy: 0.9576, F1 Micro: 0.9738, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1318, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1165, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0943, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0775, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "Epoch 9/10, Train Loss: 0.0696, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9751\n",
      "Epoch 10/10, Train Loss: 0.0589, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.98      0.95      0.96       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3709, Accuracy: 0.8596, F1 Micro: 0.8596, F1 Macro: 0.8158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2095, Accuracy: 0.8757, F1 Micro: 0.8757, F1 Macro: 0.8441\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1586, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8679\n",
      "Epoch 4/10, Train Loss: 0.1188, Accuracy: 0.8962, F1 Micro: 0.8962, F1 Macro: 0.8667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0971, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0755, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.8773\n",
      "Epoch 7/10, Train Loss: 0.0596, Accuracy: 0.8998, F1 Micro: 0.8998, F1 Macro: 0.8702\n",
      "Epoch 8/10, Train Loss: 0.0492, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.032, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8782\n",
      "Epoch 10/10, Train Loss: 0.0128, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8722\n",
      "\n",
      "Sentiment analysis accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       789\n",
      "    positive       0.94      0.73      0.82       329\n",
      "\n",
      "    accuracy                           0.91      1118\n",
      "   macro avg       0.92      0.85      0.88      1118\n",
      "weighted avg       0.91      0.91      0.90      1118\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.8716\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.85      0.79        78\n",
      "     neutral       0.98      0.95      0.96       491\n",
      "    positive       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.74      0.93      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.83      0.71      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.61      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.75      0.79       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.66      0.76        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.84      0.94      0.89        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.86      0.88       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 314.46151781082153 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 8.122881990857422e-05\n",
      "Samples above threshold: 32\n",
      "Acquired samples: 25\n",
      "Sampling duration: 7.2915284633636475 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4583, Accuracy: 0.8816, F1 Micro: 0.9299, F1 Macro: 0.924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.282, Accuracy: 0.9382, F1 Micro: 0.9624, F1 Macro: 0.9601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1974, Accuracy: 0.9512, F1 Micro: 0.97, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.16, Accuracy: 0.9542, F1 Micro: 0.9718, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1377, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9747\n",
      "Epoch 6/10, Train Loss: 0.1089, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0946, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.0763, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0664, Accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.977\n",
      "Epoch 10/10, Train Loss: 0.0551, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.92      0.98      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3675, Accuracy: 0.866, F1 Micro: 0.866, F1 Macro: 0.8179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2118, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1507, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1098, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0836, Accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.8909\n",
      "Epoch 6/10, Train Loss: 0.0761, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8815\n",
      "Epoch 7/10, Train Loss: 0.065, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8743\n",
      "Epoch 8/10, Train Loss: 0.0422, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8852\n",
      "Epoch 9/10, Train Loss: 0.0456, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8879\n",
      "Epoch 10/10, Train Loss: 0.0267, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8864\n",
      "\n",
      "Sentiment analysis accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.8909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       780\n",
      "    positive       0.93      0.77      0.84       317\n",
      "\n",
      "    accuracy                           0.92      1097\n",
      "   macro avg       0.92      0.87      0.89      1097\n",
      "weighted avg       0.92      0.92      0.91      1097\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.8845\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.83      0.74      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.67      0.73       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.85       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.73      0.50      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.76      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.94      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.81      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 303.7323522567749 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 6.025514448992908e-05\n",
      "Samples above threshold: 29\n",
      "Acquired samples: 50\n",
      "Sampling duration: 6.7555177211761475 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4546, Accuracy: 0.8823, F1 Micro: 0.9303, F1 Macro: 0.9248\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2815, Accuracy: 0.9413, F1 Micro: 0.964, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2007, Accuracy: 0.9512, F1 Micro: 0.9701, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1604, Accuracy: 0.9559, F1 Micro: 0.9729, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1333, Accuracy: 0.9609, F1 Micro: 0.9759, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1096, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0918, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0797, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0653, Accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9768\n",
      "Epoch 10/10, Train Loss: 0.0554, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.37, Accuracy: 0.862, F1 Micro: 0.862, F1 Macro: 0.8035\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2053, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1333, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8848\n",
      "Epoch 4/10, Train Loss: 0.1173, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8835\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0772, Accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8926\n",
      "Epoch 6/10, Train Loss: 0.0569, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8867\n",
      "Epoch 7/10, Train Loss: 0.0459, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8896\n",
      "Epoch 8/10, Train Loss: 0.0411, Accuracy: 0.9172, F1 Micro: 0.9172, F1 Macro: 0.8928\n",
      "Epoch 9/10, Train Loss: 0.023, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.888\n",
      "Epoch 10/10, Train Loss: 0.0277, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.888\n",
      "\n",
      "Sentiment analysis accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8926\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       780\n",
      "    positive       0.94      0.76      0.84       307\n",
      "\n",
      "    accuracy                           0.92      1087\n",
      "   macro avg       0.92      0.87      0.89      1087\n",
      "weighted avg       0.92      0.92      0.92      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8803\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.68      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.60      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.87      0.89       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.84      0.95      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.73      0.77       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        85\n",
      "     neutral       0.97      0.99      0.98       418\n",
      "    positive       0.96      0.96      0.96        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 311.65736842155457 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 4.098377576156054e-05\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 50\n",
      "Sampling duration: 5.662058353424072 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4489, Accuracy: 0.8872, F1 Micro: 0.9331, F1 Macro: 0.9276\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2658, Accuracy: 0.9429, F1 Micro: 0.9651, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1897, Accuracy: 0.9531, F1 Micro: 0.9711, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1536, Accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1272, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1032, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0858, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9762\n",
      "Epoch 8/10, Train Loss: 0.075, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9759\n",
      "Epoch 9/10, Train Loss: 0.0637, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9762\n",
      "Epoch 10/10, Train Loss: 0.0518, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.93       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3891, Accuracy: 0.8729, F1 Micro: 0.8729, F1 Macro: 0.8389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1944, Accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.8793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1571, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8853\n",
      "Epoch 4/10, Train Loss: 0.1093, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8838\n",
      "Epoch 5/10, Train Loss: 0.0909, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8803\n",
      "Epoch 6/10, Train Loss: 0.0622, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.057, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.893\n",
      "Epoch 8/10, Train Loss: 0.0417, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8824\n",
      "Epoch 9/10, Train Loss: 0.0353, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8853\n",
      "Epoch 10/10, Train Loss: 0.0266, Accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.8811\n",
      "\n",
      "Sentiment analysis accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       778\n",
      "    positive       0.95      0.76      0.84       316\n",
      "\n",
      "    accuracy                           0.92      1094\n",
      "   macro avg       0.93      0.87      0.89      1094\n",
      "weighted avg       0.92      0.92      0.91      1094\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8803\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.80      0.85       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.78      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.92      0.93       571\n",
      "weighted avg       0.95      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.90       200\n",
      "     neutral       0.95      0.92      0.93       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.75      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.85        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.93      0.97      0.95        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.83      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 306.50064969062805 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 4.5627966756001115e-05\n",
      "Samples above threshold: 19\n",
      "Acquired samples: 50\n",
      "Sampling duration: 4.720845699310303 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4452, Accuracy: 0.8865, F1 Micro: 0.9329, F1 Macro: 0.9281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2671, Accuracy: 0.9446, F1 Micro: 0.9661, F1 Macro: 0.9639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1899, Accuracy: 0.95, F1 Micro: 0.9693, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1541, Accuracy: 0.9573, F1 Micro: 0.9736, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1208, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1011, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "Epoch 7/10, Train Loss: 0.0839, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9746\n",
      "Epoch 8/10, Train Loss: 0.0691, Accuracy: 0.9639, F1 Micro: 0.9775, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0595, Accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9771\n",
      "Epoch 10/10, Train Loss: 0.0493, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3519, Accuracy: 0.8716, F1 Micro: 0.8716, F1 Macro: 0.8349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1841, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8837\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1351, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0968, Accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.8951\n",
      "Epoch 5/10, Train Loss: 0.0572, Accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0455, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.8954\n",
      "Epoch 7/10, Train Loss: 0.0385, Accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.8958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0359, Accuracy: 0.9247, F1 Micro: 0.9247, F1 Macro: 0.9025\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0218, Accuracy: 0.9247, F1 Micro: 0.9247, F1 Macro: 0.9019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0177, Accuracy: 0.9256, F1 Micro: 0.9256, F1 Macro: 0.903\n",
      "\n",
      "Sentiment analysis accuracy: 0.9256, F1 Micro: 0.9256, F1 Macro: 0.903\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       770\n",
      "    positive       0.95      0.78      0.86       305\n",
      "\n",
      "    accuracy                           0.93      1075\n",
      "   macro avg       0.93      0.88      0.90      1075\n",
      "weighted avg       0.93      0.93      0.92      1075\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9611, F1 Micro: 0.9611, F1 Macro: 0.8883\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.62      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.76      0.81       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 318.16616225242615 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 2.6883296413870994e-05\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 50\n",
      "Sampling duration: 3.9000132083892822 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4382, Accuracy: 0.8861, F1 Micro: 0.9327, F1 Macro: 0.9279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.258, Accuracy: 0.9405, F1 Micro: 0.9636, F1 Macro: 0.961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1888, Accuracy: 0.9521, F1 Micro: 0.9706, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1513, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.122, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0988, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0816, Accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0683, Accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9767\n",
      "Epoch 9/10, Train Loss: 0.0566, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0487, Accuracy: 0.967, F1 Micro: 0.9795, F1 Macro: 0.9776\n",
      "\n",
      "Aspect detection accuracy: 0.967, F1 Micro: 0.9795, F1 Macro: 0.9776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.98       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.356, Accuracy: 0.871, F1 Micro: 0.871, F1 Macro: 0.827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.209, Accuracy: 0.8959, F1 Micro: 0.8959, F1 Macro: 0.8562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1228, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1088, Accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.8895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0671, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.8923\n",
      "Epoch 6/10, Train Loss: 0.0487, Accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0379, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.8947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0328, Accuracy: 0.9217, F1 Micro: 0.9217, F1 Macro: 0.8976\n",
      "Epoch 9/10, Train Loss: 0.0249, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.8957\n",
      "Epoch 10/10, Train Loss: 0.0261, Accuracy: 0.9207, F1 Micro: 0.9207, F1 Macro: 0.895\n",
      "\n",
      "Sentiment analysis accuracy: 0.9217, F1 Micro: 0.9217, F1 Macro: 0.8976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.95       783\n",
      "    positive       0.92      0.78      0.85       302\n",
      "\n",
      "    accuracy                           0.92      1085\n",
      "   macro avg       0.92      0.88      0.90      1085\n",
      "weighted avg       0.92      0.92      0.92      1085\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9611, F1 Micro: 0.9611, F1 Macro: 0.8754\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.97      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85        78\n",
      "     neutral       0.98      0.97      0.98       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.94      0.88       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.69      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.65      0.73       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.89      0.91       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.93      0.93       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.76      0.81       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.84      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 329.04769682884216 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 1.503196517660399e-05\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 50\n",
      "Sampling duration: 2.829434871673584 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4279, Accuracy: 0.8931, F1 Micro: 0.9363, F1 Macro: 0.9313\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2516, Accuracy: 0.9455, F1 Micro: 0.9666, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1824, Accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1438, Accuracy: 0.9557, F1 Micro: 0.9728, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1203, Accuracy: 0.9618, F1 Micro: 0.9764, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0951, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0811, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0652, Accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0579, Accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.9772\n",
      "Epoch 10/10, Train Loss: 0.0473, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3632, Accuracy: 0.8875, F1 Micro: 0.8875, F1 Macro: 0.8513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1807, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.136, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8838\n",
      "Epoch 4/10, Train Loss: 0.095, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0744, Accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.8941\n",
      "Epoch 6/10, Train Loss: 0.0529, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0435, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.8986\n",
      "Epoch 8/10, Train Loss: 0.024, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0433, Accuracy: 0.9247, F1 Micro: 0.9247, F1 Macro: 0.9021\n",
      "Epoch 10/10, Train Loss: 0.0173, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8902\n",
      "\n",
      "Sentiment analysis accuracy: 0.9247, F1 Micro: 0.9247, F1 Macro: 0.9021\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       772\n",
      "    positive       0.94      0.79      0.86       304\n",
      "\n",
      "    accuracy                           0.92      1076\n",
      "   macro avg       0.93      0.88      0.90      1076\n",
      "weighted avg       0.93      0.92      0.92      1076\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9613, F1 Micro: 0.9613, F1 Macro: 0.8897\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.77      0.82        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.89      0.69      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.88       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.76      0.59      0.67        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.84      0.94      0.89        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 328.5307786464691 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 1.0909145203186199e-05\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 36\n",
      "Sampling duration: 1.9739580154418945 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4284, Accuracy: 0.888, F1 Micro: 0.9339, F1 Macro: 0.9293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2482, Accuracy: 0.9427, F1 Micro: 0.965, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1761, Accuracy: 0.951, F1 Micro: 0.97, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1433, Accuracy: 0.9547, F1 Micro: 0.9721, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1168, Accuracy: 0.9582, F1 Micro: 0.9742, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0943, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.078, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0677, Accuracy: 0.9651, F1 Micro: 0.9784, F1 Macro: 0.9766\n",
      "Epoch 9/10, Train Loss: 0.0569, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.047, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.977\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.95      0.94      0.94       317\n",
      "       linen       0.94      0.97      0.96       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3396, Accuracy: 0.8822, F1 Micro: 0.8822, F1 Macro: 0.8442\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1918, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1266, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0871, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.8926\n",
      "Epoch 5/10, Train Loss: 0.0664, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8875\n",
      "Epoch 6/10, Train Loss: 0.0551, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8734\n",
      "Epoch 7/10, Train Loss: 0.0449, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8843\n",
      "Epoch 8/10, Train Loss: 0.0302, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8899\n",
      "Epoch 9/10, Train Loss: 0.0307, Accuracy: 0.9172, F1 Micro: 0.9172, F1 Macro: 0.8902\n",
      "Epoch 10/10, Train Loss: 0.0198, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8891\n",
      "\n",
      "Sentiment analysis accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.8926\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.99      0.95       780\n",
      "    positive       0.95      0.75      0.84       307\n",
      "\n",
      "    accuracy                           0.92      1087\n",
      "   macro avg       0.93      0.87      0.89      1087\n",
      "weighted avg       0.92      0.92      0.92      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.8687\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.76      0.79       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.55      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.94      0.94       315\n",
      "    positive       0.88      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.89       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.78      0.83       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.87      0.87        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.73      0.65      0.69        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.72      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 326.64060974121094 s\n",
      "Total runtime: 7334.044450998306 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6302de40",
   "metadata": {
    "papermill": {
     "duration": 0.178323,
     "end_time": "2025-03-30T10:00:57.027148",
     "exception": false,
     "start_time": "2025-03-30T10:00:56.848825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9558b00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6222, Accuracy: 0.7984, F1 Micro: 0.8875, F1 Macro: 0.8819\n",
      "Epoch 2/10, Train Loss: 0.4944, Accuracy: 0.7981, F1 Micro: 0.8873, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4566, Accuracy: 0.7997, F1 Micro: 0.8881, F1 Macro: 0.8821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4288, Accuracy: 0.8017, F1 Micro: 0.8893, F1 Macro: 0.8836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4243, Accuracy: 0.804, F1 Micro: 0.8907, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4161, Accuracy: 0.8135, F1 Micro: 0.8944, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4005, Accuracy: 0.8179, F1 Micro: 0.8965, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3794, Accuracy: 0.8247, F1 Micro: 0.9001, F1 Macro: 0.8939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3213, Accuracy: 0.8417, F1 Micro: 0.9083, F1 Macro: 0.9019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3264, Accuracy: 0.8519, F1 Micro: 0.9131, F1 Macro: 0.9062\n",
      "\n",
      "Aspect detection accuracy: 0.8519, F1 Micro: 0.9131, F1 Macro: 0.9062\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.88      1.00      0.94       462\n",
      "   air_panas       0.83      1.00      0.91       480\n",
      "         bau       0.87      0.98      0.92       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.78      0.78      0.78       317\n",
      "       linen       0.79      0.92      0.85       392\n",
      "     service       0.87      0.96      0.91       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.86      1.00      0.93       498\n",
      "\n",
      "   micro avg       0.86      0.97      0.91      4614\n",
      "   macro avg       0.86      0.96      0.91      4614\n",
      "weighted avg       0.86      0.97      0.91      4614\n",
      " samples avg       0.86      0.97      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5506, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4796, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4879, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4287, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3515, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3279, Accuracy: 0.7, F1 Micro: 0.7, F1 Macro: 0.6242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2793, Accuracy: 0.7073, F1 Micro: 0.7073, F1 Macro: 0.6432\n",
      "Epoch 8/10, Train Loss: 0.202, Accuracy: 0.6873, F1 Micro: 0.6873, F1 Macro: 0.6008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2003, Accuracy: 0.7309, F1 Micro: 0.7309, F1 Macro: 0.6829\n",
      "Epoch 10/10, Train Loss: 0.1315, Accuracy: 0.7109, F1 Micro: 0.7109, F1 Macro: 0.649\n",
      "\n",
      "Sentiment analysis accuracy: 0.7309, F1 Micro: 0.7309, F1 Macro: 0.6829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.93      0.81       332\n",
      "    positive       0.80      0.43      0.56       218\n",
      "\n",
      "    accuracy                           0.73       550\n",
      "   macro avg       0.75      0.68      0.68       550\n",
      "weighted avg       0.75      0.73      0.71       550\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8433, F1 Micro: 0.8433, F1 Macro: 0.4292\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.46      0.61        97\n",
      "     neutral       0.88      1.00      0.94       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.59      0.49      0.51       571\n",
      "weighted avg       0.86      0.88      0.86       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.28      0.33      0.30       571\n",
      "weighted avg       0.69      0.83      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.35      0.08      0.13        78\n",
      "     neutral       0.87      0.98      0.92       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.41      0.35      0.35       571\n",
      "weighted avg       0.79      0.85      0.81       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.69      0.71       200\n",
      "     neutral       0.78      0.77      0.78       315\n",
      "    positive       0.39      0.46      0.42        56\n",
      "\n",
      "    accuracy                           0.71       571\n",
      "   macro avg       0.63      0.64      0.64       571\n",
      "weighted avg       0.72      0.71      0.72       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.48      0.56       162\n",
      "     neutral       0.78      0.92      0.85       387\n",
      "    positive       0.50      0.09      0.15        22\n",
      "\n",
      "    accuracy                           0.76       571\n",
      "   macro avg       0.66      0.50      0.52       571\n",
      "weighted avg       0.75      0.76      0.74       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.49      0.57        85\n",
      "     neutral       0.87      0.96      0.91       418\n",
      "    positive       0.83      0.56      0.67        68\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.79      0.67      0.72       571\n",
      "weighted avg       0.83      0.84      0.83       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        74\n",
      "     neutral       0.87      1.00      0.93       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.80       571\n",
      "\n",
      "Total train time: 85.73438739776611 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.001300726318731904\n",
      "Samples above threshold: 215\n",
      "Acquired samples: 215\n",
      "Sampling duration: 41.51055932044983 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5682, Accuracy: 0.8, F1 Micro: 0.8884, F1 Macro: 0.883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4963, Accuracy: 0.8038, F1 Micro: 0.8904, F1 Macro: 0.8848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4761, Accuracy: 0.8227, F1 Micro: 0.8992, F1 Macro: 0.8941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4326, Accuracy: 0.8417, F1 Micro: 0.9084, F1 Macro: 0.9008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4007, Accuracy: 0.8533, F1 Micro: 0.9146, F1 Macro: 0.9095\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3496, Accuracy: 0.8727, F1 Micro: 0.9251, F1 Macro: 0.9203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3011, Accuracy: 0.8852, F1 Micro: 0.9318, F1 Macro: 0.9275\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2608, Accuracy: 0.896, F1 Micro: 0.9381, F1 Macro: 0.935\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2355, Accuracy: 0.9116, F1 Micro: 0.9467, F1 Macro: 0.9436\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2156, Accuracy: 0.9196, F1 Micro: 0.9511, F1 Macro: 0.9473\n",
      "\n",
      "Aspect detection accuracy: 0.9196, F1 Micro: 0.9511, F1 Macro: 0.9473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.88      1.00      0.94       480\n",
      "         bau       0.93      0.97      0.95       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.90      0.83      0.86       317\n",
      "       linen       0.90      0.95      0.92       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.95      1.00      0.97       530\n",
      "          tv       0.93      1.00      0.96       516\n",
      "        wifi       0.97      0.99      0.98       498\n",
      "\n",
      "   micro avg       0.93      0.98      0.95      4614\n",
      "   macro avg       0.93      0.97      0.95      4614\n",
      "weighted avg       0.93      0.98      0.95      4614\n",
      " samples avg       0.93      0.97      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5973, Accuracy: 0.6932, F1 Micro: 0.6932, F1 Macro: 0.4094\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4901, Accuracy: 0.8117, F1 Micro: 0.8117, F1 Macro: 0.7607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.36, Accuracy: 0.814, F1 Micro: 0.814, F1 Macro: 0.7491\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3512, Accuracy: 0.825, F1 Micro: 0.825, F1 Macro: 0.7787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2726, Accuracy: 0.8394, F1 Micro: 0.8394, F1 Macro: 0.7956\n",
      "Epoch 6/10, Train Loss: 0.2751, Accuracy: 0.8317, F1 Micro: 0.8317, F1 Macro: 0.7849\n",
      "Epoch 7/10, Train Loss: 0.2406, Accuracy: 0.8328, F1 Micro: 0.8328, F1 Macro: 0.7735\n",
      "Epoch 8/10, Train Loss: 0.1748, Accuracy: 0.8339, F1 Micro: 0.8339, F1 Macro: 0.7831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1325, Accuracy: 0.8394, F1 Micro: 0.8394, F1 Macro: 0.7832\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1197, Accuracy: 0.8494, F1 Micro: 0.8494, F1 Macro: 0.8071\n",
      "\n",
      "Sentiment analysis accuracy: 0.8494, F1 Micro: 0.8494, F1 Macro: 0.8071\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.95      0.90       626\n",
      "    positive       0.85      0.62      0.72       277\n",
      "\n",
      "    accuracy                           0.85       903\n",
      "   macro avg       0.85      0.79      0.81       903\n",
      "weighted avg       0.85      0.85      0.84       903\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.6802\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.89      0.92        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.81      0.87      0.84        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.34      0.49        86\n",
      "     neutral       0.88      1.00      0.94       475\n",
      "    positive       1.00      0.20      0.33        10\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.93      0.51      0.59       571\n",
      "weighted avg       0.89      0.88      0.86       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.54      0.63        78\n",
      "     neutral       0.93      0.97      0.95       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.56      0.50      0.53       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       1.00      0.03      0.06        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.62      0.34      0.33       571\n",
      "weighted avg       0.88      0.87      0.82       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.77      0.79       200\n",
      "     neutral       0.90      0.83      0.86       315\n",
      "    positive       0.53      0.89      0.67        56\n",
      "\n",
      "    accuracy                           0.81       571\n",
      "   macro avg       0.75      0.83      0.77       571\n",
      "weighted avg       0.83      0.81      0.82       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.80      0.81       162\n",
      "     neutral       0.90      0.95      0.92       387\n",
      "    positive       0.67      0.09      0.16        22\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.79      0.61      0.63       571\n",
      "weighted avg       0.86      0.87      0.86       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.84      0.84        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.90      0.91      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.90      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.24      0.35        29\n",
      "     neutral       0.95      1.00      0.97       525\n",
      "    positive       0.75      0.35      0.48        17\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.78      0.53      0.60       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.33      0.49        54\n",
      "     neutral       0.93      1.00      0.96       511\n",
      "    positive       0.67      0.33      0.44         6\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.85      0.56      0.63       571\n",
      "weighted avg       0.93      0.93      0.91       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.81      0.87        74\n",
      "     neutral       0.97      0.99      0.98       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.93      0.90       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Total train time: 130.75408577919006 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.031144876033067703\n",
      "Samples above threshold: 193\n",
      "Acquired samples: 193\n",
      "Sampling duration: 48.901161432266235 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.556, Accuracy: 0.7937, F1 Micro: 0.88, F1 Macro: 0.843\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4991, Accuracy: 0.8137, F1 Micro: 0.8893, F1 Macro: 0.846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4635, Accuracy: 0.847, F1 Micro: 0.9095, F1 Macro: 0.8937\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3936, Accuracy: 0.8766, F1 Micro: 0.9258, F1 Macro: 0.9131\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3239, Accuracy: 0.905, F1 Micro: 0.9423, F1 Macro: 0.9349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2642, Accuracy: 0.9238, F1 Micro: 0.9534, F1 Macro: 0.9475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2218, Accuracy: 0.9335, F1 Micro: 0.959, F1 Macro: 0.9536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2019, Accuracy: 0.9406, F1 Micro: 0.9636, F1 Macro: 0.9604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1699, Accuracy: 0.9415, F1 Micro: 0.9642, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1517, Accuracy: 0.9448, F1 Micro: 0.9661, F1 Macro: 0.9632\n",
      "\n",
      "Aspect detection accuracy: 0.9448, F1 Micro: 0.9661, F1 Macro: 0.9632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.94      1.00      0.97       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.88      1.00      0.94       500\n",
      "  kebersihan       0.89      0.90      0.89       317\n",
      "       linen       0.90      0.97      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.97      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6299, Accuracy: 0.8144, F1 Micro: 0.8144, F1 Macro: 0.7495\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4817, Accuracy: 0.8636, F1 Micro: 0.8636, F1 Macro: 0.807\n",
      "Epoch 3/10, Train Loss: 0.3723, Accuracy: 0.8554, F1 Micro: 0.8554, F1 Macro: 0.8106\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3012, Accuracy: 0.8738, F1 Micro: 0.8738, F1 Macro: 0.8263\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2157, Accuracy: 0.8872, F1 Micro: 0.8872, F1 Macro: 0.8406\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1513, Accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.8551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1245, Accuracy: 0.8985, F1 Micro: 0.8985, F1 Macro: 0.8577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0636, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8593\n",
      "Epoch 9/10, Train Loss: 0.0599, Accuracy: 0.8944, F1 Micro: 0.8944, F1 Macro: 0.8501\n",
      "Epoch 10/10, Train Loss: 0.0682, Accuracy: 0.8964, F1 Micro: 0.8964, F1 Macro: 0.8515\n",
      "\n",
      "Sentiment analysis accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.93       716\n",
      "    positive       0.91      0.69      0.78       259\n",
      "\n",
      "    accuracy                           0.90       975\n",
      "   macro avg       0.90      0.83      0.86       975\n",
      "weighted avg       0.90      0.90      0.89       975\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.7917\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.66      0.78        86\n",
      "     neutral       0.94      1.00      0.97       475\n",
      "    positive       0.43      0.30      0.35        10\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.77      0.65      0.70       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.76      0.79        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.74      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.88      1.00      0.94       496\n",
      "    positive       1.00      0.10      0.19        68\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.63      0.37      0.37       571\n",
      "weighted avg       0.88      0.88      0.84       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.83       200\n",
      "     neutral       0.89      0.90      0.89       315\n",
      "    positive       0.75      0.89      0.81        56\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.83      0.86      0.85       571\n",
      "weighted avg       0.87      0.86      0.86       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.80      0.85       162\n",
      "     neutral       0.90      0.97      0.94       387\n",
      "    positive       0.67      0.27      0.39        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.82      0.68      0.72       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.82      0.86        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.45      0.54        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.77      0.59      0.67        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.68      0.73       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.86      0.91       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 167.27157187461853 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.002070812182500958\n",
      "Samples above threshold: 174\n",
      "Acquired samples: 174\n",
      "Sampling duration: 44.29351091384888 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5539, Accuracy: 0.7998, F1 Micro: 0.8828, F1 Macro: 0.8421\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5017, Accuracy: 0.8427, F1 Micro: 0.9081, F1 Macro: 0.8983\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4415, Accuracy: 0.8639, F1 Micro: 0.9201, F1 Macro: 0.9148\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3491, Accuracy: 0.9099, F1 Micro: 0.9454, F1 Macro: 0.938\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2725, Accuracy: 0.9344, F1 Micro: 0.9602, F1 Macro: 0.9574\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2248, Accuracy: 0.9418, F1 Micro: 0.9645, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1983, Accuracy: 0.9479, F1 Micro: 0.968, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1692, Accuracy: 0.9491, F1 Micro: 0.9688, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.147, Accuracy: 0.9509, F1 Micro: 0.9698, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1297, Accuracy: 0.9531, F1 Micro: 0.9712, F1 Macro: 0.9686\n",
      "\n",
      "Aspect detection accuracy: 0.9531, F1 Micro: 0.9712, F1 Macro: 0.9686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.91      1.00      0.95       500\n",
      "  kebersihan       0.90      0.93      0.91       317\n",
      "       linen       0.90      0.97      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.99      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5968, Accuracy: 0.841, F1 Micro: 0.841, F1 Macro: 0.7779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4076, Accuracy: 0.8588, F1 Micro: 0.8588, F1 Macro: 0.7961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.322, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8671\n",
      "Epoch 4/10, Train Loss: 0.2061, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.149, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1293, Accuracy: 0.9165, F1 Micro: 0.9165, F1 Macro: 0.8885\n",
      "Epoch 7/10, Train Loss: 0.0945, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0802, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8894\n",
      "Epoch 9/10, Train Loss: 0.0525, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8818\n",
      "Epoch 10/10, Train Loss: 0.052, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8675\n",
      "\n",
      "Sentiment analysis accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       732\n",
      "    positive       0.92      0.76      0.83       274\n",
      "\n",
      "    accuracy                           0.92      1006\n",
      "   macro avg       0.92      0.87      0.89      1006\n",
      "weighted avg       0.92      0.92      0.91      1006\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.8304\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.84      0.87        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.78      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.76      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.91      1.00      0.95       496\n",
      "    positive       0.93      0.37      0.53        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.61      0.45      0.49       571\n",
      "weighted avg       0.90      0.91      0.89       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.85       200\n",
      "     neutral       0.90      0.93      0.91       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.88      0.91      0.89       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.80      0.85       162\n",
      "     neutral       0.90      0.97      0.94       387\n",
      "    positive       0.70      0.32      0.44        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.83      0.70      0.74       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.81      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.87      0.97      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.48      0.60        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.79      0.65      0.71        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.71      0.76       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.97      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.98      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 191.18512439727783 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0018201357685029508\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 156\n",
      "Sampling duration: 39.994549036026 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5533, Accuracy: 0.7915, F1 Micro: 0.8775, F1 Macro: 0.8166\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4852, Accuracy: 0.8429, F1 Micro: 0.9069, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3985, Accuracy: 0.905, F1 Micro: 0.9429, F1 Macro: 0.9381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2991, Accuracy: 0.9368, F1 Micro: 0.9614, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2311, Accuracy: 0.9464, F1 Micro: 0.9671, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1934, Accuracy: 0.9505, F1 Micro: 0.9696, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1682, Accuracy: 0.9559, F1 Micro: 0.9727, F1 Macro: 0.9699\n",
      "Epoch 8/10, Train Loss: 0.1418, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.97\n",
      "Epoch 9/10, Train Loss: 0.1263, Accuracy: 0.9556, F1 Micro: 0.9724, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1137, Accuracy: 0.9564, F1 Micro: 0.9729, F1 Macro: 0.9695\n",
      "\n",
      "Aspect detection accuracy: 0.9564, F1 Micro: 0.9729, F1 Macro: 0.9695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.87      0.91       317\n",
      "       linen       0.92      0.95      0.94       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.97      0.97      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.97      0.97      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5523, Accuracy: 0.8168, F1 Micro: 0.8168, F1 Macro: 0.7725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3822, Accuracy: 0.8565, F1 Micro: 0.8565, F1 Macro: 0.8137\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.264, Accuracy: 0.8727, F1 Micro: 0.8727, F1 Macro: 0.8363\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2016, Accuracy: 0.8791, F1 Micro: 0.8791, F1 Macro: 0.8442\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1298, Accuracy: 0.8809, F1 Micro: 0.8809, F1 Macro: 0.8479\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1051, Accuracy: 0.8827, F1 Micro: 0.8827, F1 Macro: 0.8485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0863, Accuracy: 0.889, F1 Micro: 0.889, F1 Macro: 0.8581\n",
      "Epoch 8/10, Train Loss: 0.063, Accuracy: 0.8863, F1 Micro: 0.8863, F1 Macro: 0.8545\n",
      "Epoch 9/10, Train Loss: 0.0372, Accuracy: 0.8881, F1 Micro: 0.8881, F1 Macro: 0.86\n",
      "Epoch 10/10, Train Loss: 0.0689, Accuracy: 0.8836, F1 Micro: 0.8836, F1 Macro: 0.8545\n",
      "\n",
      "Sentiment analysis accuracy: 0.889, F1 Micro: 0.889, F1 Macro: 0.8581\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.98      0.92       764\n",
      "    positive       0.95      0.68      0.79       344\n",
      "\n",
      "    accuracy                           0.89      1108\n",
      "   macro avg       0.91      0.83      0.86      1108\n",
      "weighted avg       0.90      0.89      0.88      1108\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.8413\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.75      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.79      0.79        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.75      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.71      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.89      0.86       200\n",
      "     neutral       0.94      0.87      0.90       315\n",
      "    positive       0.83      0.98      0.90        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.87      0.91      0.89       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.85       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.87      0.75      0.79       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.62      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.53      0.62        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.72      0.75       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 218.42484211921692 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0013615284580737348\n",
      "Samples above threshold: 141\n",
      "Acquired samples: 141\n",
      "Sampling duration: 36.35642957687378 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.544, Accuracy: 0.8068, F1 Micro: 0.8916, F1 Macro: 0.8855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4709, Accuracy: 0.8549, F1 Micro: 0.9153, F1 Macro: 0.9089\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.367, Accuracy: 0.9217, F1 Micro: 0.9523, F1 Macro: 0.9467\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2681, Accuracy: 0.9446, F1 Micro: 0.966, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2138, Accuracy: 0.9533, F1 Micro: 0.9712, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1854, Accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1541, Accuracy: 0.9587, F1 Micro: 0.9744, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1334, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.973\n",
      "Epoch 9/10, Train Loss: 0.1194, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9728\n",
      "Epoch 10/10, Train Loss: 0.1042, Accuracy: 0.9604, F1 Micro: 0.9754, F1 Macro: 0.9723\n",
      "\n",
      "Aspect detection accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.973\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.91      0.95      0.93       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.96      0.99      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.501, Accuracy: 0.86, F1 Micro: 0.86, F1 Macro: 0.8144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3281, Accuracy: 0.8849, F1 Micro: 0.8849, F1 Macro: 0.8555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2341, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8899\n",
      "Epoch 4/10, Train Loss: 0.1592, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1193, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8886\n",
      "Epoch 6/10, Train Loss: 0.085, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0994, Accuracy: 0.9166, F1 Micro: 0.9166, F1 Macro: 0.892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.061, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.8942\n",
      "Epoch 9/10, Train Loss: 0.0697, Accuracy: 0.9003, F1 Micro: 0.9003, F1 Macro: 0.8668\n",
      "Epoch 10/10, Train Loss: 0.0349, Accuracy: 0.9166, F1 Micro: 0.9166, F1 Macro: 0.892\n",
      "\n",
      "Sentiment analysis accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.8942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       743\n",
      "    positive       0.94      0.76      0.84       300\n",
      "\n",
      "    accuracy                           0.92      1043\n",
      "   macro avg       0.93      0.87      0.89      1043\n",
      "weighted avg       0.92      0.92      0.92      1043\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9543, F1 Micro: 0.9543, F1 Macro: 0.8524\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.89        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.80      0.40      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.90      0.75      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.77      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.85      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.55      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.82      0.87       200\n",
      "     neutral       0.91      0.95      0.93       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.89      0.36      0.52        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.72      0.77       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.82      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.55      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 232.38093185424805 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0010120819439180197\n",
      "Samples above threshold: 127\n",
      "Acquired samples: 127\n",
      "Sampling duration: 31.398319005966187 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5465, Accuracy: 0.8109, F1 Micro: 0.8925, F1 Macro: 0.883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4595, Accuracy: 0.8814, F1 Micro: 0.9292, F1 Macro: 0.9214\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3338, Accuracy: 0.9342, F1 Micro: 0.9595, F1 Macro: 0.9547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2533, Accuracy: 0.9493, F1 Micro: 0.9686, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2077, Accuracy: 0.9556, F1 Micro: 0.9725, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1676, Accuracy: 0.9561, F1 Micro: 0.9729, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1454, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1248, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9734\n",
      "Epoch 9/10, Train Loss: 0.1053, Accuracy: 0.9611, F1 Micro: 0.9758, F1 Macro: 0.9729\n",
      "Epoch 10/10, Train Loss: 0.0928, Accuracy: 0.9606, F1 Micro: 0.9755, F1 Macro: 0.972\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.91      0.93      0.92       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5022, Accuracy: 0.8467, F1 Micro: 0.8467, F1 Macro: 0.7921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2932, Accuracy: 0.8947, F1 Micro: 0.8947, F1 Macro: 0.8643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2235, Accuracy: 0.9003, F1 Micro: 0.9003, F1 Macro: 0.8681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.147, Accuracy: 0.9021, F1 Micro: 0.9021, F1 Macro: 0.876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1188, Accuracy: 0.904, F1 Micro: 0.904, F1 Macro: 0.8781\n",
      "Epoch 6/10, Train Loss: 0.0901, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.8725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0673, Accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.8767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0486, Accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0453, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.032, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8831\n",
      "\n",
      "Sentiment analysis accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       766\n",
      "    positive       0.92      0.75      0.83       317\n",
      "\n",
      "    accuracy                           0.91      1083\n",
      "   macro avg       0.91      0.86      0.88      1083\n",
      "weighted avg       0.91      0.91      0.91      1083\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9548, F1 Micro: 0.9548, F1 Macro: 0.8503\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.79      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.88      0.72      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86       200\n",
      "     neutral       0.91      0.93      0.92       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.90      0.90       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.67      0.55      0.60        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.83      0.79      0.81       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.45      0.58        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.73      0.65      0.69        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.70      0.75       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.86      0.99      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 258.81799149513245 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.000787689257413149\n",
      "Samples above threshold: 114\n",
      "Acquired samples: 114\n",
      "Sampling duration: 27.934433937072754 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5334, Accuracy: 0.8186, F1 Micro: 0.8936, F1 Macro: 0.8704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.437, Accuracy: 0.8962, F1 Micro: 0.9374, F1 Macro: 0.9298\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3011, Accuracy: 0.9398, F1 Micro: 0.9633, F1 Macro: 0.9602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2358, Accuracy: 0.9519, F1 Micro: 0.9702, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1951, Accuracy: 0.9564, F1 Micro: 0.9732, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1638, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.141, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1147, Accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1019, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9759\n",
      "Epoch 10/10, Train Loss: 0.0875, Accuracy: 0.9639, F1 Micro: 0.9775, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.464, Accuracy: 0.8493, F1 Micro: 0.8493, F1 Macro: 0.8101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.282, Accuracy: 0.8952, F1 Micro: 0.8952, F1 Macro: 0.8626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2227, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1494, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1251, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8902\n",
      "Epoch 6/10, Train Loss: 0.0871, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8875\n",
      "Epoch 7/10, Train Loss: 0.0731, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8843\n",
      "Epoch 8/10, Train Loss: 0.0602, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8877\n",
      "Epoch 9/10, Train Loss: 0.051, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8901\n",
      "Epoch 10/10, Train Loss: 0.0333, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8801\n",
      "\n",
      "Sentiment analysis accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       774\n",
      "    positive       0.94      0.75      0.84       314\n",
      "\n",
      "    accuracy                           0.92      1088\n",
      "   macro avg       0.92      0.87      0.89      1088\n",
      "weighted avg       0.92      0.92      0.91      1088\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.8538\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.86      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.75      0.79       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.86      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.89       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.78      0.81       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.89      0.97      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.88      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 271.3149962425232 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0006533012492582202\n",
      "Samples above threshold: 103\n",
      "Acquired samples: 103\n",
      "Sampling duration: 24.622187614440918 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5254, Accuracy: 0.8075, F1 Micro: 0.8926, F1 Macro: 0.8879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.419, Accuracy: 0.903, F1 Micro: 0.9419, F1 Macro: 0.9364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.298, Accuracy: 0.9444, F1 Micro: 0.9659, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2246, Accuracy: 0.9528, F1 Micro: 0.9709, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1873, Accuracy: 0.9559, F1 Micro: 0.9729, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1588, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1324, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9748\n",
      "Epoch 8/10, Train Loss: 0.1151, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0965, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9749\n",
      "Epoch 10/10, Train Loss: 0.0875, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9743\n",
      "\n",
      "Aspect detection accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.92      0.94      0.93       317\n",
      "       linen       0.94      0.95      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4468, Accuracy: 0.8537, F1 Micro: 0.8537, F1 Macro: 0.802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2574, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.85\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1994, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.126, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1007, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8832\n",
      "Epoch 6/10, Train Loss: 0.0691, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0588, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8821\n",
      "Epoch 8/10, Train Loss: 0.0492, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8767\n",
      "Epoch 9/10, Train Loss: 0.0331, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0383, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8861\n",
      "\n",
      "Sentiment analysis accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       772\n",
      "    positive       0.91      0.76      0.83       308\n",
      "\n",
      "    accuracy                           0.91      1080\n",
      "   macro avg       0.91      0.87      0.89      1080\n",
      "weighted avg       0.91      0.91      0.91      1080\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.8564\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.86      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.77      0.83       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.84      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.55      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.84      0.88       200\n",
      "     neutral       0.92      0.94      0.93       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.87      0.86       162\n",
      "     neutral       0.94      0.95      0.95       387\n",
      "    positive       0.57      0.36      0.44        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.79      0.73      0.75       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.90      0.93      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 287.00857758522034 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0005379195208661259\n",
      "Samples above threshold: 92\n",
      "Acquired samples: 62\n",
      "Sampling duration: 22.04660177230835 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5276, Accuracy: 0.8273, F1 Micro: 0.9019, F1 Macro: 0.8965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4052, Accuracy: 0.9193, F1 Micro: 0.9507, F1 Macro: 0.9455\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.278, Accuracy: 0.9455, F1 Micro: 0.9665, F1 Macro: 0.9636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2169, Accuracy: 0.9514, F1 Micro: 0.9701, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1787, Accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1502, Accuracy: 0.9601, F1 Micro: 0.9752, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1275, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1097, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0934, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.0798, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.92      0.94      0.93       317\n",
      "       linen       0.95      0.95      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4347, Accuracy: 0.866, F1 Micro: 0.866, F1 Macro: 0.8247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2674, Accuracy: 0.8937, F1 Micro: 0.8937, F1 Macro: 0.8593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.18, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1384, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.882\n",
      "Epoch 5/10, Train Loss: 0.0979, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.8734\n",
      "Epoch 6/10, Train Loss: 0.0827, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0549, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8833\n",
      "Epoch 8/10, Train Loss: 0.0465, Accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.8761\n",
      "Epoch 9/10, Train Loss: 0.0467, Accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.8756\n",
      "Epoch 10/10, Train Loss: 0.0255, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8819\n",
      "\n",
      "Sentiment analysis accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8833\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       776\n",
      "    positive       0.93      0.75      0.83       306\n",
      "\n",
      "    accuracy                           0.91      1082\n",
      "   macro avg       0.92      0.86      0.88      1082\n",
      "weighted avg       0.91      0.91      0.91      1082\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9578, F1 Micro: 0.9578, F1 Macro: 0.8596\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.78      0.93      0.85        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.79      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.68      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.60      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88       200\n",
      "     neutral       0.92      0.94      0.93       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.90      0.87       162\n",
      "     neutral       0.95      0.95      0.95       387\n",
      "    positive       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.93      0.75      0.80       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.90      0.90        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 294.53087639808655 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.0005366989353206009\n",
      "Samples above threshold: 86\n",
      "Acquired samples: 86\n",
      "Sampling duration: 20.128315448760986 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5125, Accuracy: 0.8403, F1 Micro: 0.9083, F1 Macro: 0.9027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3795, Accuracy: 0.93, F1 Micro: 0.9574, F1 Macro: 0.9534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.262, Accuracy: 0.9451, F1 Micro: 0.9664, F1 Macro: 0.9639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2061, Accuracy: 0.9547, F1 Micro: 0.972, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1627, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1422, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1187, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.104, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9761\n",
      "Epoch 9/10, Train Loss: 0.0875, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9743\n",
      "Epoch 10/10, Train Loss: 0.079, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4087, Accuracy: 0.8471, F1 Micro: 0.8471, F1 Macro: 0.7977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2467, Accuracy: 0.8851, F1 Micro: 0.8851, F1 Macro: 0.8472\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.179, Accuracy: 0.895, F1 Micro: 0.895, F1 Macro: 0.8619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1285, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.09, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8865\n",
      "Epoch 6/10, Train Loss: 0.0841, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8787\n",
      "Epoch 7/10, Train Loss: 0.0658, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8836\n",
      "Epoch 8/10, Train Loss: 0.0593, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.8805\n",
      "Epoch 9/10, Train Loss: 0.0299, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8831\n",
      "Epoch 10/10, Train Loss: 0.0292, Accuracy: 0.9041, F1 Micro: 0.9041, F1 Macro: 0.875\n",
      "\n",
      "Sentiment analysis accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       783\n",
      "    positive       0.92      0.76      0.83       322\n",
      "\n",
      "    accuracy                           0.91      1105\n",
      "   macro avg       0.91      0.87      0.89      1105\n",
      "weighted avg       0.91      0.91      0.91      1105\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9592, F1 Micro: 0.9592, F1 Macro: 0.8794\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.86      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.75      0.80        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.63      0.67       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.76      0.81       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.89      0.93      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.64      0.94      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.80      0.78       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 303.7390241622925 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.0004052511969348416\n",
      "Samples above threshold: 77\n",
      "Acquired samples: 77\n",
      "Sampling duration: 17.86498713493347 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5075, Accuracy: 0.8333, F1 Micro: 0.9039, F1 Macro: 0.8961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3727, Accuracy: 0.922, F1 Micro: 0.9527, F1 Macro: 0.9486\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2504, Accuracy: 0.9474, F1 Micro: 0.9677, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1896, Accuracy: 0.958, F1 Micro: 0.9741, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1649, Accuracy: 0.9609, F1 Micro: 0.9757, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1371, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1147, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0997, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0869, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9756\n",
      "Epoch 10/10, Train Loss: 0.0741, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3946, Accuracy: 0.8606, F1 Micro: 0.8606, F1 Macro: 0.8125\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2387, Accuracy: 0.8899, F1 Micro: 0.8899, F1 Macro: 0.8523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1726, Accuracy: 0.9009, F1 Micro: 0.9009, F1 Macro: 0.8705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1188, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8846\n",
      "Epoch 5/10, Train Loss: 0.1007, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8812\n",
      "Epoch 6/10, Train Loss: 0.058, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.037, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8873\n",
      "Epoch 8/10, Train Loss: 0.0396, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8702\n",
      "Epoch 9/10, Train Loss: 0.0281, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8755\n",
      "Epoch 10/10, Train Loss: 0.0319, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8798\n",
      "\n",
      "Sentiment analysis accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.99      0.94       777\n",
      "    positive       0.96      0.73      0.83       313\n",
      "\n",
      "    accuracy                           0.91      1090\n",
      "   macro avg       0.93      0.86      0.89      1090\n",
      "weighted avg       0.92      0.91      0.91      1090\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9587, F1 Micro: 0.9587, F1 Macro: 0.8778\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.61      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.91      0.91       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.88      0.32      0.47        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.71      0.75       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.66      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.91      0.81      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 317.7523763179779 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.0003035831439774487\n",
      "Samples above threshold: 70\n",
      "Acquired samples: 70\n",
      "Sampling duration: 15.992618322372437 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5037, Accuracy: 0.829, F1 Micro: 0.9033, F1 Macro: 0.8986\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.354, Accuracy: 0.9328, F1 Micro: 0.959, F1 Macro: 0.9558\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2379, Accuracy: 0.9458, F1 Micro: 0.9667, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1941, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1581, Accuracy: 0.9608, F1 Micro: 0.9758, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1315, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1142, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9755\n",
      "Epoch 8/10, Train Loss: 0.0966, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0819, Accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9766\n",
      "Epoch 10/10, Train Loss: 0.0722, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4123, Accuracy: 0.8609, F1 Micro: 0.8609, F1 Macro: 0.8069\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.252, Accuracy: 0.8878, F1 Micro: 0.8878, F1 Macro: 0.8452\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1519, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1181, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0668, Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.8984\n",
      "Epoch 6/10, Train Loss: 0.07, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8754\n",
      "Epoch 7/10, Train Loss: 0.0604, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.891\n",
      "Epoch 8/10, Train Loss: 0.0465, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.8899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0204, Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.8972\n",
      "Epoch 10/10, Train Loss: 0.016, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8895\n",
      "\n",
      "Sentiment analysis accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.8972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       776\n",
      "    positive       0.94      0.77      0.85       302\n",
      "\n",
      "    accuracy                           0.92      1078\n",
      "   macro avg       0.93      0.88      0.90      1078\n",
      "weighted avg       0.92      0.92      0.92      1078\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.8615\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.77      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.85      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.75      0.79       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 322.86485862731934 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.0002190881350543356\n",
      "Samples above threshold: 63\n",
      "Acquired samples: 52\n",
      "Sampling duration: 14.460343599319458 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4909, Accuracy: 0.8457, F1 Micro: 0.9113, F1 Macro: 0.9073\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3353, Accuracy: 0.9377, F1 Micro: 0.962, F1 Macro: 0.9589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2316, Accuracy: 0.9502, F1 Micro: 0.9694, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.183, Accuracy: 0.9547, F1 Micro: 0.9721, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1537, Accuracy: 0.9615, F1 Micro: 0.976, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1256, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1101, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Epoch 8/10, Train Loss: 0.0922, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9753\n",
      "Epoch 9/10, Train Loss: 0.0782, Accuracy: 0.9639, F1 Micro: 0.9775, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.068, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3819, Accuracy: 0.8655, F1 Micro: 0.8655, F1 Macro: 0.8252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2309, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1483, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8829\n",
      "Epoch 4/10, Train Loss: 0.1186, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8839\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0916, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8863\n",
      "Epoch 6/10, Train Loss: 0.0609, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0506, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.8936\n",
      "Epoch 8/10, Train Loss: 0.0521, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8823\n",
      "Epoch 9/10, Train Loss: 0.0324, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8884\n",
      "Epoch 10/10, Train Loss: 0.0311, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.8829\n",
      "\n",
      "Sentiment analysis accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.8936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       780\n",
      "    positive       0.94      0.77      0.84       320\n",
      "\n",
      "    accuracy                           0.92      1100\n",
      "   macro avg       0.92      0.87      0.89      1100\n",
      "weighted avg       0.92      0.92      0.91      1100\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9592, F1 Micro: 0.9592, F1 Macro: 0.8757\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.86      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.79      0.74      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.58      0.57      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.76      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.87      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.69      0.78        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.84      0.94      0.89        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.88      0.89       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 329.3115084171295 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.00020575551025103778\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 58\n",
      "Sampling duration: 13.07266879081726 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4959, Accuracy: 0.8519, F1 Micro: 0.9145, F1 Macro: 0.9095\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3357, Accuracy: 0.933, F1 Micro: 0.9592, F1 Macro: 0.9562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2282, Accuracy: 0.9484, F1 Micro: 0.9683, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1795, Accuracy: 0.9566, F1 Micro: 0.9732, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.15, Accuracy: 0.9613, F1 Micro: 0.9761, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.124, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9754\n",
      "Epoch 7/10, Train Loss: 0.1086, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.0889, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9751\n",
      "Epoch 9/10, Train Loss: 0.0778, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0666, Accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9773\n",
      "\n",
      "Aspect detection accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.93      0.96      0.95       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3893, Accuracy: 0.8661, F1 Micro: 0.8661, F1 Macro: 0.8248\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2344, Accuracy: 0.892, F1 Micro: 0.892, F1 Macro: 0.8522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1648, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1067, Accuracy: 0.9169, F1 Micro: 0.9169, F1 Macro: 0.8901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0838, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.8997\n",
      "Epoch 6/10, Train Loss: 0.0638, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.8905\n",
      "Epoch 7/10, Train Loss: 0.0665, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.8931\n",
      "Epoch 8/10, Train Loss: 0.0348, Accuracy: 0.9224, F1 Micro: 0.9224, F1 Macro: 0.8979\n",
      "Epoch 9/10, Train Loss: 0.0472, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8825\n",
      "Epoch 10/10, Train Loss: 0.048, Accuracy: 0.9224, F1 Micro: 0.9224, F1 Macro: 0.8972\n",
      "\n",
      "Sentiment analysis accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.8997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       780\n",
      "    positive       0.93      0.78      0.85       303\n",
      "\n",
      "    accuracy                           0.92      1083\n",
      "   macro avg       0.93      0.88      0.90      1083\n",
      "weighted avg       0.92      0.92      0.92      1083\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.8801\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.83      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.71      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.61      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91       200\n",
      "     neutral       0.93      0.96      0.95       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.78      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.89      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 334.0804252624512 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.00014204393082764002\n",
      "Samples above threshold: 52\n",
      "Acquired samples: 52\n",
      "Sampling duration: 11.906286001205444 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4868, Accuracy: 0.8491, F1 Micro: 0.9126, F1 Macro: 0.9058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3216, Accuracy: 0.9368, F1 Micro: 0.9615, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2185, Accuracy: 0.9516, F1 Micro: 0.9702, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1769, Accuracy: 0.9604, F1 Micro: 0.9754, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1469, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.121, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1008, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "Epoch 8/10, Train Loss: 0.0884, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0755, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0641, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.97      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3692, Accuracy: 0.8745, F1 Micro: 0.8745, F1 Macro: 0.8304\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2134, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1592, Accuracy: 0.9075, F1 Micro: 0.9075, F1 Macro: 0.8843\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0892, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8868\n",
      "Epoch 5/10, Train Loss: 0.0634, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0683, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.8978\n",
      "Epoch 7/10, Train Loss: 0.0485, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.892\n",
      "Epoch 8/10, Train Loss: 0.0401, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.8965\n",
      "Epoch 9/10, Train Loss: 0.0251, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8863\n",
      "Epoch 10/10, Train Loss: 0.0257, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.8959\n",
      "\n",
      "Sentiment analysis accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.8978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       773\n",
      "    positive       0.95      0.77      0.85       319\n",
      "\n",
      "    accuracy                           0.92      1092\n",
      "   macro avg       0.93      0.88      0.90      1092\n",
      "weighted avg       0.92      0.92      0.92      1092\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.8861\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.97      0.97       496\n",
      "    positive       0.81      0.79      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.64      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.89       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.86      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.91      0.90       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.91      0.77      0.82       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.66      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 343.12846183776855 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 9.536818834021688e-05\n",
      "Samples above threshold: 47\n",
      "Acquired samples: 50\n",
      "Sampling duration: 10.587198734283447 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.482, Accuracy: 0.8547, F1 Micro: 0.9153, F1 Macro: 0.9084\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.314, Accuracy: 0.9392, F1 Micro: 0.9629, F1 Macro: 0.9605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2178, Accuracy: 0.9484, F1 Micro: 0.9683, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1721, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.144, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1187, Accuracy: 0.9653, F1 Micro: 0.9785, F1 Macro: 0.9764\n",
      "Epoch 7/10, Train Loss: 0.1017, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9751\n",
      "Epoch 8/10, Train Loss: 0.0864, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0741, Accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "Epoch 10/10, Train Loss: 0.0607, Accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.94      0.94       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3712, Accuracy: 0.8586, F1 Micro: 0.8586, F1 Macro: 0.812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2123, Accuracy: 0.8966, F1 Micro: 0.8966, F1 Macro: 0.8684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1448, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.8755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1156, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8786\n",
      "Epoch 5/10, Train Loss: 0.0807, Accuracy: 0.8994, F1 Micro: 0.8994, F1 Macro: 0.8717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0696, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0606, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8817\n",
      "Epoch 8/10, Train Loss: 0.0385, Accuracy: 0.9075, F1 Micro: 0.9075, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0302, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8911\n",
      "Epoch 10/10, Train Loss: 0.035, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8777\n",
      "\n",
      "Sentiment analysis accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8911\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       782\n",
      "    positive       0.94      0.76      0.84       321\n",
      "\n",
      "    accuracy                           0.92      1103\n",
      "   macro avg       0.92      0.87      0.89      1103\n",
      "weighted avg       0.92      0.92      0.91      1103\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9611, F1 Micro: 0.9611, F1 Macro: 0.8869\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.86      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.87      0.79      0.83        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.78      0.64      0.68       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91       200\n",
      "     neutral       0.95      0.94      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.76      0.81       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 349.11559295654297 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 8.491249172948301e-05\n",
      "Samples above threshold: 42\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.513549327850342 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4799, Accuracy: 0.8561, F1 Micro: 0.9162, F1 Macro: 0.9097\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3086, Accuracy: 0.9406, F1 Micro: 0.9636, F1 Macro: 0.9609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2156, Accuracy: 0.9484, F1 Micro: 0.9684, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1714, Accuracy: 0.958, F1 Micro: 0.9741, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1435, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9744\n",
      "Epoch 6/10, Train Loss: 0.1187, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0994, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9761\n",
      "Epoch 8/10, Train Loss: 0.0858, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9752\n",
      "Epoch 9/10, Train Loss: 0.0708, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "Epoch 10/10, Train Loss: 0.0594, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.99      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.93       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3746, Accuracy: 0.865, F1 Micro: 0.865, F1 Macro: 0.8136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2115, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1489, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.119, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8817\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0865, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8891\n",
      "Epoch 6/10, Train Loss: 0.0873, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8817\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0534, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0462, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8886\n",
      "Epoch 9/10, Train Loss: 0.0385, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.8836\n",
      "Epoch 10/10, Train Loss: 0.0331, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8865\n",
      "\n",
      "Sentiment analysis accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       776\n",
      "    positive       0.94      0.75      0.83       313\n",
      "\n",
      "    accuracy                           0.91      1089\n",
      "   macro avg       0.92      0.87      0.89      1089\n",
      "weighted avg       0.92      0.91      0.91      1089\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9592, F1 Micro: 0.9592, F1 Macro: 0.8684\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.78      0.84        78\n",
      "     neutral       0.97      0.99      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.92      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.75      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.58      0.59       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.89      0.36      0.52        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.73      0.78       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.95      0.87      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.90      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 347.81300473213196 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 8.965698361862451e-05\n",
      "Samples above threshold: 37\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.560317754745483 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4712, Accuracy: 0.8628, F1 Micro: 0.9196, F1 Macro: 0.9133\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2916, Accuracy: 0.9417, F1 Micro: 0.9642, F1 Macro: 0.9614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2066, Accuracy: 0.9486, F1 Micro: 0.9684, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1604, Accuracy: 0.9589, F1 Micro: 0.9747, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1353, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1153, Accuracy: 0.9609, F1 Micro: 0.9759, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0991, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0795, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9756\n",
      "Epoch 9/10, Train Loss: 0.0694, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9759\n",
      "Epoch 10/10, Train Loss: 0.0573, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.97      0.90      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3684, Accuracy: 0.8447, F1 Micro: 0.8447, F1 Macro: 0.8069\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2282, Accuracy: 0.8941, F1 Micro: 0.8941, F1 Macro: 0.8622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1588, Accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1181, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0754, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8726\n",
      "Epoch 6/10, Train Loss: 0.0757, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.064, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8738\n",
      "Epoch 8/10, Train Loss: 0.0489, Accuracy: 0.8986, F1 Micro: 0.8986, F1 Macro: 0.8654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0432, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0326, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8774\n",
      "\n",
      "Sentiment analysis accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.99      0.94       788\n",
      "    positive       0.95      0.71      0.82       326\n",
      "\n",
      "    accuracy                           0.91      1114\n",
      "   macro avg       0.92      0.85      0.88      1114\n",
      "weighted avg       0.91      0.91      0.90      1114\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8685\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.87      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.95      0.94       571\n",
      "weighted avg       0.96      0.95      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.93      0.89       200\n",
      "     neutral       0.97      0.90      0.93       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.89      0.36      0.52        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.73      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.91      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 362.21903371810913 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 7.596098294015974e-05\n",
      "Samples above threshold: 32\n",
      "Acquired samples: 25\n",
      "Sampling duration: 7.391340494155884 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.467, Accuracy: 0.8618, F1 Micro: 0.9189, F1 Macro: 0.9125\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2902, Accuracy: 0.938, F1 Micro: 0.9621, F1 Macro: 0.9589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2067, Accuracy: 0.9493, F1 Micro: 0.9689, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1649, Accuracy: 0.9552, F1 Micro: 0.9724, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1356, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.111, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9751\n",
      "Epoch 7/10, Train Loss: 0.0975, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.08, Accuracy: 0.9639, F1 Micro: 0.9775, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0683, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0584, Accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.94      0.95       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3757, Accuracy: 0.8598, F1 Micro: 0.8598, F1 Macro: 0.8205\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2186, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1606, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8863\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1102, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0796, Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.898\n",
      "Epoch 6/10, Train Loss: 0.0583, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8879\n",
      "Epoch 7/10, Train Loss: 0.0595, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.8963\n",
      "Epoch 8/10, Train Loss: 0.0454, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8929\n",
      "Epoch 9/10, Train Loss: 0.0311, Accuracy: 0.9212, F1 Micro: 0.9212, F1 Macro: 0.8992\n",
      "Epoch 10/10, Train Loss: 0.0262, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.893\n",
      "\n",
      "Sentiment analysis accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.99      0.95       779\n",
      "    positive       0.96      0.76      0.85       312\n",
      "\n",
      "    accuracy                           0.92      1091\n",
      "   macro avg       0.93      0.87      0.90      1091\n",
      "weighted avg       0.92      0.92      0.92      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.8779\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.77      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.81      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.75      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91       200\n",
      "     neutral       0.95      0.94      0.95       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       1.00      0.36      0.53        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.73      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.90        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.85      0.86       571\n",
      "weighted avg       0.98      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.86      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 360.9590766429901 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 3.89651413570391e-05\n",
      "Samples above threshold: 29\n",
      "Acquired samples: 50\n",
      "Sampling duration: 6.927496910095215 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4614, Accuracy: 0.8632, F1 Micro: 0.9203, F1 Macro: 0.916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2864, Accuracy: 0.9389, F1 Micro: 0.9626, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2079, Accuracy: 0.9493, F1 Micro: 0.9689, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1559, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1337, Accuracy: 0.9597, F1 Micro: 0.975, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1078, Accuracy: 0.9622, F1 Micro: 0.9766, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0949, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "Epoch 8/10, Train Loss: 0.08, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0647, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9759\n",
      "Epoch 10/10, Train Loss: 0.0574, Accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3708, Accuracy: 0.857, F1 Micro: 0.857, F1 Macro: 0.7987\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2096, Accuracy: 0.8944, F1 Micro: 0.8944, F1 Macro: 0.8606\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.138, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0997, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8772\n",
      "Epoch 5/10, Train Loss: 0.0733, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0634, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0612, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.881\n",
      "Epoch 8/10, Train Loss: 0.034, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.038, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.882\n",
      "Epoch 10/10, Train Loss: 0.0264, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8767\n",
      "\n",
      "Sentiment analysis accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       783\n",
      "    positive       0.93      0.74      0.82       315\n",
      "\n",
      "    accuracy                           0.91      1098\n",
      "   macro avg       0.92      0.86      0.88      1098\n",
      "weighted avg       0.91      0.91      0.91      1098\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.8672\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.90      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.75      1.00      0.86        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.96      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.85      0.83      0.84       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.88      0.66      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.55      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.92      0.91       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.94      0.93       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.75      0.81       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.89      0.88        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.94      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.84      0.94      0.89        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.85      0.87       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 366.0791697502136 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 4.091684786544647e-05\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 50\n",
      "Sampling duration: 6.006255149841309 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4637, Accuracy: 0.8752, F1 Micro: 0.9259, F1 Macro: 0.9188\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2801, Accuracy: 0.9446, F1 Micro: 0.966, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1988, Accuracy: 0.9526, F1 Micro: 0.9709, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1545, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1295, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1102, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0938, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Epoch 8/10, Train Loss: 0.077, Accuracy: 0.9589, F1 Micro: 0.9746, F1 Macro: 0.9726\n",
      "Epoch 9/10, Train Loss: 0.0661, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9748\n",
      "Epoch 10/10, Train Loss: 0.054, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.94      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3654, Accuracy: 0.8699, F1 Micro: 0.8699, F1 Macro: 0.8301\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2125, Accuracy: 0.8981, F1 Micro: 0.8981, F1 Macro: 0.8677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1464, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8725\n",
      "Epoch 4/10, Train Loss: 0.1183, Accuracy: 0.8999, F1 Micro: 0.8999, F1 Macro: 0.87\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0917, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0597, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8879\n",
      "Epoch 7/10, Train Loss: 0.0499, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8845\n",
      "Epoch 8/10, Train Loss: 0.0454, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8863\n",
      "Epoch 9/10, Train Loss: 0.0446, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8819\n",
      "Epoch 10/10, Train Loss: 0.0338, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.8784\n",
      "\n",
      "Sentiment analysis accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       780\n",
      "    positive       0.94      0.75      0.83       319\n",
      "\n",
      "    accuracy                           0.91      1099\n",
      "   macro avg       0.92      0.86      0.89      1099\n",
      "weighted avg       0.92      0.91      0.91      1099\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8824\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.88      0.87       162\n",
      "     neutral       0.94      0.95      0.94       387\n",
      "    positive       0.73      0.50      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.84      0.78      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 364.5852391719818 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 5.034606692788657e-05\n",
      "Samples above threshold: 19\n",
      "Acquired samples: 50\n",
      "Sampling duration: 4.916085958480835 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4532, Accuracy: 0.8733, F1 Micro: 0.9251, F1 Macro: 0.9185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.268, Accuracy: 0.9418, F1 Micro: 0.9645, F1 Macro: 0.9622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1874, Accuracy: 0.9512, F1 Micro: 0.9701, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.153, Accuracy: 0.9575, F1 Micro: 0.9738, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1274, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "Epoch 6/10, Train Loss: 0.1028, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9747\n",
      "Epoch 7/10, Train Loss: 0.0885, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0721, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0633, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0528, Accuracy: 0.9661, F1 Micro: 0.9789, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.9661, F1 Micro: 0.9789, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.96      0.92      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3366, Accuracy: 0.8678, F1 Micro: 0.8678, F1 Macro: 0.8306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2056, Accuracy: 0.8966, F1 Micro: 0.8966, F1 Macro: 0.8657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.145, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1198, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8795\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0912, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8844\n",
      "Epoch 6/10, Train Loss: 0.0655, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8784\n",
      "Epoch 7/10, Train Loss: 0.0577, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8794\n",
      "Epoch 8/10, Train Loss: 0.039, Accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.8753\n",
      "Epoch 9/10, Train Loss: 0.0324, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8802\n",
      "Epoch 10/10, Train Loss: 0.0283, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8748\n",
      "\n",
      "Sentiment analysis accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       792\n",
      "    positive       0.93      0.75      0.83       320\n",
      "\n",
      "    accuracy                           0.91      1112\n",
      "   macro avg       0.92      0.86      0.88      1112\n",
      "weighted avg       0.91      0.91      0.91      1112\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8713\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.90      0.93        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.55      0.60      0.57        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.83      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.86      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.96      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.92      0.90       200\n",
      "     neutral       0.96      0.92      0.94       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.76      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.68      0.88      0.77        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 374.99887681007385 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 2.399741788394749e-05\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 50\n",
      "Sampling duration: 3.955610752105713 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4475, Accuracy: 0.8771, F1 Micro: 0.9276, F1 Macro: 0.923\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2649, Accuracy: 0.9425, F1 Micro: 0.9649, F1 Macro: 0.9629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1866, Accuracy: 0.9493, F1 Micro: 0.9687, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1499, Accuracy: 0.9564, F1 Micro: 0.9731, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1237, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1015, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9759\n",
      "Epoch 7/10, Train Loss: 0.0868, Accuracy: 0.9641, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "Epoch 8/10, Train Loss: 0.0747, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.0602, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0492, Accuracy: 0.9667, F1 Micro: 0.9793, F1 Macro: 0.9774\n",
      "\n",
      "Aspect detection accuracy: 0.9667, F1 Micro: 0.9793, F1 Macro: 0.9774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.95      0.95       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3421, Accuracy: 0.8638, F1 Micro: 0.8638, F1 Macro: 0.8252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2155, Accuracy: 0.8983, F1 Micro: 0.8983, F1 Macro: 0.8659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1351, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1057, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8832\n",
      "Epoch 5/10, Train Loss: 0.0637, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0494, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0369, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.8922\n",
      "Epoch 8/10, Train Loss: 0.0361, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8837\n",
      "Epoch 9/10, Train Loss: 0.0222, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8872\n",
      "Epoch 10/10, Train Loss: 0.0335, Accuracy: 0.9155, F1 Micro: 0.9155, F1 Macro: 0.889\n",
      "\n",
      "Sentiment analysis accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.8922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       786\n",
      "    positive       0.94      0.76      0.84       315\n",
      "\n",
      "    accuracy                           0.92      1101\n",
      "   macro avg       0.93      0.87      0.89      1101\n",
      "weighted avg       0.92      0.92      0.91      1101\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9611, F1 Micro: 0.9611, F1 Macro: 0.8898\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.86      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.86      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.67      0.74       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91       200\n",
      "     neutral       0.95      0.95      0.95       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.87      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.75      0.41      0.53        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.75      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 378.3304109573364 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 1.6734873497625813e-05\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 50\n",
      "Sampling duration: 3.1290507316589355 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4438, Accuracy: 0.8915, F1 Micro: 0.9356, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2576, Accuracy: 0.9431, F1 Micro: 0.9651, F1 Macro: 0.9629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1813, Accuracy: 0.9498, F1 Micro: 0.9691, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1391, Accuracy: 0.9576, F1 Micro: 0.9739, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1186, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0992, Accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9774\n",
      "Epoch 7/10, Train Loss: 0.0811, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9759\n",
      "Epoch 8/10, Train Loss: 0.0688, Accuracy: 0.9661, F1 Micro: 0.9789, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.0582, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.975\n",
      "Epoch 10/10, Train Loss: 0.046, Accuracy: 0.9639, F1 Micro: 0.9775, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.95      0.94      0.95       317\n",
      "       linen       0.94      0.98      0.96       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       0.99      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.99      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3616, Accuracy: 0.8702, F1 Micro: 0.8702, F1 Macro: 0.8277\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1998, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1378, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.8948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1037, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.8957\n",
      "Epoch 5/10, Train Loss: 0.0872, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.8941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0629, Accuracy: 0.9281, F1 Micro: 0.9281, F1 Macro: 0.905\n",
      "Epoch 7/10, Train Loss: 0.05, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.8946\n",
      "Epoch 8/10, Train Loss: 0.0376, Accuracy: 0.9253, F1 Micro: 0.9253, F1 Macro: 0.9019\n",
      "Epoch 9/10, Train Loss: 0.0398, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9041\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0278, Accuracy: 0.9281, F1 Micro: 0.9281, F1 Macro: 0.9059\n",
      "\n",
      "Sentiment analysis accuracy: 0.9281, F1 Micro: 0.9281, F1 Macro: 0.9059\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.98      0.95       775\n",
      "    positive       0.93      0.80      0.86       296\n",
      "\n",
      "    accuracy                           0.93      1071\n",
      "   macro avg       0.93      0.89      0.91      1071\n",
      "weighted avg       0.93      0.93      0.93      1071\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.879\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.87      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.78      0.70      0.74        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.91      0.86      0.88       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.83      0.92      0.87       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.85      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.60      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.89      0.90       200\n",
      "     neutral       0.95      0.94      0.95       315\n",
      "    positive       0.83      0.98      0.90        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.90      0.94      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89       162\n",
      "     neutral       0.94      0.98      0.96       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.89      0.75      0.80       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.78      0.80       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.96      0.97        74\n",
      "     neutral       0.99      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 376.96984028816223 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 2.225250136689283e-05\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 36\n",
      "Sampling duration: 2.0510973930358887 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4413, Accuracy: 0.8786, F1 Micro: 0.9277, F1 Macro: 0.9191\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2551, Accuracy: 0.945, F1 Micro: 0.9662, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1789, Accuracy: 0.9524, F1 Micro: 0.9708, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1412, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1144, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0937, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0811, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "Epoch 8/10, Train Loss: 0.0655, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9758\n",
      "Epoch 9/10, Train Loss: 0.0554, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0479, Accuracy: 0.9675, F1 Micro: 0.9799, F1 Macro: 0.9779\n",
      "\n",
      "Aspect detection accuracy: 0.9675, F1 Micro: 0.9799, F1 Macro: 0.9779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.96      0.99      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.99      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3392, Accuracy: 0.8729, F1 Micro: 0.8729, F1 Macro: 0.8209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1805, Accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.8638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1266, Accuracy: 0.9156, F1 Micro: 0.9156, F1 Macro: 0.8888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0936, Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.898\n",
      "Epoch 5/10, Train Loss: 0.082, Accuracy: 0.9212, F1 Micro: 0.9212, F1 Macro: 0.8946\n",
      "Epoch 6/10, Train Loss: 0.0547, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.8953\n",
      "Epoch 7/10, Train Loss: 0.0421, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.889\n",
      "Epoch 8/10, Train Loss: 0.0379, Accuracy: 0.9165, F1 Micro: 0.9165, F1 Macro: 0.8919\n",
      "Epoch 9/10, Train Loss: 0.025, Accuracy: 0.9165, F1 Micro: 0.9165, F1 Macro: 0.8932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0255, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9008\n",
      "\n",
      "Sentiment analysis accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       778\n",
      "    positive       0.94      0.78      0.85       300\n",
      "\n",
      "    accuracy                           0.92      1078\n",
      "   macro avg       0.93      0.88      0.90      1078\n",
      "weighted avg       0.93      0.92      0.92      1078\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.962, F1 Micro: 0.962, F1 Macro: 0.8859\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.96      0.99      0.97       496\n",
      "    positive       0.88      0.74      0.80        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.67      0.74       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.75      0.79       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 387.4679973125458 s\n",
      "Total runtime: 8428.807722330093 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6765788,
     "sourceId": 10888066,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7419.248438,
   "end_time": "2025-03-30T10:01:00.273829",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-30T07:57:21.025391",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0527ef74fafb4bcda86055487013c8e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1e1b0a0701214d46bb4b70be637d55d0",
       "placeholder": "",
       "style": "IPY_MODEL_bd6bb1d14a5a444596394f6f7a8dc62d",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt:100%"
      }
     },
     "0c27afb85ea947ceba7ddb6928cde790": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0f7321cc60b042a99ff5f3d104dabcad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1786d9924a834fdd923ae3cd18cb6b5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fe238a50043f430583f3f591ff6d6cbf",
       "placeholder": "",
       "style": "IPY_MODEL_78a365cf28cb4ac4ac80897e7578efc6",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:100%"
      }
     },
     "1898e9b6be54428598a917885a4c1974": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1dedb86a1fbe4b5380792b324c24912e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1786d9924a834fdd923ae3cd18cb6b5c",
        "IPY_MODEL_53e4eefcf4e04b4c84f459645e232619",
        "IPY_MODEL_59ebd458c2514ec68d663558e3252487"
       ],
       "layout": "IPY_MODEL_df77f0879a204041b15ea226a2c45151",
       "tabbable": null,
       "tooltip": null
      }
     },
     "1e1b0a0701214d46bb4b70be637d55d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1f53ede33d974c4197f592406b144269": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1898e9b6be54428598a917885a4c1974",
       "placeholder": "",
       "style": "IPY_MODEL_c7b25eeebf394489adf493b6c14f480e",
       "tabbable": null,
       "tooltip": null,
       "value": "112/112[00:00&lt;00:00,11.3kB/s]"
      }
     },
     "25680e156cb545128d4f35657b248cc6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2a9717a1a0ba4a83a3a3c3162b0e3720",
       "placeholder": "",
       "style": "IPY_MODEL_e23202491d0a410386b9f97466d47cdd",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json:100%"
      }
     },
     "296c8edbce5941aaab44dabffcdfc0ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2a9717a1a0ba4a83a3a3c3162b0e3720": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c4903dfdc884853bd9a48d4c5ac4a90": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3007df1462c948359cf91908cf797db7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "34499787d7ba4fdda0f61ae2dd02dc6f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3cb19dc9e41b40608ad41c6066a5474a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "420f577222a2440f98c72ecdb4a2d100": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_95f031fe87fb45e59812690b1a617268",
        "IPY_MODEL_5a0881ac25e74bb0acd6267cb6a3146a",
        "IPY_MODEL_88e1e1704a8f423da7eaba4c045e0ee0"
       ],
       "layout": "IPY_MODEL_2c4903dfdc884853bd9a48d4c5ac4a90",
       "tabbable": null,
       "tooltip": null
      }
     },
     "498176a25b344c398ca51e3fe8be6990": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4a12ff12c137461f85491aadbe298dbc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_59cc1677cba34e7091269e2846f5e651",
       "placeholder": "",
       "style": "IPY_MODEL_3cb19dc9e41b40608ad41c6066a5474a",
       "tabbable": null,
       "tooltip": null,
       "value": "229k/229k[00:00&lt;00:00,5.57MB/s]"
      }
     },
     "4c53f0cb86ca40a794f4f1f1a84442ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4ee11d61732f49ea971b54c7ca206258": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "53e4eefcf4e04b4c84f459645e232619": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0c27afb85ea947ceba7ddb6928cde790",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3007df1462c948359cf91908cf797db7",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     },
     "59cc1677cba34e7091269e2846f5e651": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "59ebd458c2514ec68d663558e3252487": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f52fd5267f5a4cc5993b24ff65d22220",
       "placeholder": "",
       "style": "IPY_MODEL_7a44101ce8524bb48fb94606c710cb15",
       "tabbable": null,
       "tooltip": null,
       "value": "1.53k/1.53k[00:00&lt;00:00,147kB/s]"
      }
     },
     "5a0881ac25e74bb0acd6267cb6a3146a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4c53f0cb86ca40a794f4f1f1a84442ff",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4ee11d61732f49ea971b54c7ca206258",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "6377619e7dd846ee9636e5918418eb05": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6cb98bcd14ad495c9d07993f530abf44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_25680e156cb545128d4f35657b248cc6",
        "IPY_MODEL_bd911c4259e1436aa237dde740ac968a",
        "IPY_MODEL_1f53ede33d974c4197f592406b144269"
       ],
       "layout": "IPY_MODEL_df9b4ad6946f4fa689450951fcaba47e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "78a365cf28cb4ac4ac80897e7578efc6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7a44101ce8524bb48fb94606c710cb15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "817ff77cb09c455a9bde3b62055e6ccb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "885e9426347c4779960f2191a74c1ec3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0527ef74fafb4bcda86055487013c8e1",
        "IPY_MODEL_e61f1cb13e4542d2b28f41637016d063",
        "IPY_MODEL_4a12ff12c137461f85491aadbe298dbc"
       ],
       "layout": "IPY_MODEL_817ff77cb09c455a9bde3b62055e6ccb",
       "tabbable": null,
       "tooltip": null
      }
     },
     "88e1e1704a8f423da7eaba4c045e0ee0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c7ef20ace5644677a0c898a0fa806fea",
       "placeholder": "",
       "style": "IPY_MODEL_b5b87b73160341228317630d689a1988",
       "tabbable": null,
       "tooltip": null,
       "value": "2.00/2.00[00:00&lt;00:00,169B/s]"
      }
     },
     "95f031fe87fb45e59812690b1a617268": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f1e3b16120634d3ba7f555f3b7946d74",
       "placeholder": "",
       "style": "IPY_MODEL_6377619e7dd846ee9636e5918418eb05",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:100%"
      }
     },
     "b5b87b73160341228317630d689a1988": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bd6bb1d14a5a444596394f6f7a8dc62d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bd911c4259e1436aa237dde740ac968a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0f7321cc60b042a99ff5f3d104dabcad",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_498176a25b344c398ca51e3fe8be6990",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "c7b25eeebf394489adf493b6c14f480e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c7ef20ace5644677a0c898a0fa806fea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "df77f0879a204041b15ea226a2c45151": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "df9b4ad6946f4fa689450951fcaba47e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e23202491d0a410386b9f97466d47cdd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e61f1cb13e4542d2b28f41637016d063": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_34499787d7ba4fdda0f61ae2dd02dc6f",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_296c8edbce5941aaab44dabffcdfc0ff",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "f1e3b16120634d3ba7f555f3b7946d74": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f52fd5267f5a4cc5993b24ff65d22220": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fe238a50043f430583f3f591ff6d6cbf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
