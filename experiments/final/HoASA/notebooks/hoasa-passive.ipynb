{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56abe4cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T11:29:13.144311Z",
     "iopub.status.busy": "2025-04-13T11:29:13.143983Z",
     "iopub.status.idle": "2025-04-13T11:29:50.735451Z",
     "shell.execute_reply": "2025-04-13T11:29:50.734740Z"
    },
    "papermill": {
     "duration": 37.598979,
     "end_time": "2025-04-13T11:29:50.737039",
     "exception": false,
     "start_time": "2025-04-13T11:29:13.138060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b57313e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T11:29:50.747309Z",
     "iopub.status.busy": "2025-04-13T11:29:50.746855Z",
     "iopub.status.idle": "2025-04-13T11:29:50.750042Z",
     "shell.execute_reply": "2025-04-13T11:29:50.749438Z"
    },
    "papermill": {
     "duration": 0.009319,
     "end_time": "2025-04-13T11:29:50.751252",
     "exception": false,
     "start_time": "2025-04-13T11:29:50.741933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0cd1289",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T11:29:50.760629Z",
     "iopub.status.busy": "2025-04-13T11:29:50.760428Z",
     "iopub.status.idle": "2025-04-13T11:29:50.773572Z",
     "shell.execute_reply": "2025-04-13T11:29:50.772808Z"
    },
    "papermill": {
     "duration": 0.019087,
     "end_time": "2025-04-13T11:29:50.774732",
     "exception": false,
     "start_time": "2025-04-13T11:29:50.755645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "312c4416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T11:29:50.783708Z",
     "iopub.status.busy": "2025-04-13T11:29:50.783484Z",
     "iopub.status.idle": "2025-04-13T11:29:50.872951Z",
     "shell.execute_reply": "2025-04-13T11:29:50.872153Z"
    },
    "papermill": {
     "duration": 0.095312,
     "end_time": "2025-04-13T11:29:50.874293",
     "exception": false,
     "start_time": "2025-04-13T11:29:50.778981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>ac</th>\n",
       "      <th>air_panas</th>\n",
       "      <th>bau</th>\n",
       "      <th>general</th>\n",
       "      <th>kebersihan</th>\n",
       "      <th>linen</th>\n",
       "      <th>service</th>\n",
       "      <th>sunrise_meal</th>\n",
       "      <th>tv</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kebersihan kurang...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sangat mengecewakan... hotel bad image, kebers...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tempat nyaman bersih tapi tv terlalu tinggi ti...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>pos</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>semuanya bagus sesuai profile,dan harga promo ...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>pos</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tempat tidur sangat keras, bantal besar dan ke...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review    ac air_panas   bau  \\\n",
       "0                               kebersihan kurang...  neut      neut  neut   \n",
       "1  sangat mengecewakan... hotel bad image, kebers...  neut      neut  neut   \n",
       "2  Tempat nyaman bersih tapi tv terlalu tinggi ti...  neut      neut  neut   \n",
       "3  semuanya bagus sesuai profile,dan harga promo ...  neut       neg  neut   \n",
       "4  Tempat tidur sangat keras, bantal besar dan ke...   neg       neg  neut   \n",
       "\n",
       "  general kebersihan linen service sunrise_meal    tv  wifi  \n",
       "0    neut        neg  neut    neut         neut  neut  neut  \n",
       "1    neut        neg  neut    neut         neut  neut  neut  \n",
       "2    neut        pos  neut    neut         neut   neg  neut  \n",
       "3     pos       neut  neut    neut         neut  neut  neut  \n",
       "4    neut       neut   neg    neut         neut  neut  neut  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/hoasa-dataset/train_preprocess.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/hoasa-dataset/valid_preprocess.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('/kaggle/input/hoasa-dataset/test_preprocess.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data, test_data], ignore_index=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d383909",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T11:29:50.884504Z",
     "iopub.status.busy": "2025-04-13T11:29:50.884304Z",
     "iopub.status.idle": "2025-04-13T11:29:50.893345Z",
     "shell.execute_reply": "2025-04-13T11:29:50.892808Z"
    },
    "papermill": {
     "duration": 0.015629,
     "end_time": "2025-04-13T11:29:50.894627",
     "exception": false,
     "start_time": "2025-04-13T11:29:50.878998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "538d136a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T11:29:50.903988Z",
     "iopub.status.busy": "2025-04-13T11:29:50.903737Z",
     "iopub.status.idle": "2025-04-13T11:29:50.920815Z",
     "shell.execute_reply": "2025-04-13T11:29:50.920189Z"
    },
    "papermill": {
     "duration": 0.023035,
     "end_time": "2025-04-13T11:29:50.922041",
     "exception": false,
     "start_time": "2025-04-13T11:29:50.899006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2283,) (2283, 10)\n",
      "(571,) (571, 10)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[1:]\n",
    "val_labels = val_data.columns[1:]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['review'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['review'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2556886a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T11:29:50.931606Z",
     "iopub.status.busy": "2025-04-13T11:29:50.931397Z",
     "iopub.status.idle": "2025-04-13T11:29:50.935447Z",
     "shell.execute_reply": "2025-04-13T11:29:50.934745Z"
    },
    "papermill": {
     "duration": 0.01018,
     "end_time": "2025-04-13T11:29:50.936695",
     "exception": false,
     "start_time": "2025-04-13T11:29:50.926515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "aspect_list = ['ac', 'air_panas', 'bau', 'general', 'kebersihan', 'linen', 'service', 'sunrise_meal', 'tv', 'wifi']\n",
    "aspect_mapping = {'ac': 0, 'air_panas': 1, 'bau': 2, 'general': 3, 'kebersihan': 4, 'linen': 5, 'service': 6, 'sunrise_meal': 7, 'tv': 8, 'wifi': 9}\n",
    "label_mapping = {\"neg\": 0, \"neut\": 1, 'neg_pos': 1, 'pos': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c5f293a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T11:29:50.946333Z",
     "iopub.status.busy": "2025-04-13T11:29:50.946124Z",
     "iopub.status.idle": "2025-04-13T11:29:50.951613Z",
     "shell.execute_reply": "2025-04-13T11:29:50.950989Z"
    },
    "papermill": {
     "duration": 0.011458,
     "end_time": "2025-04-13T11:29:50.952736",
     "exception": false,
     "start_time": "2025-04-13T11:29:50.941278",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AspectDetectionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, label_mapping, tokenizer, max_length=96, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        \n",
    "        original_labels = [self.label_mapping[label] for label in self.labels[idx]]\n",
    "        encoded_labels = [1 if label == 1 else 0 for label in original_labels]\n",
    "        \n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['ori_indices'] = idx\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(original_labels, dtype=torch.float)\n",
    "        item['labels'] = torch.tensor(encoded_labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16d71b11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T11:29:50.962399Z",
     "iopub.status.busy": "2025-04-13T11:29:50.962202Z",
     "iopub.status.idle": "2025-04-13T11:29:50.968888Z",
     "shell.execute_reply": "2025-04-13T11:29:50.968186Z"
    },
    "papermill": {
     "duration": 0.012748,
     "end_time": "2025-04-13T11:29:50.970128",
     "exception": false,
     "start_time": "2025-04-13T11:29:50.957380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, texts, labels, aspects, indices, label_mapping, tokenizer, max_length=96, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.aspects = aspects\n",
    "        self.indices = indices\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = aspect_token + ' ' + self.aspects[idx] + ' ' + review_token + ' ' + self.texts[idx] \n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        if isinstance(self.labels[idx], str):\n",
    "            self.labels[idx] = self.label_mapping[self.labels[idx]]\n",
    "        elif torch.is_tensor(self.labels[idx]):\n",
    "            self.labels[idx] = int(self.labels[idx].item())\n",
    "\n",
    "        encoded_label = 1 if self.labels[idx] == 2 else self.labels[idx]\n",
    "        one_hot_label = F.one_hot(torch.tensor(encoded_label, dtype=torch.long), num_classes=2).float()\n",
    "\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['aspect'] = self.aspects[idx]\n",
    "        item['labels'] = one_hot_label\n",
    "        item['ori_indices'] = self.indices[idx]\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc053f7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T11:29:50.979680Z",
     "iopub.status.busy": "2025-04-13T11:29:50.979465Z",
     "iopub.status.idle": "2025-04-13T11:29:51.706525Z",
     "shell.execute_reply": "2025-04-13T11:29:51.705843Z"
    },
    "papermill": {
     "duration": 0.733651,
     "end_time": "2025-04-13T11:29:51.708141",
     "exception": false,
     "start_time": "2025-04-13T11:29:50.974490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f6459e26684a58865857359398a1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9576078bc90d41e39633e833331c87a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a7dd2921134916b44ef499bea2b6be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2894a5f6104efb88942ff83271b39d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "review_token = '[REVIEW]'\n",
    "aspect_token = '[ASPECT]'\n",
    "special_tokens_dict = {'additional_special_tokens': [review_token, aspect_token]}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c36fdcd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T11:29:51.719865Z",
     "iopub.status.busy": "2025-04-13T11:29:51.719589Z",
     "iopub.status.idle": "2025-04-13T11:29:51.724322Z",
     "shell.execute_reply": "2025-04-13T11:29:51.723519Z"
    },
    "papermill": {
     "duration": 0.011778,
     "end_time": "2025-04-13T11:29:51.725576",
     "exception": false,
     "start_time": "2025-04-13T11:29:51.713798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = 42 + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    \n",
    "def build_aspect_dataset(sequence_length, num_workers=4):\n",
    "    train_dataset = AspectDetectionDataset(X_train, y_train, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = AspectDetectionDataset(X_val, y_val, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=num_workers, worker_init_fn=seed_worker\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=num_workers, worker_init_fn=seed_worker\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "505947e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T11:29:51.736347Z",
     "iopub.status.busy": "2025-04-13T11:29:51.736113Z",
     "iopub.status.idle": "2025-04-13T11:29:51.745983Z",
     "shell.execute_reply": "2025-04-13T11:29:51.745329Z"
    },
    "papermill": {
     "duration": 0.016597,
     "end_time": "2025-04-13T11:29:51.747224",
     "exception": false,
     "start_time": "2025-04-13T11:29:51.730627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sentiment_dataset(device, train_dataset, val_dataset, aspect_detection_model, tokenizer, max_length=96):\n",
    "    ignored_keys = ['labels', 'ori_text', 'ori_label', 'ori_indices', 'aspect']\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=4, worker_init_fn=seed_worker,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=4, worker_init_fn=seed_worker,\n",
    "    )\n",
    "\n",
    "    aspect_detection_model.to(device)\n",
    "    aspect_detection_model.eval()\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    train_aspects = []\n",
    "    train_indices = []\n",
    "\n",
    "    val_data = []\n",
    "    val_labels = []\n",
    "    val_aspects = []\n",
    "    val_indices = []\n",
    "\n",
    "    # Transform train set\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        train_aspects.append(aspect_list[j])\n",
    "                        train_data.append(batch['ori_text'][i])\n",
    "                        train_labels.append(batch['ori_label'][i][j])\n",
    "                        train_indices.append(batch['ori_indices'][i])\n",
    "            \n",
    "        # Transform validation set\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        val_aspects.append(aspect_list[j])\n",
    "                        val_data.append(batch['ori_text'][i])\n",
    "                        val_labels.append(batch['ori_label'][i][j])\n",
    "                        val_indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    train_dataset = SentimentAnalysisDataset(train_data, train_labels, train_aspects, train_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "    val_dataset = SentimentAnalysisDataset(val_data, val_labels, val_aspects, val_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=4, worker_init_fn=seed_worker,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=4, worker_init_fn=seed_worker,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddb7bff7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T11:29:51.757905Z",
     "iopub.status.busy": "2025-04-13T11:29:51.757663Z",
     "iopub.status.idle": "2025-04-13T11:29:51.761934Z",
     "shell.execute_reply": "2025-04-13T11:29:51.761293Z"
    },
    "papermill": {
     "duration": 0.011009,
     "end_time": "2025-04-13T11:29:51.763194",
     "exception": false,
     "start_time": "2025-04-13T11:29:51.752185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p, classes):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Accuracy: proportion of correctly predicted labels over total labels\n",
    "    accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        target_names=classes,\n",
    "        zero_division=0\n",
    "    ) \n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ab2d9a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T11:29:51.774326Z",
     "iopub.status.busy": "2025-04-13T11:29:51.774129Z",
     "iopub.status.idle": "2025-04-13T11:29:51.780289Z",
     "shell.execute_reply": "2025-04-13T11:29:51.779512Z"
    },
    "papermill": {
     "duration": 0.012866,
     "end_time": "2025-04-13T11:29:51.781518",
     "exception": false,
     "start_time": "2025-04-13T11:29:51.768652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics_overall(p, classes):\n",
    "    preds = torch.tensor(p.predictions)\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Ensure it's in the correct shape\n",
    "    if preds.shape != labels.shape:\n",
    "        raise ValueError(\"Shape mismatch: predictions and labels must have the same shape.\")\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Compute per-label (column-wise) precision, recall, F1\n",
    "    precision_list, recall_list, f1_micro_list, f1_macro_list = [], [], [], []\n",
    "    \n",
    "    for i in range(labels.shape[1]):  # Loop through each column (multi-output)\n",
    "        prec, rec, f1_micro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='micro', zero_division=0\n",
    "        )\n",
    "        _, _, f1_macro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='macro', zero_division=0\n",
    "        )\n",
    "\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        f1_micro_list.append(f1_micro)\n",
    "        f1_macro_list.append(f1_macro)\n",
    "\n",
    "    # Compute average metrics across all outputs\n",
    "    precision = sum(precision_list) / len(precision_list)\n",
    "    recall = sum(recall_list) / len(recall_list)\n",
    "    f1_micro = sum(f1_micro_list) / len(f1_micro_list)\n",
    "    f1_macro = sum(f1_macro_list) / len(f1_macro_list)\n",
    "\n",
    "    # Generate classification report per output\n",
    "    reports = [classification_report(labels[:, i], preds[:, i], target_names=classes, zero_division=0) for i in range(labels.shape[1])]\n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'reports': reports  # Returns list of reports, one for each output label\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7746a43c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T11:29:51.792359Z",
     "iopub.status.busy": "2025-04-13T11:29:51.792153Z",
     "iopub.status.idle": "2025-04-13T11:29:51.857541Z",
     "shell.execute_reply": "2025-04-13T11:29:51.855979Z"
    },
    "papermill": {
     "duration": 0.072467,
     "end_time": "2025-04-13T11:29:51.859363",
     "exception": false,
     "start_time": "2025-04-13T11:29:51.786896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "aspect_accuracies = manager.list()\n",
    "aspect_f1_micros = manager.list()\n",
    "aspect_f1_macros = manager.list()\n",
    "\n",
    "sentiment_accuracies = manager.list()\n",
    "sentiment_f1_micros = manager.list()\n",
    "sentiment_f1_macros = manager.list()\n",
    "\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "975f4dce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T11:29:51.871288Z",
     "iopub.status.busy": "2025-04-13T11:29:51.871008Z",
     "iopub.status.idle": "2025-04-13T11:29:51.902244Z",
     "shell.execute_reply": "2025-04-13T11:29:51.901659Z"
    },
    "papermill": {
     "duration": 0.038819,
     "end_time": "2025-04-13T11:29:51.903473",
     "exception": false,
     "start_time": "2025-04-13T11:29:51.864654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(sequence_length, model_name, aspect_metrics, sentiment_metrics, metrics, seed=42, layers_freezed=6, trials=1):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "    ignored_keys = ['labels', 'ori_text', 'ori_label', 'ori_indices', 'aspect']\n",
    "\n",
    "    # Define model\n",
    "    aspect_model = BertForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "\n",
    "    for name, param in aspect_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    aspect_optimizer = torch.optim.AdamW(aspect_model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    aspect_train_loader, aspect_val_loader, aspect_train_dataset, aspect_val_dataset = build_aspect_dataset(sequence_length)\n",
    "    aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader = accelerator.prepare(\n",
    "        aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader\n",
    "    )\n",
    "\n",
    "    aspect_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ASPECT DETECTION\n",
    "    accelerator.print(\"ASPECT DETECTION\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        aspect_model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in aspect_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            aspect_optimizer.zero_grad()\n",
    "            outputs = aspect_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            aspect_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        aspect_model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in aspect_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = aspect_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "                \n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "        \n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}),\n",
    "            aspect_list\n",
    "        )\n",
    "\n",
    "        if aspect_result is None or result['f1_micro'] >= aspect_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            aspect_result = result\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(aspect_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'aspect-model-{sequence_length}-{layers_freezed}-{trials}',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{EPOCHS}, Train Loss: {round(epoch_loss / len(aspect_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"\\nAspect detection accuracy: {round(aspect_result['accuracy'], 4)}, F1 Micro: {round(aspect_result['f1_micro'], 4)}, F1 Macro: {round(aspect_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(aspect_result['report'])\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        aspect_metrics[0].append(aspect_result['accuracy'])\n",
    "        aspect_metrics[1].append(aspect_result['f1_micro'])\n",
    "        aspect_metrics[2].append(aspect_result['f1_macro'])\n",
    "\n",
    "    best_aspect_model = BertForSequenceClassification.from_pretrained(f'aspect-model-{sequence_length}-{layers_freezed}-{trials}')\n",
    "    best_aspect_model = accelerator.prepare(best_aspect_model)\n",
    "\n",
    "    # SENTIMENT ANALYSIS ON NON NEUTRAL ASPECTS\n",
    "    accelerator.print(\"-------------------------\")\n",
    "    accelerator.print(\"SENTIMENT ANALYSIS\")\n",
    "\n",
    "    sentiment_model = BertForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=2,\n",
    "    )\n",
    "    sentiment_optimizer = torch.optim.AdamW(sentiment_model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "\n",
    "    for name, param in sentiment_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    sentiment_train_loader, sentiment_val_loader, sentiment_train_dataset, sentiment_val_dataset = build_sentiment_dataset(\n",
    "        device, aspect_train_dataset, aspect_val_dataset, best_aspect_model, tokenizer, max_length=sequence_length\n",
    "    )\n",
    "    sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader = accelerator.prepare(\n",
    "        sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader\n",
    "    )\n",
    "    sentiment_result = None\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        sentiment_model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in sentiment_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            sentiment_optimizer.zero_grad()\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            sentiment_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        sentiment_model.eval()\n",
    "        sentiment_val_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in sentiment_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                \n",
    "                outputs = sentiment_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                for i in range(len(preds)):\n",
    "                    val_output = {\n",
    "                        'label': batch['labels'][i],\n",
    "                        'aspect': batch['aspect'][i],\n",
    "                        'ori_indices': batch['ori_indices'][i],\n",
    "                        'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                    }\n",
    "                    sentiment_val_outputs.append(val_output)\n",
    "\n",
    "        # accelerator.print(\"Before gathering:\", sentiment_val_outputs[0])\n",
    "        sentiment_val_outputs = accelerator.gather_for_metrics(sentiment_val_outputs)\n",
    "        # accelerator.print(\"After gathering:\", sentiment_val_outputs[0])\n",
    "        unique_val_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_val_outputs}\n",
    "        sentiment_val_outputs = list(unique_val_outputs.values())\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': [item['pred'] for item in sentiment_val_outputs], 'label_ids': [np.argmax(item['label'].cpu().numpy()) for item in sentiment_val_outputs]}),\n",
    "            ['negative', 'positive']\n",
    "        )\n",
    "        \n",
    "        # result = compute_metrics_sentiment(type('EvalOutput', (object,), {'predictions': [item['pred'] for item in sentiment_val_outputs], 'label_ids': [np.argmax(item['label'].cpu().numpy()) for item in sentiment_val_outputs]}))\n",
    "\n",
    "        if sentiment_result is None or result['f1_micro'] >= sentiment_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            sentiment_result = result\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(sentiment_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'sentiment-model-{sequence_length}-{layers_freezed}-{trials}',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{EPOCHS}, Train Loss: {round(epoch_loss / len(sentiment_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    accelerator.print(f\"\\nSentiment analysis accuracy: {round(sentiment_result['accuracy'], 4)}, F1 Micro: {round(sentiment_result['f1_micro'], 4)}, F1 Macro: {round(sentiment_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(sentiment_result['report'])\n",
    "    \n",
    "    if accelerator.is_main_process:\n",
    "        sentiment_metrics[0].append(sentiment_result['accuracy'])\n",
    "        sentiment_metrics[1].append(sentiment_result['f1_micro'])\n",
    "        sentiment_metrics[2].append(sentiment_result['f1_macro'])\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    best_sentiment_model = BertForSequenceClassification.from_pretrained(f'sentiment-model-{sequence_length}-{layers_freezed}-{trials}')\n",
    "    best_sentiment_model = accelerator.prepare(best_sentiment_model)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    aspect_labels = []\n",
    "    aspect_indices = []\n",
    "    aspect_preds = []\n",
    "\n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = []\n",
    "    \n",
    "    best_aspect_model.eval()\n",
    "    best_sentiment_model.eval()\n",
    "\n",
    "    # if accelerator.is_main_process:\n",
    "    with torch.no_grad():\n",
    "        # x = 0\n",
    "        for batch in aspect_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_aspect_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            aspect_indices.append(accelerator.gather(batch['ori_indices']))\n",
    "            aspect_labels.append(accelerator.gather(batch['ori_label']))\n",
    "            aspect_preds.append(accelerator.gather(preds))\n",
    "\n",
    "        aspect_indices = torch.cat(aspect_indices).cpu().numpy()\n",
    "        aspect_labels = torch.cat(aspect_labels).cpu().numpy()\n",
    "        aspect_preds = torch.cat(aspect_preds).cpu().numpy()\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        aspect_outputs = [\n",
    "            {'ori_indices': aspect_indices[i], \n",
    "             'ori_labels': aspect_labels[i], \n",
    "             'pred': aspect_preds[i]}\n",
    "            for i in range(len(aspect_preds))\n",
    "        ]\n",
    "        aspect_outputs = {x['ori_indices'].item(): x for x in aspect_outputs}\n",
    "    \n",
    "        for batch in sentiment_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_sentiment_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "    \n",
    "            for i in range(len(preds)):\n",
    "                output = {\n",
    "                    'aspect': batch['aspect'][i],\n",
    "                    'ori_indices': batch['ori_indices'][i],\n",
    "                    'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                }\n",
    "                sentiment_outputs.append(output)\n",
    "\n",
    "        sentiment_outputs = accelerator.gather_for_metrics(sentiment_outputs)\n",
    "        sentiment_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_outputs}\n",
    "\n",
    "    # Replcae non neutral aspect to its predicted sentiment\n",
    "    if accelerator.is_main_process:\n",
    "        i = -1\n",
    "        for (ori_index, aspect), value in sentiment_outputs.items():\n",
    "            aspect = aspect_mapping[aspect]\n",
    "            aspect_outputs[ori_index]['pred'][aspect] = 2 if value['pred'] == 1.0 else value['pred']\n",
    "\n",
    "        result = compute_metrics_overall(\n",
    "            type('EvalOutput', (object,), {'predictions': [output['pred'] for output in aspect_outputs.values()], 'label_ids': [output['ori_labels'] for output in aspect_outputs.values()]}),\n",
    "            ['negative', 'neutral', 'positive'],\n",
    "        )\n",
    "\n",
    "        accelerator.print(\"-------------------------\")\n",
    "        accelerator.print(f\"Overall accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "        for i in range(len(train_labels)):\n",
    "            accelerator.print(f\"Aspect {aspect_list[i]} report:\")\n",
    "            accelerator.print(result['reports'][i])\n",
    "            \n",
    "    \n",
    "        if accelerator.is_main_process:\n",
    "            metrics[0].append(result['accuracy'])\n",
    "            metrics[1].append(result['f1_micro'])\n",
    "            metrics[2].append(result['f1_macro'])\n",
    "    \n",
    "    accelerator.print(f\"Total train time: {duration} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9102eab6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T11:29:51.914545Z",
     "iopub.status.busy": "2025-04-13T11:29:51.914337Z",
     "iopub.status.idle": "2025-04-13T11:29:52.884252Z",
     "shell.execute_reply": "2025-04-13T11:29:52.883390Z"
    },
    "papermill": {
     "duration": 0.976792,
     "end_time": "2025-04-13T11:29:52.885574",
     "exception": false,
     "start_time": "2025-04-13T11:29:51.908782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of tokenized text: 24.516863775733682\n",
      "Max token length: 183\n"
     ]
    }
   ],
   "source": [
    "# Tokenize each text and calculate their lengths\n",
    "token_lengths = [len(tokenizer.tokenize(text)) for text in X_train]\n",
    "\n",
    "# Calculate the average length\n",
    "average_length = sum(token_lengths) / len(token_lengths)\n",
    "max_length = max(token_lengths)\n",
    "\n",
    "print(\"Average length of tokenized text:\", average_length)\n",
    "print(\"Max token length:\", max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8872cc33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T11:29:52.896868Z",
     "iopub.status.busy": "2025-04-13T11:29:52.896599Z",
     "iopub.status.idle": "2025-04-13T11:29:53.209555Z",
     "shell.execute_reply": "2025-04-13T11:29:53.208605Z"
    },
    "papermill": {
     "duration": 0.320065,
     "end_time": "2025-04-13T11:29:53.210996",
     "exception": false,
     "start_time": "2025-04-13T11:29:52.890931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts, bins = np.histogram(token_lengths, range=(0, 100))\n",
    "plt.stairs(counts, bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2507bce0",
   "metadata": {
    "papermill": {
     "duration": 0.005121,
     "end_time": "2025-04-13T11:29:53.221595",
     "exception": false,
     "start_time": "2025-04-13T11:29:53.216474",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a4c41f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T11:29:53.232959Z",
     "iopub.status.busy": "2025-04-13T11:29:53.232668Z",
     "iopub.status.idle": "2025-04-13T12:43:05.711208Z",
     "shell.execute_reply": "2025-04-13T12:43:05.710168Z"
    },
    "papermill": {
     "duration": 4392.486237,
     "end_time": "2025-04-13T12:43:05.712972",
     "exception": false,
     "start_time": "2025-04-13T11:29:53.226735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "Batch size: 8, sequence length: 24\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3733, Accuracy: 0.9165, F1 Micro: 0.9498, F1 Macro: 0.9471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2449, Accuracy: 0.9347, F1 Micro: 0.9603, F1 Macro: 0.9576\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1919, Accuracy: 0.9382, F1 Micro: 0.9623, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1578, Accuracy: 0.9401, F1 Micro: 0.9634, F1 Macro: 0.9605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1296, Accuracy: 0.9411, F1 Micro: 0.9637, F1 Macro: 0.9598\n",
      "Epoch 6/10, Train Loss: 0.1037, Accuracy: 0.9401, F1 Micro: 0.9631, F1 Macro: 0.9597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0779, Accuracy: 0.9417, F1 Micro: 0.9642, F1 Macro: 0.9613\n",
      "Epoch 8/10, Train Loss: 0.0634, Accuracy: 0.9394, F1 Micro: 0.9626, F1 Macro: 0.9594\n",
      "Epoch 9/10, Train Loss: 0.0471, Accuracy: 0.9396, F1 Micro: 0.9628, F1 Macro: 0.9595\n",
      "Epoch 10/10, Train Loss: 0.0373, Accuracy: 0.9408, F1 Micro: 0.9635, F1 Macro: 0.9603\n",
      "\n",
      "Aspect detection accuracy: 0.9417, F1 Micro: 0.9642, F1 Macro: 0.9613\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.97      0.99      0.98       462\n",
      "   air_panas       0.95      0.99      0.97       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.91      0.99      0.95       500\n",
      "  kebersihan       0.89      0.93      0.91       317\n",
      "       linen       0.90      0.95      0.93       392\n",
      "     service       0.94      0.95      0.95       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.98      0.99      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      4614\n",
      "   macro avg       0.95      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.96      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "-------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3376, Accuracy: 0.8494, F1 Micro: 0.8494, F1 Macro: 0.7931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2036, Accuracy: 0.8678, F1 Micro: 0.8678, F1 Macro: 0.8193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1614, Accuracy: 0.8718, F1 Micro: 0.8718, F1 Macro: 0.8244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1354, Accuracy: 0.8769, F1 Micro: 0.8769, F1 Macro: 0.8366\n",
      "Epoch 5/10, Train Loss: 0.0937, Accuracy: 0.8759, F1 Micro: 0.8759, F1 Macro: 0.8323\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0887, Accuracy: 0.881, F1 Micro: 0.881, F1 Macro: 0.8429\n",
      "Epoch 7/10, Train Loss: 0.0608, Accuracy: 0.8739, F1 Micro: 0.8739, F1 Macro: 0.8337\n",
      "Epoch 8/10, Train Loss: 0.0447, Accuracy: 0.8749, F1 Micro: 0.8749, F1 Macro: 0.8361\n",
      "Epoch 9/10, Train Loss: 0.051, Accuracy: 0.8769, F1 Micro: 0.8769, F1 Macro: 0.8311\n",
      "Epoch 10/10, Train Loss: 0.0368, Accuracy: 0.8779, F1 Micro: 0.8779, F1 Macro: 0.8355\n",
      "\n",
      "Sentiment analysis accuracy: 0.881, F1 Micro: 0.881, F1 Macro: 0.8429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92       703\n",
      "    positive       0.87      0.68      0.77       280\n",
      "\n",
      "    accuracy                           0.88       983\n",
      "   macro avg       0.88      0.82      0.84       983\n",
      "weighted avg       0.88      0.88      0.88       983\n",
      "\n",
      "-------------------------\n",
      "Overall accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.7803\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        97\n",
      "     neutral       0.97      0.99      0.98       459\n",
      "    positive       0.87      0.87      0.87        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.69      0.78        86\n",
      "     neutral       0.95      0.99      0.97       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.80      0.69      0.74       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.73      0.78        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.74      0.80       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.91      0.99      0.95       496\n",
      "    positive       0.80      0.41      0.54        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.57      0.47      0.50       571\n",
      "weighted avg       0.89      0.91      0.89       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.81      0.84       200\n",
      "     neutral       0.89      0.93      0.91       315\n",
      "    positive       0.82      0.82      0.82        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.86      0.85      0.86       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.80      0.83       162\n",
      "     neutral       0.90      0.95      0.93       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.85      0.71      0.75       571\n",
      "weighted avg       0.89      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.73      0.77        85\n",
      "     neutral       0.94      0.95      0.95       418\n",
      "    positive       0.80      0.82      0.81        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.84      0.84       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.31      0.44        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.81      0.67      0.71       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.89      0.92        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.91      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.86      0.90        74\n",
      "     neutral       0.98      0.99      0.99       494\n",
      "    positive       0.33      0.33      0.33         3\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.75      0.73      0.74       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Total train time: 673.9152600765228 s\n",
      "=========================================================================================\n",
      "Batch size: 8, sequence length: 32\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3694, Accuracy: 0.922, F1 Micro: 0.9528, F1 Macro: 0.9501\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.22, Accuracy: 0.9432, F1 Micro: 0.9652, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1639, Accuracy: 0.9484, F1 Micro: 0.9683, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1286, Accuracy: 0.9526, F1 Micro: 0.9708, F1 Macro: 0.9681\n",
      "Epoch 5/10, Train Loss: 0.1021, Accuracy: 0.9512, F1 Micro: 0.9698, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0791, Accuracy: 0.9535, F1 Micro: 0.9711, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0608, Accuracy: 0.9536, F1 Micro: 0.9713, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0485, Accuracy: 0.9538, F1 Micro: 0.9715, F1 Macro: 0.9691\n",
      "Epoch 9/10, Train Loss: 0.0361, Accuracy: 0.9536, F1 Micro: 0.9713, F1 Macro: 0.9686\n",
      "Epoch 10/10, Train Loss: 0.0287, Accuracy: 0.953, F1 Micro: 0.9709, F1 Macro: 0.9685\n",
      "\n",
      "Aspect detection accuracy: 0.9538, F1 Micro: 0.9715, F1 Macro: 0.9691\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.96      0.99      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.91      0.94      0.93       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.95      0.96       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "-------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.319, Accuracy: 0.8721, F1 Micro: 0.8721, F1 Macro: 0.8286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2072, Accuracy: 0.8837, F1 Micro: 0.8837, F1 Macro: 0.8488\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1383, Accuracy: 0.8953, F1 Micro: 0.8953, F1 Macro: 0.8646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1146, Accuracy: 0.9021, F1 Micro: 0.9021, F1 Macro: 0.8697\n",
      "Epoch 5/10, Train Loss: 0.0859, Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.8679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0603, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8775\n",
      "Epoch 7/10, Train Loss: 0.0499, Accuracy: 0.9002, F1 Micro: 0.9002, F1 Macro: 0.8674\n",
      "Epoch 8/10, Train Loss: 0.0312, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.8641\n",
      "Epoch 9/10, Train Loss: 0.0476, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.8765\n",
      "Epoch 10/10, Train Loss: 0.0219, Accuracy: 0.9041, F1 Micro: 0.9041, F1 Macro: 0.8754\n",
      "\n",
      "Sentiment analysis accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       737\n",
      "    positive       0.93      0.73      0.82       295\n",
      "\n",
      "    accuracy                           0.91      1032\n",
      "   macro avg       0.92      0.85      0.88      1032\n",
      "weighted avg       0.91      0.91      0.90      1032\n",
      "\n",
      "-------------------------\n",
      "Overall accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.8231\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.92      0.93        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.87      0.87      0.87        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.79      0.86        86\n",
      "     neutral       0.97      1.00      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.76      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.72      0.79        78\n",
      "     neutral       0.95      0.99      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.73      0.81       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.80      0.59      0.68        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.58      0.52      0.55       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.88       200\n",
      "     neutral       0.91      0.94      0.93       315\n",
      "    positive       0.89      0.89      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.90      0.90       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.86       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.69      0.50      0.58        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.83      0.76      0.79       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.82        85\n",
      "     neutral       0.97      0.95      0.96       418\n",
      "    positive       0.88      0.87      0.87        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.88      0.89      0.88       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.48      0.58        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.92      0.65      0.76        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.71      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.97      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.99      0.75      0.81       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 704.1990256309509 s\n",
      "=========================================================================================\n",
      "Batch size: 8, sequence length: 40\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3652, Accuracy: 0.9266, F1 Micro: 0.9555, F1 Macro: 0.9528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2067, Accuracy: 0.9479, F1 Micro: 0.968, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1507, Accuracy: 0.9531, F1 Micro: 0.9712, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1174, Accuracy: 0.9563, F1 Micro: 0.973, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0935, Accuracy: 0.9587, F1 Micro: 0.9743, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0719, Accuracy: 0.9599, F1 Micro: 0.9751, F1 Macro: 0.9726\n",
      "Epoch 7/10, Train Loss: 0.0564, Accuracy: 0.9556, F1 Micro: 0.9725, F1 Macro: 0.9703\n",
      "Epoch 8/10, Train Loss: 0.0451, Accuracy: 0.9594, F1 Micro: 0.9748, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0339, Accuracy: 0.9601, F1 Micro: 0.9752, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0277, Accuracy: 0.9606, F1 Micro: 0.9755, F1 Macro: 0.9731\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9755, F1 Macro: 0.9731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.96      0.96       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      0.99      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "-------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3186, Accuracy: 0.8726, F1 Micro: 0.8726, F1 Macro: 0.8304\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1851, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.875\n",
      "Epoch 3/10, Train Loss: 0.1251, Accuracy: 0.8937, F1 Micro: 0.8937, F1 Macro: 0.8607\n",
      "Epoch 4/10, Train Loss: 0.0892, Accuracy: 0.8937, F1 Micro: 0.8937, F1 Macro: 0.862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0602, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0516, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8857\n",
      "Epoch 7/10, Train Loss: 0.0449, Accuracy: 0.8964, F1 Micro: 0.8964, F1 Macro: 0.8654\n",
      "Epoch 8/10, Train Loss: 0.0348, Accuracy: 0.9001, F1 Micro: 0.9001, F1 Macro: 0.8724\n",
      "Epoch 9/10, Train Loss: 0.0293, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8733\n",
      "Epoch 10/10, Train Loss: 0.0202, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8787\n",
      "\n",
      "Sentiment analysis accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       767\n",
      "    positive       0.95      0.74      0.83       324\n",
      "\n",
      "    accuracy                           0.91      1091\n",
      "   macro avg       0.92      0.86      0.89      1091\n",
      "weighted avg       0.91      0.91      0.91      1091\n",
      "\n",
      "-------------------------\n",
      "Overall accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.8581\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.81      0.74      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.75      0.62      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.71      0.45      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.76      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.86      0.84        85\n",
      "     neutral       0.97      0.96      0.96       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.93      0.81      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        74\n",
      "     neutral       1.00      0.99      0.99       494\n",
      "    positive       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.81      0.76      0.78       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 707.0559000968933 s\n",
      "=========================================================================================\n",
      "Batch size: 8, sequence length: 48\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3603, Accuracy: 0.9297, F1 Micro: 0.9572, F1 Macro: 0.9542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1965, Accuracy: 0.9543, F1 Micro: 0.9719, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1403, Accuracy: 0.9615, F1 Micro: 0.9762, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1058, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0837, Accuracy: 0.9644, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0638, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0485, Accuracy: 0.9668, F1 Micro: 0.9794, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0391, Accuracy: 0.9684, F1 Micro: 0.9804, F1 Macro: 0.9784\n",
      "Epoch 9/10, Train Loss: 0.0302, Accuracy: 0.9668, F1 Micro: 0.9793, F1 Macro: 0.9771\n",
      "Epoch 10/10, Train Loss: 0.0251, Accuracy: 0.9674, F1 Micro: 0.9797, F1 Macro: 0.9777\n",
      "\n",
      "Aspect detection accuracy: 0.9684, F1 Micro: 0.9804, F1 Macro: 0.9784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.95      0.97      0.96       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "-------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.314, Accuracy: 0.8863, F1 Micro: 0.8863, F1 Macro: 0.8467\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1686, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1264, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8939\n",
      "Epoch 4/10, Train Loss: 0.0875, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0681, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8924\n",
      "Epoch 6/10, Train Loss: 0.052, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8859\n",
      "Epoch 7/10, Train Loss: 0.0378, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8849\n",
      "Epoch 8/10, Train Loss: 0.0285, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0311, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.9024\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0147, Accuracy: 0.9276, F1 Micro: 0.9276, F1 Macro: 0.9054\n",
      "\n",
      "Sentiment analysis accuracy: 0.9276, F1 Micro: 0.9276, F1 Macro: 0.9054\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       784\n",
      "    positive       0.95      0.79      0.86       307\n",
      "\n",
      "    accuracy                           0.93      1091\n",
      "   macro avg       0.93      0.89      0.91      1091\n",
      "weighted avg       0.93      0.93      0.93      1091\n",
      "\n",
      "-------------------------\n",
      "Overall accuracy: 0.9632, F1 Micro: 0.9632, F1 Macro: 0.8906\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.92      0.95        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.87      0.88       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.85        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.85      0.76      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.68      0.74       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89       162\n",
      "     neutral       0.95      0.97      0.96       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.77      0.82       571\n",
      "weighted avg       0.93      0.93      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.97      0.81      0.86       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 723.7576425075531 s\n",
      "=========================================================================================\n",
      "Batch size: 16, sequence length: 24\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4285, Accuracy: 0.8832, F1 Micro: 0.9312, F1 Macro: 0.9272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2869, Accuracy: 0.9269, F1 Micro: 0.9556, F1 Macro: 0.9525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.217, Accuracy: 0.933, F1 Micro: 0.9593, F1 Macro: 0.9562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1836, Accuracy: 0.9363, F1 Micro: 0.9613, F1 Macro: 0.9581\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1664, Accuracy: 0.942, F1 Micro: 0.9644, F1 Macro: 0.9613\n",
      "Epoch 6/10, Train Loss: 0.1375, Accuracy: 0.9401, F1 Micro: 0.9631, F1 Macro: 0.9598\n",
      "Epoch 7/10, Train Loss: 0.1101, Accuracy: 0.9389, F1 Micro: 0.9623, F1 Macro: 0.959\n",
      "Epoch 8/10, Train Loss: 0.0989, Accuracy: 0.9403, F1 Micro: 0.9632, F1 Macro: 0.9601\n",
      "Epoch 9/10, Train Loss: 0.0817, Accuracy: 0.9403, F1 Micro: 0.9631, F1 Macro: 0.96\n",
      "Epoch 10/10, Train Loss: 0.0676, Accuracy: 0.9401, F1 Micro: 0.963, F1 Macro: 0.96\n",
      "\n",
      "Aspect detection accuracy: 0.942, F1 Micro: 0.9644, F1 Macro: 0.9613\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.97      0.99      0.98       462\n",
      "   air_panas       0.95      0.99      0.97       480\n",
      "         bau       0.95      0.98      0.97       496\n",
      "     general       0.91      0.99      0.95       500\n",
      "  kebersihan       0.90      0.91      0.91       317\n",
      "       linen       0.90      0.95      0.92       392\n",
      "     service       0.93      0.97      0.95       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.98      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      4614\n",
      "   macro avg       0.95      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.96      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "-------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.37, Accuracy: 0.8547, F1 Micro: 0.8547, F1 Macro: 0.8082\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2468, Accuracy: 0.87, F1 Micro: 0.87, F1 Macro: 0.8213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1632, Accuracy: 0.8823, F1 Micro: 0.8823, F1 Macro: 0.8423\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1567, Accuracy: 0.8864, F1 Micro: 0.8864, F1 Macro: 0.8502\n",
      "Epoch 5/10, Train Loss: 0.1339, Accuracy: 0.8802, F1 Micro: 0.8802, F1 Macro: 0.8421\n",
      "Epoch 6/10, Train Loss: 0.095, Accuracy: 0.8721, F1 Micro: 0.8721, F1 Macro: 0.8364\n",
      "Epoch 7/10, Train Loss: 0.1079, Accuracy: 0.8833, F1 Micro: 0.8833, F1 Macro: 0.8464\n",
      "Epoch 8/10, Train Loss: 0.0727, Accuracy: 0.8854, F1 Micro: 0.8854, F1 Macro: 0.8483\n",
      "Epoch 9/10, Train Loss: 0.0514, Accuracy: 0.8833, F1 Micro: 0.8833, F1 Macro: 0.8452\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0464, Accuracy: 0.8874, F1 Micro: 0.8874, F1 Macro: 0.8489\n",
      "\n",
      "Sentiment analysis accuracy: 0.8874, F1 Micro: 0.8874, F1 Macro: 0.8489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93       697\n",
      "    positive       0.92      0.67      0.77       280\n",
      "\n",
      "    accuracy                           0.89       977\n",
      "   macro avg       0.90      0.82      0.85       977\n",
      "weighted avg       0.89      0.89      0.88       977\n",
      "\n",
      "-------------------------\n",
      "Overall accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.7945\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.88      0.91        97\n",
      "     neutral       0.97      0.99      0.98       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.95      0.91      0.93       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.67      0.75        86\n",
      "     neutral       0.95      0.99      0.97       475\n",
      "    positive       0.50      0.30      0.37        10\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.77      0.66      0.70       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.71      0.77        78\n",
      "     neutral       0.95      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.89      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.91      0.99      0.95       496\n",
      "    positive       0.82      0.41      0.55        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.58      0.47      0.50       571\n",
      "weighted avg       0.89      0.91      0.89       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85       200\n",
      "     neutral       0.90      0.91      0.91       315\n",
      "    positive       0.85      0.89      0.87        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.87      0.88      0.87       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82       162\n",
      "     neutral       0.90      0.95      0.92       387\n",
      "    positive       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.92      0.72      0.77       571\n",
      "weighted avg       0.89      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.73      0.78        85\n",
      "     neutral       0.93      0.98      0.95       418\n",
      "    positive       0.89      0.79      0.84        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.83      0.86       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.41      0.52        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.77      0.59      0.67        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.67      0.72       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.89      0.91        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.85      0.90       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.88      0.92        74\n",
      "     neutral       0.98      1.00      0.99       494\n",
      "    positive       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.82      0.74      0.77       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 358.1417398452759 s\n",
      "=========================================================================================\n",
      "Batch size: 16, sequence length: 32\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.426, Accuracy: 0.8852, F1 Micro: 0.9324, F1 Macro: 0.9283\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.269, Accuracy: 0.9352, F1 Micro: 0.9605, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1956, Accuracy: 0.9377, F1 Micro: 0.9621, F1 Macro: 0.9594\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1569, Accuracy: 0.9467, F1 Micro: 0.9673, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1371, Accuracy: 0.9523, F1 Micro: 0.9705, F1 Macro: 0.968\n",
      "Epoch 6/10, Train Loss: 0.1133, Accuracy: 0.951, F1 Micro: 0.9697, F1 Macro: 0.9667\n",
      "Epoch 7/10, Train Loss: 0.091, Accuracy: 0.9509, F1 Micro: 0.9696, F1 Macro: 0.9666\n",
      "Epoch 8/10, Train Loss: 0.0818, Accuracy: 0.9521, F1 Micro: 0.9704, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0636, Accuracy: 0.9535, F1 Micro: 0.9713, F1 Macro: 0.9686\n",
      "Epoch 10/10, Train Loss: 0.054, Accuracy: 0.9533, F1 Micro: 0.9711, F1 Macro: 0.9684\n",
      "\n",
      "Aspect detection accuracy: 0.9535, F1 Micro: 0.9713, F1 Macro: 0.9686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.91      0.93      0.92       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.96      0.97      0.96       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      0.99      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "-------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3435, Accuracy: 0.8519, F1 Micro: 0.8519, F1 Macro: 0.8182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2156, Accuracy: 0.8885, F1 Micro: 0.8885, F1 Macro: 0.8546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1466, Accuracy: 0.8971, F1 Micro: 0.8971, F1 Macro: 0.865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1257, Accuracy: 0.8971, F1 Micro: 0.8971, F1 Macro: 0.8637\n",
      "Epoch 5/10, Train Loss: 0.0859, Accuracy: 0.8952, F1 Micro: 0.8952, F1 Macro: 0.8651\n",
      "Epoch 6/10, Train Loss: 0.0687, Accuracy: 0.8894, F1 Micro: 0.8894, F1 Macro: 0.8539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0588, Accuracy: 0.8971, F1 Micro: 0.8971, F1 Macro: 0.8647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0379, Accuracy: 0.8971, F1 Micro: 0.8971, F1 Macro: 0.8663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0347, Accuracy: 0.899, F1 Micro: 0.899, F1 Macro: 0.8685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0217, Accuracy: 0.9019, F1 Micro: 0.9019, F1 Macro: 0.8724\n",
      "\n",
      "Sentiment analysis accuracy: 0.9019, F1 Micro: 0.9019, F1 Macro: 0.8724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       735\n",
      "    positive       0.93      0.72      0.81       305\n",
      "\n",
      "    accuracy                           0.90      1040\n",
      "   macro avg       0.91      0.85      0.87      1040\n",
      "weighted avg       0.90      0.90      0.90      1040\n",
      "\n",
      "-------------------------\n",
      "Overall accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.8366\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.93      0.94        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.80      0.87        86\n",
      "     neutral       0.97      1.00      0.98       475\n",
      "    positive       0.78      0.70      0.74        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.90      0.83      0.86       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.73      0.79        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.90      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.86      0.63      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.77      0.59      0.64       571\n",
      "weighted avg       0.93      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.87       200\n",
      "     neutral       0.91      0.93      0.92       315\n",
      "    positive       0.89      0.89      0.89        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.89      0.89       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85       162\n",
      "     neutral       0.91      0.96      0.94       387\n",
      "    positive       0.89      0.36      0.52        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.72      0.77       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.81      0.82        85\n",
      "     neutral       0.96      0.97      0.96       418\n",
      "    positive       0.92      0.87      0.89        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.90      0.88      0.89       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.38      0.51        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.73      0.76       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        74\n",
      "     neutral       0.99      0.99      0.99       494\n",
      "    positive       0.25      0.33      0.29         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.73      0.74      0.73       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 392.001131772995 s\n",
      "=========================================================================================\n",
      "Batch size: 16, sequence length: 40\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4247, Accuracy: 0.8865, F1 Micro: 0.9331, F1 Macro: 0.9292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2582, Accuracy: 0.9378, F1 Micro: 0.9622, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1807, Accuracy: 0.9458, F1 Micro: 0.9669, F1 Macro: 0.9647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1423, Accuracy: 0.9523, F1 Micro: 0.9707, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1267, Accuracy: 0.9582, F1 Micro: 0.974, F1 Macro: 0.9717\n",
      "Epoch 6/10, Train Loss: 0.1034, Accuracy: 0.9569, F1 Micro: 0.9733, F1 Macro: 0.9707\n",
      "Epoch 7/10, Train Loss: 0.081, Accuracy: 0.9566, F1 Micro: 0.9731, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0722, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0601, Accuracy: 0.9604, F1 Micro: 0.9754, F1 Macro: 0.9732\n",
      "Epoch 10/10, Train Loss: 0.051, Accuracy: 0.9597, F1 Micro: 0.975, F1 Macro: 0.9726\n",
      "\n",
      "Aspect detection accuracy: 0.9604, F1 Micro: 0.9754, F1 Macro: 0.9732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.96      0.96      0.96       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "-------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3429, Accuracy: 0.8676, F1 Micro: 0.8676, F1 Macro: 0.8265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2067, Accuracy: 0.8925, F1 Micro: 0.8925, F1 Macro: 0.8617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1357, Accuracy: 0.8961, F1 Micro: 0.8961, F1 Macro: 0.8652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0872, Accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.8671\n",
      "Epoch 5/10, Train Loss: 0.0848, Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0476, Accuracy: 0.8998, F1 Micro: 0.8998, F1 Macro: 0.8712\n",
      "Epoch 7/10, Train Loss: 0.0418, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8694\n",
      "Epoch 8/10, Train Loss: 0.0347, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0226, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8724\n",
      "Epoch 10/10, Train Loss: 0.0148, Accuracy: 0.8888, F1 Micro: 0.8888, F1 Macro: 0.8547\n",
      "\n",
      "Sentiment analysis accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       766\n",
      "    positive       0.94      0.71      0.81       322\n",
      "\n",
      "    accuracy                           0.90      1088\n",
      "   macro avg       0.91      0.85      0.87      1088\n",
      "weighted avg       0.91      0.90      0.90      1088\n",
      "\n",
      "-------------------------\n",
      "Overall accuracy: 0.9539, F1 Micro: 0.9539, F1 Macro: 0.8533\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.78      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.72      0.62      0.65       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.84      0.93      0.88        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.75      0.79       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.82      0.80        85\n",
      "     neutral       0.96      0.96      0.96       418\n",
      "    positive       0.92      0.88      0.90        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.89      0.89      0.89       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.48      0.61        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.77      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.76      0.82       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 389.010724067688 s\n",
      "=========================================================================================\n",
      "Batch size: 16, sequence length: 48\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4203, Accuracy: 0.8898, F1 Micro: 0.935, F1 Macro: 0.9316\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2506, Accuracy: 0.9448, F1 Micro: 0.9663, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1736, Accuracy: 0.9484, F1 Micro: 0.9685, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1345, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.117, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9765\n",
      "Epoch 6/10, Train Loss: 0.0948, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0744, Accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9772\n",
      "Epoch 8/10, Train Loss: 0.0662, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0534, Accuracy: 0.9674, F1 Micro: 0.9797, F1 Macro: 0.9775\n",
      "Epoch 10/10, Train Loss: 0.0455, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9674, F1 Micro: 0.9797, F1 Macro: 0.9775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "-------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3526, Accuracy: 0.869, F1 Micro: 0.869, F1 Macro: 0.8301\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2074, Accuracy: 0.8844, F1 Micro: 0.8844, F1 Macro: 0.844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1358, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0951, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8822\n",
      "Epoch 5/10, Train Loss: 0.0785, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8782\n",
      "Epoch 6/10, Train Loss: 0.0565, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.053, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0366, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0226, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0122, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8892\n",
      "\n",
      "Sentiment analysis accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8892\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       787\n",
      "    positive       0.95      0.75      0.84       320\n",
      "\n",
      "    accuracy                           0.92      1107\n",
      "   macro avg       0.93      0.87      0.89      1107\n",
      "weighted avg       0.92      0.92      0.91      1107\n",
      "\n",
      "-------------------------\n",
      "Overall accuracy: 0.9618, F1 Micro: 0.9618, F1 Macro: 0.8918\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.92      0.92        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.87      0.76      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.68      0.74       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       162\n",
      "     neutral       0.93      0.98      0.95       387\n",
      "    positive       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.94      0.75      0.80       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.88      0.87        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.55      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 392.7164795398712 s\n"
     ]
    }
   ],
   "source": [
    "sizes = [8, 16]\n",
    "lengths = [24, 32, 40, 48]\n",
    "\n",
    "used_sizes = []\n",
    "used_lengths = []\n",
    "\n",
    "for size in sizes:\n",
    "    BATCH_SIZE = size\n",
    "    for length in lengths:\n",
    "        print(\"=========================================================================================\")\n",
    "        print(f\"Batch size: {BATCH_SIZE}, sequence length: {length}\")\n",
    "        used_sizes.append(BATCH_SIZE)\n",
    "        used_lengths.append(length)\n",
    "        \n",
    "        args = (\n",
    "            length, \n",
    "            'indobenchmark/indobert-base-p1', \n",
    "            (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "            (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros), \n",
    "            (accuracies, f1_micros, f1_macros), \n",
    "            42, \n",
    "            6,\n",
    "            1\n",
    "        )\n",
    "        notebook_launcher(train_model, args, num_processes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b993fcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T12:43:05.822952Z",
     "iopub.status.busy": "2025-04-13T12:43:05.822626Z",
     "iopub.status.idle": "2025-04-13T12:43:05.867541Z",
     "shell.execute_reply": "2025-04-13T12:43:05.866704Z"
    },
    "papermill": {
     "duration": 0.102982,
     "end_time": "2025-04-13T12:43:05.869084",
     "exception": false,
     "start_time": "2025-04-13T12:43:05.766102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Batch Size': used_sizes,\n",
    "    'Sequence Length': used_lengths,\n",
    "    'Aspect Accuracy': list(aspect_accuracies),\n",
    "    'Aspect F1 Micro': list(aspect_f1_micros),\n",
    "    'Aspect F1 Macro': list(aspect_f1_macros),\n",
    "    'Sentiment Accuracy': list(sentiment_accuracies),\n",
    "    'Sentiment F1 Micro': list(sentiment_f1_micros),\n",
    "    'Sentiment F1 Macro': list(sentiment_f1_macros),\n",
    "    'Accuracy': list(accuracies),\n",
    "    'F1 Micro': list(f1_micros),\n",
    "    'F1 Macro': list(f1_macros),\n",
    "})\n",
    "\n",
    "results.to_csv(f'hoasa-hyperparameters-tuning.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "008c084d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T12:43:05.977498Z",
     "iopub.status.busy": "2025-04-13T12:43:05.977202Z",
     "iopub.status.idle": "2025-04-13T13:16:30.561818Z",
     "shell.execute_reply": "2025-04-13T13:16:30.560524Z"
    },
    "papermill": {
     "duration": 2004.644388,
     "end_time": "2025-04-13T13:16:30.563711",
     "exception": false,
     "start_time": "2025-04-13T12:43:05.919323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "SEED: 50\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.42, Accuracy: 0.8906, F1 Micro: 0.9353, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2502, Accuracy: 0.941, F1 Micro: 0.9641, F1 Macro: 0.9623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1742, Accuracy: 0.9512, F1 Micro: 0.9701, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1333, Accuracy: 0.9575, F1 Micro: 0.9738, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1166, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0947, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0748, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0689, Accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.0548, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0467, Accuracy: 0.9667, F1 Micro: 0.9792, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.9667, F1 Micro: 0.9792, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.98      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "-------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.341, Accuracy: 0.8677, F1 Micro: 0.8677, F1 Macro: 0.8272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1845, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.8679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1384, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0895, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0662, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8813\n",
      "Epoch 6/10, Train Loss: 0.0561, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8754\n",
      "Epoch 7/10, Train Loss: 0.0406, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0454, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0333, Accuracy: 0.9085, F1 Micro: 0.9085, F1 Macro: 0.8819\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0247, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8851\n",
      "\n",
      "Sentiment analysis accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8851\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       790\n",
      "    positive       0.95      0.74      0.83       336\n",
      "\n",
      "    accuracy                           0.91      1126\n",
      "   macro avg       0.92      0.86      0.89      1126\n",
      "weighted avg       0.91      0.91      0.91      1126\n",
      "\n",
      "-------------------------\n",
      "Overall accuracy: 0.9609, F1 Micro: 0.9609, F1 Macro: 0.8952\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.82      0.79      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.69      0.74       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.87      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       1.00      0.36      0.53        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.73      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.85        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.89      0.97      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.69      0.78        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.88      0.90       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 398.29076623916626 s\n",
      "=====================\n",
      "SEED: 81\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4435, Accuracy: 0.8809, F1 Micro: 0.9301, F1 Macro: 0.9256\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2648, Accuracy: 0.9399, F1 Micro: 0.9634, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1839, Accuracy: 0.949, F1 Micro: 0.9688, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1428, Accuracy: 0.954, F1 Micro: 0.9717, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.123, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0991, Accuracy: 0.9637, F1 Micro: 0.9774, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0782, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0715, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0581, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0506, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "-------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3331, Accuracy: 0.8718, F1 Micro: 0.8718, F1 Macro: 0.8374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1863, Accuracy: 0.8998, F1 Micro: 0.8998, F1 Macro: 0.8714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1389, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8819\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0966, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8832\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0819, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0609, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.8894\n",
      "Epoch 7/10, Train Loss: 0.039, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8886\n",
      "Epoch 8/10, Train Loss: 0.0344, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8879\n",
      "Epoch 9/10, Train Loss: 0.0266, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8843\n",
      "Epoch 10/10, Train Loss: 0.0187, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8877\n",
      "\n",
      "Sentiment analysis accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.8894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       783\n",
      "    positive       0.95      0.75      0.84       325\n",
      "\n",
      "    accuracy                           0.91      1108\n",
      "   macro avg       0.93      0.87      0.89      1108\n",
      "weighted avg       0.92      0.91      0.91      1108\n",
      "\n",
      "-------------------------\n",
      "Overall accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.8842\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.25      0.14      0.18         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.83      0.74      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.68      0.62      0.64       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.88      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.65      0.59      0.62        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.83      0.80      0.81       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.66      0.76        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.84      0.87       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 397.27755904197693 s\n",
      "=====================\n",
      "SEED: 14\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4357, Accuracy: 0.879, F1 Micro: 0.9292, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2666, Accuracy: 0.9349, F1 Micro: 0.9605, F1 Macro: 0.9583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1816, Accuracy: 0.9484, F1 Micro: 0.9685, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1417, Accuracy: 0.9557, F1 Micro: 0.9728, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.124, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0985, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "Epoch 7/10, Train Loss: 0.0784, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0702, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0576, Accuracy: 0.9675, F1 Micro: 0.9798, F1 Macro: 0.9777\n",
      "Epoch 10/10, Train Loss: 0.0491, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.9675, F1 Micro: 0.9798, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.98      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "-------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3325, Accuracy: 0.8676, F1 Micro: 0.8676, F1 Macro: 0.823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1884, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1168, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0856, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0594, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8912\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0358, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8902\n",
      "Epoch 7/10, Train Loss: 0.0396, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0291, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9007\n",
      "Epoch 9/10, Train Loss: 0.0255, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8889\n",
      "Epoch 10/10, Train Loss: 0.0133, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.8837\n",
      "\n",
      "Sentiment analysis accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       786\n",
      "    positive       0.95      0.78      0.85       324\n",
      "\n",
      "    accuracy                           0.92      1110\n",
      "   macro avg       0.93      0.88      0.90      1110\n",
      "weighted avg       0.92      0.92      0.92      1110\n",
      "\n",
      "-------------------------\n",
      "Overall accuracy: 0.9629, F1 Micro: 0.9629, F1 Macro: 0.9006\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.83      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.86      0.79      0.82        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.69      0.75       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.91      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.89       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.72      0.59      0.65        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.93      0.97      0.95        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.66      0.76        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.84      0.87       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 392.882004737854 s\n",
      "=====================\n",
      "SEED: 3\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4217, Accuracy: 0.888, F1 Micro: 0.9336, F1 Macro: 0.9286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2478, Accuracy: 0.9443, F1 Micro: 0.9659, F1 Macro: 0.9637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1748, Accuracy: 0.9502, F1 Micro: 0.9695, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1362, Accuracy: 0.9533, F1 Micro: 0.9713, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.118, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0948, Accuracy: 0.9637, F1 Micro: 0.9774, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0749, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0678, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "Epoch 9/10, Train Loss: 0.0548, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.046, Accuracy: 0.9668, F1 Micro: 0.9793, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9668, F1 Micro: 0.9793, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      0.99      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.98      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "-------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3342, Accuracy: 0.8629, F1 Micro: 0.8629, F1 Macro: 0.8212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1977, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1299, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8799\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0934, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0841, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0569, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8934\n",
      "Epoch 7/10, Train Loss: 0.0383, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.8784\n",
      "Epoch 8/10, Train Loss: 0.0395, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8846\n",
      "Epoch 9/10, Train Loss: 0.0245, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8773\n",
      "Epoch 10/10, Train Loss: 0.0262, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8822\n",
      "\n",
      "Sentiment analysis accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       789\n",
      "    positive       0.94      0.77      0.84       327\n",
      "\n",
      "    accuracy                           0.92      1116\n",
      "   macro avg       0.92      0.87      0.89      1116\n",
      "weighted avg       0.92      0.92      0.91      1116\n",
      "\n",
      "-------------------------\n",
      "Overall accuracy: 0.9613, F1 Micro: 0.9613, F1 Macro: 0.8864\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.86      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.29      0.40         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.85      0.76      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.83      0.68      0.73       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.94      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.75      0.41      0.53        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.75      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.89        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.94      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.81      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      0.99      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      1.00      0.95       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 393.88445258140564 s\n",
      "=====================\n",
      "SEED: 94\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4368, Accuracy: 0.8851, F1 Micro: 0.932, F1 Macro: 0.9273\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.256, Accuracy: 0.9415, F1 Micro: 0.9644, F1 Macro: 0.9624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1764, Accuracy: 0.9477, F1 Micro: 0.968, F1 Macro: 0.9657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1377, Accuracy: 0.9568, F1 Micro: 0.9734, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1189, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0965, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9764\n",
      "Epoch 7/10, Train Loss: 0.0753, Accuracy: 0.9639, F1 Micro: 0.9775, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0692, Accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0566, Accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9771\n",
      "Epoch 10/10, Train Loss: 0.048, Accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.95      0.95       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "-------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3456, Accuracy: 0.8799, F1 Micro: 0.8799, F1 Macro: 0.8446\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1711, Accuracy: 0.9019, F1 Micro: 0.9019, F1 Macro: 0.8695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1188, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.099, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0669, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.051, Accuracy: 0.9193, F1 Micro: 0.9193, F1 Macro: 0.8943\n",
      "Epoch 7/10, Train Loss: 0.0399, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8876\n",
      "Epoch 8/10, Train Loss: 0.0264, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.8917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0302, Accuracy: 0.9193, F1 Micro: 0.9193, F1 Macro: 0.8943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.028, Accuracy: 0.9193, F1 Micro: 0.9193, F1 Macro: 0.8936\n",
      "\n",
      "Sentiment analysis accuracy: 0.9193, F1 Micro: 0.9193, F1 Macro: 0.8936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       782\n",
      "    positive       0.95      0.75      0.84       309\n",
      "\n",
      "    accuracy                           0.92      1091\n",
      "   macro avg       0.93      0.87      0.89      1091\n",
      "weighted avg       0.92      0.92      0.92      1091\n",
      "\n",
      "-------------------------\n",
      "Overall accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.8829\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.50      0.50      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.81      0.79      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.89      0.91       200\n",
      "     neutral       0.94      0.95      0.95       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.93      0.76      0.81       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.89      0.89        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.81      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 393.38240456581116 s\n"
     ]
    }
   ],
   "source": [
    "seeds = [50, 81, 14, 3, 94]\n",
    "\n",
    "aspect_accuracies = manager.list()\n",
    "aspect_f1_micros = manager.list()\n",
    "aspect_f1_macros = manager.list()\n",
    "sentiment_accuracies = manager.list()\n",
    "sentiment_f1_micros = manager.list()\n",
    "sentiment_f1_macros = manager.list()\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "\n",
    "trial = 1\n",
    "for seed in seeds:\n",
    "    print(\"=====================\")\n",
    "    print(\"SEED:\", seed)\n",
    "    set_seed(seed)\n",
    "    \n",
    "    LEARNING_RATE = 2e-5\n",
    "    BATCH_SIZE = 16\n",
    "    args = (\n",
    "        48, \n",
    "        'indobenchmark/indobert-base-p1', \n",
    "        (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "        (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros), \n",
    "        (accuracies, f1_micros, f1_macros), \n",
    "        42, \n",
    "        6,\n",
    "        trial\n",
    "    )\n",
    "    \n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "    trial += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dcb645d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T13:16:30.742388Z",
     "iopub.status.busy": "2025-04-13T13:16:30.742058Z",
     "iopub.status.idle": "2025-04-13T13:16:30.759370Z",
     "shell.execute_reply": "2025-04-13T13:16:30.758741Z"
    },
    "papermill": {
     "duration": 0.101565,
     "end_time": "2025-04-13T13:16:30.760469",
     "exception": false,
     "start_time": "2025-04-13T13:16:30.658904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Trial': [1,2,3,4,5],\n",
    "    'Aspect Accuracy': list(aspect_accuracies),\n",
    "    'Aspect F1 Micro': list(aspect_f1_micros),\n",
    "    'Aspect F1 Macro': list(aspect_f1_macros),\n",
    "    'Sentiment Accuracy': list(sentiment_accuracies),\n",
    "    'Sentiment F1 Micro': list(sentiment_f1_micros),\n",
    "    'Sentiment F1 Macro': list(sentiment_f1_macros),\n",
    "    'Accuracy': list(accuracies),\n",
    "    'F1 Micro': list(f1_micros),\n",
    "    'F1 Macro': list(f1_macros),\n",
    "})\n",
    "\n",
    "results.to_csv(f'hoasa-passive-results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6175442,
     "sourceId": 10027624,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6444.494151,
   "end_time": "2025-04-13T13:16:33.854822",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-13T11:29:09.360671",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "048fc07e0119484b9972c620a9b42b16": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0812f714006a406792bc5b7208395710": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0da7b51814844e3fafda4da2037e58ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3560fba2243e4110aeba9932862896fc",
       "max": 112.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_63e24154d67f4e119db48ee1b2884a0b",
       "tabbable": null,
       "tooltip": null,
       "value": 112.0
      }
     },
     "14bfa2afebcb49cda3f7f270b4d05390": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b1d9219490df4e7ea49268c8a166f1ee",
       "placeholder": "",
       "style": "IPY_MODEL_0812f714006a406792bc5b7208395710",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:100%"
      }
     },
     "1890ed15d0ff4ba9ae4932ee002e0779": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a7b8e8dc66144b978d4ddd5648ef7bce",
       "max": 1534.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_243cd6efe9c94d999bad7755e84f7636",
       "tabbable": null,
       "tooltip": null,
       "value": 1534.0
      }
     },
     "18e00592b93b47159b9deee91eee6f43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "243cd6efe9c94d999bad7755e84f7636": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2f5574a902484640b28696371198a643": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "325a58f568c046fbb6496e1bfd5885b6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "33fed793c2e5464bb4015b0e080fd101": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3de4f3f36c254964bcae0235d0d7d326",
       "placeholder": "",
       "style": "IPY_MODEL_606e8612d0904c4897e8b50e70511aa3",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json:100%"
      }
     },
     "3560fba2243e4110aeba9932862896fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "35bca356dcdd4f689406db0ed0fe2c3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e298b0e2d0744cad900e23b231fe8d06",
       "max": 229167.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a6990374d1264feda5c3fab50332df4b",
       "tabbable": null,
       "tooltip": null,
       "value": 229167.0
      }
     },
     "39bce2d6453f42099f04df7c6dd9d53b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_946f40eff2584323bce1984a635298dc",
       "placeholder": "",
       "style": "IPY_MODEL_a7c8c6a2a83742dba80ad2d65cd62c1c",
       "tabbable": null,
       "tooltip": null,
       "value": "2.00/2.00[00:00&lt;00:00,196B/s]"
      }
     },
     "3de4f3f36c254964bcae0235d0d7d326": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "40c07ffa6b1d4c9b8630ac8dae832be1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "413324c6f7d7498f94c5dae85a81d9f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b1f1594c58c04311ae5cf4e385e8b8be",
       "placeholder": "",
       "style": "IPY_MODEL_d308e538275b4d94bdbc41edc750e6dd",
       "tabbable": null,
       "tooltip": null,
       "value": "112/112[00:00&lt;00:00,11.5kB/s]"
      }
     },
     "606e8612d0904c4897e8b50e70511aa3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "63db5cbd11004e8e99f5a2d7f21b753c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "63e24154d67f4e119db48ee1b2884a0b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6f666cb1e92843279f66916d6b32a176": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9a982cc5270b47aba4389ec05b6682e3",
       "placeholder": "",
       "style": "IPY_MODEL_c423a9dd8df3425cabf98da144b29e58",
       "tabbable": null,
       "tooltip": null,
       "value": "1.53k/1.53k[00:00&lt;00:00,173kB/s]"
      }
     },
     "761dea975cd5429d9e9ca906d2a891d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_048fc07e0119484b9972c620a9b42b16",
       "placeholder": "",
       "style": "IPY_MODEL_f07ae1e93abf4d13a225dca6f667ddbc",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt:100%"
      }
     },
     "946f40eff2584323bce1984a635298dc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9576078bc90d41e39633e833331c87a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_761dea975cd5429d9e9ca906d2a891d6",
        "IPY_MODEL_35bca356dcdd4f689406db0ed0fe2c3e",
        "IPY_MODEL_c80268ab5fe14756a212741014113288"
       ],
       "layout": "IPY_MODEL_cc99be11472643e08ff188a7f65291cc",
       "tabbable": null,
       "tooltip": null
      }
     },
     "967bd58c58b64432a4ff71c50bd4dee7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9a982cc5270b47aba4389ec05b6682e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a6990374d1264feda5c3fab50332df4b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a7b8e8dc66144b978d4ddd5648ef7bce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a7c8c6a2a83742dba80ad2d65cd62c1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b1d9219490df4e7ea49268c8a166f1ee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b1f1594c58c04311ae5cf4e385e8b8be": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bcee563728134140b56b343f8a583b3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d0bb41aac0a4484e9ec2cd39b775f000",
       "placeholder": "",
       "style": "IPY_MODEL_2f5574a902484640b28696371198a643",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:100%"
      }
     },
     "c423a9dd8df3425cabf98da144b29e58": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c80268ab5fe14756a212741014113288": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e9a6275a171e4b1488dc65c0e3b5e739",
       "placeholder": "",
       "style": "IPY_MODEL_d96ddb35567c43a1bdf0921bd39d9aa5",
       "tabbable": null,
       "tooltip": null,
       "value": "229k/229k[00:00&lt;00:00,6.21MB/s]"
      }
     },
     "cc99be11472643e08ff188a7f65291cc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d0bb41aac0a4484e9ec2cd39b775f000": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d308e538275b4d94bdbc41edc750e6dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d83dc62e79a64b4f8d70a51c484a2069": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_40c07ffa6b1d4c9b8630ac8dae832be1",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_18e00592b93b47159b9deee91eee6f43",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "d96ddb35567c43a1bdf0921bd39d9aa5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dc2894a5f6104efb88942ff83271b39d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_14bfa2afebcb49cda3f7f270b4d05390",
        "IPY_MODEL_1890ed15d0ff4ba9ae4932ee002e0779",
        "IPY_MODEL_6f666cb1e92843279f66916d6b32a176"
       ],
       "layout": "IPY_MODEL_63db5cbd11004e8e99f5a2d7f21b753c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e298b0e2d0744cad900e23b231fe8d06": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e7a7dd2921134916b44ef499bea2b6be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_33fed793c2e5464bb4015b0e080fd101",
        "IPY_MODEL_0da7b51814844e3fafda4da2037e58ed",
        "IPY_MODEL_413324c6f7d7498f94c5dae85a81d9f1"
       ],
       "layout": "IPY_MODEL_325a58f568c046fbb6496e1bfd5885b6",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e9a6275a171e4b1488dc65c0e3b5e739": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f07ae1e93abf4d13a225dca6f667ddbc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f4f6459e26684a58865857359398a1f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bcee563728134140b56b343f8a583b3f",
        "IPY_MODEL_d83dc62e79a64b4f8d70a51c484a2069",
        "IPY_MODEL_39bce2d6453f42099f04df7c6dd9d53b"
       ],
       "layout": "IPY_MODEL_967bd58c58b64432a4ff71c50bd4dee7",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
