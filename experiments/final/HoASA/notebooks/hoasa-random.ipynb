{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "821c166b",
   "metadata": {
    "papermill": {
     "duration": 0.011168,
     "end_time": "2025-04-20T08:36:25.396604",
     "exception": false,
     "start_time": "2025-04-20T08:36:25.385436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2ffc598",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:36:25.418715Z",
     "iopub.status.busy": "2025-04-20T08:36:25.418457Z",
     "iopub.status.idle": "2025-04-20T08:36:50.105564Z",
     "shell.execute_reply": "2025-04-20T08:36:50.104606Z"
    },
    "papermill": {
     "duration": 24.699924,
     "end_time": "2025-04-20T08:36:50.107285",
     "exception": false,
     "start_time": "2025-04-20T08:36:25.407361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f74d58",
   "metadata": {
    "papermill": {
     "duration": 0.009813,
     "end_time": "2025-04-20T08:36:50.128352",
     "exception": false,
     "start_time": "2025-04-20T08:36:50.118539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19d26bf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:36:50.149774Z",
     "iopub.status.busy": "2025-04-20T08:36:50.149308Z",
     "iopub.status.idle": "2025-04-20T08:36:50.152940Z",
     "shell.execute_reply": "2025-04-20T08:36:50.152140Z"
    },
    "papermill": {
     "duration": 0.016024,
     "end_time": "2025-04-20T08:36:50.154320",
     "exception": false,
     "start_time": "2025-04-20T08:36:50.138296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45949c05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:36:50.175598Z",
     "iopub.status.busy": "2025-04-20T08:36:50.175371Z",
     "iopub.status.idle": "2025-04-20T08:36:50.178864Z",
     "shell.execute_reply": "2025-04-20T08:36:50.178281Z"
    },
    "papermill": {
     "duration": 0.015002,
     "end_time": "2025-04-20T08:36:50.179958",
     "exception": false,
     "start_time": "2025-04-20T08:36:50.164956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9f7b6cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:36:50.201282Z",
     "iopub.status.busy": "2025-04-20T08:36:50.201061Z",
     "iopub.status.idle": "2025-04-20T08:36:50.210254Z",
     "shell.execute_reply": "2025-04-20T08:36:50.209536Z"
    },
    "papermill": {
     "duration": 0.021016,
     "end_time": "2025-04-20T08:36:50.211465",
     "exception": false,
     "start_time": "2025-04-20T08:36:50.190449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b5af6c",
   "metadata": {
    "papermill": {
     "duration": 0.010064,
     "end_time": "2025-04-20T08:36:50.232004",
     "exception": false,
     "start_time": "2025-04-20T08:36:50.221940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9281781",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:36:50.252743Z",
     "iopub.status.busy": "2025-04-20T08:36:50.252545Z",
     "iopub.status.idle": "2025-04-20T08:36:50.309220Z",
     "shell.execute_reply": "2025-04-20T08:36:50.307702Z"
    },
    "papermill": {
     "duration": 0.068698,
     "end_time": "2025-04-20T08:36:50.310757",
     "exception": false,
     "start_time": "2025-04-20T08:36:50.242059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "aspect_accuracies = manager.list()\n",
    "aspect_f1_micros = manager.list()\n",
    "aspect_f1_macros = manager.list()\n",
    "sentiment_accuracies = manager.list()\n",
    "sentiment_f1_micros = manager.list()\n",
    "sentiment_f1_macros = manager.list()\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'hoasa-random'\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "sequence_length = 48\n",
    "\n",
    "aspect_list = ['ac', 'air_panas', 'bau', 'general', 'kebersihan', 'linen', 'service', 'sunrise_meal', 'tv', 'wifi']\n",
    "aspect_mapping = {'ac': 0, 'air_panas': 1, 'bau': 2, 'general': 3, 'kebersihan': 4, 'linen': 5, 'service': 6, 'sunrise_meal': 7, 'tv': 8, 'wifi': 9}\n",
    "label_mapping = {\"neg\": 0, \"neut\": 1, 'neg_pos': 1, 'pos': 2}\n",
    "ignored_keys = ['labels', 'ori_text', 'ori_label', 'ori_indices', 'aspect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595cb12e",
   "metadata": {
    "papermill": {
     "duration": 0.010055,
     "end_time": "2025-04-20T08:36:50.331510",
     "exception": false,
     "start_time": "2025-04-20T08:36:50.321455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18fffa92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:36:50.352785Z",
     "iopub.status.busy": "2025-04-20T08:36:50.352516Z",
     "iopub.status.idle": "2025-04-20T08:36:50.444838Z",
     "shell.execute_reply": "2025-04-20T08:36:50.444040Z"
    },
    "papermill": {
     "duration": 0.104816,
     "end_time": "2025-04-20T08:36:50.446399",
     "exception": false,
     "start_time": "2025-04-20T08:36:50.341583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>ac</th>\n",
       "      <th>air_panas</th>\n",
       "      <th>bau</th>\n",
       "      <th>general</th>\n",
       "      <th>kebersihan</th>\n",
       "      <th>linen</th>\n",
       "      <th>service</th>\n",
       "      <th>sunrise_meal</th>\n",
       "      <th>tv</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kebersihan kurang...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sangat mengecewakan... hotel bad image, kebers...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tempat nyaman bersih tapi tv terlalu tinggi ti...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>pos</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>semuanya bagus sesuai profile,dan harga promo ...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>pos</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tempat tidur sangat keras, bantal besar dan ke...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review    ac air_panas   bau  \\\n",
       "0                               kebersihan kurang...  neut      neut  neut   \n",
       "1  sangat mengecewakan... hotel bad image, kebers...  neut      neut  neut   \n",
       "2  Tempat nyaman bersih tapi tv terlalu tinggi ti...  neut      neut  neut   \n",
       "3  semuanya bagus sesuai profile,dan harga promo ...  neut       neg  neut   \n",
       "4  Tempat tidur sangat keras, bantal besar dan ke...   neg       neg  neut   \n",
       "\n",
       "  general kebersihan linen service sunrise_meal    tv  wifi  \n",
       "0    neut        neg  neut    neut         neut  neut  neut  \n",
       "1    neut        neg  neut    neut         neut  neut  neut  \n",
       "2    neut        pos  neut    neut         neut   neg  neut  \n",
       "3     pos       neut  neut    neut         neut  neut  neut  \n",
       "4    neut       neut   neg    neut         neut  neut  neut  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/hoasa-dataset/train_preprocess.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/hoasa-dataset/valid_preprocess.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('/kaggle/input/hoasa-dataset/test_preprocess.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data, test_data], ignore_index=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e571d32e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:36:50.468654Z",
     "iopub.status.busy": "2025-04-20T08:36:50.468425Z",
     "iopub.status.idle": "2025-04-20T08:36:50.476219Z",
     "shell.execute_reply": "2025-04-20T08:36:50.475577Z"
    },
    "papermill": {
     "duration": 0.02031,
     "end_time": "2025-04-20T08:36:50.477555",
     "exception": false,
     "start_time": "2025-04-20T08:36:50.457245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa98b7ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:36:50.500829Z",
     "iopub.status.busy": "2025-04-20T08:36:50.500606Z",
     "iopub.status.idle": "2025-04-20T08:36:50.511935Z",
     "shell.execute_reply": "2025-04-20T08:36:50.511132Z"
    },
    "papermill": {
     "duration": 0.024101,
     "end_time": "2025-04-20T08:36:50.513198",
     "exception": false,
     "start_time": "2025-04-20T08:36:50.489097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2283,) (2283, 10)\n",
      "(571,) (571, 10)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[1:]\n",
    "val_labels = val_data.columns[1:]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['review'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['review'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71f6a46",
   "metadata": {
    "papermill": {
     "duration": 0.010464,
     "end_time": "2025-04-20T08:36:50.535875",
     "exception": false,
     "start_time": "2025-04-20T08:36:50.525411",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4771d09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:36:50.557816Z",
     "iopub.status.busy": "2025-04-20T08:36:50.557609Z",
     "iopub.status.idle": "2025-04-20T08:36:50.563173Z",
     "shell.execute_reply": "2025-04-20T08:36:50.562519Z"
    },
    "papermill": {
     "duration": 0.017975,
     "end_time": "2025-04-20T08:36:50.564436",
     "exception": false,
     "start_time": "2025-04-20T08:36:50.546461",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AspectDetectionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, label_mapping, tokenizer, max_length=sequence_length, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        \n",
    "        original_labels = [self.label_mapping[label] for label in self.labels[idx]]\n",
    "        encoded_labels = [1 if label == 1 else 0 for label in original_labels]\n",
    "        \n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['ori_indices'] = idx\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(original_labels, dtype=torch.float)\n",
    "        item['labels'] = torch.tensor(encoded_labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6ba90de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:36:50.586421Z",
     "iopub.status.busy": "2025-04-20T08:36:50.586189Z",
     "iopub.status.idle": "2025-04-20T08:36:50.592729Z",
     "shell.execute_reply": "2025-04-20T08:36:50.592108Z"
    },
    "papermill": {
     "duration": 0.018916,
     "end_time": "2025-04-20T08:36:50.593944",
     "exception": false,
     "start_time": "2025-04-20T08:36:50.575028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, texts, labels, aspects, indices, label_mapping, tokenizer, max_length=96, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.aspects = aspects\n",
    "        self.indices = indices\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = aspect_token + ' ' + self.aspects[idx] + ' ' + review_token + ' ' + self.texts[idx] \n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        if isinstance(self.labels[idx], str):\n",
    "            self.labels[idx] = self.label_mapping[self.labels[idx]]\n",
    "        elif torch.is_tensor(self.labels[idx]):\n",
    "            self.labels[idx] = int(self.labels[idx].item())\n",
    "\n",
    "        encoded_label = 1 if self.labels[idx] == 2 else self.labels[idx]\n",
    "        one_hot_label = F.one_hot(torch.tensor(encoded_label, dtype=torch.long), num_classes=2).float()\n",
    "\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['aspect'] = self.aspects[idx]\n",
    "        item['labels'] = one_hot_label\n",
    "        item['ori_indices'] = self.indices[idx]\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e30d6328",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:36:50.615570Z",
     "iopub.status.busy": "2025-04-20T08:36:50.615344Z",
     "iopub.status.idle": "2025-04-20T08:36:52.111140Z",
     "shell.execute_reply": "2025-04-20T08:36:52.110490Z"
    },
    "papermill": {
     "duration": 1.507958,
     "end_time": "2025-04-20T08:36:52.112470",
     "exception": false,
     "start_time": "2025-04-20T08:36:50.604512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b254c89b8a49e7820f02c88fb3ab10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c903cc9e8d0495cb068d554c3f9db53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25efea56466490ea6992b0724a57fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a34b1e720e4e8d837177492e525858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "review_token = '[REVIEW]'\n",
    "aspect_token = '[ASPECT]'\n",
    "special_tokens_dict = {'additional_special_tokens': [review_token, aspect_token]}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "536e8072",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:36:52.135871Z",
     "iopub.status.busy": "2025-04-20T08:36:52.135642Z",
     "iopub.status.idle": "2025-04-20T08:36:52.139596Z",
     "shell.execute_reply": "2025-04-20T08:36:52.139038Z"
    },
    "papermill": {
     "duration": 0.016661,
     "end_time": "2025-04-20T08:36:52.140718",
     "exception": false,
     "start_time": "2025-04-20T08:36:52.124057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_aspect_dataset(X_train, y_train, X_val, y_val, sequence_length, num_workers=4):\n",
    "    train_dataset = AspectDetectionDataset(X_train, y_train, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = AspectDetectionDataset(X_val, y_val, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed694c9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:36:52.163403Z",
     "iopub.status.busy": "2025-04-20T08:36:52.163196Z",
     "iopub.status.idle": "2025-04-20T08:36:52.172326Z",
     "shell.execute_reply": "2025-04-20T08:36:52.171689Z"
    },
    "papermill": {
     "duration": 0.021753,
     "end_time": "2025-04-20T08:36:52.173478",
     "exception": false,
     "start_time": "2025-04-20T08:36:52.151725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sentiment_dataset(device, train_dataset, val_dataset, aspect_detection_model, tokenizer, max_length=sequence_length):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    aspect_detection_model.to(device)\n",
    "    aspect_detection_model.eval()\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    train_aspects = []\n",
    "    train_indices = []\n",
    "\n",
    "    val_data = []\n",
    "    val_labels = []\n",
    "    val_aspects = []\n",
    "    val_indices = []\n",
    "\n",
    "    # Transform train set\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        train_aspects.append(aspect_list[j])\n",
    "                        train_data.append(batch['ori_text'][i])\n",
    "                        train_labels.append(batch['ori_label'][i][j])\n",
    "                        train_indices.append(batch['ori_indices'][i])\n",
    "            \n",
    "        # Transform validation set\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        val_aspects.append(aspect_list[j])\n",
    "                        val_data.append(batch['ori_text'][i])\n",
    "                        val_labels.append(batch['ori_label'][i][j])\n",
    "                        val_indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    train_dataset = SentimentAnalysisDataset(train_data, train_labels, train_aspects, train_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "    val_dataset = SentimentAnalysisDataset(val_data, val_labels, val_aspects, val_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbaa4c7",
   "metadata": {
    "papermill": {
     "duration": 0.012117,
     "end_time": "2025-04-20T08:36:52.196597",
     "exception": false,
     "start_time": "2025-04-20T08:36:52.184480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daf1be53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:36:52.221841Z",
     "iopub.status.busy": "2025-04-20T08:36:52.221570Z",
     "iopub.status.idle": "2025-04-20T08:36:52.225367Z",
     "shell.execute_reply": "2025-04-20T08:36:52.224680Z"
    },
    "papermill": {
     "duration": 0.018157,
     "end_time": "2025-04-20T08:36:52.226652",
     "exception": false,
     "start_time": "2025-04-20T08:36:52.208495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cceaa5e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:36:52.251116Z",
     "iopub.status.busy": "2025-04-20T08:36:52.250861Z",
     "iopub.status.idle": "2025-04-20T08:36:52.255528Z",
     "shell.execute_reply": "2025-04-20T08:36:52.254817Z"
    },
    "papermill": {
     "duration": 0.018498,
     "end_time": "2025-04-20T08:36:52.256801",
     "exception": false,
     "start_time": "2025-04-20T08:36:52.238303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p, label, classes):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        labels=label,\n",
    "        target_names=classes,\n",
    "        zero_division=0\n",
    "    ) \n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88f4388e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:36:52.281347Z",
     "iopub.status.busy": "2025-04-20T08:36:52.281134Z",
     "iopub.status.idle": "2025-04-20T08:36:52.287184Z",
     "shell.execute_reply": "2025-04-20T08:36:52.286557Z"
    },
    "papermill": {
     "duration": 0.019651,
     "end_time": "2025-04-20T08:36:52.288364",
     "exception": false,
     "start_time": "2025-04-20T08:36:52.268713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics_overall(p, classes):\n",
    "    preds = torch.tensor(p.predictions)\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Ensure it's in the correct shape\n",
    "    if preds.shape != labels.shape:\n",
    "        raise ValueError(\"Shape mismatch: predictions and labels must have the same shape.\")\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Compute per-label (column-wise) precision, recall, F1\n",
    "    precision_list, recall_list, f1_micro_list, f1_macro_list = [], [], [], []\n",
    "    \n",
    "    for i in range(labels.shape[1]):  # Loop through each column (multi-output)\n",
    "        prec, rec, f1_micro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='micro', zero_division=0\n",
    "        )\n",
    "        _, _, f1_macro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='macro', zero_division=0\n",
    "        )\n",
    "\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        f1_micro_list.append(f1_micro)\n",
    "        f1_macro_list.append(f1_macro)\n",
    "\n",
    "    # Compute average metrics across all outputs\n",
    "    precision = sum(precision_list) / len(precision_list)\n",
    "    recall = sum(recall_list) / len(recall_list)\n",
    "    f1_micro = sum(f1_micro_list) / len(f1_micro_list)\n",
    "    f1_macro = sum(f1_macro_list) / len(f1_macro_list)\n",
    "\n",
    "    # Generate classification report per output\n",
    "    reports = [classification_report(labels[:, i], preds[:, i], target_names=classes, zero_division=0) for i in range(labels.shape[1])]\n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'reports': reports  # Returns list of reports, one for each output label\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96e4ae81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:36:52.312082Z",
     "iopub.status.busy": "2025-04-20T08:36:52.311858Z",
     "iopub.status.idle": "2025-04-20T08:36:52.337543Z",
     "shell.execute_reply": "2025-04-20T08:36:52.336944Z"
    },
    "papermill": {
     "duration": 0.038922,
     "end_time": "2025-04-20T08:36:52.338665",
     "exception": false,
     "start_time": "2025-04-20T08:36:52.299743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, aspect_metrics, sentiment_metrics, metrics, trials, seed):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "\n",
    "    nearest_cp = current_train_size\n",
    "    if nearest_cp not in checkpoints:\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "    percentage = math.ceil(nearest_cp / total_data * 100)\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in aspect_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    aspect_optimizer = torch.optim.AdamW(aspect_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    aspect_train_loader, aspect_val_loader, aspect_train_dataset, aspect_val_dataset = build_aspect_dataset(current_X_train, current_y_train, X_val, y_val, sequence_length)\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader = accelerator.prepare(\n",
    "        aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader\n",
    "    )\n",
    "\n",
    "    aspect_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ASPECT DETECTION\n",
    "    accelerator.print(\"ASPECT DETECTION\")\n",
    "    for epoch in range(epochs):\n",
    "        aspect_model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in aspect_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            aspect_optimizer.zero_grad()\n",
    "            outputs = aspect_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            aspect_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        aspect_model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in aspect_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = aspect_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}),\n",
    "            None,\n",
    "            aspect_list,\n",
    "        )\n",
    "\n",
    "        if aspect_result is None or result['f1_micro'] >= aspect_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(aspect_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-aspect-{trials + 1}-model-{percentage}',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            aspect_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(aspect_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"\\nAspect detection accuracy: {round(aspect_result['accuracy'], 4)}, F1 Micro: {round(aspect_result['f1_micro'], 4)}, F1 Macro: {round(aspect_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(aspect_result['report'])\n",
    "\n",
    "    best_aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{trials + 1}-model-{percentage}')\n",
    "    best_aspect_model = accelerator.prepare(best_aspect_model)\n",
    "\n",
    "    # SENTIMENT ANALYSIS ON NON NEUTRAL ASPECTS\n",
    "    accelerator.print(\"--------------------------------------------------\")\n",
    "    accelerator.print(\"SENTIMENT ANALYSIS\")\n",
    "\n",
    "    sentiment_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=2,\n",
    "    )\n",
    "    sentiment_optimizer = torch.optim.AdamW(sentiment_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "    for name, param in sentiment_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    sentiment_train_loader, sentiment_val_loader, sentiment_train_dataset, sentiment_val_dataset = build_sentiment_dataset(\n",
    "        device, aspect_train_dataset, aspect_val_dataset, best_aspect_model, tokenizer, max_length=sequence_length\n",
    "    )\n",
    "    sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader = accelerator.prepare(\n",
    "        sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader\n",
    "    )\n",
    "    sentiment_result = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sentiment_model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in sentiment_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            sentiment_optimizer.zero_grad()\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            sentiment_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        sentiment_model.eval()\n",
    "        sentiment_val_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in sentiment_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                \n",
    "                outputs = sentiment_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                for i in range(len(preds)):\n",
    "                    val_output = {\n",
    "                        'label': batch['labels'][i],\n",
    "                        'aspect': batch['aspect'][i],\n",
    "                        'ori_indices': batch['ori_indices'][i],\n",
    "                        'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                    }\n",
    "                    sentiment_val_outputs.append(val_output)\n",
    "\n",
    "        sentiment_val_outputs = accelerator.gather_for_metrics(sentiment_val_outputs)\n",
    "        unique_val_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_val_outputs}\n",
    "        sentiment_val_outputs = list(unique_val_outputs.values())\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': [item['pred'] for item in sentiment_val_outputs], 'label_ids': [np.argmax(item['label'].cpu().numpy()) for item in sentiment_val_outputs]}),\n",
    "            [0, 1],\n",
    "            ['negative', 'positive']\n",
    "        )\n",
    "\n",
    "        if sentiment_result is None or result['f1_micro'] >= sentiment_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            sentiment_result = result\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(sentiment_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                 f'{filename}-sentiment-{trials + 1}-model-{percentage}',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(sentiment_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    accelerator.print(f\"\\nSentiment analysis accuracy: {round(sentiment_result['accuracy'], 4)}, F1 Micro: {round(sentiment_result['f1_micro'], 4)}, F1 Macro: {round(sentiment_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(sentiment_result['report'])\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    best_sentiment_model = BertForSequenceClassification.from_pretrained( f'{filename}-sentiment-{trials + 1}-model-{percentage}')\n",
    "    best_sentiment_model = accelerator.prepare(best_sentiment_model)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    aspect_labels = []\n",
    "    aspect_indices = []\n",
    "    aspect_preds = []\n",
    "\n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = []\n",
    "    \n",
    "    best_aspect_model.eval()\n",
    "    best_sentiment_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in aspect_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = aspect_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            aspect_indices.append(accelerator.gather(batch['ori_indices']))\n",
    "            aspect_labels.append(accelerator.gather(batch['ori_label']))\n",
    "            aspect_preds.append(accelerator.gather(preds))\n",
    "\n",
    "        aspect_indices = torch.cat(aspect_indices).cpu().numpy()\n",
    "        aspect_labels = torch.cat(aspect_labels).cpu().numpy()\n",
    "        aspect_preds = torch.cat(aspect_preds).cpu().numpy()\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        aspect_outputs = [\n",
    "            {'ori_indices': aspect_indices[i], \n",
    "             'ori_labels': aspect_labels[i], \n",
    "             'pred': aspect_preds[i]}\n",
    "            for i in range(len(aspect_preds))\n",
    "        ]\n",
    "        aspect_outputs = {x['ori_indices'].item(): x for x in aspect_outputs}\n",
    "    \n",
    "        for batch in sentiment_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "    \n",
    "            for i in range(len(preds)):\n",
    "                output = {\n",
    "                    'aspect': batch['aspect'][i],\n",
    "                    'ori_indices': batch['ori_indices'][i],\n",
    "                    'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                }\n",
    "                sentiment_outputs.append(output)\n",
    "\n",
    "        sentiment_outputs = accelerator.gather_for_metrics(sentiment_outputs)\n",
    "        sentiment_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_outputs}\n",
    "\n",
    "    # Replcae non neutral aspect to its predicted sentiment\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        i = -1\n",
    "        for (ori_index, aspect), value in sentiment_outputs.items():\n",
    "            aspect = aspect_mapping[aspect]\n",
    "            aspect_outputs[ori_index]['pred'][aspect] = 2 if value['pred'] == 1.0 else value['pred']\n",
    "\n",
    "        result = compute_metrics_overall(\n",
    "            type('EvalOutput', (object,), {'predictions': [output['pred'] for output in aspect_outputs.values()], 'label_ids': [output['ori_labels'] for output in aspect_outputs.values()]}),\n",
    "            ['negative', 'neutral', 'positive'],\n",
    "        )\n",
    "\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        for i in range(len(train_labels)):\n",
    "            accelerator.print(f\"Aspect {aspect_list[i]} report:\")\n",
    "            accelerator.print(result['reports'][i])\n",
    "       \n",
    "        \n",
    "        aspect_metrics[0].append(aspect_result['accuracy'])\n",
    "        aspect_metrics[1].append(aspect_result['f1_micro'])\n",
    "        aspect_metrics[2].append(aspect_result['f1_macro'])\n",
    "        sentiment_metrics[0].append(sentiment_result['accuracy'])\n",
    "        sentiment_metrics[1].append(sentiment_result['f1_micro'])\n",
    "        sentiment_metrics[2].append(sentiment_result['f1_macro'])\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(result['accuracy'])\n",
    "        metrics[2].append(result['f1_micro'])\n",
    "        metrics[3].append(result['f1_macro'])\n",
    "        \n",
    "    accelerator.print(f\"Total train time: {duration} s\")\n",
    "    accelerator.end_training()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10be6818",
   "metadata": {
    "papermill": {
     "duration": 0.011054,
     "end_time": "2025-04-20T08:36:52.360921",
     "exception": false,
     "start_time": "2025-04-20T08:36:52.349867",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa1f8007",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:36:52.384399Z",
     "iopub.status.busy": "2025-04-20T08:36:52.384177Z",
     "iopub.status.idle": "2025-04-20T08:36:52.389189Z",
     "shell.execute_reply": "2025-04-20T08:36:52.388550Z"
    },
    "papermill": {
     "duration": 0.018041,
     "end_time": "2025-04-20T08:36:52.390380",
     "exception": false,
     "start_time": "2025-04-20T08:36:52.372339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a58d668",
   "metadata": {
    "papermill": {
     "duration": 0.010914,
     "end_time": "2025-04-20T08:36:52.412458",
     "exception": false,
     "start_time": "2025-04-20T08:36:52.401544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22f97387",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:36:52.437025Z",
     "iopub.status.busy": "2025-04-20T08:36:52.436752Z",
     "iopub.status.idle": "2025-04-20T08:36:52.444416Z",
     "shell.execute_reply": "2025-04-20T08:36:52.443705Z"
    },
    "papermill": {
     "duration": 0.021406,
     "end_time": "2025-04-20T08:36:52.445603",
     "exception": false,
     "start_time": "2025-04-20T08:36:52.424197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_sampling(current_train_size, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, n_samples=min_increment):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    nearest_cp = 0\n",
    "    arrived_at_cp = False\n",
    "    for cp in checkpoints:\n",
    "        if cp > current_train_size:\n",
    "            nearest_cp = cp\n",
    "            break\n",
    "\n",
    "    num_of_candidates = math.ceil(0.1 * len(remaining_indices))\n",
    "\n",
    "    if num_of_candidates <= n_samples and n_samples < nearest_cp - current_train_size:\n",
    "        num_of_candidates = n_samples\n",
    "    elif num_of_candidates > n_samples and num_of_candidates < nearest_cp - current_train_size:\n",
    "        num_of_candidates = max(n_samples, num_of_candidates)\n",
    "    else:\n",
    "        num_of_candidates = nearest_cp - current_train_size\n",
    "        arrived_at_cp = True\n",
    "\n",
    "    random_indices = random.sample(range(len(X_pool)), num_of_candidates)\n",
    "\n",
    "    if arrived_at_cp:\n",
    "        temp = train_indices.copy()\n",
    "        temp.extend([remaining_indices[i] for i in random_indices])\n",
    "            \n",
    "        # Save acquired data up to checkpoint\n",
    "        acquired_data = pd.DataFrame({\n",
    "            'processed_text': [X_train[i] for i in temp],\n",
    "            'ac': [y_train[i][0] for i in temp],\n",
    "            'air_panas': [y_train[i][1] for i in temp],\n",
    "            'bau': [y_train[i][2] for i in temp],\n",
    "            'general': [y_train[i][3] for i in temp],\n",
    "            'kebersihan': [y_train[i][4] for i in temp],\n",
    "            'linen': [y_train[i][5] for i in temp],\n",
    "            'service': [y_train[i][6] for i in temp],\n",
    "            'sunrise_meal': [y_train[i][7] for i in temp],\n",
    "            'tv': [y_train[i][8] for i in temp],\n",
    "            'wifi': [y_train[i][9] for i in temp],\n",
    "        })\n",
    "\n",
    "        acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "    end_time = time.time() \n",
    "    duration = end_time - start_time\n",
    "\n",
    "    sampling_dur.append(duration)\n",
    "    for i in random_indices:\n",
    "        new_samples.append(remaining_indices[i])\n",
    "        \n",
    "    print(\"Nearest checkpoint:\", nearest_cp)\n",
    "    print(\"Acquired samples:\", len(random_indices))\n",
    "    print(f\"Sampling duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68b27a7",
   "metadata": {
    "papermill": {
     "duration": 0.011453,
     "end_time": "2025-04-20T08:36:52.468635",
     "exception": false,
     "start_time": "2025-04-20T08:36:52.457182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e97c00a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:36:52.493280Z",
     "iopub.status.busy": "2025-04-20T08:36:52.493006Z",
     "iopub.status.idle": "2025-04-20T08:36:52.502287Z",
     "shell.execute_reply": "2025-04-20T08:36:52.501595Z"
    },
    "papermill": {
     "duration": 0.022953,
     "end_time": "2025-04-20T08:36:52.503500",
     "exception": false,
     "start_time": "2025-04-20T08:36:52.480547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    aspect_accuracies = manager.list()\n",
    "    aspect_f1_micros = manager.list()\n",
    "    aspect_f1_macros = manager.list()\n",
    "    sentiment_accuracies = manager.list()\n",
    "    sentiment_f1_micros = manager.list()\n",
    "    sentiment_f1_macros = manager.list()\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        # Train the model\n",
    "        args = (\n",
    "            current_train_size, \n",
    "            train_indices, \n",
    "            (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "            (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "            (data_used, accuracies, f1_micros, f1_macros), \n",
    "            i,\n",
    "            seed\n",
    "        )\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        random_sampling(\n",
    "            current_train_size, \n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices, \n",
    "            remaining_indices, \n",
    "            sampling_dur, \n",
    "            new_samples, \n",
    "            i\n",
    "        )\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    args = (\n",
    "        current_train_size, \n",
    "        train_indices, \n",
    "        (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "        (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "        (data_used, accuracies, f1_micros, f1_macros), \n",
    "        i,\n",
    "        seed\n",
    "    )\n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    aspect_accuracies, aspect_f1_micros, aspect_f1_macros = list(aspect_accuracies), list(aspect_f1_micros), list(aspect_f1_macros)\n",
    "    sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros = list(sentiment_accuracies), list(sentiment_f1_micros), list(sentiment_f1_macros)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Aspect Accuracy': aspect_accuracies,\n",
    "        'Aspect F1 Micro': aspect_f1_micros,\n",
    "        'Aspect F1 Macro': aspect_f1_macros,\n",
    "        'Sentiment Accuracy': sentiment_accuracies,\n",
    "        'Sentiment F1 Micro': sentiment_f1_micros,\n",
    "        'Sentiment F1 Macro': sentiment_f1_macros,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7462831e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:36:52.528331Z",
     "iopub.status.busy": "2025-04-20T08:36:52.528098Z",
     "iopub.status.idle": "2025-04-20T08:36:52.531017Z",
     "shell.execute_reply": "2025-04-20T08:36:52.530420Z"
    },
    "papermill": {
     "duration": 0.01676,
     "end_time": "2025-04-20T08:36:52.532301",
     "exception": false,
     "start_time": "2025-04-20T08:36:52.515541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acbd7c1",
   "metadata": {
    "papermill": {
     "duration": 0.011694,
     "end_time": "2025-04-20T08:36:52.555362",
     "exception": false,
     "start_time": "2025-04-20T08:36:52.543668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503c85db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5865, Accuracy: 0.7995, F1 Micro: 0.8876, F1 Macro: 0.8805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4747, Accuracy: 0.801, F1 Micro: 0.8892, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4337, Accuracy: 0.8007, F1 Micro: 0.8893, F1 Macro: 0.8848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.425, Accuracy: 0.8033, F1 Micro: 0.8905, F1 Macro: 0.8856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4065, Accuracy: 0.8064, F1 Micro: 0.8916, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4121, Accuracy: 0.8101, F1 Micro: 0.8933, F1 Macro: 0.8874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3857, Accuracy: 0.8177, F1 Micro: 0.8971, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3725, Accuracy: 0.8321, F1 Micro: 0.9044, F1 Macro: 0.8994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3428, Accuracy: 0.841, F1 Micro: 0.9088, F1 Macro: 0.9042\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3197, Accuracy: 0.8507, F1 Micro: 0.9137, F1 Macro: 0.9092\n",
      "\n",
      "Aspect detection accuracy: 0.8507, F1 Micro: 0.9137, F1 Macro: 0.9092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.84      1.00      0.91       462\n",
      "   air_panas       0.84      1.00      0.91       480\n",
      "         bau       0.86      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.80      0.85      0.83       317\n",
      "       linen       0.71      0.99      0.83       392\n",
      "     service       0.88      0.97      0.93       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.86      1.00      0.93       498\n",
      "\n",
      "   micro avg       0.85      0.99      0.91      4614\n",
      "   macro avg       0.85      0.98      0.91      4614\n",
      "weighted avg       0.85      0.99      0.91      4614\n",
      " samples avg       0.85      0.99      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6014, Accuracy: 0.6293, F1 Micro: 0.6293, F1 Macro: 0.3862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5503, Accuracy: 0.6293, F1 Micro: 0.6293, F1 Macro: 0.3862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4934, Accuracy: 0.6293, F1 Micro: 0.6293, F1 Macro: 0.3862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3898, Accuracy: 0.6878, F1 Micro: 0.6878, F1 Macro: 0.5444\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3441, Accuracy: 0.7488, F1 Micro: 0.7488, F1 Macro: 0.6959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2311, Accuracy: 0.7634, F1 Micro: 0.7634, F1 Macro: 0.719\n",
      "Epoch 7/10, Train Loss: 0.181, Accuracy: 0.7439, F1 Micro: 0.7439, F1 Macro: 0.6915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2402, Accuracy: 0.7756, F1 Micro: 0.7756, F1 Macro: 0.7399\n",
      "Epoch 9/10, Train Loss: 0.1526, Accuracy: 0.7512, F1 Micro: 0.7512, F1 Macro: 0.6996\n",
      "Epoch 10/10, Train Loss: 0.1164, Accuracy: 0.7537, F1 Micro: 0.7537, F1 Macro: 0.7047\n",
      "\n",
      "Sentiment analysis accuracy: 0.7756, F1 Micro: 0.7756, F1 Macro: 0.7399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.91      0.84       258\n",
      "    positive       0.78      0.55      0.64       152\n",
      "\n",
      "    accuracy                           0.78       410\n",
      "   macro avg       0.78      0.73      0.74       410\n",
      "weighted avg       0.78      0.78      0.76       410\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8405, F1 Micro: 0.8405, F1 Macro: 0.4036\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.27      0.42        97\n",
      "     neutral       0.84      1.00      0.91       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.59      0.42      0.44       571\n",
      "weighted avg       0.84      0.85      0.81       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.01      0.02        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.44      0.34      0.31       571\n",
      "weighted avg       0.77      0.83      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        78\n",
      "     neutral       0.86      1.00      0.92       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.74      0.86      0.80       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.68      0.70       200\n",
      "     neutral       0.80      0.85      0.83       315\n",
      "    positive       0.35      0.29      0.31        56\n",
      "\n",
      "    accuracy                           0.74       571\n",
      "   macro avg       0.62      0.61      0.61       571\n",
      "weighted avg       0.73      0.74      0.73       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.18      0.30       162\n",
      "     neutral       0.71      0.99      0.83       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.72       571\n",
      "   macro avg       0.52      0.39      0.37       571\n",
      "weighted avg       0.72      0.72      0.64       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.54      0.61        85\n",
      "     neutral       0.88      0.98      0.93       418\n",
      "    positive       0.84      0.54      0.66        68\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.81      0.69      0.73       571\n",
      "weighted avg       0.85      0.86      0.85       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        74\n",
      "     neutral       0.87      1.00      0.93       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.80       571\n",
      "\n",
      "Total train time: 83.9908537864685 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 215\n",
      "Sampling duration: 0.0002448558807373047 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5312, Accuracy: 0.8014, F1 Micro: 0.8896, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4611, Accuracy: 0.8061, F1 Micro: 0.8919, F1 Macro: 0.887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4265, Accuracy: 0.8382, F1 Micro: 0.9076, F1 Macro: 0.9035\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3619, Accuracy: 0.8554, F1 Micro: 0.9165, F1 Macro: 0.9129\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3336, Accuracy: 0.8736, F1 Micro: 0.9261, F1 Macro: 0.9229\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2821, Accuracy: 0.8882, F1 Micro: 0.934, F1 Macro: 0.9314\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2381, Accuracy: 0.904, F1 Micro: 0.9424, F1 Macro: 0.9394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2169, Accuracy: 0.9149, F1 Micro: 0.9487, F1 Macro: 0.9461\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1941, Accuracy: 0.9222, F1 Micro: 0.953, F1 Macro: 0.9504\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1624, Accuracy: 0.9278, F1 Micro: 0.9562, F1 Macro: 0.9537\n",
      "\n",
      "Aspect detection accuracy: 0.9278, F1 Micro: 0.9562, F1 Macro: 0.9537\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.92      0.99      0.96       480\n",
      "         bau       0.95      0.98      0.97       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.86      0.94      0.90       317\n",
      "       linen       0.84      0.97      0.90       392\n",
      "     service       0.96      0.96      0.96       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.98      0.99      0.99       498\n",
      "\n",
      "   micro avg       0.93      0.99      0.96      4614\n",
      "   macro avg       0.93      0.98      0.95      4614\n",
      "weighted avg       0.93      0.99      0.96      4614\n",
      " samples avg       0.93      0.98      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4746, Accuracy: 0.7459, F1 Micro: 0.7459, F1 Macro: 0.4272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3397, Accuracy: 0.8051, F1 Micro: 0.8051, F1 Macro: 0.7339\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2814, Accuracy: 0.8144, F1 Micro: 0.8144, F1 Macro: 0.7002\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2159, Accuracy: 0.848, F1 Micro: 0.848, F1 Macro: 0.7724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1527, Accuracy: 0.8596, F1 Micro: 0.8596, F1 Macro: 0.7817\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1167, Accuracy: 0.8654, F1 Micro: 0.8654, F1 Macro: 0.7947\n",
      "Epoch 7/10, Train Loss: 0.1075, Accuracy: 0.8619, F1 Micro: 0.8619, F1 Macro: 0.7932\n",
      "Epoch 8/10, Train Loss: 0.147, Accuracy: 0.8248, F1 Micro: 0.8248, F1 Macro: 0.6896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1088, Accuracy: 0.8759, F1 Micro: 0.8759, F1 Macro: 0.8102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0669, Accuracy: 0.877, F1 Micro: 0.877, F1 Macro: 0.8132\n",
      "\n",
      "Sentiment analysis accuracy: 0.877, F1 Micro: 0.877, F1 Macro: 0.8132\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.98      0.92       643\n",
      "    positive       0.91      0.58      0.70       219\n",
      "\n",
      "    accuracy                           0.88       862\n",
      "   macro avg       0.89      0.78      0.81       862\n",
      "weighted avg       0.88      0.88      0.87       862\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.6597\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.91      0.67      0.77        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.94      0.86      0.89       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.57      0.70        86\n",
      "     neutral       0.92      0.99      0.96       475\n",
      "    positive       0.60      0.30      0.40        10\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.81      0.62      0.69       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.72      0.77        78\n",
      "     neutral       0.95      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.50      0.03      0.06        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.46      0.34      0.33       571\n",
      "weighted avg       0.82      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.76      0.81       200\n",
      "     neutral       0.86      0.94      0.90       315\n",
      "    positive       0.81      0.77      0.79        56\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.84      0.82      0.83       571\n",
      "weighted avg       0.86      0.86      0.85       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.65      0.75       162\n",
      "     neutral       0.84      0.97      0.90       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.57      0.54      0.55       571\n",
      "weighted avg       0.82      0.85      0.82       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.78      0.77        85\n",
      "     neutral       0.96      0.97      0.96       418\n",
      "    positive       0.92      0.82      0.87        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.86      0.87       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.91      0.88        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.62      0.63      0.63       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.88      0.92        74\n",
      "     neutral       0.98      0.99      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.96      0.92       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 120.61229205131531 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 193\n",
      "Sampling duration: 0.0002002716064453125 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.512, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4362, Accuracy: 0.8347, F1 Micro: 0.9057, F1 Macro: 0.9013\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3844, Accuracy: 0.8599, F1 Micro: 0.9184, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3193, Accuracy: 0.8877, F1 Micro: 0.9335, F1 Macro: 0.9302\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2502, Accuracy: 0.9184, F1 Micro: 0.9508, F1 Macro: 0.9482\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2169, Accuracy: 0.9273, F1 Micro: 0.9558, F1 Macro: 0.9533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1834, Accuracy: 0.9292, F1 Micro: 0.957, F1 Macro: 0.9542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1598, Accuracy: 0.9302, F1 Micro: 0.9576, F1 Macro: 0.9549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1422, Accuracy: 0.9399, F1 Micro: 0.9633, F1 Macro: 0.9607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1258, Accuracy: 0.941, F1 Micro: 0.9638, F1 Macro: 0.9611\n",
      "\n",
      "Aspect detection accuracy: 0.941, F1 Micro: 0.9638, F1 Macro: 0.9611\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.96      0.99      0.98       480\n",
      "         bau       0.96      0.97      0.97       496\n",
      "     general       0.88      0.99      0.93       500\n",
      "  kebersihan       0.92      0.90      0.91       317\n",
      "       linen       0.85      0.97      0.91       392\n",
      "     service       0.96      0.96      0.96       423\n",
      "sunrise_meal       0.96      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      4614\n",
      "   macro avg       0.95      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.96      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4994, Accuracy: 0.7903, F1 Micro: 0.7903, F1 Macro: 0.687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3503, Accuracy: 0.8304, F1 Micro: 0.8304, F1 Macro: 0.7696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2303, Accuracy: 0.8561, F1 Micro: 0.8561, F1 Macro: 0.8013\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1781, Accuracy: 0.8613, F1 Micro: 0.8613, F1 Macro: 0.8204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2049, Accuracy: 0.8746, F1 Micro: 0.8746, F1 Macro: 0.8269\n",
      "Epoch 6/10, Train Loss: 0.1533, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.7886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1055, Accuracy: 0.8798, F1 Micro: 0.8798, F1 Macro: 0.829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.084, Accuracy: 0.889, F1 Micro: 0.889, F1 Macro: 0.8458\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0843, Accuracy: 0.89, F1 Micro: 0.89, F1 Macro: 0.8484\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0605, Accuracy: 0.89, F1 Micro: 0.89, F1 Macro: 0.8436\n",
      "\n",
      "Sentiment analysis accuracy: 0.89, F1 Micro: 0.89, F1 Macro: 0.8436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93       709\n",
      "    positive       0.94      0.64      0.76       264\n",
      "\n",
      "    accuracy                           0.89       973\n",
      "   macro avg       0.91      0.81      0.84       973\n",
      "weighted avg       0.90      0.89      0.88       973\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9345, F1 Micro: 0.9345, F1 Macro: 0.7597\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.92      0.73      0.81        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.89      0.91       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        86\n",
      "     neutral       0.96      0.99      0.98       475\n",
      "    positive       0.60      0.30      0.40        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.83      0.69      0.74       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.77      0.79        78\n",
      "     neutral       0.96      0.97      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.58      0.59       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.88      0.99      0.93       496\n",
      "    positive       0.75      0.13      0.23        68\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.54      0.38      0.39       571\n",
      "weighted avg       0.86      0.88      0.84       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85       200\n",
      "     neutral       0.92      0.90      0.91       315\n",
      "    positive       0.88      0.88      0.88        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.88      0.88      0.88       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.67      0.77       162\n",
      "     neutral       0.84      0.97      0.90       387\n",
      "    positive       0.75      0.14      0.23        22\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.83      0.59      0.63       571\n",
      "weighted avg       0.86      0.85      0.84       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        85\n",
      "     neutral       0.96      0.96      0.96       418\n",
      "    positive       0.87      0.91      0.89        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.89      0.90      0.90       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.24      0.34        29\n",
      "     neutral       0.96      1.00      0.98       525\n",
      "    positive       0.73      0.47      0.57        17\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.57      0.63       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 148.8705472946167 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 174\n",
      "Sampling duration: 0.0001773834228515625 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5065, Accuracy: 0.8177, F1 Micro: 0.8956, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4243, Accuracy: 0.8415, F1 Micro: 0.9091, F1 Macro: 0.905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3532, Accuracy: 0.8825, F1 Micro: 0.9309, F1 Macro: 0.9278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2729, Accuracy: 0.9191, F1 Micro: 0.9513, F1 Macro: 0.9483\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2184, Accuracy: 0.9297, F1 Micro: 0.9573, F1 Macro: 0.955\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1813, Accuracy: 0.9356, F1 Micro: 0.9608, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1586, Accuracy: 0.9422, F1 Micro: 0.9646, F1 Macro: 0.9622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1403, Accuracy: 0.9457, F1 Micro: 0.9666, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1207, Accuracy: 0.9479, F1 Micro: 0.9679, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1077, Accuracy: 0.9491, F1 Micro: 0.9686, F1 Macro: 0.9662\n",
      "\n",
      "Aspect detection accuracy: 0.9491, F1 Micro: 0.9686, F1 Macro: 0.9662\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.91      0.98      0.94       500\n",
      "  kebersihan       0.93      0.91      0.92       317\n",
      "       linen       0.87      0.97      0.92       392\n",
      "     service       0.97      0.96      0.96       423\n",
      "sunrise_meal       0.96      1.00      0.98       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4686, Accuracy: 0.8092, F1 Micro: 0.8092, F1 Macro: 0.7476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3052, Accuracy: 0.8219, F1 Micro: 0.8219, F1 Macro: 0.7273\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2135, Accuracy: 0.8513, F1 Micro: 0.8513, F1 Macro: 0.7848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1964, Accuracy: 0.8787, F1 Micro: 0.8787, F1 Macro: 0.8417\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.136, Accuracy: 0.8894, F1 Micro: 0.8894, F1 Macro: 0.857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1106, Accuracy: 0.8924, F1 Micro: 0.8924, F1 Macro: 0.8592\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0863, Accuracy: 0.8953, F1 Micro: 0.8953, F1 Macro: 0.8585\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.069, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8667\n",
      "Epoch 9/10, Train Loss: 0.0501, Accuracy: 0.8953, F1 Micro: 0.8953, F1 Macro: 0.8582\n",
      "Epoch 10/10, Train Loss: 0.0516, Accuracy: 0.8982, F1 Micro: 0.8982, F1 Macro: 0.8662\n",
      "\n",
      "Sentiment analysis accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93       731\n",
      "    positive       0.92      0.71      0.80       291\n",
      "\n",
      "    accuracy                           0.90      1022\n",
      "   macro avg       0.91      0.84      0.87      1022\n",
      "weighted avg       0.90      0.90      0.90      1022\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9424, F1 Micro: 0.9424, F1 Macro: 0.8064\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.78      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.81      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.91      0.98      0.94       496\n",
      "    positive       0.75      0.40      0.52        68\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.55      0.46      0.49       571\n",
      "weighted avg       0.88      0.90      0.88       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.87       200\n",
      "     neutral       0.93      0.91      0.92       315\n",
      "    positive       0.81      0.96      0.88        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.87      0.91      0.89       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.72      0.80       162\n",
      "     neutral       0.87      0.97      0.92       387\n",
      "    positive       0.60      0.14      0.22        22\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.79      0.61      0.65       571\n",
      "weighted avg       0.86      0.87      0.86       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.80      0.82        85\n",
      "     neutral       0.97      0.96      0.97       418\n",
      "    positive       0.86      0.94      0.90        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.89      0.90      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.17      0.29        29\n",
      "     neutral       0.96      1.00      0.98       525\n",
      "    positive       0.72      0.76      0.74        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.84      0.65      0.67       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.97      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 166.46530604362488 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 156\n",
      "Sampling duration: 0.00018906593322753906 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4865, Accuracy: 0.8033, F1 Micro: 0.8906, F1 Macro: 0.886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4051, Accuracy: 0.8681, F1 Micro: 0.9227, F1 Macro: 0.9189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3085, Accuracy: 0.9097, F1 Micro: 0.9459, F1 Macro: 0.9434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2421, Accuracy: 0.9266, F1 Micro: 0.9555, F1 Macro: 0.9525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1981, Accuracy: 0.9359, F1 Micro: 0.961, F1 Macro: 0.9586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.17, Accuracy: 0.9455, F1 Micro: 0.9666, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.139, Accuracy: 0.9491, F1 Micro: 0.9688, F1 Macro: 0.9664\n",
      "Epoch 8/10, Train Loss: 0.1205, Accuracy: 0.949, F1 Micro: 0.9687, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1033, Accuracy: 0.9549, F1 Micro: 0.9721, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.091, Accuracy: 0.9549, F1 Micro: 0.9721, F1 Macro: 0.9697\n",
      "\n",
      "Aspect detection accuracy: 0.9549, F1 Micro: 0.9721, F1 Macro: 0.9697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.93      0.92      0.92       317\n",
      "       linen       0.90      0.97      0.93       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4486, Accuracy: 0.8335, F1 Micro: 0.8335, F1 Macro: 0.7595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2835, Accuracy: 0.8596, F1 Micro: 0.8596, F1 Macro: 0.803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1769, Accuracy: 0.8925, F1 Micro: 0.8925, F1 Macro: 0.8564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1357, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8756\n",
      "Epoch 5/10, Train Loss: 0.0992, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8733\n",
      "Epoch 6/10, Train Loss: 0.0771, Accuracy: 0.8809, F1 Micro: 0.8809, F1 Macro: 0.8314\n",
      "Epoch 7/10, Train Loss: 0.0675, Accuracy: 0.8955, F1 Micro: 0.8955, F1 Macro: 0.8555\n",
      "Epoch 8/10, Train Loss: 0.0529, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8639\n",
      "Epoch 9/10, Train Loss: 0.0245, Accuracy: 0.8964, F1 Micro: 0.8964, F1 Macro: 0.8609\n",
      "Epoch 10/10, Train Loss: 0.0109, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8698\n",
      "\n",
      "Sentiment analysis accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       744\n",
      "    positive       0.90      0.75      0.82       289\n",
      "\n",
      "    accuracy                           0.91      1033\n",
      "   macro avg       0.90      0.86      0.88      1033\n",
      "weighted avg       0.90      0.91      0.90      1033\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.8186\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.95       496\n",
      "    positive       0.83      0.50      0.62        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.58      0.50      0.53       571\n",
      "weighted avg       0.90      0.92      0.90       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       200\n",
      "     neutral       0.93      0.92      0.92       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.78      0.81       162\n",
      "     neutral       0.90      0.97      0.93       387\n",
      "    positive       0.75      0.14      0.23        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.83      0.63      0.66       571\n",
      "weighted avg       0.88      0.88      0.87       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.85        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.91      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.90      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.28      0.40        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.80      0.66      0.70       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 175.11029529571533 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 141\n",
      "Sampling duration: 0.0001456737518310547 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4771, Accuracy: 0.816, F1 Micro: 0.8968, F1 Macro: 0.8921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.375, Accuracy: 0.8819, F1 Micro: 0.9301, F1 Macro: 0.9256\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2883, Accuracy: 0.9179, F1 Micro: 0.9506, F1 Macro: 0.9478\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2234, Accuracy: 0.9307, F1 Micro: 0.9578, F1 Macro: 0.9554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1824, Accuracy: 0.9385, F1 Micro: 0.9626, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1551, Accuracy: 0.9462, F1 Micro: 0.967, F1 Macro: 0.9647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1266, Accuracy: 0.95, F1 Micro: 0.9692, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1103, Accuracy: 0.9531, F1 Micro: 0.9711, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1, Accuracy: 0.9554, F1 Micro: 0.9725, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0888, Accuracy: 0.9561, F1 Micro: 0.9729, F1 Macro: 0.9704\n",
      "\n",
      "Aspect detection accuracy: 0.9561, F1 Micro: 0.9729, F1 Macro: 0.9704\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.93      0.92      0.92       317\n",
      "       linen       0.88      0.98      0.93       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3965, Accuracy: 0.8375, F1 Micro: 0.8375, F1 Macro: 0.7973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2497, Accuracy: 0.8663, F1 Micro: 0.8663, F1 Macro: 0.8197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1823, Accuracy: 0.8856, F1 Micro: 0.8856, F1 Macro: 0.8484\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.145, Accuracy: 0.8952, F1 Micro: 0.8952, F1 Macro: 0.8622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0855, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0671, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8791\n",
      "Epoch 7/10, Train Loss: 0.0631, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8736\n",
      "Epoch 8/10, Train Loss: 0.0454, Accuracy: 0.9019, F1 Micro: 0.9019, F1 Macro: 0.8692\n",
      "Epoch 9/10, Train Loss: 0.0484, Accuracy: 0.901, F1 Micro: 0.901, F1 Macro: 0.8713\n",
      "Epoch 10/10, Train Loss: 0.038, Accuracy: 0.9019, F1 Micro: 0.9019, F1 Macro: 0.8686\n",
      "\n",
      "Sentiment analysis accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       744\n",
      "    positive       0.90      0.75      0.82       296\n",
      "\n",
      "    accuracy                           0.91      1040\n",
      "   macro avg       0.91      0.86      0.88      1040\n",
      "weighted avg       0.91      0.91      0.90      1040\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.8462\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.80      0.40      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.89      0.75      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.93      0.99      0.96       496\n",
      "    positive       0.85      0.51      0.64        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.76      0.55      0.61       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       200\n",
      "     neutral       0.93      0.92      0.92       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.73      0.80       162\n",
      "     neutral       0.88      0.98      0.93       387\n",
      "    positive       1.00      0.18      0.31        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.92      0.63      0.68       571\n",
      "weighted avg       0.88      0.88      0.87       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.95      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.41      0.50        29\n",
      "     neutral       0.97      1.00      0.99       525\n",
      "    positive       0.71      0.59      0.65        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.77      0.67      0.71       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 195.17178606987 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 127\n",
      "Sampling duration: 0.00016021728515625 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4798, Accuracy: 0.8099, F1 Micro: 0.8938, F1 Macro: 0.8891\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3619, Accuracy: 0.888, F1 Micro: 0.9337, F1 Macro: 0.9304\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2654, Accuracy: 0.9281, F1 Micro: 0.9565, F1 Macro: 0.9545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2048, Accuracy: 0.9372, F1 Micro: 0.9617, F1 Macro: 0.9595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1608, Accuracy: 0.9469, F1 Micro: 0.9674, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1402, Accuracy: 0.9519, F1 Micro: 0.9704, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.119, Accuracy: 0.9547, F1 Micro: 0.972, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.104, Accuracy: 0.9557, F1 Micro: 0.9727, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.088, Accuracy: 0.9578, F1 Micro: 0.974, F1 Macro: 0.9717\n",
      "Epoch 10/10, Train Loss: 0.0761, Accuracy: 0.9576, F1 Micro: 0.9739, F1 Macro: 0.9718\n",
      "\n",
      "Aspect detection accuracy: 0.9578, F1 Micro: 0.974, F1 Macro: 0.9717\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.91      0.94      0.93       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.99      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3863, Accuracy: 0.861, F1 Micro: 0.861, F1 Macro: 0.8093\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.244, Accuracy: 0.8756, F1 Micro: 0.8756, F1 Macro: 0.8327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1947, Accuracy: 0.896, F1 Micro: 0.896, F1 Macro: 0.8589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.122, Accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.8783\n",
      "Epoch 5/10, Train Loss: 0.1046, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8763\n",
      "Epoch 6/10, Train Loss: 0.0777, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0382, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8808\n",
      "Epoch 8/10, Train Loss: 0.0404, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8786\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0421, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8847\n",
      "Epoch 10/10, Train Loss: 0.0208, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8772\n",
      "\n",
      "Sentiment analysis accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8847\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       748\n",
      "    positive       0.93      0.74      0.83       281\n",
      "\n",
      "    accuracy                           0.91      1029\n",
      "   macro avg       0.92      0.86      0.88      1029\n",
      "weighted avg       0.92      0.91      0.91      1029\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.951, F1 Micro: 0.951, F1 Macro: 0.8233\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.86      0.90        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.78      0.82        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.96       496\n",
      "    positive       0.84      0.47      0.60        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.49      0.52       571\n",
      "weighted avg       0.90      0.92      0.90       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.89       200\n",
      "     neutral       0.93      0.94      0.93       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.83      0.82       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       1.00      0.14      0.24        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.91      0.64      0.67       571\n",
      "weighted avg       0.89      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.28      0.40        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.67      0.82      0.74        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.79      0.70      0.71       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 211.69282484054565 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 114\n",
      "Sampling duration: 0.00014352798461914062 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.479, Accuracy: 0.8337, F1 Micro: 0.9054, F1 Macro: 0.9007\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3537, Accuracy: 0.9045, F1 Micro: 0.9429, F1 Macro: 0.94\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2399, Accuracy: 0.9354, F1 Micro: 0.9605, F1 Macro: 0.9577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1906, Accuracy: 0.9476, F1 Micro: 0.9678, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1606, Accuracy: 0.9507, F1 Micro: 0.9696, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1343, Accuracy: 0.9533, F1 Micro: 0.9712, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1125, Accuracy: 0.9543, F1 Micro: 0.9718, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0939, Accuracy: 0.958, F1 Micro: 0.9741, F1 Macro: 0.9716\n",
      "Epoch 9/10, Train Loss: 0.0809, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0725, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9732\n",
      "\n",
      "Aspect detection accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.97      0.96       500\n",
      "  kebersihan       0.92      0.93      0.93       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4149, Accuracy: 0.8253, F1 Micro: 0.8253, F1 Macro: 0.7953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2588, Accuracy: 0.8717, F1 Micro: 0.8717, F1 Macro: 0.8331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2033, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8722\n",
      "Epoch 4/10, Train Loss: 0.141, Accuracy: 0.8978, F1 Micro: 0.8978, F1 Macro: 0.8666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0929, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0632, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8775\n",
      "Epoch 7/10, Train Loss: 0.0463, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0395, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0369, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8801\n",
      "Epoch 10/10, Train Loss: 0.0345, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8764\n",
      "\n",
      "Sentiment analysis accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       761\n",
      "    positive       0.93      0.74      0.82       315\n",
      "\n",
      "    accuracy                           0.91      1076\n",
      "   macro avg       0.91      0.86      0.88      1076\n",
      "weighted avg       0.91      0.91      0.90      1076\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9534, F1 Micro: 0.9534, F1 Macro: 0.8674\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.78      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.43      0.55         7\n",
      "     neutral       0.95      0.97      0.96       496\n",
      "    positive       0.80      0.69      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.83      0.70      0.75       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       200\n",
      "     neutral       0.92      0.93      0.93       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.80      0.84       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.88      0.32      0.47        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.70      0.75       571\n",
      "weighted avg       0.90      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.84      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.90      0.91      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.38      0.50        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.80      0.73      0.75       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 224.12076210975647 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 103\n",
      "Sampling duration: 0.0001430511474609375 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4697, Accuracy: 0.8432, F1 Micro: 0.9099, F1 Macro: 0.905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3308, Accuracy: 0.9125, F1 Micro: 0.9477, F1 Macro: 0.9458\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2398, Accuracy: 0.9352, F1 Micro: 0.9607, F1 Macro: 0.9585\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1872, Accuracy: 0.9474, F1 Micro: 0.9677, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1566, Accuracy: 0.9516, F1 Micro: 0.9701, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.126, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1053, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0921, Accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0786, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9745\n",
      "Epoch 10/10, Train Loss: 0.0695, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9739\n",
      "\n",
      "Aspect detection accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       0.99      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3768, Accuracy: 0.8401, F1 Micro: 0.8401, F1 Macro: 0.8007\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2578, Accuracy: 0.8826, F1 Micro: 0.8826, F1 Macro: 0.8512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.156, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8793\n",
      "Epoch 4/10, Train Loss: 0.1044, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0686, Accuracy: 0.9085, F1 Micro: 0.9085, F1 Macro: 0.8825\n",
      "Epoch 6/10, Train Loss: 0.053, Accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.8775\n",
      "Epoch 7/10, Train Loss: 0.0327, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8764\n",
      "Epoch 8/10, Train Loss: 0.0407, Accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.8767\n",
      "Epoch 9/10, Train Loss: 0.0174, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8755\n",
      "Epoch 10/10, Train Loss: 0.0571, Accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.8759\n",
      "\n",
      "Sentiment analysis accuracy: 0.9085, F1 Micro: 0.9085, F1 Macro: 0.8825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       767\n",
      "    positive       0.92      0.75      0.83       315\n",
      "\n",
      "    accuracy                           0.91      1082\n",
      "   macro avg       0.91      0.86      0.88      1082\n",
      "weighted avg       0.91      0.91      0.91      1082\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9559, F1 Micro: 0.9559, F1 Macro: 0.8665\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.86      0.90        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.78      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.66      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.71      0.59      0.64       571\n",
      "weighted avg       0.92      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.84      0.84       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       1.00      0.32      0.48        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.71      0.76       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.79      0.83        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.86      0.96      0.90        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.90      0.91      0.90       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.67      1.00      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.87      0.97      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 233.16684007644653 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 62\n",
      "Sampling duration: 0.028278350830078125 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4676, Accuracy: 0.8427, F1 Micro: 0.9096, F1 Macro: 0.9055\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3208, Accuracy: 0.9207, F1 Micro: 0.9522, F1 Macro: 0.9496\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2251, Accuracy: 0.9373, F1 Micro: 0.9619, F1 Macro: 0.9598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1835, Accuracy: 0.9484, F1 Micro: 0.9682, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1575, Accuracy: 0.9516, F1 Micro: 0.9703, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1225, Accuracy: 0.9552, F1 Micro: 0.9724, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1033, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.973\n",
      "Epoch 8/10, Train Loss: 0.0962, Accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0758, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0661, Accuracy: 0.9613, F1 Micro: 0.9761, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9761, F1 Macro: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.378, Accuracy: 0.8567, F1 Micro: 0.8567, F1 Macro: 0.806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2455, Accuracy: 0.8843, F1 Micro: 0.8843, F1 Macro: 0.8499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1603, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0994, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.076, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8891\n",
      "Epoch 6/10, Train Loss: 0.0616, Accuracy: 0.9165, F1 Micro: 0.9165, F1 Macro: 0.888\n",
      "Epoch 7/10, Train Loss: 0.0413, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8838\n",
      "Epoch 8/10, Train Loss: 0.0333, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8766\n",
      "Epoch 9/10, Train Loss: 0.0427, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8805\n",
      "Epoch 10/10, Train Loss: 0.0317, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8874\n",
      "\n",
      "Sentiment analysis accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       765\n",
      "    positive       0.94      0.75      0.83       289\n",
      "\n",
      "    accuracy                           0.92      1054\n",
      "   macro avg       0.92      0.87      0.89      1054\n",
      "weighted avg       0.92      0.92      0.91      1054\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9546, F1 Micro: 0.9546, F1 Macro: 0.8382\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.76      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.95       496\n",
      "    positive       0.84      0.47      0.60        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.59      0.49      0.52       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.83      0.98      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.86       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.64      0.41      0.50        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.82      0.73      0.77       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.80      0.80       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.67      1.00      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.87      0.97      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 241.32946109771729 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 86\n",
      "Sampling duration: 0.00012826919555664062 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4662, Accuracy: 0.8535, F1 Micro: 0.9154, F1 Macro: 0.9106\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3132, Accuracy: 0.9255, F1 Micro: 0.9549, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.207, Accuracy: 0.9448, F1 Micro: 0.9661, F1 Macro: 0.9636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1729, Accuracy: 0.9495, F1 Micro: 0.969, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1492, Accuracy: 0.9554, F1 Micro: 0.9725, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1221, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.9717\n",
      "Epoch 7/10, Train Loss: 0.1004, Accuracy: 0.9576, F1 Micro: 0.9739, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0844, Accuracy: 0.9594, F1 Micro: 0.9748, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0697, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9732\n",
      "Epoch 10/10, Train Loss: 0.0618, Accuracy: 0.9571, F1 Micro: 0.9734, F1 Macro: 0.9708\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.90      0.97      0.94       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3625, Accuracy: 0.8651, F1 Micro: 0.8651, F1 Macro: 0.8151\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2233, Accuracy: 0.8934, F1 Micro: 0.8934, F1 Macro: 0.8601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1564, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.112, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8879\n",
      "Epoch 5/10, Train Loss: 0.0854, Accuracy: 0.8991, F1 Micro: 0.8991, F1 Macro: 0.8635\n",
      "Epoch 6/10, Train Loss: 0.0551, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8849\n",
      "Epoch 7/10, Train Loss: 0.0533, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0282, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8884\n",
      "Epoch 9/10, Train Loss: 0.0182, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0249, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8889\n",
      "\n",
      "Sentiment analysis accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       757\n",
      "    positive       0.92      0.77      0.84       303\n",
      "\n",
      "    accuracy                           0.91      1060\n",
      "   macro avg       0.92      0.87      0.89      1060\n",
      "weighted avg       0.91      0.91      0.91      1060\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.855\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.78      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.75      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.82      0.62      0.71        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.75      0.58      0.63       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89       200\n",
      "     neutral       0.94      0.91      0.93       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       1.00      0.36      0.53        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.93      0.72      0.77       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.84      0.80        85\n",
      "     neutral       0.98      0.95      0.96       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.38      0.52        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.94      0.80        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.77      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 245.973961353302 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 77\n",
      "Sampling duration: 0.00011515617370605469 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4617, Accuracy: 0.8583, F1 Micro: 0.9175, F1 Macro: 0.9121\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3035, Accuracy: 0.9269, F1 Micro: 0.9557, F1 Macro: 0.9529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2139, Accuracy: 0.9401, F1 Micro: 0.9636, F1 Macro: 0.962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1677, Accuracy: 0.947, F1 Micro: 0.9676, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1404, Accuracy: 0.9549, F1 Micro: 0.9721, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1152, Accuracy: 0.9566, F1 Micro: 0.9732, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1015, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0845, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.974\n",
      "Epoch 9/10, Train Loss: 0.0736, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9737\n",
      "Epoch 10/10, Train Loss: 0.0617, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9734\n",
      "\n",
      "Aspect detection accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.94      0.95      0.94       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3917, Accuracy: 0.8506, F1 Micro: 0.8506, F1 Macro: 0.8169\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2156, Accuracy: 0.8873, F1 Micro: 0.8873, F1 Macro: 0.8544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1525, Accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.8773\n",
      "Epoch 4/10, Train Loss: 0.1032, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8769\n",
      "Epoch 5/10, Train Loss: 0.0793, Accuracy: 0.901, F1 Micro: 0.901, F1 Macro: 0.8761\n",
      "Epoch 6/10, Train Loss: 0.0648, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.8648\n",
      "Epoch 7/10, Train Loss: 0.0572, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8728\n",
      "Epoch 8/10, Train Loss: 0.039, Accuracy: 0.8964, F1 Micro: 0.8964, F1 Macro: 0.8638\n",
      "Epoch 9/10, Train Loss: 0.0316, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0359, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8778\n",
      "\n",
      "Sentiment analysis accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.94       771\n",
      "    positive       0.95      0.72      0.82       320\n",
      "\n",
      "    accuracy                           0.91      1091\n",
      "   macro avg       0.92      0.85      0.88      1091\n",
      "weighted avg       0.91      0.91      0.90      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9562, F1 Micro: 0.9562, F1 Macro: 0.8742\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.76      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.83      0.65      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.70      0.59      0.63       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.90      0.95      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85       162\n",
      "     neutral       0.94      0.95      0.94       387\n",
      "    positive       0.64      0.41      0.50        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.81      0.74      0.76       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.86      0.83        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.62      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 253.03168749809265 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 70\n",
      "Sampling duration: 0.000110626220703125 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4609, Accuracy: 0.8564, F1 Micro: 0.9174, F1 Macro: 0.9139\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3096, Accuracy: 0.9281, F1 Micro: 0.9566, F1 Macro: 0.9543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2145, Accuracy: 0.9411, F1 Micro: 0.9641, F1 Macro: 0.9619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1695, Accuracy: 0.9519, F1 Micro: 0.9704, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1439, Accuracy: 0.9573, F1 Micro: 0.9736, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1174, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0951, Accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0834, Accuracy: 0.9611, F1 Micro: 0.976, F1 Macro: 0.9739\n",
      "Epoch 9/10, Train Loss: 0.0705, Accuracy: 0.9608, F1 Micro: 0.9756, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0616, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9739\n",
      "\n",
      "Aspect detection accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.92      0.94      0.93       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3605, Accuracy: 0.8549, F1 Micro: 0.8549, F1 Macro: 0.7956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2276, Accuracy: 0.882, F1 Micro: 0.882, F1 Macro: 0.8461\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1583, Accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.8687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1071, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8863\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0641, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8887\n",
      "Epoch 6/10, Train Loss: 0.0604, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8857\n",
      "Epoch 7/10, Train Loss: 0.0425, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.881\n",
      "Epoch 8/10, Train Loss: 0.0287, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8857\n",
      "Epoch 9/10, Train Loss: 0.027, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8817\n",
      "Epoch 10/10, Train Loss: 0.0231, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8802\n",
      "\n",
      "Sentiment analysis accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       764\n",
      "    positive       0.91      0.77      0.84       304\n",
      "\n",
      "    accuracy                           0.91      1068\n",
      "   macro avg       0.91      0.87      0.89      1068\n",
      "weighted avg       0.91      0.91      0.91      1068\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.8543\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.82      0.93      0.87       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.14      0.14      0.14         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.80      0.54      0.65        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.63      0.56      0.58       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88       200\n",
      "     neutral       0.92      0.94      0.93       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.81      0.85       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.78      0.32      0.45        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.86      0.70      0.75       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.81      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.62      0.83      0.71         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.85      0.91      0.88       571\n",
      "weighted avg       0.99      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 267.1495409011841 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 52\n",
      "Sampling duration: 0.015783071517944336 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4562, Accuracy: 0.8644, F1 Micro: 0.9209, F1 Macro: 0.9161\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2977, Accuracy: 0.929, F1 Micro: 0.957, F1 Macro: 0.9547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2059, Accuracy: 0.9422, F1 Micro: 0.9646, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1644, Accuracy: 0.9517, F1 Micro: 0.9703, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1383, Accuracy: 0.9552, F1 Micro: 0.9723, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1146, Accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0971, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0796, Accuracy: 0.9615, F1 Micro: 0.9762, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0706, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0581, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3724, Accuracy: 0.8657, F1 Micro: 0.8657, F1 Macro: 0.824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2189, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1535, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.8643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1011, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.068, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0458, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8859\n",
      "Epoch 7/10, Train Loss: 0.0311, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8795\n",
      "Epoch 8/10, Train Loss: 0.0351, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8832\n",
      "Epoch 9/10, Train Loss: 0.0256, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8794\n",
      "Epoch 10/10, Train Loss: 0.0244, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8764\n",
      "\n",
      "Sentiment analysis accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8859\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       777\n",
      "    positive       0.95      0.74      0.83       310\n",
      "\n",
      "    accuracy                           0.91      1087\n",
      "   macro avg       0.93      0.86      0.89      1087\n",
      "weighted avg       0.92      0.91      0.91      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.8567\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.97      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.66      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.76      0.60      0.64       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.85       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.78      0.32      0.45        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.71      0.75       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.84      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.92      0.97      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.41      0.56        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.68      0.88      0.77        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.76      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.55      1.00      0.71         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.83      0.95      0.87       571\n",
      "weighted avg       0.99      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 276.8967092037201 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 58\n",
      "Sampling duration: 0.00010156631469726562 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4514, Accuracy: 0.8623, F1 Micro: 0.9197, F1 Macro: 0.9145\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2871, Accuracy: 0.9323, F1 Micro: 0.959, F1 Macro: 0.9567\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1998, Accuracy: 0.9446, F1 Micro: 0.9661, F1 Macro: 0.9637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1614, Accuracy: 0.9503, F1 Micro: 0.9696, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1322, Accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1108, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9731\n",
      "Epoch 7/10, Train Loss: 0.0901, Accuracy: 0.9599, F1 Micro: 0.9751, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.076, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0656, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9751\n",
      "Epoch 10/10, Train Loss: 0.0576, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9739\n",
      "\n",
      "Aspect detection accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3801, Accuracy: 0.8695, F1 Micro: 0.8695, F1 Macro: 0.8301\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2131, Accuracy: 0.8938, F1 Micro: 0.8938, F1 Macro: 0.8564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1475, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1049, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8846\n",
      "Epoch 5/10, Train Loss: 0.0636, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0638, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8865\n",
      "Epoch 7/10, Train Loss: 0.0461, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0321, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.8984\n",
      "Epoch 9/10, Train Loss: 0.0261, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8838\n",
      "Epoch 10/10, Train Loss: 0.0108, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8829\n",
      "\n",
      "Sentiment analysis accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.8984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.95       767\n",
      "    positive       0.92      0.79      0.85       306\n",
      "\n",
      "    accuracy                           0.92      1073\n",
      "   macro avg       0.92      0.88      0.90      1073\n",
      "weighted avg       0.92      0.92      0.92      1073\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9564, F1 Micro: 0.9564, F1 Macro: 0.8802\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.09      0.14      0.11         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.86      0.54      0.67        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.63      0.56      0.58       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.89      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.76      0.81       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.87      0.86        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 281.5700304508209 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 52\n",
      "Sampling duration: 0.00011730194091796875 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4593, Accuracy: 0.8694, F1 Micro: 0.9238, F1 Macro: 0.9195\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2962, Accuracy: 0.9252, F1 Micro: 0.9549, F1 Macro: 0.9522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.209, Accuracy: 0.9436, F1 Micro: 0.9655, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1671, Accuracy: 0.9516, F1 Micro: 0.9703, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1328, Accuracy: 0.9564, F1 Micro: 0.9732, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1128, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0947, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0778, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0646, Accuracy: 0.9639, F1 Micro: 0.9775, F1 Macro: 0.9751\n",
      "Epoch 10/10, Train Loss: 0.0552, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9639, F1 Micro: 0.9775, F1 Macro: 0.9751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.93      0.92      0.93       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3623, Accuracy: 0.8526, F1 Micro: 0.8526, F1 Macro: 0.797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2134, Accuracy: 0.8897, F1 Micro: 0.8897, F1 Macro: 0.8568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1604, Accuracy: 0.8942, F1 Micro: 0.8942, F1 Macro: 0.8658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1128, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0925, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.055, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0395, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8824\n",
      "Epoch 8/10, Train Loss: 0.0424, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8737\n",
      "Epoch 9/10, Train Loss: 0.0264, Accuracy: 0.9014, F1 Micro: 0.9014, F1 Macro: 0.8725\n",
      "Epoch 10/10, Train Loss: 0.0246, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8746\n",
      "\n",
      "Sentiment analysis accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       779\n",
      "    positive       0.94      0.74      0.83       327\n",
      "\n",
      "    accuracy                           0.91      1106\n",
      "   macro avg       0.92      0.86      0.88      1106\n",
      "weighted avg       0.91      0.91      0.91      1106\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9571, F1 Micro: 0.9571, F1 Macro: 0.8769\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.25      0.14      0.18         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.82      0.69      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.68      0.60      0.63       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.88      0.86       200\n",
      "     neutral       0.93      0.91      0.92       315\n",
      "    positive       0.89      0.89      0.89        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.89      0.89       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.67      0.36      0.47        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.82      0.73      0.76       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.93      0.97      0.95        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 290.86025381088257 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.000164031982421875 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4562, Accuracy: 0.8733, F1 Micro: 0.9253, F1 Macro: 0.9202\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2793, Accuracy: 0.9354, F1 Micro: 0.9607, F1 Macro: 0.9585\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1945, Accuracy: 0.9448, F1 Micro: 0.9662, F1 Macro: 0.9638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1585, Accuracy: 0.9552, F1 Micro: 0.9724, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1311, Accuracy: 0.9575, F1 Micro: 0.9738, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1035, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0864, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0759, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0652, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9758\n",
      "Epoch 10/10, Train Loss: 0.0551, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3566, Accuracy: 0.8637, F1 Micro: 0.8637, F1 Macro: 0.8167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2087, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1415, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8837\n",
      "Epoch 4/10, Train Loss: 0.0996, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8806\n",
      "Epoch 5/10, Train Loss: 0.0643, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0543, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8874\n",
      "Epoch 7/10, Train Loss: 0.0392, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0224, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0283, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.8953\n",
      "Epoch 10/10, Train Loss: 0.0249, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.895\n",
      "\n",
      "Sentiment analysis accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.8953\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       770\n",
      "    positive       0.95      0.76      0.85       316\n",
      "\n",
      "    accuracy                           0.92      1086\n",
      "   macro avg       0.93      0.87      0.90      1086\n",
      "weighted avg       0.92      0.92      0.92      1086\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.8814\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.79      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.73      0.50      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.77      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.66      0.76        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.84      0.94      0.89        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.86      0.88       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 294.42787051200867 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.0001010894775390625 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.446, Accuracy: 0.8776, F1 Micro: 0.928, F1 Macro: 0.9239\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2739, Accuracy: 0.9356, F1 Micro: 0.9609, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1962, Accuracy: 0.9491, F1 Micro: 0.9686, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.158, Accuracy: 0.9543, F1 Micro: 0.9719, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1257, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1052, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9733\n",
      "Epoch 7/10, Train Loss: 0.0879, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9728\n",
      "Epoch 8/10, Train Loss: 0.0739, Accuracy: 0.9587, F1 Micro: 0.9744, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0625, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0513, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.91      0.92       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3619, Accuracy: 0.8629, F1 Micro: 0.8629, F1 Macro: 0.8256\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.203, Accuracy: 0.8912, F1 Micro: 0.8912, F1 Macro: 0.8649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1338, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1006, Accuracy: 0.904, F1 Micro: 0.904, F1 Macro: 0.8753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0645, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0556, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0349, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8845\n",
      "Epoch 8/10, Train Loss: 0.032, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8782\n",
      "Epoch 9/10, Train Loss: 0.0309, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8774\n",
      "Epoch 10/10, Train Loss: 0.0277, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8814\n",
      "\n",
      "Sentiment analysis accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8845\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       775\n",
      "    positive       0.91      0.76      0.83       319\n",
      "\n",
      "    accuracy                           0.91      1094\n",
      "   macro avg       0.91      0.87      0.88      1094\n",
      "weighted avg       0.91      0.91      0.91      1094\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9562, F1 Micro: 0.9562, F1 Macro: 0.8586\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.77      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.82      0.66      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.59      0.65       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.89      0.88       200\n",
      "     neutral       0.94      0.91      0.92       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.93      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.83      0.86       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.74      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.94      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.79       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 298.74409437179565 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.00011968612670898438 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4497, Accuracy: 0.8729, F1 Micro: 0.9253, F1 Macro: 0.9198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2741, Accuracy: 0.9333, F1 Micro: 0.9595, F1 Macro: 0.9572\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1902, Accuracy: 0.9488, F1 Micro: 0.9686, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1517, Accuracy: 0.9538, F1 Micro: 0.9715, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1214, Accuracy: 0.9587, F1 Micro: 0.9744, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1058, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9742\n",
      "Epoch 7/10, Train Loss: 0.0883, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0716, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0608, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9759\n",
      "Epoch 10/10, Train Loss: 0.0525, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.378, Accuracy: 0.8745, F1 Micro: 0.8745, F1 Macro: 0.8412\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2129, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1326, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0943, Accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.893\n",
      "Epoch 5/10, Train Loss: 0.0656, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8832\n",
      "Epoch 6/10, Train Loss: 0.0463, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.884\n",
      "Epoch 7/10, Train Loss: 0.0388, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8811\n",
      "Epoch 8/10, Train Loss: 0.0344, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8848\n",
      "Epoch 9/10, Train Loss: 0.0226, Accuracy: 0.9009, F1 Micro: 0.9009, F1 Macro: 0.8736\n",
      "Epoch 10/10, Train Loss: 0.0183, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.877\n",
      "\n",
      "Sentiment analysis accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.99      0.94       782\n",
      "    positive       0.96      0.75      0.84       318\n",
      "\n",
      "    accuracy                           0.92      1100\n",
      "   macro avg       0.93      0.87      0.89      1100\n",
      "weighted avg       0.92      0.92      0.91      1100\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9557, F1 Micro: 0.9557, F1 Macro: 0.8622\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.90      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.75      1.00      0.86        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.96      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.58      0.70      0.64        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.86      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.81      0.69      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.70      0.60      0.64       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89       200\n",
      "     neutral       0.95      0.92      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.82      0.84       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.67      0.55      0.60        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.82      0.78      0.80       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.89      0.96      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.64      0.94      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.81      0.79       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.67      0.67      0.67         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.87      0.86      0.86       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 297.72816729545593 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 25\n",
      "Sampling duration: 0.017600536346435547 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4392, Accuracy: 0.8819, F1 Micro: 0.9306, F1 Macro: 0.9267\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2649, Accuracy: 0.9342, F1 Micro: 0.9601, F1 Macro: 0.9581\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.191, Accuracy: 0.9507, F1 Micro: 0.9697, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1478, Accuracy: 0.9561, F1 Micro: 0.973, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1268, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1021, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9752\n",
      "Epoch 7/10, Train Loss: 0.0853, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0718, Accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.977\n",
      "Epoch 9/10, Train Loss: 0.0618, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9742\n",
      "Epoch 10/10, Train Loss: 0.0516, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3443, Accuracy: 0.8654, F1 Micro: 0.8654, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2121, Accuracy: 0.8925, F1 Micro: 0.8925, F1 Macro: 0.8679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.145, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8839\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0948, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8847\n",
      "Epoch 5/10, Train Loss: 0.0775, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8816\n",
      "Epoch 6/10, Train Loss: 0.0581, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0404, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8847\n",
      "Epoch 8/10, Train Loss: 0.0353, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0302, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8857\n",
      "Epoch 10/10, Train Loss: 0.02, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8778\n",
      "\n",
      "Sentiment analysis accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       783\n",
      "    positive       0.92      0.76      0.83       324\n",
      "\n",
      "    accuracy                           0.91      1107\n",
      "   macro avg       0.91      0.87      0.89      1107\n",
      "weighted avg       0.91      0.91      0.91      1107\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.8695\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.85      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.54      0.70      0.61        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.85      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.82      0.78      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.63      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.92      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.88      0.89      0.88        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.85       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.56      0.41      0.47        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.79      0.74      0.76       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.67      0.94      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.82      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 306.3181824684143 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.822845458984375e-05 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4447, Accuracy: 0.8823, F1 Micro: 0.9307, F1 Macro: 0.9276\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2636, Accuracy: 0.9375, F1 Micro: 0.962, F1 Macro: 0.9598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1932, Accuracy: 0.9457, F1 Micro: 0.9668, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1499, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1233, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "Epoch 6/10, Train Loss: 0.1033, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0861, Accuracy: 0.9651, F1 Micro: 0.9784, F1 Macro: 0.9764\n",
      "Epoch 8/10, Train Loss: 0.0688, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9761\n",
      "Epoch 9/10, Train Loss: 0.0612, Accuracy: 0.9622, F1 Micro: 0.9766, F1 Macro: 0.9745\n",
      "Epoch 10/10, Train Loss: 0.0506, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.9651, F1 Micro: 0.9784, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.91      0.96      0.93       317\n",
      "       linen       0.94      0.97      0.96       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.99      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3577, Accuracy: 0.8746, F1 Micro: 0.8746, F1 Macro: 0.8377\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1771, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1245, Accuracy: 0.9199, F1 Micro: 0.9199, F1 Macro: 0.8946\n",
      "Epoch 4/10, Train Loss: 0.088, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0662, Accuracy: 0.9218, F1 Micro: 0.9218, F1 Macro: 0.8973\n",
      "Epoch 6/10, Train Loss: 0.0425, Accuracy: 0.9199, F1 Micro: 0.9199, F1 Macro: 0.8946\n",
      "Epoch 7/10, Train Loss: 0.046, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8865\n",
      "Epoch 8/10, Train Loss: 0.0312, Accuracy: 0.9199, F1 Micro: 0.9199, F1 Macro: 0.8951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0327, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9018\n",
      "Epoch 10/10, Train Loss: 0.023, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8874\n",
      "\n",
      "Sentiment analysis accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9018\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       768\n",
      "    positive       0.93      0.78      0.85       293\n",
      "\n",
      "    accuracy                           0.93      1061\n",
      "   macro avg       0.93      0.88      0.90      1061\n",
      "weighted avg       0.93      0.93      0.92      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9573, F1 Micro: 0.9573, F1 Macro: 0.8638\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.81      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.17      0.14      0.15         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.59      0.70        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.65      0.57      0.60       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.90      0.93      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.86       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.70      0.32      0.44        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.83      0.72      0.75       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.88      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.62      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.89      0.93       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 303.905473947525 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.632110595703125e-05 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4366, Accuracy: 0.8828, F1 Micro: 0.9309, F1 Macro: 0.9273\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.256, Accuracy: 0.9366, F1 Micro: 0.9615, F1 Macro: 0.9594\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1828, Accuracy: 0.953, F1 Micro: 0.9711, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1454, Accuracy: 0.9582, F1 Micro: 0.9742, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1227, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1016, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9762\n",
      "Epoch 7/10, Train Loss: 0.0847, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9741\n",
      "Epoch 8/10, Train Loss: 0.0698, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9748\n",
      "Epoch 9/10, Train Loss: 0.057, Accuracy: 0.9637, F1 Micro: 0.9774, F1 Macro: 0.9751\n",
      "Epoch 10/10, Train Loss: 0.0503, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.96      0.91      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3676, Accuracy: 0.8622, F1 Micro: 0.8622, F1 Macro: 0.8279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2186, Accuracy: 0.8991, F1 Micro: 0.8991, F1 Macro: 0.8687\n",
      "Epoch 3/10, Train Loss: 0.151, Accuracy: 0.8982, F1 Micro: 0.8982, F1 Macro: 0.8711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1219, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8769\n",
      "Epoch 5/10, Train Loss: 0.0994, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0861, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0677, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0402, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.881\n",
      "Epoch 9/10, Train Loss: 0.0409, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8728\n",
      "Epoch 10/10, Train Loss: 0.0331, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.869\n",
      "\n",
      "Sentiment analysis accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       788\n",
      "    positive       0.93      0.74      0.82       322\n",
      "\n",
      "    accuracy                           0.91      1110\n",
      "   macro avg       0.91      0.86      0.88      1110\n",
      "weighted avg       0.91      0.91      0.90      1110\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9559, F1 Micro: 0.9559, F1 Macro: 0.8425\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.83      0.94      0.87       571\n",
      "weighted avg       0.96      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.91      0.88       200\n",
      "     neutral       0.96      0.90      0.93       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.67      0.55      0.60        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.83      0.79      0.81       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.34      0.49        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.55      0.94      0.70        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.79      0.76      0.72       571\n",
      "weighted avg       0.97      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.99      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.88      0.88      0.88       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 311.15368604660034 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.655952453613281e-05 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4299, Accuracy: 0.8842, F1 Micro: 0.9313, F1 Macro: 0.926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2596, Accuracy: 0.9377, F1 Micro: 0.962, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1792, Accuracy: 0.9517, F1 Micro: 0.9703, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.143, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1128, Accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9749\n",
      "Epoch 6/10, Train Loss: 0.0933, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9749\n",
      "Epoch 7/10, Train Loss: 0.0784, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9749\n",
      "Epoch 8/10, Train Loss: 0.0676, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0578, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0462, Accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3428, Accuracy: 0.8604, F1 Micro: 0.8604, F1 Macro: 0.8147\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2089, Accuracy: 0.891, F1 Micro: 0.891, F1 Macro: 0.8614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1335, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.87\n",
      "Epoch 4/10, Train Loss: 0.0938, Accuracy: 0.8955, F1 Micro: 0.8955, F1 Macro: 0.8612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0598, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0491, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.8794\n",
      "Epoch 7/10, Train Loss: 0.0451, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8779\n",
      "Epoch 8/10, Train Loss: 0.0398, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0351, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0321, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8807\n",
      "\n",
      "Sentiment analysis accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       784\n",
      "    positive       0.94      0.73      0.82       326\n",
      "\n",
      "    accuracy                           0.91      1110\n",
      "   macro avg       0.92      0.86      0.88      1110\n",
      "weighted avg       0.91      0.91      0.90      1110\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.8801\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.61      0.66       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.78      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.87      0.87        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.96      0.96      0.96        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 320.090948343277 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.0001742839813232422 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4328, Accuracy: 0.8845, F1 Micro: 0.9319, F1 Macro: 0.9283\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2554, Accuracy: 0.9392, F1 Micro: 0.963, F1 Macro: 0.961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1814, Accuracy: 0.9545, F1 Micro: 0.972, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1448, Accuracy: 0.9573, F1 Micro: 0.9737, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1149, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0945, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9759\n",
      "Epoch 7/10, Train Loss: 0.0798, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "Epoch 8/10, Train Loss: 0.0703, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Epoch 9/10, Train Loss: 0.0562, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0487, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.91      0.93       317\n",
      "       linen       0.94      0.98      0.96       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3369, Accuracy: 0.8594, F1 Micro: 0.8594, F1 Macro: 0.8178\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2149, Accuracy: 0.889, F1 Micro: 0.889, F1 Macro: 0.8543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1303, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0926, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8772\n",
      "Epoch 5/10, Train Loss: 0.0599, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0564, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8815\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0413, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8823\n",
      "Epoch 8/10, Train Loss: 0.0272, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8779\n",
      "Epoch 9/10, Train Loss: 0.0248, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8731\n",
      "Epoch 10/10, Train Loss: 0.0183, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8782\n",
      "\n",
      "Sentiment analysis accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8823\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       786\n",
      "    positive       0.93      0.75      0.83       331\n",
      "\n",
      "    accuracy                           0.91      1117\n",
      "   macro avg       0.91      0.86      0.88      1117\n",
      "weighted avg       0.91      0.91      0.90      1117\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9592, F1 Micro: 0.9592, F1 Macro: 0.8699\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.91        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.77      0.79       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.81      0.76      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.63      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89       200\n",
      "     neutral       0.95      0.91      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       162\n",
      "     neutral       0.94      0.98      0.96       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.75      0.79       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.88      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.96      0.96      0.96        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.96      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 330.59539794921875 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.393692016601562e-05 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4321, Accuracy: 0.8903, F1 Micro: 0.9352, F1 Macro: 0.9324\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2523, Accuracy: 0.9418, F1 Micro: 0.9644, F1 Macro: 0.9622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1755, Accuracy: 0.951, F1 Micro: 0.9699, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1398, Accuracy: 0.9575, F1 Micro: 0.9738, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1157, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0963, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "Epoch 7/10, Train Loss: 0.0822, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9739\n",
      "Epoch 8/10, Train Loss: 0.0692, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9748\n",
      "Epoch 9/10, Train Loss: 0.0546, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.975\n",
      "Epoch 10/10, Train Loss: 0.0472, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.94      0.93       317\n",
      "       linen       0.95      0.96      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3371, Accuracy: 0.8704, F1 Micro: 0.8704, F1 Macro: 0.8313\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2056, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1295, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0992, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.883\n",
      "Epoch 5/10, Train Loss: 0.0963, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8807\n",
      "Epoch 6/10, Train Loss: 0.0724, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8799\n",
      "Epoch 7/10, Train Loss: 0.0372, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8799\n",
      "Epoch 8/10, Train Loss: 0.0346, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8756\n",
      "Epoch 9/10, Train Loss: 0.0449, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8804\n",
      "Epoch 10/10, Train Loss: 0.032, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8766\n",
      "\n",
      "Sentiment analysis accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       781\n",
      "    positive       0.94      0.74      0.83       315\n",
      "\n",
      "    accuracy                           0.91      1096\n",
      "   macro avg       0.92      0.86      0.88      1096\n",
      "weighted avg       0.91      0.91      0.91      1096\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.8686\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.90      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.75      1.00      0.86        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.96      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.83      0.65      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.54      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.89       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.82      0.98      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.86       162\n",
      "     neutral       0.95      0.96      0.95       387\n",
      "    positive       0.69      0.50      0.58        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.83      0.77      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.95      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.59      0.72        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.74      1.00      0.85        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.86      0.85       571\n",
      "weighted avg       0.98      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 324.0399384498596 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 36\n",
      "Sampling duration: 0.02008342742919922 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4218, Accuracy: 0.8955, F1 Micro: 0.9379, F1 Macro: 0.9346\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2451, Accuracy: 0.9378, F1 Micro: 0.9622, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1754, Accuracy: 0.9524, F1 Micro: 0.9708, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1414, Accuracy: 0.9557, F1 Micro: 0.9728, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1165, Accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.097, Accuracy: 0.9651, F1 Micro: 0.9784, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0771, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0642, Accuracy: 0.967, F1 Micro: 0.9795, F1 Macro: 0.9775\n",
      "Epoch 9/10, Train Loss: 0.056, Accuracy: 0.9651, F1 Micro: 0.9784, F1 Macro: 0.9766\n",
      "Epoch 10/10, Train Loss: 0.0449, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.967, F1 Micro: 0.9795, F1 Macro: 0.9775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3235, Accuracy: 0.8716, F1 Micro: 0.8716, F1 Macro: 0.8288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2065, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8792\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1393, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.891\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.104, Accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8926\n",
      "Epoch 5/10, Train Loss: 0.0632, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8891\n",
      "Epoch 6/10, Train Loss: 0.0486, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0415, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.8934\n",
      "Epoch 8/10, Train Loss: 0.0315, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.8899\n",
      "Epoch 9/10, Train Loss: 0.02, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.8899\n",
      "Epoch 10/10, Train Loss: 0.0164, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.8904\n",
      "\n",
      "Sentiment analysis accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.8934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       780\n",
      "    positive       0.95      0.75      0.84       318\n",
      "\n",
      "    accuracy                           0.92      1098\n",
      "   macro avg       0.93      0.87      0.89      1098\n",
      "weighted avg       0.92      0.92      0.91      1098\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9611, F1 Micro: 0.9611, F1 Macro: 0.8797\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.85      0.76      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.77      0.63      0.67       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.78      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.62      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.77      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 333.07306480407715 s\n",
      "Total runtime: 6732.110173225403 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACCoAAAHqCAYAAADInz0eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADoJElEQVR4nOzdd3RU5d7F8e9MOhBCSQgtdKRIb6EX6UVpAop0sCBgwfsiKAhYABuigIIUaUEQKSIiVem9iYj0XlJoCQnpM+8fJwQCAZOQZJLJ/qw1i+TMmZnfCV7dN7PneUxWq9WKiIiIiIiIiIiIiIiIiIiISDow23oAERERERERERERERERERERyTpUVBAREREREREREREREREREZF0o6KCiIiIiIiIiIiIiIiIiIiIpBsVFURERERERERERERERERERCTdqKggIiIiIiIiIiIiIiIiIiIi6UZFBREREREREREREREREREREUk3KiqIiIiIiIiIiIiIiIiIiIhIulFRQURERERERERERERERERERNKNigoiIiIiIiIiIiIiIiIiIiKSblRUEBEREREREZEMrU+fPhQrVszWY4iIiIiIiIhIKlFRQUQkhb799ltMJhO+vr62HkVERERE5InMmTMHk8mU6G348OHx561bt47+/ftToUIFHBwckl0euPucAwYMSPT+999/P/6ca9euPckliYiIiEgWojwrIpL5ONp6ABGRzMrPz49ixYqxZ88eTp06RalSpWw9koiIiIjIE/nwww8pXrx4gmMVKlSI/3rhwoUsXryYatWqUbBgwRS9hqurK0uXLuXbb7/F2dk5wX0//vgjrq6uREREJDg+Y8YMLBZLil5PRERERLKOjJpnRUTkYVpRQUQkBc6ePcuOHTuYOHEiXl5e+Pn52XqkRIWFhdl6BBERERHJRFq3bk2PHj0S3KpUqRJ//7hx4wgJCWH79u1Urlw5Ra/RqlUrQkJC+P333xMc37FjB2fPnqVt27YPPcbJyQkXF5cUvd79LBaLfmksIiIiYscyap5Na/o9sIhkRioqiIikgJ+fH7lz56Zt27Y8//zziRYVbt26xdtvv02xYsVwcXGhcOHC9OrVK8GSXxEREYwZM4annnoKV1dXChQoQKdOnTh9+jQAmzZtwmQysWnTpgTPfe7cOUwmE3PmzIk/1qdPH3LkyMHp06dp06YN7u7uvPTSSwBs3bqVLl26UKRIEVxcXPDx8eHtt98mPDz8obmPHTtG165d8fLyws3NjTJlyvD+++8D8Oeff2IymVi+fPlDj1u4cCEmk4mdO3cm++cpIiIiIplDwYIFcXJyeqLnKFSoEA0bNmThwoUJjvv5+VGxYsUEn3i7q0+fPg8ty2uxWPj666+pWLEirq6ueHl50apVK/bt2xd/jslkYvDgwfj5+fH000/j4uLCmjVrADh48CCtW7cmZ86c5MiRg6ZNm7Jr164nujYRERERydhslWdT6/ezAGPGjMFkMnH06FG6d+9O7ty5qV+/PgAxMTF89NFHlCxZEhcXF4oVK8Z7771HZGTkE12ziEha0NYPIiIp4OfnR6dOnXB2dubFF1/ku+++Y+/evdSsWROA0NBQGjRowL///ku/fv2oVq0a165dY+XKlVy6dAlPT09iY2Np164dGzdu5IUXXuDNN9/k9u3brF+/niNHjlCyZMlkzxUTE0PLli2pX78+X3zxBdmyZQNgyZIl3Llzh4EDB5I3b1727NnD5MmTuXTpEkuWLIl//OHDh2nQoAFOTk688sorFCtWjNOnT/Prr7/yySef0LhxY3x8fPDz86Njx44P/UxKlixJnTp1nuAnKyIiIiK2FBwc/NBeup6enqn+Ot27d+fNN98kNDSUHDlyEBMTw5IlSxg6dGiSVzzo378/c+bMoXXr1gwYMICYmBi2bt3Krl27qFGjRvx5f/zxBz/99BODBw/G09OTYsWK8c8//9CgQQNy5szJsGHDcHJyYvr06TRu3JjNmzfj6+ub6tcsIiIiImkvo+bZ1Pr97P26dOlC6dKlGTduHFarFYABAwYwd+5cnn/+ed555x12797N+PHj+ffffxP98JmIiC2pqCAikkz79+/n2LFjTJ48GYD69etTuHBh/Pz84osKn3/+OUeOHGHZsmUJ3tAfOXJkfGicN28eGzduZOLEibz99tvx5wwfPjz+nOSKjIykS5cujB8/PsHxTz/9FDc3t/jvX3nlFUqVKsV7773HhQsXKFKkCABDhgzBarVy4MCB+GMAEyZMAIxPpPXo0YOJEycSHByMh4cHAEFBQaxbty5Bs1dEREREMp9mzZo9dCyl2fRxnn/+eQYPHsyKFSvo0aMH69at49q1a7z44ov88MMP//n4P//8kzlz5vDGG2/w9ddfxx9/5513Hpr3+PHj/P3335QvXz7+WMeOHYmOjmbbtm2UKFECgF69elGmTBmGDRvG5s2bU+lKRURERCQ9ZdQ8m1q/n71f5cqVE6zq8NdffzF37lwGDBjAjBkzAHj99dfJly8fX3zxBX/++SdNmjRJtZ+BiMiT0tYPIiLJ5Ofnh7e3d3yoM5lMdOvWjUWLFhEbGwvA0qVLqVy58kOrDtw9/+45np6eDBky5JHnpMTAgQMfOnZ/CA4LC+PatWvUrVsXq9XKwYMHAaNssGXLFvr165cgBD84T69evYiMjOTnn3+OP7Z48WJiYmLo0aNHiucWEREREdubOnUq69evT3BLC7lz56ZVq1b8+OOPgLGNWN26dSlatGiSHr906VJMJhOjR49+6L4Hs3SjRo0SlBRiY2NZt24dHTp0iC8pABQoUIDu3buzbds2QkJCUnJZIiIiImJjGTXPpubvZ+967bXXEny/evVqAIYOHZrg+DvvvAPAb7/9lpxLFBFJc1pRQUQkGWJjY1m0aBFNmjTh7Nmz8cd9fX358ssv2bhxIy1atOD06dN07tz5sc91+vRpypQpg6Nj6v2r2NHRkcKFCz90/MKFC3zwwQesXLmSmzdvJrgvODgYgDNnzgAkuofa/cqWLUvNmjXx8/Ojf//+gFHeqF27NqVKlUqNyxARERERG6lVq1aCbRPSUvfu3enZsycXLlxgxYoVfPbZZ0l+7OnTpylYsCB58uT5z3OLFy+e4PugoCDu3LlDmTJlHjq3XLlyWCwWLl68yNNPP53keUREREQkY8ioeTY1fz9714M59/z585jN5od+R5s/f35y5crF+fPnk/S8IiLpRUUFEZFk+OOPP7h69SqLFi1i0aJFD93v5+dHixYtUu31HrWywt2VGx7k4uKC2Wx+6NzmzZtz48YN3n33XcqWLUv27Nm5fPkyffr0wWKxJHuuXr168eabb3Lp0iUiIyPZtWsXU6ZMSfbziIiIiEjW9dxzz+Hi4kLv3r2JjIyka9euafI69396TUREREQktSQ1z6bF72fh0Tn3SVbrFRFJTyoqiIgkg5+fH/ny5WPq1KkP3bds2TKWL1/OtGnTKFmyJEeOHHnsc5UsWZLdu3cTHR2Nk5NToufkzp0bgFu3biU4npz2699//82JEyeYO3cuvXr1ij/+4LJnd5e9/a+5AV544QWGDh3Kjz/+SHh4OE5OTnTr1i3JM4mIiIiIuLm50aFDBxYsWEDr1q3x9PRM8mNLlizJ2rVruXHjRpJWVbifl5cX2bJl4/jx4w/dd+zYMcxmMz4+Psl6ThERERHJepKaZ9Pi97OJKVq0KBaLhZMnT1KuXLn44wEBAdy6dSvJ26yJiKQX83+fIiIiAOHh4Sxbtox27drx/PPPP3QbPHgwt2/fZuXKlXTu3Jm//vqL5cuXP/Q8VqsVgM6dO3Pt2rVEVyK4e07RokVxcHBgy5YtCe7/9ttvkzy3g4NDgue8+/XXX3+d4DwvLy8aNmzI7NmzuXDhQqLz3OXp6Unr1q1ZsGABfn5+tGrVKlm/WBYRERERAfjf//7H6NGjGTVqVLIe17lzZ6xWK2PHjn3ovgez64McHBxo0aIFv/zyC+fOnYs/HhAQwMKFC6lfvz45c+ZM1jwiIiIikjUlJc+mxe9nE9OmTRsAJk2alOD4xIkTAWjbtu1/PoeISHrSigoiIkm0cuVKbt++zXPPPZfo/bVr18bLyws/Pz8WLlzIzz//TJcuXejXrx/Vq1fnxo0brFy5kmnTplG5cmV69erFvHnzGDp0KHv27KFBgwaEhYWxYcMGXn/9ddq3b4+HhwddunRh8uTJmEwmSpYsyapVqwgMDEzy3GXLlqVkyZL873//4/Lly+TMmZOlS5c+tBcawDfffEP9+vWpVq0ar7zyCsWLF+fcuXP89ttvHDp0KMG5vXr14vnnnwfgo48+SvoPUkREREQyrcOHD7Ny5UoATp06RXBwMB9//DEAlStX5tlnn03W81WuXJnKlSsne44mTZrQs2dPvvnmG06ePEmrVq2wWCxs3bqVJk2aMHjw4Mc+/uOPP2b9+vXUr1+f119/HUdHR6ZPn05kZORj9xYWERERkczNFnk2rX4/m9gsvXv35vvvv+fWrVs0atSIPXv2MHfuXDp06ECTJk2SdW0iImlNRQURkSTy8/PD1dWV5s2bJ3q/2Wymbdu2+Pn5ERkZydatWxk9ejTLly9n7ty55MuXj6ZNm1K4cGHAaNKuXr2aTz75hIULF7J06VLy5s1L/fr1qVixYvzzTp48mejoaKZNm4aLiwtdu3bl888/p0KFCkma28nJiV9//ZU33niD8ePH4+rqSseOHRk8ePBDIbpy5crs2rWLUaNG8d133xEREUHRokUT3V/t2WefJXfu3FgslkeWN0RERETEvhw4cOChT4vd/b53797J/sXuk/jhhx+oVKkSs2bN4v/+7//w8PCgRo0a1K1b9z8f+/TTT7N161ZGjBjB+PHjsVgs+Pr6smDBAnx9fdNhehERERGxBVvk2bT6/WxiZs6cSYkSJZgzZw7Lly8nf/78jBgxgtGjR6f6dYmIPCmTNSnrxYiIiDwgJiaGggUL8uyzzzJr1ixbjyMiIiIiIiIiIiIiIiKZhNnWA4iISOa0YsUKgoKC6NWrl61HERERERERERERERERkUxEKyqIiEiy7N69m8OHD/PRRx/h6enJgQMHbD2SiIiIiIiIiIiIiIiIZCJaUUFERJLlu+++Y+DAgeTLl4958+bZehwRERERERERERERERHJZLSigoiIiIiIiIiIiIiIiIiIiKQbraggIiIiIiIiIiIiIiIiIiIi6UZFBREREREREREREREREREREUk3jrYeILVYLBauXLmCu7s7JpPJ1uOIiIiISBqyWq3cvn2bggULYjbbX/dW2VZEREQk61C2FRERERF7kZxsazdFhStXruDj42PrMUREREQkHV28eJHChQvbeoxUp2wrIiIikvWkV7adOnUqn3/+Of7+/lSuXJnJkydTq1atRM+Njo5m/PjxzJ07l8uXL1OmTBk+/fRTWrVqleTXU7YVERERyXqSkm3tpqjg7u4OGBedM2dOG08jIiIiImkpJCQEHx+f+Axob5RtRURERLKO9My2ixcvZujQoUybNg1fX18mTZpEy5YtOX78OPny5Xvo/JEjR7JgwQJmzJhB2bJlWbt2LR07dmTHjh1UrVo1Sa+pbCsiIiKSdSQn25qsVqs1HWZKcyEhIXh4eBAcHKzAKyIiImLn7D372fv1iYiIiMg96Zn9fH19qVmzJlOmTAGMbRl8fHwYMmQIw4cPf+j8ggUL8v777zNo0KD4Y507d8bNzY0FCxYk6TWVbUVERESyjuRkP/vb9ExEREREREREREREEoiKimL//v00a9Ys/pjZbKZZs2bs3Lkz0cdERkbi6uqa4Jibmxvbtm175OtERkYSEhKS4CYiIiIi8iAVFURERERERERERETs3LVr14iNjcXb2zvBcW9vb/z9/RN9TMuWLZk4cSInT57EYrGwfv16li1bxtWrVx/5OuPHj8fDwyP+5uPjk6rXISIiIiL2QUUFEREREREREREREXnI119/TenSpSlbtizOzs4MHjyYvn37YjY/+tfKI0aMIDg4OP528eLFdJxYRERERDILFRVERERERERERERE7JynpycODg4EBAQkOB4QEED+/PkTfYyXlxcrVqwgLCyM8+fPc+zYMXLkyEGJEiUe+TouLi7kzJkzwU1ERERE5EEqKoiIiIiIiIiIiIjYOWdnZ6pXr87GjRvjj1ksFjZu3EidOnUe+1hXV1cKFSpETEwMS5cupX379mk9roiIiIjYOUdbDyAiIiIiIiIiIiIiaW/o0KH07t2bGjVqUKtWLSZNmkRYWBh9+/YFoFevXhQqVIjx48cDsHv3bi5fvkyVKlW4fPkyY8aMwWKxMGzYMFtehoiIiIjYARUVRERERERERERERLKAbt26ERQUxAcffIC/vz9VqlRhzZo1eHt7A3DhwgXM5nuL8EZERDBy5EjOnDlDjhw5aNOmDfPnzydXrlw2ugIRERERsRcmq9VqtfUQqSEkJAQPDw+Cg4O175mIiIiInbP37Gfv1yciIiIi99h79rP36xMRERGRe5KT/cyPvVdEREREREREREREREREREQkFamoICIiIiIiIiIiIiIiIiIiIulGRQURERERERERERERERERERFJNyoqiIiIiIiIiIiIiIiIiIiISLpRUUFERERERERERERERERERETSjYoKIiIiIiIiIiIiIiIiIiIikm5UVBARERGRJzJrFuzfb+spRERERERSwelZcEPhVkRERMRqtXLs2jG2nN+C1Wq19Thih1JUVJg6dSrFihXD1dUVX19f9uzZ88hzo6Oj+fDDDylZsiSurq5UrlyZNWvWPHTe5cuX6dGjB3nz5sXNzY2KFSuyb9++lIwnIiIiIulk+3Z49VWoWxeOHrX1NCmjbCsiIiIiAARthz2vwrq6EJxJw62IiIjYteCIYBb+vZCdF3cSGhWaqs99t5gwbd80Xvj5BQp8WYByU8vRaE4jPt3+aaq+lj3admEbF4Iv2HqMBC4EX+DszbO2HuORHJP7gMWLFzN06FCmTZuGr68vkyZNomXLlhw/fpx8+fI9dP7IkSNZsGABM2bMoGzZsqxdu5aOHTuyY8cOqlatCsDNmzepV68eTZo04ffff8fLy4uTJ0+SO3fuJ79CEREREUkTQUHQrRvExkLXrlCunK0nSj5lWxEREREBICIItnUDaywU6Qo5M2G4FREREbt2J/oOLRa0YM9l40M2JkyUzFOSyt6VqeRdicrelamcvzJFPYpiMpn+8/nuFhM2ndvE5vOb2XRuEwFhAQnOcTI7EW2JZuQfI6nnU48GRRukybVldsv+XUbnnzrj7ODMW75v8V6D9/Bw9bDpTHsv7+XZH58lt1tudvbfSS7XXDadJzEmazLX6vD19aVmzZpMmTIFAIvFgo+PD0OGDGH48OEPnV+wYEHef/99Bg0aFH+sc+fOuLm5sWDBAgCGDx/O9u3b2bp1a4ovJCQkBA8PD4KDg8mZM2eKn0dERERE/pvFAm3awNq1UKYM7N0L7u7p9/qplf2UbUVEREQEqwU2tYGrayFnGWi5F5zSL9zae/az9+sTERFJDxarha5LurL036W4O7uTwzkHV0OvJnquh4sHlbwrJSgvVMhXATdHt/hiwqbzm9h0bhOBYYEJHuvi4EJdn7o0KtqIxsUa41vYl1d+fYX5h+dTyL0QB189iFd2r/S45EzDarVSc0ZN9l+9t32YVzYvPmzyIQOqDcDRnOx1A57Y0qNL6bm8J+Ex4VTyrsTq7qsplLNQurx2crJfsn4yUVFR7N+/nxEjRsQfM5vNNGvWjJ07dyb6mMjISFxdXRMcc3NzY9u2bfHfr1y5kpYtW9KlSxc2b95MoUKFeP3113n55ZcfOUtkZCSRkZHx34eEhCTnUkREREQypdhYMJnAnKINvFLPhAlGScHNDZYsSd+SQmpRthURERGxMUtcuDXZONwenWCUFBzcoP6SdC0piIiIiCTFexvfY+m/S3F2cOa37r/RoGgDgsKC+CvgL/7y/4vDgYf5y/8vjgYdJTgymK0XtrL1wr0P0Zgw4eHqwa2IWwme19XRlTqF69C4WGMaF2tMrUK1cHVM+Luvb9t+y94rezl27Ri9VvTit+6/YbZ1fstAtpzfwv6r+3F1dGXGszP4eMvHHL9+nIG/DWTynsl82eJLWpVqlS6zWK1WPt/xOe9ueBeA1qVas/j5xbi7ZMx8m6yiwrVr14iNjcXb2zvBcW9vb44dO5boY1q2bMnEiRNp2LAhJUuWZOPGjSxbtozY2Nj4c86cOcN3333H0KFDee+999i7dy9vvPEGzs7O9O7dO9HnHT9+PGPHjk3O+CIiIiKZ2tKl8MorEBoKhQuDj49xK1Ik4Z8+PuDhYfzONy1s2gSjRhlfT50KFSumzeukNWVbERERERu6sBT2vAIxoZCtMGTzMW7Zi8R9XQSyxx1zSsNwG7AJDseF2xpTIVcmDbciIiJit2YemMmn2z8FYNZzs+K3X/DK7kWzEs1oVqJZ/LlRsVEcu3aMwwFGceGvAOMWGBbIrYhbuDq6UtenLo2L3ismuDi6PPb1czjnYEmXJdSaUYs1p9bw2fbPGF7/4ZVIs6ovdn4BQO/KvelRqQfdnu7G9P3TGb1pNEeDjtLarzWtSrXii+Zf8HS+p9NsjujYaAb+NpBZB2cBMLjmYL5q9ZVNVnRIqmRt/XDlyhUKFSrEjh07qFOnTvzxYcOGsXnzZnbv3v3QY4KCgnj55Zf59ddfMZlMlCxZkmbNmjF79mzCw8MBcHZ2pkaNGuzYsSP+cW+88QZ79+597KfZHvzUmY+Pj5YQExEREbs0ZQq88QYkNbm5uycsMhQpAp06QfnyTzZHQABUqQL+/tC7N8yZ82TPl1KpsXyssq2IiIiIjRyfAvvfAJIYbh3d75UWshUxygw+ncDjCcNteAD8XgUi/KF4b6gz58meL4XsfWsEe78+ERHJPLZd2MbEnRPpXrE7z5d/3tbjJMmGMxtotaAVsdZYRjcazZjGY1L0PAGhAVy5fYXyXuX/s5jwKLMPzqb/yv44mBz4s/ef8YWJrOxo0FGe/vZpTJg4NvgYT+V9Kv6+m+E3+XjLx0zeM5loSzRmk5lXqr3C2CZjyZc9X6rOcSviFp1/6swfZ//AbDIzqeUkhvgOSdXXSKrkZL9krcvh6emJg4MDAQEBCY4HBASQP3/+RB/j5eXFihUrCAsL4/z58xw7dowcOXJQokSJ+HMKFChA+Qd+a16uXDkuXLjwyFlcXFzImTNngpuIiIhkLlYrbN4MXbrAU0/B3LlJfyM+q7BYYPhwGDLE+Nm8/jqcPQtbt8LChfDppzBoEDz3HFStCnnzGo+7fRuOHjW2Z5gxw1gBoWJFGDgQgoJSNktsLLz0klFSKF/eWE0hM1O2FRERkVRltULAZtjaBX59Cs4o3D7EaoFDw2H/EMAKpV+H585Cs61QdyFU+RRKD4JCz0HuquASF25jbkPwUWN7htMzjBUQVleEPQMhIoXh1hILO14ySgoe5aFmJg+3IiIi8khRsVG8v/F9Gs1pxPJjy+mypAtD1w4lOjba1qM91tGgozz/0/PEWmPpUakHoxuNTvFzeefwpmqBqikuKQD0rdKXnpV6EmuN5cWlLxIUlsIcZkcm7pwIQPuy7ROUFAByu+Xmy5ZfcnTQUTqV64TFamHa/mmUnlyaz7Z/RkRMRKrMcObmGerMqsMfZ/8gh3MOVr6w0mYlheRK1loPzs7OVK9enY0bN9KhQwcALBYLGzduZPDgwY99rKurK4UKFSI6OpqlS5fStWvX+Pvq1avH8ePHE5x/4sQJihYtmpzxREREJJMIDYUFC4xVAv75597xPn2MN9+nT4dixdJ/rogIowBQtSp4eqb/6z8oKgr69zd+VgDjxhmlBZPp8T+fO3fg4sV7twsXYM8eWL0apk0zfsYjRxorNLgk4/+bfPQRbNwI2bLBzz9D9uxPdHk2p2wrIiIiqSI6FM4tgBNTIPi+cLurD5xbCLWmQ45i6T9XbAQEbjXe8HfNAOE2Ngp29zd+VgCVx0H5uHD7uJ9PzB24c9G4hV2EOxfg+h64shpOTYPzC+HpkVDmDXBIRrg98hEEbASHbFD/Z3DM5OFWREREEnX82nFeWvYS+6/uB6CeTz22X9zOV7u+4sDVAyx+fjHeObz/41nSX0BoAG0XtiU4MpgGRRow89mZmNJqK6wkMplMfNv2W/Ze2cuxa8fotaIXv3X/DbMpWZ+Ltxv+of7MPzwfgP/V+d8jzyuVpxRLuy5ly/ktDF07lP1X9/PuhneZtm8anzb7lOfLP5/iv9sdF3fQYVEHgu4EUThnYVa9uIrK+Sun6LlsIVlbPwAsXryY3r17M336dGrVqsWkSZP46aefOHbsGN7e3vTq1YtChQoxfvx4AHbv3s3ly5epUqUKly9fZsyYMZw9e5YDBw6QK1cuAPbu3UvdunUZO3YsXbt2Zc+ePbz88st8//33vPTSS0maS0uIiYiIZHwnTsC338IPP0BIiHEsWzbo0QMKFIAJEyAy0ngDfPx4Y6UAczrl3JgYaNMG1q83fldaqxa0agWtW0ONGuDgkD5z3BUSAp07w4YN4OgIM2caWy08ic2b4e234eBB4/sSJeDzz6Fjx//e8nfDBmjRwvhQ4Pz5xt+ZLaVW9lO2FRERkRQLOQEnv4UzP0B0XLh1yAbFe4BrATg6ASyRxhvglcfDU4MgvX6Ja4mBTW3Afz1ggry1oEArKNga8tQAczqH2+gQ2NoZ/DeAyRF8Z0KJJwy3AZvhwNtwMy7c5igBVT+HwkkIt/4b4I8WgBXqzDf+zmzI3rOfvV+fiIhkTFarlen7pzN07VDCY8LJ7Zqb75/9nufLP8+yf5fRe0VvQqNCKeReiJ+7/kztwrVtPXK88Ohwmsxtwu7LuymVpxS7+u8ib7a8th4r3pHAI9SaUYvwmHDGPTOOEQ1GpPlrWq1WroZepUCOAjYvbNz1/sb3GbdtHHUK12FH/x3//QDAYrWw4PACRmwcwZXbVwCjPNOxbEc8s3nimc0Tr+xe8V+7O7s/8noXHVlEnxV9iIyNpFqBavz64q8UdC+YateXUsnJfskuKgBMmTKFzz//HH9/f6pUqcI333yDr68vAI0bN6ZYsWLMiduwePPmzQwcOJAzZ86QI0cO2rRpw4QJEyhYMOEPatWqVYwYMYKTJ09SvHhxhg4dyssvv5zkmRR4RUREMqbYWOOT/FOmwLp1946XKmUUEfr0gbj3dzl+HAYMgG3bjO/r1jXeoC9XLu3nHDoUvvrKKCTExia8L29e40361q2NP73TuGR99apRmjh0yCht/PyzUZpIDbGxMG8evPeesYUDQKNGMHEiVKuW+GOuXIEqVYwtIwYMMLaSsLXUzH7KtiIiIpJklljjk/wnpoD/feE2RymjiFCiDzjnMo6FHIfdAyAoLtx61jXeoPdIh3C7fygc/wpMDmB9INy65IX8LYzSQv4W4JbG4Tb8qlGauHnIKG3U/xkKplK4tcTC2Xnw13vGFg4A+RpBtYmQ5xHh9s4V+L0KRAZByQHga/twa+/Zz96vT0REMp7AsED6r+zPqhOrAGhWohlz2s+hUM5C8ef8G/QvnX7qxLFrx3AyOzG59WReqf6Kzd8Et1gtdPu5Gz8f/Zk8bnnY1X8XpfOWtulMiZl9cDb9V/bHbDKzqfcmGhRtkGavFRwRTI/lPVh1YhUlcpega/mudHm6C1XzV7XZ31doVChFvirCzYibLO26lE7lOiXr8WFRYXyx4ws+2/EZd6LvPPI8Zwdno7yQ7V55wSubFxExEcw8OBOA9mXa49fJj+zOGWOFsDQvKmRECrwiIiIZy/XrMGsWfPcdnDtnHDOZoG1bGDwYmjdPfLUEi8XYnuDdd40tIpyd4YMPYNgwcHJKm1nnzjUKEwBLlkCdOrBmjXFbvx6CgxOeX736vdUWfH2NFQ9Sy7FjxnOfPw/58hklj+rVU+/57woNhU8/hS++MLa8MJmMFRs++QTuf889JgaaNoUtW6BSJdi1C9zcUn+e5LL37Gfv1yciIpLpRF6H07Pg5HcQdi7uoAkKtoWnBkOB5omvlmC1wMlpcOhdiAkFszNU+ADKDwNzGoXbM3ONbScA6i8BzzpwdQ1cWWOssBD9QLjNU/3eagt5fcGciuE2+BhsagVh58E1HzRebbxeaosOhaOfwrEvjC0vMBkrNlT6BLLdF24tMfBHUwjcArkqQYtd4Gj7cGvv2c/er09EJLVcuX2FWQdmERETgbOD8yNvLo4uj77P4dH3OZodbf4mfHpYdWIV/Vf2JzAsEGcHZyY0ncCbtd9MdHuCkMgQ+qzow/JjywHoV6UfU9tOxdXRNb3HjjdiwwgmbJ+Ak9mJDb020LBoQ5vN8jhWq5XeK3oz//B8CroX5NCrh/DK7pXqr3Ps2jHaL2rPiesnHrrPlqWFybsn88aaNyiVpxTHBh3DIYUrll0Oucy3e7/lfPB5rt25RtCdIK7duca1O9ceW2C465067/Bps09T/PppQUUFBV4RERGbsFrhwAGYOhV+/NF4Axwgd27jk/ivvWZsN5AUFy4Y5//+u/F9pUowe3bqv2m/a5exokBUFIwaBR9+mPD+6GjjnDVrjFnubptwV65cRumiXTujhJH3CVZh27EDnn0WbtyA0qWN10zqzyulLlyAESNg4ULj++zZYfhweOcdo5Dw3nvGNhw5csD+/fDUU2k7T1LZe/az9+sTERHJFKxWuHkATkyF8z/GvQEOOOc2Polf+jVju4GkCLsAe16Dq3HhNlclqD079d+0v7YLNjQCSxRUGAWVHgi3lmjjnKtr4Mrv97ZNuMspl1G6KNgOCrU1Vl9IqaAdsPlZiLoB7qWhyZqk/7xSKuwCHBoB5+PCrWN2KD8cyr5jFBIOvQdHx4NjDmi1H3JmjHBr79nP3q9PRCQ1BIQGUP+H+py6cSrNXsOE6aHyQuGchZnebjpVC1RNs9dNL3ei7/DO2neYtn8aABXzVcSvkx8VvSs+9nFWq5XPtn/Ge3+8h8VqoUbBGiztupQiHkXSY+wEZh6Yycu/Gityzu84nx6VbLz36n8IjQql5oyaHLt2jJYlW7L6pdWJFkJS6tfjv/LSspe4HXWbwjkLs7DTQq6GXmXJ0SX8duI3wmPC489Nz9JCjCWGpyY/xdlbZ/m2zbcMrDkwTV7nTvSd+NJCUNi9AkPQnSBuhN/gmeLP8Hz559PktZ+EigoKvCIiImkqIgJOnTK2arj/duxYwtUHqlY1Vk944QXIli35r2O1Gm+gv/mmsUKD2Qz/+x+MGZM6n+q/fBlq1DC2QOjQAZYuTXyVh/v5+8PatUZpYd06uHnz3n1mM9SvD889B+3bG9tbJNUvvxg/p4gIqFULVq0Cr9QvIT/Srl3w9tvGnwA+PtCzJ4wbZ3y/aBF065Z+8/wXe89+9n59IiIiGUpsBNw+ZWzVcPu48WfIcQg5lnD1gdxVjdUTir4AjikMt+cWwoE3jRUaTGYo+z+oOCZ1PtV/5zKsqWFsgVC4AzRYmvgqD/cL94era43Sgv86iLov3JrM4FUfCj0HhduDezLC7aVfYPsLxs82by1otApc0zHcXtsF+9+G63HhNpsPFO8J/8SF23qLoGjGCbf2nv3s/fpERJ5USGQIjec05qD/QYp6FKVD2Q5ExUbF3yJjIxN8/+AtMibx+yNjI5P0+j45fdj/yv40+TR8etl3ZR89lvXg+PXjALxd+23GNR2XrJUR1p9ez4tLX+R6+HU8s3myqPMimpZomlYjP2TDmQ209mtNjCWG0Y1GM6bxmHR77SdxJPAItWbUIjwmnHHPjGNEgxFP/JwWq4WPt3zM6E2jAWhYtCFLuiwhX/Z88eeERoWy+uRqfvrnJ1afXJ2upYWf/vmJbj93I69bXi68fYFsTin4/wZ2TEUFBV4REcnCoqLghx+MJf2vXoU8eYwVDfLkSfh1Ysfufn33P6VXrz5cRjh+3NjKwWJJ/PWdnKBLF6OgULu2saXAkwoMNMoKixYZ35cuDTNmGCshpFR4ODRsCPv2QYUKsHOnsWpAcsTGwp49xvYMK1fC4cMJ7y9X7l5poVYtcHjEClzTpsGgQcbPtF074zqz22BLMavVeO1334WLF+8df/11Y5WMjMTes5+9X5+IiEiSxUbBmR/g3y8g4io45zFWNHDOAy73fZ3osbivneL+Wxp+9YEiQlwxIeycsUVDYsxO4NPFKCh4plK4jQiE/W/C+bhw614aas0A7ycItzHhsKEh3NgHHhWgxU5wSma4tcTC9T1wZTVcXgm3Hgi3OctB4eegUHujfPCo5WVPToN9g4yfacF2UH+RsbJBerNajZ/xoXfhzn3htvTrUDNjhVt7z372fn0iIk8iIiaCNn5t+PPcn3hl82J7v+2Uzls6VZ7barUSa419ZJHhTvQdui/rzonrJ2havClre6zNUMvHJ0WsJZZPt3/K6E2jibHEUNC9IHM7zKVZiWYper7zt87T6adOHLh6ALPJzPim4/m/uv+X5lsKHA06St1ZdQmODOalii8xv+P8TLVNx+yDs+m/sj9mk5lNvTfRoGiDFD/X7cjb9FrRixXHVgAwuOZgJraciJPDo7dNe1xpoWTuknzT+hvalG6T4pnuZ7Va8Z3py94re/mg4QeMbTI2VZ7XnqiooMArIiI2FBoKGzdCsWLGdgXplSkjI42tEcaPT/gmc0o4OICzs/Fm/qPkzAlly0KZMglvpUuDaxpt4/brrzBwoLESAsArr0DHjsan/3187hUs/ovVaqwW4OdnlDP27k2dLRbOnTNm/OUX2LwZYmLu3Zcvn1FCaN8emjUzVpiwWo3tJj75xDhnwAD47jtwTMVtgVMiPBwmToQJE4xVMdatS7u/05Sy9+xn79cnIiKZSHQoBGyE7MWM7QrSK9zGRsKZ2fDP+IRvMqeEyQHMzhD7mHDrlBNylgX3MpDzvpt7aXBIoyB06VfYOxDC48JtqVegcEfj0//Zfe4VLP6L1Qo7e8I5P6Oc0Wpv6myxEHoOLv9qrI4QuBms94Vb13xGCaFwe8jfzFhhwmqFw6Pgn7hwW3IA1PwOzDYOtzHhcGwiHJ1grIrxzLq0+ztNIXvPfvZ+fSIiKRVriaXbz91Y+u9S3J3d2dRnE9UKVEvXGf4J/Affmb6ERYcxvN5wxjcbn66v/yTO3TpHz+U92XZhGwDPl3+e6e2mk8ctzxM9b3h0OK+vfp05h+YA0LlcZ35o/wPuLu5POnKiAkIDqD2rNudunaN+kfps6LkBF0eXNHmttGK1Wum9ojfzD8+noHtBDr16KFkrdETHRnM06Cj7r+7ny51fcjToKM4OznzX9jv6Ve2XrFkSKy24Orqyuc9mahWqldxLe8iW81toNKcRro6unH/rfIJVHsSgooICr4hIhnHunPEJ/IoVoWBBW0+Ttm7dgilT4Kuv4MYN41j+/NC8ObRsafyZLw1yS2QkzJplFBQuXTKOFSgAw4dD69bGXDdvGjPd/fNRX9+8mbCcYDZD8eJGAeHBUoK3d/r9nvp+wcHGJ/6nT3/4Pg8Po7BQpMi98sL9XxcuDC4u8PnnMGyYUchYtw6eeSb157x1y9geYuVKY8WFkJB797m5Gf88ODrCsmXGsTFj4IMPbPMzfZSYGGOeR60EYUv2nv3s/fpERDKt0HPGp/BzVYRsdh5uo27BiSlw7CuIigu3rvkhf3Mo0BIKNDferE5tsZFwehYcHQ934sKtWwEoPxwKtIboW8b2BJE3IDruz6gbxrGoG3Hf37x37P5ygskM2YvHlRDKxhUR4goJrjYKt1HBxif+TyUSbp084koLRYw/H/w6W2FwcIGjn8OhYUYho8k6yJ8G4TbqlrE9xOWVxooL0feFWwc3458LsyNcjAu3FcdAhQwWbi0xgOnRK0HYkL1nP3u/PhGRlLBarQz8bSDT90/H2cGZ31/6nWeKp8F/w5Ng8ZHFvLD0BQCWdV1Gx3IdbTJHUlmtVhYcXsCg1YO4HXUbd2d3prSZQs9KPVNtFQKr1cr0/dN54/c3iLZEU86zHMu6LaOsZ9lUef67wqPDaTK3Cbsv76ZUnlLs7L8Tz2yeqfoa6SU0KpSaM2py7NoxWpZsyeqXVmNOZBuy+0sJ+67sY//V/fzl/1eCrUoKuhdkWddl+Bb2feKZuv3cjdUnV+Od3Zs9L++hiEeRJ3rOZ398llUnVvFq9VeZ1m7aEz2XvVJRQYFXRMRmbt6EP/6ADRtg/Xo4ffrefT4+xlYAdeoYf1atmvE+pZ0S167BpEkwefK9N6N9fOD6dbhzJ+G5VatCixZGcaFuXeNN85SKiICZM41Pvd9dYaBgQaOg8PLLKf/Zhocbf4937hjX8SQzpqVNm+Drr+HMGWMFiZs3//MhgFGwCAw0PvA1ebKxRUVai4qCLVuM0sLKlXD+/L37HByMrR8GDEj7OeyJvWc/e78+EZFMI+om+P8B/hvAfz2E3hdus/kYWwF41oG8tSFP1Qz3Ke0UibgGxyfBicn33ozO5gOR1yH2gXCbuyoUaGEUFzzrGm+ap1RsBJyaaXzq/e4KA24FjYJCqZdT/rONCY8rLNwxruNJZkxLAZvg+NcQesZYQSIqieHW1dvYSgIrVJ8MZdIh3MZGQdAWuLTSKC6E3RduTQ5QcxqUUrhNDnvPfvZ+fSIiKfHBnx/w0ZaPMGFiSZcldC7f2abzDF07lK92fYW7szt7X95LGc8yNp3nUW6E32DgbwP56Z+fAKjrU5cFHRdQPHfxNHm9XZd20fmnzly5fQV3Z3fmdpibakUOi9VCt5+78fPRn8njloed/XfyVN6nUuW5beVI4BFqzahFeEw4454Zx//q/o+jQUfjCwmJlRLu8nDxoFqBavgW8uXN2m+SP0f+VJnpduRt6s2ux9+Bf1MxX0W29dtGTpeU5ZF/g/6l/LflMWHi2OBjmf7vK62oqKDAKyKSbiIjYceOe8WE/fvBct/2rg4Oxifyz5xJeBzAycl447527Xu3YsUy1oduHufqVfjyS2Op/ruFhAoV4P33oUsX49Po27cbn9hfuxYOHUr4+OzZoXHje8WFp55K2rVHRMCMGUZB4coV41ihQjBiBPTvbx/lj5QIDTUKCxcvwoULiX99/2oRL79srMqQ3v+8Wa3w99/G9hC7dhlFidat03cGe2Dv2c/er09EJMOKjYRrO4xiwtX1cHM/WO8LsSYH4xP5YWcSHgcwOxlv3OetHVdgqG1sl5BZwm34Vfj3Szj53b1CgkcFePp9KNLFWPY/aDv4r4Ora+HmoYSPd8wO+RrfKy64JzHcxkbAqRlxBYW4cOtWCJ4eASX720f5IyWiQ43Cwp2LEHYh8a/vXy2i5MtQy0bh9tbfxvYQ13fBU4OhoMJtctl79rP36xMRSa7Juyfzxpo3AJjWdhqv1njVxhMZn3JvNr8ZW85vobxXeXYP2E0O5xy2HiuBP87+Qa/lvbh8+zKOZkfGNBrDu/XfxTGNt5kKCA2g689d2XJ+CwAj6o/goyYf4fCEqzSN2DCCCdsn4GR2YkOvDTQs2jA1xrW52Qdn039lf8wmM05mp8eWEqoXqE71gtWpXqA6JfOUTHQFhtRwIfgCvjN98Q/1p3Wp1qx8cWWK/rl5eeXLzDw4kw5lO7C82/I0mNQ+qKigwCsikmbuvsm6fr1RTtiy5eFVA8qVM5a1b9YMGjWCnDnh9m3Yt894Y/buLTDw4efPly/hqgs1akCOjJWJuXABPvvMWM0gMi5nVa8OI0fCc88Z2yUkJiDA+LmtW2fcAgIS3l+kiFFYaNECmjaF3LkT3h8eDt9/D59+apQkwNjK4G5BIaOufJBRWK3GKhcXLxorXzRo8Oi/K8n47D372fv1iYhkGHffZPVfb5QTArc8vGpAznLGsvb5m4F3I3DKCdG34cY+uLbLuF3fFfep9ge45osrLtQxigt5aoBTBgu3YRfg6GdweiZY4sJtnurw9Ego/JyxXUJiwgOMn9vVdUZ5IeKBcJutSNwWES0gf1NwfiDcxoTDqe/h30+NkgQYWxmUv1tQULh9LKvVWOXizkVj5Yt8DR79dyUZnr1nP3u/PhGR5Fh0ZBHdl3bHipUPG3/IqEajbD1SPP9Qf6p/X50rt6/QpXwXFj+/ONW2UngSkTGRvP/H+3y580sASucpjV8nP2oWqpluM0THRjNs/TAm7Z4EQPMSzfmx84/kzZY3Wc8TY4nhYvBFlh9bzjvr3gFgXod59KzcM7VHthmr1UqfX/ow7695QPqXEh5l7+W9NJrTiPCYcIbUGsI3rb9J1uP9Q/0pOqkoUbFRbOu7jXpF6qXRpJmfigoKvCIiqerSpXvFhA0bHi4YeHsbpYTmzY032AsX/u/ntFrh3LmExYWDByE6OuF5ZjNUrGiUFurWhXr1oEQJ23ww7dQpYxWDuXON1RLAmGnUKKNgkJyZLBaj8LF2rVFa2LrV2B7gLrMZatUynrdZM6Pk8emn4O9v3O/jA++9B337qqAgWZO9Zz97vz4REZu6c8lYLcF/AwRseLhg4JrfKCXcvWUr9N/PabVC2LmExYWbB8HyQLg1mcGjYtyKC3XBqx7ksFG4vX3KWMXgzFxjtQQwZqowyigYJGcmq8UofFxdaxQXgraC5b5wazJDnlrG8+ZvZpQ8jn4KEXHhNpsPPP0elOirgoJkSfae/ez9+kREkmrd6XW0W9iOaEs0g2sO5pvW32SIIsD9dlzcQeM5jYm2RPNliy8ZWmeoTec5EniEl5a9xOGAwwC8Wv1VvmzxJdmds9tknh///pH+K/sTHhNOUY+iLOu2jGoFqsXfb7VaCQgL4OzNs5y9dZazN89y5uYZ4+tbZ7kYfJFYa2z8+R80/ICxTcba4lLSVIwlhk3nNlHUo6hNSgmPsuzfZXT+ydhm5ZtW3zDEd0iSHzvyj5F8svUTaheuzY5+OzLc/3YzEhUVFHhFRJ5ISAhs2nSvnHDsWML7s2UzVkq4u2pChQqp87vViAijrHB/eeHChYfP8/a+V1qoV8/YPiIt36w/ehTGjYMff7y3fUXTpsYKCo0apc61h4UZq1PcLS78+2/i5xUpYmwt0acPODs/+euKZFb2nv3s/fpERNJVdAgEbLq3akLIA+HWMTvkaxRXTGgOHk+nTsCLjYAbB43Swt0Cw51Ewq2r973Sglc9Y/uItHyzPvgo/DMOzv94b/sK76ZQYaTxc0iNa48JM1anuFtcCHlEuM1WBCq8D8X7gIPCrWRd9p797P36RESSYs/lPTwz9xnCosN4ocIL+HXyyzBv3j5o6p6pDP59MA4mBzb02kDjYo3TfYaQyBAmbJvAxJ0TiYyNxDObJ7Oem8VzZZ5L91kedDjgMJ0Wd+L0zdO4OrryUsWX8A/158zNM5y7dY7wmPDHPt7ZwZliuYrRtXxXPmzyod7wTmefbvuU4RuHYzaZ+fXFX2lTus1/PiYsKgyfr3y4GXGTpV2X0qlcp3SYNPNSUUGBV0QkWaKjYffue8WE3bsh9l6xE7MZata8t2pCnTrp9yb5lSvGPDt2GLd9+xKuPABGSaFmzXvFhTp1wNPzyV/74EH45BNYuvTesbZtjaJAnTpP/vyPc+GC8fexdi1s3Ah58sCwYdC7twoKImD/2c/er09EJE1ZouHa7nvFhOu74b5PLRmf7q9plBIKNDe2ZkivN8nvXDHmubYDgnYYKwtYHgi3ZhfIW9MoLXjWM7aNcE2FcHvjIPzzCVy8L9wWbAtPvw9eaRxuwy7EbROxFvw3gnMeKD8MivdWQUEE+89+9n59IiL/5di1Y9SfXZ/r4ddpXqI5q7qvwjkDZyCr1UqvFb1YcHgB+bLn48ArByiUMwmrjKWC6NhoZhyYwZhNYwi6EwRAm9JtmPXcLPLnyJ8uMyTFzfCb9Fjeg9UnVz90nwkThXMWpnju4hTPVZwSuUtQPFfx+O8LuBfIsCWVrMBqtTJg5QBmH5pNDuccbO+3nUrelR77mCl7pjDk9yGUzF2S44OP42B2SKdpMycVFRR4RUQey2o1PrG/YYPxZvimTRAamvCc0qXvFRMaN4bcuRN7pvQXEQH798P27UZxYft2uHbt4fPKlDFKC3dXXihTJukfDtu50ygo/PbbvWOdOxsFhapVU+c6ROTJ2Hv2s/frExFJVVar8Yl9/w3Glg6BmyDmgXDrXtooJuRvBt5NwDmXLSZ9WGwE3NgPQdvjygvbITKRcJuzjFFa8Kpr/JkzGeE2aKdRULhyX7j16WwUFPIo3IpkBPae/ez9+kREHudSyCXqzqrLxZCL1CxYk429NuLu4m7rsf7Tneg71JlVh8MBh6lduDab+2xO03KF1Wrl1xO/Mmz9MI5fPw5Ambxl+Lz557R7ql2GXHXAYrUw59AcTlw/EV9EKJG7BEU8imToIopAVGwUrRa04s9zf+KT04fdA3ZTwL1AoufGWGJ4avJTnL11lqltpvJ6zdfTedrMR0UFBV4RkQTuFhO2bIGtW41iwpUrCc/Jm9coJtwtJxQtapNRk81qhZMnjcLC3fJCYtsm5M1rlBbuFhdq1AA3t4TPs3kzfPyxsYIBGCtJvPgijBgBTz+dPtcjIklj79nP3q9PROSJ3C0mBG6BwK1GMSH8gXDr4hm3lUPcLXsmCre3T8YVF7Ybqy4ktm2CS15ju4i7W0bkqQGOD4TbwM1w5GMIiAu3JjMUfRHKj4BcCrciGYm9Zz97vz4RkUe5EX6DBj804GjQUcrkLcPWvlvxyu5l67GS7PSN09SYUYNbEbd4vcbrTG07NU1eZ9+Vffxv3f/YfH4zAJ7ZPBnbeCwvV3sZJwenNHlNkZvhN6kzqw7Hrx+nRsEabO6zmWxO2R46b8k/S+j6c1fyuuXlwtsXEj1HElJRQYFXRLK4mBj46y+jmLBlC2zb9vCqA66u0KDBvWJC5crGG/P24Pp1Y1WEu8WFPXuMlRju5+QE1aoZpYVy5WDOHON8AEdH6NULhg83VpYQkYzH3rOfvV+fiEiyWGLg1l9xxYQtELTt4VUHHFzBq6FRSijQHHJVMt6YtweR1+HaznurLlzfY6zEcD+zE+SuZpQWcpaDs3OM8wFMjlC8F5QfDjkVbkUyInvPfvZ+fSIiiQmLCqP5/ObsvLSTQu6F2N5vO0VzZZLy7H1+O/Eb7X5sB8DcDnPpVblXqj33+Vvnef+P9/H72w8AV0dX3q79Nu/WexcPV49Uex2RRzl14xS1Z9bmevh1OpfrzE9dfkqwLYfVasV3pi97r+zlg4YfMLbJWBtOm3moqKDAKyJZTEQE7N17b8WE7dsf3srBzQ3q1DHKCQ0bGl/fv6KAPYuKgoMHE24X4e//8HkuLtC/PwwblnlWlBDJquw9+9n79YmIPFZsBFzfG1dK2Gq84f7gVg4ObsZqAvkaQL6G4FnHKCtkBbFRcPNgwu0iIhIJt2YXKNkfyg/LPCtKiGRR9p797P36REQeFB0bTftF7fn91O/kds3N1r5beTpf5l3RavSfo/lwy4e4Orqys/9OquSv8kTPFxwRzPht45m0axKRsZEA9KzUk4+f+ZgiHkVSYWKRpNt6fivN5jcjKjaK4fWGM77Z+Pj7tpzfQqM5jXB1dOX8W+fJlz2fDSfNPJKT/RzTaSYREUlFt28bKwbcLSbs3g2RkQnP8fCA+vWNUkKDBlC9Ojhn0a2xnJ3B19e4DR1qrIR79uy94sLhw1C7NrzzDhQsaOtpRURERLKY6NvGigF3iwnXdoPlgXDrlAu86hulhHwNjNUDsuq+rw7O4Olr3IgLt2FnjcJC0A64dRg8a0PZdyCbwq2IiIhkDqFRoRwJPELNgjVxMDvYepwUs1gt9FvZj99P/Y6boxuruq/K1CUFgNGNR7P3yl5+P/U7nRZ3Yt8r+8jjlifZzxMdG833+79nzOYxXLtjrJDWuFhjvmj+BdULVk/tsUWSpEHRBsx6bhY9l/dkwvYJlM5bmn5V+wHwxY4vAOhdubdKCmlERQURkUzg+nVj+4a7WzkcPAixsQnP8fa+t1pCw4ZQoQI4ZN5Mn6ZMJihRwrj17GnraURERESymMjrxvYNd7dyuHkQrA+EW1dvo5Tg1dD4M1cF+9nKIbWZTJCjhHErrnArIiIimUt0bDSzDs5izKYxBIQFUCFfBT5s/CEdynbAZDLZerxksVqt/G/d/1hweAEOJgd+7vozdX3q2nqsJ2Y2mVnQaQE1vq/B2Vtn6bGsB6u6r0qwRP7jWK1WVh5fybANwzhx/QQAZT3L8nnzz2lbum2m+3sW+9OjUg9OXj/Jh1s+5NVVr1I8V3EKuBfg1xO/YsLE27XftvWIdktFBRGRDOjy5XurJWzZAv/88/A5xYrdWy2hYUMoXdr4HaWIiIiISIZy5/K91RICt0BwIuE2e7G41RLiygnupRRuRUREROyY1Wrll+O/MHzDcI5fPx5//EjgETr91IkaBWvwcZOPaVGyRaZ5I/uz7Z/x1a6vAPih/Q+0Kd3GxhOlnjxueVjadSl1Z9fl91O/8+HmDxnTeMx/Pm7flX28s+4dtpzfAoBXNi/GNh7Ly9VfxtGstygl4xjTeAwnb5zkxyM/0umnTtQpXAeA58o8RxnPMjaezn7p3wIiIjZmtcKpU/dKCVu2GNsSPKhcuXurJTRoAD4+6T+riIiIiMhjWa1w+9S9UkLgFmNbggd5lAevBnHFhAaQXeFWREREJKvYdWkX/7f+/9h2YRsAntk8Gd1oNF2f7so3u79h0q5J7Luyj1Z+rWhQpAGfPPMJDYo2sPHUjzfrwCyGbxwOwMQWE+lZ2f5WuqpaoCrT202n94rejN08lpoFa9L2qbaJnnv+1nne/+N9/P72A8DV0ZWhtYfybv13yeny+D3rRWzBZDIxu/1szt06x85LO/n91O8A/K/u/2w8mX0zWa1Wq62HSA0hISF4eHgQHBxMzpz6l5yIZEwWi7FawsmTxioJd7dz8PdPeJ7ZDFWq3Csm1K8PXl42GVlEJEOy9+xn79cnInbCajFWS7h90lgl4e52DhEPhFuTGXJXva+YUB9cFW5FRO6y9+xn79cnIkl38vpJ3vvjPX4++jMAbo5uDK0zlGH1hiV48zowLJAJ2ybw7d5viYyNBKBFyRZ83ORjahaqaZPZH2fFsRV0/qkzFquFd+u9y4RmE2w9Upp6/bfX+W7fd+RyzcW+l/dRMk/J+PuCI4IZv208k3ZNiv+761W5Fx83+RgfD5WTJeMLDAvEd6Yv526do3bh2uzotyPTrOqSUSQn+6moICKSymJi4OJFY5WEB2+nT0Nk5MOPcXaGWrXubeNQty7oX2UiIo9m79nP3q9PRDIRSwzcuWiskhB6yvgz/uvTYEkk3JqdIW+te6sleNUFJ/27TETkUew9+9n79YnIfwsKC+KjLR/x3b7viLHEYMJE3yp9GdtkLIVzFn7k4y6HXObjLR8z8+BMYiwxAHQo24GPmnxEhXwV0mv8x9pyfgst5rcgMjaSflX6MfO5mXb/pmZUbBSN5jRi16VdVPauzI7+O3AyOzF9/3TGbh7LtTvXAGhSrAlftPiCagWq2XhikeQ5cf0E47eN503fN6mSv4qtx8l0VFRQ4BWRNBYdDefOJV5GOHvWuP9RnJygeHEoXRpq1zbKCbVqgZtbuo0vIpLp2Xv2s/frE5EMxhINoecSKSKcMrZtsDwm3JqdIHtxcC8NnrWNYkLeWuCocCsiklT2nv3s/fpE5NHuRN9h0q5JTNg2gdtRtwFoXao1nzb7lIreFZP8PGdunmHs5rEsOLwAi9WCCRMvVHiBsY3HUjpv6bQa/z/95f8XjeY0IjgymOfKPMfSrktxNGeNHdcvhVyi+vfVCQwLpGXJlpy9dZYT108AUM6zHJ83/5w2pdvYfWlDRB6mooICr4ikgshIo3Rwfwnh5Enjz/PnITb20Y91cYGSJaFUqYdvPj7gmDXyqohImrH37Gfv1yciNhAbCaFnE5YRbp80vg87D9bHhFuzC7iXhBylwD3udvfrbD6QRX4ZKyKSVuw9+9n79YnIw2Itscz7ax6j/hzF5duXAahWoBqfNfuMpiWapvh5/w36l9GbRrPk6BIAHEwO9KnShw8afUARjyKpMntSnbl5hnqz6+Ef6k+DIg1Y22Mtbk5Zq6y76dwmms1rRmzc/5fIlz0fHzb+kP7V+meZwoaIPCw52U//phCRLO3OHThzJvGVES5cgMdVudzcHi4hlC5t/FmoEJjN6XcdIiIiIiLE3IHQM4lv0xB2AXhMuHVwS1hAcC9lrJKQoxRkKwQmhVsREREReTyr1cra02sZtn4Yfwf+DUBRj6J88swnvFjxRcxPmCnLeZXjpy4/cfDqQUb9OYrfTv7GrIOzmH94Pq9Wf5X3GrxH/hz5U+NSHisgNIAW81vgH+pPJe9KrHxxZZYrKQA0LtaYb9t+y8dbPqZX5V4MqzeMnC4qpIlI0mlFBRGxW1FR4O9v3K5eNW7+/nDp0r0ywuXLj3+OHDnulQ8evBUoAFq5SkTENuw9+9n79YlICsRGQYQ/hPtDxFUIv2p8HX7pXiEh/D/CrWMOo3zwYCEhRylwU7gVEbEVe89+9n59ImI4cPUAw9YPY+PZjQDkcs3FyAYjGVRrEK6Ormnymjsu7mDkHyP589yfALg5ujGk1hCG1RtG3mx50+Q1gyOCaTy3MYf8D1EsVzF29NtBAfcCafJaIiKZkVZUEBG7ZbVCSMi98sGDJYT7v75+PWnP6eGReBmhdGnw8tLva0VEREQkjVitEB0SV0C4+nAJ4e7XEf4QmcRw6+SReBnBvTS4KNyKiIiISOo6d+scI/8Yid/ffgA4OzgzpNYQ3mvwHnnc8qTpa9f1qcsfvf/gj7N/8P4f77Pr0i4+2/EZ0/ZPY2jtobxd5+1U/YR/REwEHRZ34JD/IfJlz8e6HutUUhAReQIqKohIhhAbC0FB/10+uHoVwsOT/rxOTpA/v3ErUODe7f5CQp48+n2tiIiIiKQiSyxEBt0rGYRfffTXsckIt2YncM1v3NwK3LvdX0hwVrgVERERkbR3M/wm47aO45s93xAVGwVA94rd+eSZTyiWq1i6zvJM8WfY0W8Hv538jZF/jOSvgL8Ys3kM3+z5hnfrvcvgWoPJ5pTtiV4j1hLLS8teYtO5Tbg7u/P7S79TOm/pVLoCEZGsSUUFEUlT4eH/XTy4ehUCA8FiSfrz5syZsHzwqK9z5wazttMVERERkdQQE/7fxYPwqxAZCNZkhFunnAnLB4/62jk3POG+viIiIiIiTyIyJpIpe6bwydZPuBlxE4AmxZrwefPPqV6wus3mMplMtHuqHW1Kt+Hnoz/zwZ8fcPz6cd7d8C5f7fqK9xu8z8vVXsbF0SXZz221Wnn9t9dZ9u8ynB2c+eWFX6hWoFoaXIWISNaiooKIpKpr12DWLFi4EM6fh+DgpD/WZIJ8+R5fPLi7OkL27Gl3DSIiIiIiAERcgzOz4NxCCDsP0ckIt5jANd/jiweu+cEtPzgq3IqIiIhIxmaxWlh0ZBHv//E+526dA6BCvgp81uwzWpVqhSmDrOplNpnp+nRXOpXrhN9hP8ZsHsO5W+cY8vsQPt/xOR80/IDeVXrjaE7622Mf/PkB3x/4HhMmFnZaSJPiTdLwCkREsg4VFUQkVezbB1OmwKJFEBmZ8D4Xl4TbLjyqhODlBY76t5KIiIiI2Nr1fXBiCpxfBJYHwq3ZJeG2C48qIbh4QTJ++SkiIiIiklH9efZP/m/9/7H/6n4ACroX5KMmH9G7cm8czA42ni5xjmZHelfpzYsVX2TWgVl8vPVjLgRfYMCvA/h0+6eMbTyWbhW6Yf6PFcu+2f0NH2/9GIDv2n5H5/Kd02N8EZEsQb81EZEUi4yEJUuMgsLu3feOV6sGgwZBnTpGAcHDQ9vkioiIiEgGFxsJF5YYBYXr94Xb3NXgqUHgWccoIDgp3IqIiIhI1nAk8AjvbniX1SdXA+Du7M7w+sN5q/ZbZHPKZuPpksbZwZmBNQfSp0ofvt37LRO2T+DkjZN0X9ad8dvG81GTj3iuzHOJrgjx498/8uaaNwH4qMlHvFrj1fQeX0TErqmoICLJdvEiTJsGM2ZAUJBxzMkJunUzCgq+vvrdrYiIiIhkEmEX4dQ0ODUDIuPCrdkJinQzCgp5FW5FREREJGu5HHKZ0ZtG88OhH7BYLTiaHXmt+muMajSKfNnz2Xq8FHFzcuOduu/wSvVX+Hr313yx4wv+DvybDos7ULNgTT5+5mOal2geX1hYe2otvVb0AmBIrSG83+B9W44vImKXVFQQkSSxWuHPP43VE375BSwW43jhwvDaazBgAHh723ZGEREREZEksVoh4E9j9YTLv4A1LtxmKwylXoOSA8BN4VZEREREspaQyBA+2/4ZE3dOJDwmHIDO5Tozvul4SuctbePpUoe7izsjG47k9Zqv88WOL/h699fsvbKXlgta0rBoQz555hOczE50/qkzMZYYXqjwApNaTUp0xQUREXkyKiqIyGPdvg3z5sHUqfDvv/eON2kCgwfDc8+Bo/5NIiIiIiKZQfRtODsPTkyFkPvCrXcTeGowFHoOzAq3IiIiIpK1RMdGM33/dMZuHsu1O9cAqOtTly+af0Ednzo2ni5t5HHLw7im43jT900mbJvAd/u+Y8v5LTT4oQEuDi5ExkbSomQL5naYi9lktvW4IiJ2Sb+BEZFEHTtmlBPmzjXKCgDZs0Pv3vD66/D007adT0REREQkyYKPwcmpcGYuxMSFW8fsULw3lH4dcincioiIiEjWY7VaWfbvMkZsHMHJGycBeCrvU0xoOoEOZTtkiVUEvHN481WrrxhaZygfb/mY2YdmExkbSa1CtVjadSnODs62HlFExG6pqCAi8WJiYNUqY3uHjRvvHS9TBgYNgl69wMPDdvOJiIiIiCSZJQYurzK2dwi4L9zmLAOlB0HxXuCscCsiIiIiWdP2C9v5v/X/x85LOwHIlz0fYxqNYUC1ATg5ONl4uvTn4+HD9GenM6zeMNafWc8LFV4gh3MOW48lImLXVFQQEYKCYOZMmDYNLlwwjpnN8OyzxvYOTZtCFijPioiIiIg9iAiC0zPh5DS4ExduTWYo9KyxvYO3wq2IiIiIZF3Hrx1nxMYRLD+2HIBsTtl4p847/F/d/8Pdxd3G09leyTwlKZmnpK3HEBHJElRUEMnC9uwxtndYtAiiooxjefPCyy/Da69B0aK2nU9EREREJMmu7TG2dzi/CCxx4dYlL5R8GUq/BtkVbkVEREQka7FarZy6cYodF3cYt0s7+CfwH6xYMZvM9KvSj7FNxlLQvaCtRxURkSxIRQWRLCYiAn76ydjeYe/ee8dr1DBWT+jWDVxdbTefiIiIiEiSxUbA+Z+M7R1u3Bdu89QwVk8o2g0cFG5FREREJGu4E32HfVf2xRcTdl7aybU71x46r23ptnza7FOezve0DaYUERExqKggkkWcP29s7TBzJlyLy6bOzkYxYfBgqFXLtvOJiIiIiCRZ2Hlja4fTMyEyLtyanaFIN6Og4KlwKyIiIiL272LwxQSrJRzyP0SMJSbBOS4OLtQoWIO6PnWp61OXOoXr4J3D20YTi4iI3KOigogds1ph40Zje4eVK8FiMY77+MDAgTBgAHh52XZGEREREZEksVohYCOcmAqXV4I1Ltxm84HSA6HkAHBVuBURERER+xQVG8Uh/0MJVku4FHLpofMK5ChAvSL1qFu4LnV86lA1f1VcHF1sMLGIiMjjqaggYodCQmDePKOgcOzYveNNmxqrJ7RrB476X7+IiIiIZAbRIXBmHpycCiH3hVvvpsbqCYXagVnhVkRERETsS2BYIDsv7oxfLWHflX1ExEQkOMfB5ECV/FXiV0qo61OXIh5FMJlMNppaREQk6fTbHBE7cvSoUU6YNw9CQ41jOXJAnz7w+utQrpxNxxMRERERSbrgo8bqCWfnQUxcuHXMASX6QOnXwUPhVkRERETsQ6wlln+C/kmwWsKpG6ceOi+PW54EpYSaBWuS3Tm7DSYWERF5cioqiGRyMTHGtg5Tp8Iff9w7Xq4cDBoEPXtCzpy2m09EREREJMksMca2DiemQsB94TZnOXhqEBTvCU4KtyIiIiKSud2KuMXuS7vjSwm7Lu3idtTth8572uvpBMWEp/I+pdUSRETEbqioIJJJBQbCjBkwbRpcituKzGyG9u2N7R2aNAFlVhERERHJFCIC4dQMODUN7sSFW5MZCrU3tnfwVrgVERERkczJarVy8sZJo5RwcSc7Lu3gn8B/sGJNcF4O5xzULlw7vpTgW8iX3G65bTS1iIhI2lNRQSST2bMHJk+Gn36CqCjjmKcnvPIKvPoqFCli2/lERERERJLs2h44MRku/ASWuHDr4gmlXoFSr0J2hVsRERERyVzuRN9h7+W98asl7Li4g+vh1x86r2TuktTxqUPdwnWp61OXCvkq4GB2sMHEIiIitqGigkgmsWsXjB4N69bdO+bra2zv0KULuLrabjYRERERkWS5tgsOjwb/+8JtXl9je4ciXcBB4VZEREREMo+QyBDGbR3HxrMbOeR/iBhLTIL7XRxcqFGwBnV96sZv5eCdw9tG04qIiGQMKiqIZHD79hkFhdWrje8dHaF7d2N7h5o1bTubiIiIiEiyXN8Hf4+GK3Hh1uQIxbob2zvkVbgVERERkcznL/+/eH7J85y6cSr+WEH3gkYpIW61hKoFquLs4GzDKUVERDIes60HEJHEHTwI7dsbZYTVq8HBAfr1gxMnYO5clRREREREJBO5cRA2t4e1NY2SgskBSvSDZ09AnbkqKYiIiKSjqVOnUqxYMVxdXfH19WXPnj2PPX/SpEmUKVMGNzc3fHx8ePvtt4mIiEinaUUyLqvVyqwDs6g9qzanbpzCJ6cP8zvO59yb57j09iWWdFnC23Xexrewr0oKIiIiidCKCiIZzN9/w5gxsGyZ8b3ZDD16wKhRUKqUTUcTEREREUmeW3/D32PgYly4NZmhWA+oMArcFW5FRETS2+LFixk6dCjTpk3D19eXSZMm0bJlS44fP06+fPkeOn/hwoUMHz6c2bNnU7duXU6cOEGfPn0wmUxMnDjRBlcgkjGERYXx+urXmffXPABal2rN/I7zyZstr40nExERyTxStKJCclq30dHRfPjhh5QsWRJXV1cqV67MmjVrHnn+hAkTMJlMvPXWWykZTSTTOnoUunWDSpWMkoLJZGzxcPSosYKCSgoiIiJpQ9lWJA0EH4Vt3WB1pbiSggmKdoe2R40VFFRSEBERsYmJEyfy8ssv07dvX8qXL8+0adPIli0bs2fPTvT8HTt2UK9ePbp3706xYsVo0aIFL7744n+uwiBiz/4N+hffmb7M+2seZpOZcc+MY1X3VSopiIiIJFOyiwp3W7ejR4/mwIEDVK5cmZYtWxIYGJjo+SNHjmT69OlMnjyZo0eP8tprr9GxY0cOHjz40Ll79+5l+vTpVKpUKflXIpJJHT8OL70EFSrATz8Zx7p2hSNHwM8PypSx7XwiIiL2TNlWJJWFHIftL8FvFeBCXLgt0hXaHoF6fpBT4VZERMRWoqKi2L9/P82aNYs/ZjabadasGTt37kz0MXXr1mX//v3xxYQzZ86wevVq2rRp88jXiYyMJCQkJMFNxF4s/HshNWfU5J+gf8ifIz8be21kRIMRmE3aZVtERCS5kv1fz+S2bufPn897771HmzZtKFGiBAMHDqRNmzZ8+eWXCc4LDQ3lpZdeYsaMGeTOnTtlVyOSiZw6Bb17Q/nysHAhWK3QqRP89RcsXmwcFxERkbSlbCuSSm6fgp294bfycH4hYAWfTtD6L6i/GDwUbkVERGzt2rVrxMbG4u3tneC4t7c3/v7+iT6me/fufPjhh9SvXx8nJydKlixJ48aNee+99x75OuPHj8fDwyP+5uPjk6rXIWILETERDFw1kJeWvURYdBjPFH+GQ68eonGxxrYeTUREJNNKVlEhJa3byMhIXF1dExxzc3Nj27ZtCY4NGjSItm3bJnjux1EzVzKrs2ehf38oWxbmzQOLBZ57Dg4cgKVLja0fREREJO0p24qkgtCzsKs/rCoLZ+eB1QKFnoNWB6DBUsitcCsiIpKZbdq0iXHjxvHtt99y4MABli1bxm+//cZHH330yMeMGDGC4ODg+NvFixfTcWKR1Hfm5hnqza7HtP3TMGFiVMNRrOuxDu8c3v/9YBEREXkkx+Sc/LjW7bFjxxJ9TMuWLZk4cSINGzakZMmSbNy4kWXLlhEbGxt/zqJFizhw4AB79+5N8izjx49n7NixyRlfxKYuXIBPPoHZsyEmxjjWpg2MGQM1a9p0NBERkSxJ2VbkCYRdgH8+gdOzwRoXbgu2gYpjIK/CrYiISEbk6emJg4MDAQEBCY4HBASQP3/+RB8zatQoevbsyYABAwCoWLEiYWFhvPLKK7z//vuYzQ9/Ds7FxQUXF5fUvwARG1j+73L6/tKX4Mhg8rrlZUGnBbQq1crWY4mIiNiFNN846euvv6Z06dKULVsWZ2dnBg8eTN++feND7MWLF3nzzTfx8/N76NNpj6NmrmQWly/DoEFQqhR8/71RUmjRAnbuhN9+U0lBREQkM1G2lSzvzmXYOwh+LQWnvjdKCvlbQIud0Pg3lRREREQyMGdnZ6pXr87GjRvjj1ksFjZu3EidOnUSfcydO3ceKiM4ODgAYLVa025YERuLjo3mnbXv0OmnTgRHBlPXpy4HXz2okoKIiEgqStaKCilp3Xp5ebFixQoiIiK4fv06BQsWZPjw4ZQoUQKA/fv3ExgYSLVq1eIfExsby5YtW5gyZQqRkZHx4fd+auZKRnf1KkyYANOnQ2SkceyZZ2DsWKhf37aziYiIiLKtSLKEX4V/JsCp6WCJC7fez0DFsZBP4VZERCSzGDp0KL1796ZGjRrUqlWLSZMmERYWRt++fQHo1asXhQoVYvz48QA8++yzTJw4kapVq+Lr68upU6cYNWoUzz77bKK5VsQeXAy+SLefu7HzkrEl4Dt13mF80/E4OTjZeDIRERH7kqyiwv2t2w4dOgD3WreDBw9+7GNdXV0pVKgQ0dHRLF26lK5duwLQtGlT/v777wTn9u3bl7Jly/Luu+8q8EqmExgIn34K334LERHGsQYN4MMPoXFjm44mIiIi91G2FUmCiEA4+imc/BZi48KtVwOo9CF4N7bpaCIiIpJ83bp1IygoiA8++AB/f3+qVKnCmjVr4rdDu3DhQoIVFEaOHInJZGLkyJFcvnwZLy8vnn32WT755BNbXYJImvr95O/0XN6T6+HX8XDxYE6HOXQo28HWY4mIiNilZBUVIPmt2927d3P58mWqVKnC5cuXGTNmDBaLhWHDhgHg7u5OhQoVErxG9uzZyZs370PHRTKya9fg889hyhS4c8c4VqeOUVBo2hRMJtvOJyIiIg9TthV5hIhr8O/ncGIKxMaFW886cQUFhVsREZHMbPDgwY8s5m7atCnB946OjowePZrRo0enw2QithNjiWHMpjF8stUo4VQrUI0lXZZQIncJG08mIiJiv5JdVEhu6zYiIoKRI0dy5swZcuTIQZs2bZg/fz65cuVKtYsQsaUbN+DLL+GbbyA01DhWs6ZRUGjZUr/DFRERyciUbUUeEHkDjn0Jx7+BmLhwm6emUVAooHArIiIiIvbHP9SfF5e+yKZzmwAYWGMgE1tOxNXR1baDiYiI2DmT1Wq12nqI1BASEoKHhwfBwcHkzJnT1uNIFnDrFnz1FUyaBCEhxrGqVY2CQtu2+h2uiIhIWrL37Gfv1ycZUNQtOPYVHJ8E0XHhNndVo6BQUOFWREQkLdl79rP365PMbdO5Tbzw8wsEhAWQ3Sk73z/7Pd0rdrf1WCIiIplWcrJfsldUEMnqQkKM1RO+/NIoKwBUqgRjx0L79vodroiIiIhkItEhxuoJ/34J0beMY7kqQcWxUFjhVkRERETsk8VqYcK2CYz6cxQWq4WnvZ7m564/U9azrK1HExERyTJUVBBJotBQmDIFPv/c2O4BoHx5o6DQqRPctyq0iIiIiEjGFh0KJ6bAv59DVFy49ShvFBR8OoFJ4VZERERE7NP1O9fpubwnv5/6HYBelXvxbZtvye6c3caTiYiIZC0qKoj8hzt34Ntv4dNP4do141iZMjBmDHTpAg4ONh1PRERERCTpYu7AyW/h6KcQGRduc5aBCmOgSBcwK9yKiIiIiP3aeXEn3X7uxsWQi7g6ujK1zVT6VumLSSuJiYiIpDsVFUQeITwcpk+HCRMgIMA4VqoUjB4NL76ogoKIiIiIZCIx4XBqOhydABFx4TZHKag4Goq+qIKCiIiIiNg1q9XK17u/5v/W/x8xlhhK5ynNz11/ppJ3JVuPJiIikmWpqCDygIgImDkTxo2Dq1eNY8WLwwcfQI8e4Kj/1YiIiIhIZhEbAadmwtFxEB4XbrMXh4ofQLEeYFa4FRERERH7FhwRTL+V/Vj27zIAupTvwsznZpLTJaeNJxMREcna9FspkThRUTB7NnzyCVy6ZBwrUgRGjYLevcHJybbziYiIiIgkWWwUnJkN/3wCd+LCbbYiUGEUlOgNZoVbEREREbF/B68e5Pklz3Pm5hmczE5MbDmRQTUHaasHERGRDEBFBcnyoqNh7lz46CO4cME4VqgQjBwJ/fqBs7Nt5xMRERERSTJLNJyZC0c+gjtx4datEFQYCSX6gYPCrYiIiIjYP6vVyvf7v+fNNW8SGRtJUY+iLOmyhJqFatp6NBEREYmjooJkWTExsGABfPghnD1rHCtQAN57DwYMAFdX284nIiIiIpJklhg4twD+/hDC4sKtWwEo/x6UGgAOCrciIiIikjWERoXy2qrX8PvbD4B2T7Vjboe55HHLY+PJRERE5H4qKkiWY7HAwoUwdiycOmUcy5cPRoyAV18FNzfbziciIiIikmRWC5xbCH+PhdC4cOuaD8qPgFKvgqPCrYiIiIhkHf8E/kOXJV3499q/OJgcGN90PO/UfQezyWzr0UREROQBKipIlhIWBt27w8qVxveenvDuuzBwIGTPbtvZRERERESSJSYMtneHy3Hh1sUTyr8LpQeCo8KtiIiIiGQt8/+az2u/vcad6DsUdC/Ios6LaFC0ga3HEhERkUdQUUGyDH9/ePZZ2LcPXFxg9GgYMgRy5LD1ZCIiIiIiyRTuD5ufhRv7wOwCFUfDU0PASeFWRERERLKW8Ohw3vj9DWYenAlAsxLN8OvkR77s+Ww8mYiIiDyOigqSJfz7L7RpA+fOQd68xooKdevaeioRERERkRQI/hc2tYGwc+CSFxquBC+FWxERERHJek5eP0mXJV34K+AvTJgY3Wg0IxuOxMHsYOvRRERE5D+oqCB2b/Nm6NABbt2CUqVg9WooXdrWU4mIiIiIpEDAZtjSAaJvQY5S0Hg15FS4FREREZGs5+ejP9Pvl37cjrqNVzYv/Dr50bxkc1uPJSIiIkmkooLYNT8/6NsXoqONFRR++QU8PW09lYiIiIhICpz1g919wRINnnWh4S/gqnArIiIiIllLVGwU/7fu//hmzzcA1C9Sn0WdF1EoZyEbTyYiIiLJYbb1ACJpwWqFTz6BHj2MkkKXLrBhg0oKIiIiIpIJWa1w5BPY2cMoKRTpAs9sUElBRERERLKc87fO0+CHBvElhWF1h/FHrz9UUhAREcmEtKKC2J3oaBg4EGbNMr7/v/+DCRPArFqOiIiIiGQ2lmjYOxBOx4Xbcv8HVSaASeFWRERERLKW3078Rs/lPbkZcZPcrrmZ22Euz5Z51tZjiYiISAqpqCB2JSTEWD1h3TqjmDB5Mrz+uq2nEhERERFJgegQ2NoF/NcZxYTqk+EphVsRERERyVpiLDGM+mMUE7ZPAKBmwZr81OUniuUqZtvBRERE5ImoqCB249IlaNsWDh+GbNlg8WJo187WU4mIiIiIpMCdS7CpLdw6DA7ZoP5iKKRwKyIiIiJZy5XbV3hx6YtsOb8FgCG1hvB5889xcXSx8WQiIiLypFRUELvw119GSeHyZcifH1atgurVbT2ViIiIiEgK3PzLKCmEXwbX/NB4FeRRuBURERGRrGXjmY10X9adwLBA3J3dmfncTLo+3dXWY4mIiEgqUVFBMr21a43tHm7fhvLlYfVqKFrU1lOJiIiIiKTAlbWwrQvE3AaP8tB4NWRXuBURERGRrMNitfDJlk8YvWk0VqxU8q7Eki5LeCrvU7YeTURERFKRigqSqc2aBa++CrGx0KQJLFsGuXLZeioRERERkRQ4PQv2vArWWPBuAg2WgXMuW08lIiIiIpJugsKC6LG8B+tOrwOgf9X+TG49GTcnNxtPJiIiIqlNRQXJlKxWGDUKPvnE+L5nT5g5E5ydbTuXiIiIiEiyWa1weBT8Exdui/UE35ngoHArIiIiIlnH4YDDtPFrw+Xbl3FzdOO7tt/Ru0pvW48lIiIiaURFBcl0IiOhXz9YuND4ftQoGDsWTCbbziUiIiIikmyxkbCrH5yPC7cVRkFFhVsRERERyVrCo8PpuqQrl29fpkzeMvzc9Wcq5Ktg67FEREQkDamoIJnKzZvQsSNs3gyOjjB9ulFaEBERERHJdKJuwpaOELgZTI5QazqUVLgVERERkaxnxMYRHL9+nAI5CrC933byZstr65FEREQkjamoIJnG2bPQpg0cOwbu7rB0KTRvbuupRERERERSIPQsbGoDIcfA0R0aLIUCCrciIiIikvX8efZPvt79NQCznpulkoKIiEgWoaKCZAp790K7dhAYCIULw+rVULGiracSEREREUmB63thczuICIRshaHxasilcCsiIiIiWU9IZAh9fukDwKvVX6V16da2HUhERETSjdnWA4j8l5UroXFjo6RQuTLs2qWSgoiIiIhkUpdWwobGRkkhV2VosUslBRERERHJst5a8xYXgi9QIncJvmjxha3HERERkXSkooJkaFOmQMeOcOcOtGoFW7dCoUK2nkpEREREJAWOT4GtHSH2DhRoBc23QjaFWxERERHJmn49/is/HPoBEybmtJ9DDuccth5JRERE0pGKCpIhWSzwzjswZIjx9csvGysruLvbejIRERERkWSyWuDAO7B/iPF1yZeh0UpwUrgVERERkawpKCyIAb8OAOB/df9Hg6INbDyRiIiIpDdHWw8g8qDwcOjZE5YuNb4fNw6GDweTybZziYiIiIgkW0w47OwJF+PCbeVxUF7hVkRERESyLqvVysDfBhIYFsjTXk/zYZMPbT2SiIiI2ICKCpKhBAVB+/awcyc4O8MPP0D37raeSkREREQkBSKCYEt7uLYTzM5Q+wcopnArIiIiIlnbwr8XsvTfpTiaHZnfcT6ujq62HklERERsQEUFyTBOnoTWreH0acidG1asgIYNbT2ViIiIiEgKhJyETa0h9DQ454aGKyCfwq2IiIiIZG2XQi4x+PfBAIxuNJqqBaraeCIRERGxFRUVJEPYvt1YSeH6dShWDH7/HcqWtfVUIiIiIiIpELTdWEkh8jpkLwaNfwcPhVsRERERydqsViv9V/bnVsQtahWqxfD6w209koiIiNiQ2dYDiCxZAk2bGiWFmjVh1y6VFEREREQkk7qwBDY2NUoKeWpCi10qKYiIiIiIANP2TWPd6XW4Oroyt8NcHM36HKWIiEhWpqKC2IzVCp9/Dl27QmSksaLCn3+Ct7etJxMRERERSSarFY5+Dtu6giUSCreHZn+Cm8KtiIiIiMipG6f43/r/AfBps08p66kyr4iISFanooLYREwMDBoEw4YZ37/xBixdCtmz23YuEREREZFks8TAvkFwKC7cPvUG1F8Kjgq3IiIiIiKxllh6r+jNneg7NCnWhMG1Btt6JBEREckAtLaSpLvQUHjhBfjtNzCZYOJEeOstW08lIiIiIpIC0aGw/QW48htggmoToexbtp5KRERERCTD+GLHF+y4uAN3Z3d+aP8DZpM+PykiIiIqKkg6u3oV2rWDAwfA1RX8/KBTJ1tPJSIiIiKSAuFXYVM7uHkAHFyhrh/4KNyKiIiIiNx1OOAwH2z6AIBvWn9D0VxFbTyRiIiIZBQqKki6+ecfaNMGLlwALy/49Vfw9bX1VCIiIiIiKXDrH9jUBu5cABcvaPQreCrcioiIiIjcFRUbRa/lvYiKjeK5Ms/Ru3JvW48kIiIiGYiKCpIu/vwTOnaE4GB46ilYvRpKlrT1VCIiIiIiKRDwJ2zpCNHB4P4UNF4N7gq3IiIiIiL3G7tpLH8F/IVnNk++b/c9JpPJ1iOJiIhIBqLNoCTNzZ8PLVsaJYX69WHHDpUURERERCSTOjsf/mxplBS86kOLHSopiIiIiIg8YNelXUzYPgGAaW2n4Z3D28YTiYiISEajooKkGasVPvoIevWC6Gjo1g3Wr4e8eW09mYiIiIhIMlmt8PdHsLMXWKKhSDd4Zj24KNyKiIiIiNwvLCqMXst7YbFa6FGpB53Ld7b1SCIiIpIBaesHSRPR0fDqq/DDD8b3774L48aBWdUYEREREclsLNGw51U4Exduy78LlceBSeFWRERERORBwzcM5+SNkxRyL8Tk1pNtPY6IiIhkUCoqSKoLDobnn4cNG4xiwrffGqUFEREREZFMJyoYtj0P/huMYkKNb6G0wq2IiIiISGI2nNnAlL1TAPih/Q/kcs1l24FEREQkw1JRQVLVxYvQti38/Tdkzw4//QRt2th6KhERERGRFAi7CJvbwq2/wTE71PsJCincioiIiIgk5lbELfr+0heA12u8TvOSzW08kYiIiGRkKipIqjl0yCgpXLkCBQrAqlVQrZqtpxIRERERSYGbh2BTWwi/Am4FoNEqyKNwKyIiIiLyKG+ueZNLIZcolacUnzX/zNbjiIiISAanooKkijVroEsXCA2Fp5+G1auhSBFbTyUiIiIikgJX1sC2LhATCh5PQ+PVkF3hVkRERETkUZb/u5x5f83DbDIzt8Ncsjtnt/VIIiIiksGZbT2AZH4zZkC7dkZJoWlT2L5dJQURERERyaROzYDN7YySgndTaL5dJQURERERkccIDAvk1VWvAjCs7jDq+tS18UQiIiKSGaioIClmscB778Err0BsLPTubayk4OFh68lERERERJLJaoFD78GeV8AaC8V7GyspOCvcioiIiIg8itVq5dVVrxJ0J4hK3pUY03iMrUcSERGRTCJFRYWpU6dSrFgxXF1d8fX1Zc+ePY88Nzo6mg8//JCSJUvi6upK5cqVWbNmTYJzxo8fT82aNXF3dydfvnx06NCB48ePp2Q0SSeRkdCjB4wfb3w/Zgz88AM4O9t0LBEREZFkU7YVYiNhRw84GhduK46B2j+Ag8KtiIiIiMjjzD88nxXHVuBkdmJeh3m4OLrYeiQRERHJJJJdVFi8eDFDhw5l9OjRHDhwgMqVK9OyZUsCAwMTPX/kyJFMnz6dyZMnc/ToUV577TU6duzIwYMH48/ZvHkzgwYNYteuXaxfv57o6GhatGhBWFhYyq9M0syNG9C8Ofz4Izg6wpw5MHo0mEy2nkxEREQkeZRthcgb8EdzOP8jmByh9hyoqHArIiIiIvJfLgRfYMjvQwAY23gslfNXtvFEIiIikpmYrFarNTkP8PX1pWbNmkyZMgUAi8WCj48PQ4YMYfjw4Q+dX7BgQd5//30GDRoUf6xz5864ubmxYMGCRF8jKCiIfPnysXnzZho2bJikuUJCQvDw8CA4OJicOXMm55IkGc6cgTZt4PhxyJkTli2Dpk1tPZWIiIhkNamV/ZRts7jQM7CpDYQcB6ec0GAZ5Fe4FRERkfRl79nP3q8vq7JYLbSY34KNZzdSu3BttvbdiqPZ0dZjiYiIiI0lJ/sla0WFqKgo9u/fT7Nmze49gdlMs2bN2LlzZ6KPiYyMxNXVNcExNzc3tm3b9sjXCQ4OBiBPnjzJGU/S2J49ULu2UVLw8YHt21VSEBERkcxL2TaLu7YH1tY2SgrZfKD5dpUURERERESS6Nu937Lx7EbcHN2Y12GeSgoiIiKSbMkqKly7do3Y2Fi8vb0THPf29sbf3z/Rx7Rs2ZKJEydy8uRJLBYL69evZ9myZVy9ejXR8y0WC2+99Rb16tWjQoUKj5wlMjKSkJCQBDdJOytWQOPGEBQEVavCrl3wmL8eERERkQxP2TYLu7gCNjaGyCDIXRVa7IJcCrciIiIiIklx4voJhq0fBsDnzT+ndN7SNp5IREREMqNkFRVS4uuvv6Z06dKULVsWZ2dnBg8eTN++fTGbE3/pQYMGceTIERYtWvTY5x0/fjweHh7xNx8fn7QYX4BvvoFOnSA83Nj2YcsWKFjQ1lOJiIiIpD9lWztw/BvY2gliw6FgG2i2BbIp3IqIiIiIJEWMJYZey3sRHhNOsxLNGFhzoK1HEhERkUwqWUUFT09PHBwcCAgISHA8ICCA/PnzJ/oYLy8vVqxYQVhYGOfPn+fYsWPkyJGDEiVKPHTu4MGDWbVqFX/++SeFCxd+7CwjRowgODg4/nbx4sXkXIok0f798OabYLXCq6/CL79Ajhy2nkpERETkySnbZkE39sP+NwErlHoVGv4CTgq3IiIiIiJJ9dn2z9h9eTceLh7Mfm42ZlOafxZSRERE7FSyUoSzszPVq1dn48aN8ccsFgsbN26kTp06j32sq6srhQoVIiYmhqVLl9K+ffv4+6xWK4MHD2b58uX88ccfFC9e/D9ncXFxIWfOnAlukvrWrjX+bNcOvvsOHLXVmIiIiNgJZdss6GpcuC3YDmp+B9pHV0REREQkyQ75H2LMpjEATG49GR8PrQQnIiIiKZfs38wNHTqU3r17U6NGDWrVqsWkSZMICwujb9++APTq1YtChQoxfvx4AHbv3s3ly5epUqUKly9fZsyYMVgsFoYNGxb/nIMGDWLhwoX88ssvuLu7x+8J7OHhgZubW2pcp6TQli3Gny1bgslk21lEREREUpuybRYTGBduCyjcioiIiIgkR2RMJD2X9yTaEk3Hsh3pUamHrUcSERGRTC7ZRYVu3boRFBTEBx98gL+/P1WqVGHNmjV4e3sDcOHChQR79EZERDBy5EjOnDlDjhw5aNOmDfPnzydXrlzx53z33XcANG7cOMFr/fDDD/Tp0yf5VyWpIiYGtm83vm7QwLaziIiIiKQFZdssxBIDQXHhNp/CrYiIiIhIcozeNJojgUfwyubF9HbTMan4KyIiIk/IZLVarbYeIjWEhITg4eFBcHCwlspNJfv2Qc2akCsXXLsGDg62nkhERETEYO/Zz96vzyau74O1NcEpF3S+BmaFWxEREckY7D372fv1ZQXbL2ynwQ8NsGJlRbcVtC/b/r8fJCIiIllScrKf+bH3Spa2davxZ/36KimIiIiISCYXFBduveqrpCAiIiIikkShUaH0XtEbK1Z6V+6tkoKIiIikGhUV5JG2xG3h27ChbecQEREREXligXHhNp/CrYiIiIhIUg1bP4zTN0/jk9OHr1t9betxRERExI6oqCCJsljuraigooKIiIiIZGpWy70VFVRUEBERERFJkrWn1vLdvu8A+KH9D3i4eth4IhEREbEnKipIov79F65fh2zZoFo1W08jIiIiIvIEgv+FyOvgkA3yKNyKiIiIiPyXm+E36beyHwBDag2haYmmNp5IRERE7I2KCpKou9s+1KkDTk62nUVERERE5IkExYVbzzpgVrgVERGRrG3q1KkUK1YMV1dXfH192bNnzyPPbdy4MSaT6aFb27Zt03FisYUhvw/hyu0rPJX3KSY0m2DrcURERMQOqaggibpbVNC2DyIiIiKS6QXGhVtt+yAiIiJZ3OLFixk6dCijR4/mwIEDVK5cmZYtWxIYGJjo+cuWLePq1avxtyNHjuDg4ECXLl3SeXJJTz8f/Rm/v/0wm8zM6zCPbE7ZbD2SiIiI2CEVFeQhVitsjdvCV0UFEREREcnUrFYIjAu3KiqIiIhIFjdx4kRefvll+vbtS/ny5Zk2bRrZsmVj9uzZiZ6fJ08e8ufPH39bv3492bJlU1HBjvmH+vPaqtcAGFF/BL6FfW08kYiIiNgrFRXkIWfPwuXLxpYPvsqhIiIiIpKZhZ2F8MvGlg95FW5FREQk64qKimL//v00a9Ys/pjZbKZZs2bs3LkzSc8xa9YsXnjhBbJnz/7IcyIjIwkJCUlwk8zBarXyyq+vcD38OlXyV+GDRh/YeiQRERGxYyoqyEPubvtQqxa4udl2FhERERGRJ3J324e8tcBR4VZERESyrmvXrhEbG4u3t3eC497e3vj7+//n4/fs2cORI0cYMGDAY88bP348Hh4e8TcfH58nmlvSzw+HfuDXE7/i7ODMvA7zcHZwtvVIIiIiYsdUVJCH3C0qaNsHEREREcn07hYVvBRuRURERJ7ErFmzqFixIrVq1XrseSNGjCA4ODj+dvHixXSaUJ7EuVvneGvNWwB81OQjKnpXtO1AIiIiYvccbT2AZDx3iwoNGth2DhERERGRJ3a3qJBP4VZERESyNk9PTxwcHAgICEhwPCAggPz58z/2sWFhYSxatIgPP/zwP1/HxcUFFxeXJ5pV0pfFaqHvL325HXWbej71eKfOO7YeSURERLIAraggCVy+DKdPg9kMdevaehoRERERkSdw5zKEngaTGTwVbkVERCRrc3Z2pnr16mzcuDH+mMViYePGjdSpU+exj12yZAmRkZH06NEjrccUG/hm9zdsOreJ7E7ZmdthLg5mB1uPJCIiIlmAVlSQBLZuNf6sUgU8PGw6ioiIiIjIkwmMC7e5qoCzwq2IiIjI0KFD6d27NzVq1KBWrVpMmjSJsLAw+vbtC0CvXr0oVKgQ48ePT/C4WbNm0aFDB/LmzWuLsSUNHbt2jBEbRwDwRYsvKJmnpI0nEhERkaxCRQVJ4G5RoaG28BURERGRzC4oLtzmU7gVERERAejWrRtBQUF88MEH+Pv7U6VKFdasWYO3tzcAFy5cwGxOuAjv8ePH2bZtG+vWrbPFyJKGomOj6bm8JxExEbQs2ZJXq79q65FEREQkC1FRQRLYEreFr4oKIiIiIpLpBcaFWxUVREREROINHjyYwYMHJ3rfpk2bHjpWpkwZrFZrGk8ltjB+23j2XdlHLtdczHpuFiaTydYjiYiISBZi/u9TJKu4fh2OHDG+rl/ftrOIiIiIiDyRyOsQHBduvRRuRURERETut//Kfj7a8hEAU9tMpVDOQjaeSERERLIaFRUk3rZtxp/lyoGXl21nERERERF5IkFx4TZnOXBVuBURERERuSsiJoJeK3oRY4nh+fLP82KFF209koiIiGRBKipIPG37ICIiIiJ2Q9s+iIiIiIgkauQfIzkadBTv7N581/Y7bfkgIiIiNqGigsRTUUFERERE7IaKCiIiIiIiD9lyfgsTd04EYOZzM/HM5mnjiURERCSrUlFBALh9Gw4eNL5u0MC2s4iIiIiIPJHo23AzLtx6KdyKiIiIiADcjrxNnxV9sGKlX5V+tHuqna1HEhERkSxMRQUBYOdOiI2F4sXBx8fW04iIiIiIPIFrO8EaC9mLQ3aFWxERERERgHfWvcPZW2cp6lGUr1p9ZetxREREJItTUUEAbfsgIiIiInZE2z6IiIiIiCSw+uRqZhyYAcCcDnPI6ZLTxhOJiIhIVqeiggD3igra9kFEREREMr34ooLCrYiIiIjI9TvXGbByAABv+b5F42KNbTuQiIiICCoqCBARAbt3G19rRQURERERydRiI+B6XLj1UrgVERERERm0ehBXQ69S1rMs45qOs/U4IiIiIoCKCgLs2QNRUZA/P5QqZetpRERERESewPU9YIkC1/zgrnArIiIiIlnb4iOLWfzPYhxMDszrMA83JzdbjyQiIiICqKggwNatxp8NG4LJZNtZRERERESeSGBcuM2ncCsiIiIiWduV21d4ffXrALzf4H1qFqpp44lERERE7lFRQdgSt4Wvtn0QERERkUwvMC7c5lO4FREREZGsy2q1MmDlAG6E36BagWqMbDjS1iOJiIiIJKCiQhYXEwPbtxtfq6ggIiIiIpmaJQauxYVbFRVEREREJAubeWAmv5/6HRcHF+Z1mIeTg5OtRxIRERFJQEWFLO7gQQgLg9y54emnbT2NiIiIiMgTuHkQYsLAOTd4KNyKiIiISNZ05uYZhq4bCsAnz3zC0/mUjUVERCTjUVEhi7u77UP9+mDWPw0iIiIikpnd3fbBqz6YFG5FREREJOuJtcTSZ0UfQqNCaVCkAW/VfsvWI4mIiIgkSr+9y+LuFhW07YOIiIiIZHp3iwra9kFEREREsqhJuyax9cJWcjjnYE6HOTiYHWw9koiIiEiiVFTIwiwW2LrV+FpFBREREfn/9u48PKry7v/4Zyb7AmFLAoGEICQgiuzEAAGVFMSE4lKlQtmq4AKPVtQKgvtP6KKIbbGgj6DWBWxL1SdBECMom+yLViBhRwQS1kCABDL3749kRgaSQMhyMpP367rmSjJz7nO+5+TM8Gn69b4Bj2YcUk5xuA0n3AIAAKD2+W/2fzXxq4mSpKl9p+qa+tdYXBEAAEDpaFSoxX74QTp2TAoJkTp2tLoaAAAAoAJO/CAVHJN8Q6QGhFsAAADULucKz2nYJ8OUX5iv/q366/5O91tdEgAAQJloVKjFnMs+dO8u+flZWwsAAABQIc5lHxp1l+yEWwAAANQu/++b/6f1B9arQVADvf3Lt2Wz2awuCQAAoEw0KtRizkaFpCRr6wAAAAAqzNmoEE64BQAAQO2yZv8avbz0ZUnSG7e9oSZ1mlhcEQAAwOXRqFBLGfNzo0IvlvAFAACAJzNGyikOtxGEWwAAANQeZ86d0bBPhqnQFGrQdYM06PpBVpcEAABwRWhUqKV27JAOHJD8/aVu3ayuBgAAAKiAUzukMwcku7/UkHALAACA2uPpjKe19fBWNQltoum3Tbe6HAAAgCtGo0It5ZxNoVs3KSjI2loAAACACnEu+9Cwm+RLuAUAAEDtsHjXYk1bNU2S9L+//F81DG5obUEAAADlQKNCLbV0adFXln0AAACAx8spDrcs+wAAAIBa4lTBKY38dKQkaVSnUbot7jaLKwIAACgfGhVqKeeMCjQqAAAAwOM5Z1QIJ9wCAACgdvhk6yfac2KPYsJi9GrfV60uBwAAoNxoVKiFfvxR2rlTstulxESrqwEAAAAq4PSP0qmdks0uhRNuAQAAUDukZaZJkn7T7jeqE1DH4moAAADKj0aFWsi57EPHjlLdutbWAgAAAFRIdnG4rd9R8iPcAgAAwPudKzynhTsWSpJS4lMsrgYAAODq0KhQC7HsAwAAALwGyz4AAACgllmxb4WOnz2uhkENldA0wepyAAAArgqNCrUQjQoAAADwGjnF4TaCcAsAAIDaIT0rXZLUP66/fOw+FlcDAABwdWhUqGUOH5Z++KHo+549ra0FAAAAqJCzh6UTxeE2nHALAACA2iEtM02SlBqXanElAAAAV49GhVpm2bKir9ddJzVqZG0tAAAAQIXkFIfbsOukQMItAAAAvN/OYzu15fAW+dh81K9VP6vLAQAAuGo0KtQyLPsAAAAAr5HNsg8AAACoXdIzi5Z96BnTU/UC61lbDAAAQAXQqFDLOBsVkpKsrQMAAACosJzicBtOuAUAAEDtkJ5V1KiQEpdicSUAAAAVQ6NCLZKbK23YUPQ9jQoAAADwaOdypWPF4TaCcAsAAADvd6rglBbvXixJSo1PtbgaAACAiqFRoRZZsUJyOKRrrpGaNbO6GgAAAKACclZIxiGFXiMFE24BAADg/TJ2ZqigsEAt6rVQm0ZtrC4HAACgQq6qUWH69OmKjY1VYGCgEhIStHr16lK3PXfunF588UW1bNlSgYGBat++vRYsWFChfeLqLF1a9LUXS/gCAAC4kG09VE5xuI0g3AIAAKB2SMtMk1Q0m4LNZrO4GgAAgIopd6PC3LlzNW7cOD333HNav3692rdvr379+ik7O7vE7SdNmqSZM2fqr3/9q3744Qc9+OCDuuOOO7TBuQbBVewTV+eb4iV8aVQAAAAoQrb1YNnF4TaccAsAAADvZ4xRela6JCklLsXiagAAACrOZowx5RmQkJCgrl276m9/+5skyeFwKDo6Wv/zP/+j8ePHX7J9VFSUJk6cqDFjxrieu+uuuxQUFKT333//qvZZktzcXIWFhenEiROqW7dueU6pVjhzRqpXTyookLZvl1q2tLoiAACAq1dZ2Y9s66HOn5H+VU9yFEgDtkt1CLcAAMBzeXv28/bzqy7rD6xX5zc7K8QvRId/f1iBvoFWlwQAAHCJ8mS/cs2oUFBQoHXr1ik5OfnnHdjtSk5O1sqVK0sck5+fr8BA99AUFBSkZcuWXfU+UX6rVxc1KTRpIl1zjdXVAAAAWI9s68GOrC5qUghqIoUSbgEAAOD90jOLZlNIviaZJgUAAOAVytWocPjwYRUWFioyMtLt+cjISB08eLDEMf369dPUqVOVlZUlh8OhRYsWad68eTpw4MBV71Mq+iNxbm6u2wOlu3DZB5YvAwAAINt6tAuXfSDcAgAAoBZIy0qTJKXGp1pcCQAAQOUoV6PC1Xj99dcVFxenNm3ayN/fX2PHjtXIkSNlt1fs0FOmTFFYWJjrER0dXUkVe6cLGxUAAABwdci2NUROcbiNINwCAADA+x06dUir96+WJN0Wd5vF1QAAAFSOcv1FtVGjRvLx8dGhQ4fcnj906JAaN25c4pjw8HB98sknysvL0549e7R161aFhobqmuL1B65mn5I0YcIEnThxwvXYt29feU6lVjl3Tlqxouh7GhUAAACKkG09lOOclFMcbmlUAAAAQC3w+fbPJUmdmnRSVJ0oi6sBAACoHOVqVPD391fnzp2VkZHhes7hcCgjI0OJiYlljg0MDFTTpk11/vx5/fvf/9bAgQMrtM+AgADVrVvX7YGSbdggnT4tNWggtW1rdTUAAAA1A9nWQx3dIBWelvwbSGGEWwAAAHi/tMyiZR9S4lIsrgQAAKDy+JZ3wLhx4zR8+HB16dJF3bp107Rp05SXl6eRI0dKkoYNG6amTZtqypQpkqRVq1Zp//796tChg/bv36/nn39eDodDv//97694n6gY57IPSUlSBWclBgAA8CpkWw/kWvYhSbIRbgEAAODdCgoL9MWOLyRJqfGpFlcDAABQecrdqDBo0CDl5OTo2Wef1cGDB9WhQwctWLBAkZGRkqS9e/e6rdF79uxZTZo0STt37lRoaKhuu+02/eMf/1C9evWueJ+omAsbFQAAAPAzsq0Hyi4Ot+GEWwAAAHi/pXuW6mTBSUWERKhLVBerywEAAKg0NmOMsbqIypCbm6uwsDCdOHGCqXIv4HBIDRtKx49Lq1dLXbtaXREAAEDFeXv28/bzu2rGIf2roXTuuNRvtdSQcAsAADyft2c/bz+/qjZu4Ti99u1rGtFhhGYPnG11OQAAAGUqT/ZjrlQv9/33RU0KISFSx45WVwMAAABUwPHvi5oUfEOk+oRbAAAAeL+0zDRJUmocyz4AAADvQqOCl3Mu+9Cjh+Rb7oU+AAAAgBrEuexDox6SnXALAAAA75Z5JFNZR7PkZ/fTL1r+wupyAAAAKhWNCl5u6dKir716WVsHAAAAUGE5xeE2gnALAAAA75eemS5J6tW8l+oGsGwGAADwLjQqeDFjfp5RgUYFAAAAeDRjfp5RgUYFAAAA1ALpWUWNCilxKRZXAgAAUPloVPBi27dLBw9K/v5S165WVwMAAABUwMnt0tmDkt1faki4BQAAgHfLzc/V13u+liSlxqdaXA0AAEDlo1HBizlnU0hIkAIDra0FAAAAqJCc4nDbMEHyIdwCAADAuy3asUjnHecV1yBOcQ3jrC4HAACg0tGo4MVY9gEAAABeg2UfAAAAUIukZaVJYjYFAADgvWhU8GI0KgAAAMBr0KgAAACAWsJhHJqfNV+SlBKXYnE1AAAAVYNGBS+1b5+0e7fk4yMlJlpdDQAAAFABefukvN2SzUdqRLgFAACAd1v701pl52Wrjn8dJTVPsrocAACAKkGjgpdaurToa6dOUp061tYCAAAAVEhOcbit30nyI9wCAADAu6VnpkuS+rbsK38ff4urAQAAqBo0Kngp57IPSTTcAgAAwNO5ln0g3AIAAMD7pWWlSZJS41MtrgQAAKDq0KjgpZyNCr1YwhcAAACeztWoQLgFAACAd/vp5E9af2C9JKl/q/4WVwMAAFB1aFTwQtnZ0pYtRd/37GltLQAAAECFnM2WcovDbTjhFgAAAN5tftZ8SVK3pt0UGRppcTUAAABVh0YFL7RsWdHX66+XGja0thYAAACgQnKKw23Y9VIA4RYAAADeLT0rXZKUEpdicSUAAABVi0YFL8SyDwAAAPAaLPsAAACAWiL/fL4W7VgkSUqNT7W4GgAAgKpFo4IXWrq06CuNCgAAAPB42cXhlkYFAAAAeLmv93ytvHN5ahLaRB0bd7S6HAAAgCpFo4KXOXFC2rix6PukJEtLAQAAACqm4IR0fGPR9+GEWwAAAHi3tMw0SUXLPthsNourAQAAqFo0KniZFSskh0Nq2VKKirK6GgAAAKACDq+QjEMKbSkFE24BAADgvYwxPzcqxKdYXA0AAEDVo1HBy3xTvIQvyz4AAADA42UXh1uWfQAAAICX23p4q3Yd3yV/H38lX5NsdTkAAABVjkYFL0OjAgAAALwGjQoAAACoJdKz0iVJN8XepFD/UIurAQAAqHo0KniRM2ekNWuKvqdRAQAAAB7t/BnpaHG4pVEBAACg0kyfPl2xsbEKDAxUQkKCVq9eXeb2x48f15gxY9SkSRMFBAQoPj5e8+fPr6Zqaw/nsg+pcakWVwIAAFA9fK0uAJVn1Srp3DmpaVOpRQurqwEAAAAq4MgqyXFOCmoqhRBuAQAAKsPcuXM1btw4zZgxQwkJCZo2bZr69eunbdu2KSIi4pLtCwoK9Itf/EIRERH617/+paZNm2rPnj2qV69e9RfvxY6dOaZle5dJklLiUyyuBgAAoHrQqOBFnMs+JCVJNpu1tQAAAAAV4lr2gXALAABQWaZOnapRo0Zp5MiRkqQZM2YoPT1ds2bN0vjx4y/ZftasWTp69KhWrFghPz8/SVJsbGx1llwrfLHjCxWaQl3b6FpdU/8aq8sBAACoFiz94EWcjQos+wAAAACP52pUINwCAABUhoKCAq1bt07Jycmu5+x2u5KTk7Vy5coSx3z22WdKTEzUmDFjFBkZqeuvv16TJ09WYWFhqcfJz89Xbm6u2wNlS8sqXvYhnmUfAABA7UGjgpcoKJBWrCj6nkYFAAAAeLTCAulwcbgNJ9wCAABUhsOHD6uwsFCRkZFuz0dGRurgwYMljtm5c6f+9a9/qbCwUPPnz9czzzyjV199Vf/v//2/Uo8zZcoUhYWFuR7R0dGVeh7eptBRqM+zPpckpcSx7AMAAKg9aFTwEuvXS2fOSA0bStdea3U1AAAAQAUcWy8VnpECGkphhFsAAACrOBwORURE6M0331Tnzp01aNAgTZw4UTNmzCh1zIQJE3TixAnXY9++fdVYsedZtX+Vjpw5onqB9dQ9urvV5QAAAFQbX6sLQOVwLvuQlCTZaT8BAACAJ3Mu+xCeJNkItwAAAJWhUaNG8vHx0aFDh9yeP3TokBo3blzimCZNmsjPz08+Pj6u56699lodPHhQBQUF8vf3v2RMQECAAgICKrd4L5aemS5J6teyn/x8/CyuBgAAoPrwVz8vsXRp0VeWfQAAAIDHyy4OtxGEWwAAgMri7++vzp07KyMjw/Wcw+FQRkaGEhMTSxzTo0cPbd++XQ6Hw/VcZmammjRpUmKTAsovLStNkpQan2pxJQAAANWLRgUvUFhIowIAAAC8hKNQyqFRAQAAoCqMGzdOb731lt59911t2bJFDz30kPLy8jRy5EhJ0rBhwzRhwgTX9g899JCOHj2qRx99VJmZmUpPT9fkyZM1ZswYq07Bq+w7sU+bD22WTTbd2upWq8sBAACoViz94AW+/146cUIKDZXat7e6GgAAAKACTnwvnTsh+YZK9Qi3AAAAlWnQoEHKycnRs88+q4MHD6pDhw5asGCBIiMjJUl79+6V/YJ1ZaOjo7Vw4UI99thjuuGGG9S0aVM9+uijeuqpp6w6Ba+SnlW07ENidKIaBTeyuBoAAIDqRaOCF/imeAnfHj0kX36jAAAA8GTZxeE2vIdkJ9wCAABUtrFjx2rs2LElvrZkyZJLnktMTNS3335bxVXVTs5GhZS4FIsrAQAAqH4s/eAFnI0KLPsAAAAAj+dsVGDZBwAAAHixM+fOKGNnhiQpNT7V4moAAACqH40KHs4YGhUAAADgJYyRcpwzKhBuAQAA4L0W716sM+fPqFndZmoX0c7qcgAAAKodjQoeLitLys6WAgKkrl2trgYAAACogJNZ0tlsyR4gNSTcAgAAwHulZaZJklLjUmWz2SyuBgAAoPrRqODhnLMp3HhjUbMCAAAA4LGcyz40ulHyIdwCAADAOxljlJ6VLklKiU+xuBoAAABr0Kjg4ZyNCklJ1tYBAAAAVJizUSGccAsAAADv9X3299p7Yq8CfQN1S4tbrC4HAADAEjQqeDhno0IvlvAFAACAp8spDrcRhFsAAAB4L+dsCre0uEXBfsEWVwMAAGANGhU82J49RQ8fHykx0epqAAAAgArI21P0sPlIjQi3AAAA8F5pmWmSpNS4VIsrAQAAsA6NCh5s6dKir507S6Gh1tYCAAAAVEh2cbht0FnyI9wCAADAOx05fUQrf1wpSUqJT7G4GgAAAOvQqODBWPYBAAAAXiObZR8AAADg/RZsXyCHcahdRDvFhMVYXQ4AAIBlaFTwYM4ZFWhUAAAAgMfLKQ634YRbAAAAeK/0rHRJUkocsykAAIDajUYFD5WdLW3dWvR9jx7W1gIAAABUyNlsKbc43IYTbgEAAOCdzjvO6/Ptn0uSUuNTLa4GAADAWjQqeCjnbArt2kkNGlhbCwAAAFAh2cXhtl47KYBwCwAAAO+0ct9KHT97XA2CGujGZjdaXQ4AAIClaFTwUN8UL+HLsg8AAADweNnF4ZZlHwAAAODF0jLTJEn9W/WXj93H4moAAACsRaOCh6JRAQAAAF4jpzjcRhBuAQAA4L3Ss9IlSSlxKRZXAgAAYD0aFTzQ8ePSpk1F3yclWVoKAAAAUDEFx6VjxeE2gnALAAAA77T7+G79N+e/8rH5qF+rflaXAwAAYDkaFTzQihWSMVJcnNSkidXVAAAAABWQs0KSkerESUGEWwAAAHin9Myi2RR6xPRQg6AGFlcDAABgPRoVPJBz2QdmUwAAAIDHcy77EE64BQAAgPdKy0qTxLIPAAAATjQqeCBno0IvlvAFAACAp8suDrcRhFsAAAB4p7yCPC3etViSlBqfanE1AAAANQONCh7m9GlpzZqi72lUAAAAgEc7f1o6UhxuaVQAAACAl8rYlaH8wnzF1ovVtY2utbocAACAGuGqGhWmT5+u2NhYBQYGKiEhQatXry5z+2nTpql169YKCgpSdHS0HnvsMZ09e9b1emFhoZ555hm1aNFCQUFBatmypV566SUZY66mPK/27bfS+fNSs2ZSbKzV1QAAAHg+sq2FDn8rmfNScDMpJNbqagAAAIAqkZZZtOxDalyqbDabxdUAAADUDL7lHTB37lyNGzdOM2bMUEJCgqZNm6Z+/fpp27ZtioiIuGT7Dz/8UOPHj9esWbPUvXt3ZWZmasSIEbLZbJo6daok6Y9//KP+/ve/691339V1112ntWvXauTIkQoLC9MjjzxS8bP0Ihcu+0CmBQAAqBiyrcWcyz6EE24BAADgnYwxSs9KlySlxKdYXA0AAEDNUe4ZFaZOnapRo0Zp5MiRatu2rWbMmKHg4GDNmjWrxO1XrFihHj16aPDgwYqNjVXfvn117733uv2XaitWrNDAgQOVkpKi2NhY/epXv1Lfvn0v+1+z1UZLlxZ9ZdkHAACAiiPbWiynONyy7AMAAAC81MaDG/XTyZ8U7Besm2JvsrocAACAGqNcjQoFBQVat26dkpOTf96B3a7k5GStXLmyxDHdu3fXunXrXH+Y3blzp+bPn6/bbrvNbZuMjAxlZmZKkjZt2qRly5apf//+5T4hb1ZQIDkvc1KStbUAAAB4OrKtxQoLpMPF1zmCcAsAAADv5JxNIfmaZAX6BlpcDQAAQM1RrqUfDh8+rMLCQkVGRro9HxkZqa1bt5Y4ZvDgwTp8+LB69uwpY4zOnz+vBx98UE8//bRrm/Hjxys3N1dt2rSRj4+PCgsL9fLLL2vIkCGl1pKfn6/8/HzXz7m5ueU5FY+0bp105ozUqJF07bVWVwMAAODZyLYWO7pOKjwjBTSS6hJuAQAA4J3SMtMkSalxqRZXAgAAULOUe+mH8lqyZIkmT56sN954Q+vXr9e8efOUnp6ul156ybXNxx9/rA8++EAffvih1q9fr3fffVevvPKK3n333VL3O2XKFIWFhbke0dHRVX0qlvumeAnfpCSW8AUAALAC2bYS5RSH23DCLQAAALxTdl62Vu8vmo3ttrjbLrM1AABA7VKuGRUaNWokHx8fHTp0yO35Q4cOqXHjxiWOeeaZZzR06FDdf//9kqR27dopLy9Po0eP1sSJE2W32/Xkk09q/Pjx+vWvf+3aZs+ePZoyZYqGDx9e4n4nTJigcePGuX7Ozc31+j/oOhsVerGELwAAQIWRbS2WXRxuIwi3AAAA8E6fZ30uI6OOjTuqad2mVpcDAABQo5RrRgV/f3917txZGRkZruccDocyMjKUmJhY4pjTp0/Lbnc/jI+PjyTJGFPmNg6Ho9RaAgICVLduXbeHNysslJYtK/qeRgUAAICKI9tayFEo5RSHWxoVAAAA4KXSs9IlSSlxKRZXAgAAUPOUa0YFSRo3bpyGDx+uLl26qFu3bpo2bZry8vI0cuRISdKwYcPUtGlTTZkyRZI0YMAATZ06VR07dlRCQoK2b9+uZ555RgMGDHD9UXfAgAF6+eWXFRMTo+uuu04bNmzQ1KlT9dvf/rYST9Wzbd4s5eZKdepI7dtbXQ0AAIB3INta5Phm6Vyu5FtHqke4BQAAgPc5V3hOC3cslCSlxqdaXA0AAEDNU+5GhUGDBiknJ0fPPvusDh48qA4dOmjBggWKjIyUJO3du9ftvyCbNGmSbDabJk2apP379ys8PNz1x1unv/71r3rmmWf08MMPKzs7W1FRUXrggQf07LPPVsIpeoelS4u+9ughFf8NHAAAABVEtrVITnG4De8h2Qm3AAAA8D7L9i5Tbn6uwoPD1bVpV6vLAQAAqHFsxjlHrYfLzc1VWFiYTpw44ZVT5f7qV9K//y1NnixNmGB1NQAAANby9uzn7eenpb+S9v1baj9Zuo5wCwAAajdvz37efn6leXzh45r67VQNbz9c79z+jtXlAAAAVIvyZD97ma+iRjBG+uabou97sYQvAAAAPJkxUnZxuI0g3AIAAMA7pWelS5JS4lIsrgQAAKBmolHBA2zbJuXkSIGBUpcuVlcDAAAAVEDuNik/R/IJlBoQbgEAAOB9th/drm1HtsnX7qu+LftaXQ4AAECNRKOCB3DOpnDjjVJAgLW1AAAAABWSUxxuG94o+RBuAQAA4H3SM4tmU0iKSVJYYJjF1QAAANRMNCp4AJZ9AAAAgNdg2QcAAAB4ubSsNElSanyqxZUAAADUXDQqeIClS4u+JiVZWwcAAABQYdnF4TaCcAsAAADvczL/pL7e/bUkKSUuxeJqAAAAai4aFWq4PXukvXslX18pMdHqagAAAIAKyNsjnd4r2XylRoRbAAAAeJ9FOxfpnOOcWjVopfiG8VaXAwAAUGPRqFDDOZd96NxZCgmxthYAAACgQpzLPjToLPkSbgEAAOB90jPTJRXNpmCz2SyuBgAAoOaiUaGGczYq9GIJXwAAAHg6Z6NCBOEWAAAA3sdhHErPKmpUSI1PtbgaAACAmo1GhRqORgUAAAB4DRoVAAAA4MXWH1ivQ3mHFOofql7NybwAAABloVGhBjt4UMrMlGw2qUcPq6sBAAAAKuDMQelkpiSbFE64BQAAgPdJy0yTJPVt2Vf+Pv4WVwMAAFCz0ahQgy1bVvS1XTupfn1rawEAAAAqJKc43NZrJ/kTbgEAAOB9XMs+xLHsAwAAwOXQqFCDsewDAAAAvAbLPgAAAMCLHTh5QGt/WitJ6h/X3+JqAAAAaj4aFWowGhUAAADgNWhUAAAAgBebnzVfktQ1qqsahza2uBoAAICaj0aFGurYMWnz5qLvk5KsrQUAAACokIJj0vHicBtOuAUAAID3cS77kBKXYnElAAAAnoFGhRpq+XLJGCk+XmpMAy4AAAA8Wc5ySUaqEy8FEW4BAADgXfLP5+uLHV9IklLjUy2uBgAAwDPQqFBDsewDAAAAvAbLPgAAAMCLfbPnG+Wdy1Pj0Mbq2KSj1eUAAAB4BBoVaqilS4u+0qgAAAAAj5ddHG5pVAAAAIAXSstMk1S07IPdxp/cAQAArgSpqQbKy5PWri36PoklfAEAAODJzudJR4vDbTjhFgAAAN7FGKO0rJ8bFQAAAHBlaFSogb79Vjp/XoqOlpo3t7oaAAAAoAIOfyuZ81JwtBRCuAUAAIB32XZkm3Ye2yl/H38lX5NsdTkAAAAeg0aFGuib4iV8e/WSbDZrawEAAAAqJLs43EYQbgEAAOB90jPTJUm9m/dWnYA6FlcDAADgOWhUqIEubFQAAAAAPNqFjQoAAACAl3Eu+5Aan2pxJQAAAJ6FRoUaJj+/aOkHiUYFAAAAeLjCfOlIcbgNJ9wCAADAuxw/e1zL9i6TJKXEpVhcDQAAgGehUaGGWbtWOntWCg+XWre2uhoAAACgAo6ulQrPSgHhUl3CLQAAALzLFzu+0HnHebVp1EYtG7S0uhwAAACPQqNCDbN0adHXpCSW8AUAAICHyy4OtxGEWwAAAHif9Kx0ScymAAAAcDVoVKhhvilewpdlHwAAAODxsovDLcs+AAAAwMsUOgo1P2u+JCk1PtXiagAAADwPjQo1SGGhtKxoSTMaFQAAAODZHIVSTnG4jSDcAgAAwLus+WmNDp8+rLCAMPWI7mF1OQAAAB6HRoUaZNMm6eRJqW5d6YYbrK4GAAAAqIDjm6TzJyW/ulI9wi0AAAC8S1pmmiSpX6t+8vPxs7gaAAAAz0OjQg3iXPahZ0/Jx8faWgAAAIAKcS370FOyE24BAADgXdKz0iVJKXEpFlcCAADgmWhUqEGcjQos+wAAAACP52xUYNkHAAAAeJkfc3/UxoMbZZNN/Vv1t7ocAAAAj0SjQg1hjLR0adH3SUnW1gIAAABUiDFSTnG4DSfcAgAAwLvMz5ovSUpolqDwkHCLqwEAAPBMNCrUEFu3SocPS4GBUpcuVlcDAAAAVEDuVin/sOQTKDUg3AIAAMC7pGWmSZJS41ItrgQAAMBz0ahQQziXfUhMlPz9ra0FAAAAqBDnsg+NEiUfwi0AAAC8x5lzZ5SxK0OSlBKfYnE1AAAAnotGhRrC2ajQiyV8AQAA4OmcjQrhhFsAAAB4lyW7l+j0udNqWqep2ke2t7ocAAAAj0WjQg1gjPT110Xf06gAAAAAj2aMlF0cbiMItwAAAPAu6VnpkqTU+FTZbDaLqwEAAPBcNCrUALt3S/v3S76+0o03Wl0NAAAAUAF5u6Uz+yWbr9SIcAsAAADvYYxRWmaaJCkljmUfAAAAKoJGhRpg6dKir126SMHB1tYCAAAAVEh2cbht0EXyJdwCAADAe/yQ84P2nNijQN9A9bmmj9XlAAAAeDQaFWqAb4qX8GXZBwAAAHi8nOJwy7IPAAAANdL06dMVGxurwMBAJSQkaPXq1aVu+84778hms7k9AgMDq7HamsU5m8LNsTcr2I+mXAAAgIqgUaEGoFEBAAAAXiObRgUAAICaau7cuRo3bpyee+45rV+/Xu3bt1e/fv2UnZ1d6pi6devqwIEDrseePXuqseKaJT0rXZKUGp9qcSUAAACej0YFix04IGVlSTab1KOH1dUAAAAAFXDmgHQyS5JNCifcAgAA1DRTp07VqFGjNHLkSLVt21YzZsxQcHCwZs2aVeoYm82mxo0bux6RkZHVWHHNcfTMUS3ft1ySlBKXYnE1AAAAno9GBYstLV7Ct317qV49S0sBAAAAKia7ONzWby/517O0FAAAALgrKCjQunXrlJyc7HrObrcrOTlZK1euLHXcqVOn1Lx5c0VHR2vgwIH673//W+Zx8vPzlZub6/bwBgu2L5DDOHR9xPVqXq+51eUAAAB4PBoVLMayDwAAAPAazmUfwgm3AAAANc3hw4dVWFh4yYwIkZGROnjwYIljWrdurVmzZunTTz/V+++/L4fDoe7du+vHH38s9ThTpkxRWFiY6xEdHV2p52EV57IPzKYAAABQOWhUsJizUSEpydo6AAAAgArLKQ63EYRbAAAAb5CYmKhhw4apQ4cO6t27t+bNm6fw8HDNnDmz1DETJkzQiRMnXI99+/ZVY8VV47zjvD7P+lySlBqfanE1AAAA3sHX6gJqs6NHpe+/L/qeRgUAAAB4tPyj0vHicBtOuAUAAKhpGjVqJB8fHx06dMjt+UOHDqlx48ZXtA8/Pz917NhR27dvL3WbgIAABQQEVKjWmubbH7/VsbPHVD+wvm5sdqPV5QAAAHgFZlSw0PLlkjFS69bSRTOuAQAAAJ4lZ7kkI9VtLQURbgEAAGoaf39/de7cWRkZGa7nHA6HMjIylJiYeEX7KCws1HfffacmTZpUVZk1UlpmmiSpf1x/+dr5b/8AAAAqA6nKQs5lH3qxhC8AAAA8nXPZh3DCLQAAQE01btw4DR8+XF26dFG3bt00bdo05eXlaeTIkZKkYcOGqWnTppoyZYok6cUXX9SNN96oVq1a6fjx4/rzn/+sPXv26P7777fyNKpdela6JCklLsXiSgAAALwHjQoWolEBAAAAXiO7ONxGEG4BAABqqkGDBiknJ0fPPvusDh48qA4dOmjBggWKLJ7ude/evbLbf56E99ixYxo1apQOHjyo+vXrq3PnzlqxYoXatm1r1SlUuz3H9+j77O9lt9l1a6tbrS4HAADAa9CoYJFTp6R164q+p1EBAAAAHu3cKelocbilUQEAAKBGGzt2rMaOHVvia0uWLHH7+bXXXtNrr71WDVXVXM7ZFLpHd1eDoAYWVwMAAOA97JffBFVh5UqpsFCKiSl6AAAAAB7r8ErJFErBMVII4RYAAADeIy0zTZKUGpdqcSUAAADehUYFiyxdWvSV2RQAAADg8XKKwy2zKQAAAMCL5BXk6atdX0mSUuJTLK4GAADAu9CoYJFvipfwpVEBAAAAHi+7ONzSqAAAAAAv8tWur5RfmK/mYc11Xfh1VpcDAADgVa6qUWH69OmKjY1VYGCgEhIStHr16jK3nzZtmlq3bq2goCBFR0frscce09mzZ9222b9/v37zm9+oYcOGCgoKUrt27bR27dqrKa/Gy8+Xvv226HsaFQAAAKxFtq2gwnzpcHG4pVEBAAAAXiQ9K12SlBKXIpvNZnE1AAAA3sW3vAPmzp2rcePGacaMGUpISNC0adPUr18/bdu2TREREZds/+GHH2r8+PGaNWuWunfvrszMTI0YMUI2m01Tp06VJB07dkw9evTQzTffrM8//1zh4eHKyspS/fr1K36GNdCaNUXNChERUny81dUAAADUXmTbSnBkjeTIlwIjpDqEWwAAAHgHY4yrUSE1PtXiagAAALxPuRsVpk6dqlGjRmnkyJGSpBkzZig9PV2zZs3S+PHjL9l+xYoV6tGjhwYPHixJio2N1b333qtVq1a5tvnjH/+o6OhozZ492/VcixYtyn0ynuLCZR9oxAUAALAO2bYS5BSH23DCLQAAALzH5kOb9WPujwryDdJNsTdZXQ4AAIDXKdfSDwUFBVq3bp2Sk5N/3oHdruTkZK1cubLEMd27d9e6detcU+ju3LlT8+fP12233eba5rPPPlOXLl109913KyIiQh07dtRbb711NefjEZyNCklJ1tYBAABQm5FtK0l2cbiNINwCAADAe6RlpkmSkq9JVpBfkMXVAAAAeJ9yzahw+PBhFRYWKjIy0u35yMhIbd26tcQxgwcP1uHDh9WzZ08ZY3T+/Hk9+OCDevrpp13b7Ny5U3//+981btw4Pf3001qzZo0eeeQR+fv7a/jw4SXuNz8/X/n5+a6fc3Nzy3Mqljl/Xlqxouj7XizhCwAAYBmybSVwnJdyisNtBOEWAAAA3sO57ENKXIrFlQAAAHincs2ocDWWLFmiyZMn64033tD69es1b948paen66WXXnJt43A41KlTJ02ePFkdO3bU6NGjNWrUKM2YMaPU/U6ZMkVhYWGuR3R0dFWfSqXYtEk6eVIKC5PatbO6GgAAAJQH2fYixzdJ509KfmFSGOEWAAAA3iEnL0ff/vitJCklnkYFAACAqlCuRoVGjRrJx8dHhw4dcnv+0KFDaty4cYljnnnmGQ0dOlT333+/2rVrpzvuuEOTJ0/WlClT5HA4JElNmjRR27Zt3cZde+212rt3b6m1TJgwQSdOnHA99u3bV55TsYxz2YeePSUfH2trAQAAqM3ItpXAuexDeE/JTrgFAACAd1iwfYGMjNpHtlezus2sLgcAAMArlatRwd/fX507d1ZGRobrOYfDoYyMDCUmJpY45vTp07Lb3Q/jU/z/0BtjJEk9evTQtm3b3LbJzMxU8+bNS60lICBAdevWdXt4AmejAss+AAAAWItsWwmcjQos+wAAAAAvkpaVJklKjU+1uBIAAADv5VveAePGjdPw4cPVpUsXdevWTdOmTVNeXp5GjhwpSRo2bJiaNm2qKVOmSJIGDBigqVOnqmPHjkpISND27dv1zDPPaMCAAa4/6j722GPq3r27Jk+erHvuuUerV6/Wm2++qTfffLMST9V6Doe0dGnR9zQqAAAAWI9sWwHGIeUUh1saFQAAAOAlzhWe08LtCyXRqAAAAFCVyt2oMGjQIOXk5OjZZ5/VwYMH1aFDBy1YsECRkZGSpL1797r9V2aTJk2SzWbTpEmTtH//foWHh2vAgAF6+eWXXdt07dpV//nPfzRhwgS9+OKLatGihaZNm6YhQ4ZUwinWHFu2SEeOSMHBUqdOVlcDAAAAsm0FnNgi5R+RfIKl+oRbAAAAeIfl+5brRP4JNQpupK5RXa0uBwAAwGvZjHOOWg+Xm5ursLAwnThxosZOlTtjhvTQQ9Itt0gXzDAMAACAcvKE7FcRHnF+WTOkNQ9JkbdIfQi3AAAAV8sjsl8FeNr5PfnFk3pl5Ssa1n6Y3r39XavLAQAA8CjlyX72Ml9FpfqmeAlfln0AAACAx8suDrcs+wAAAAAvkpaVJklKiUuxuBIAAADvRqNCNTGGRgUAAAB4CWNoVAAAAIDX2XF0h7Ye3ipfu6/6tuxrdTkAAABejUaFarJrl7R/v+TnJyUkWF0NAAAAUAF5u6Qz+yW7n9SQcAsAAADvkJ6VLknqGdNT9QLrWVsMAACAl6NRoZo4Z1Po2lUKDra2FgAAAKBCnLMpNOgq+RJuAQAA4B2cjQqpcakWVwIAAOD9aFSoJiz7AAAAAK/Bsg8AAADwMifzT2rJ7iWSpJT4FGuLAQAAqAVoVKgmzkaFpCRr6wAAAAAqzNmoEE64BQAAgHf4cueXKigsUMv6LdW6YWurywEAAPB6NCpUg59+knbskGw2qUcPq6sBAAAAKuD0T9KpHZJsUjjhFgAAAN7BuexDSlyKbDabxdUAAAB4PxoVqsHSpUVfO3SQwsIsLQUAAAComJzicFu/g+RPuAUAAIDncxiHq1EhNT7V4moAAABqBxoVqoFz2YdeLOELAAAAT+dc9iGCcAsAAADvsOHABh08dVAhfiHq1ZycCwAAUB1oVKgGNCoAAADAa9CoAAAAAC+TlpkmSerbsq8CfAMsrgYAAKB2oFGhih05In3/fdH3SUnW1gIAAABUSP4R6URxuA0n3AIAAMA7OJd9SIlLsbgSAACA2oNGhSq2bFnR1zZtpPBwa2sBAAAAKiSnONzWbSMFEm4BAADg+Q6eOqg1P62RJN0Wd5vF1QAAANQeNCpUsaVLi76y7AMAAAA8XnZxuGXZBwAAAHiJz7M+lyR1btJZTeo0sbgaAACA2oNGhSr2TfESvjQqAAAAwONlF4fbcMItAAAAvENaVpokKTU+1eJKAAAAahcaFarQyZPS+vVF39OoAAAAAI927qR0rDjcMqMCAAAAvEBBYYG+2PGFJCklLsXiagAAAGoXGhWq0MqVUmGhFBsrRUdbXQ0AAABQAYdXSqZQComVQgi3AAAA8Hzf7PlGpwpOKTIkUp2jOltdDgAAQK1Co0IVYtkHAAAAeA3nsg/MpgAAAAAvkZ6ZLkm6Le422W38qRwAAKA6kb6qkLNRISnJ2joAAACACnM2KoQTbgEAAOAd0rLSJEmp8akWVwIAAFD70KhQRc6elVavLvqeGRUAAADg0QrPSkeKwy0zKgAAAMALZB7J1Paj2+Vn99MvrvmF1eUAAADUOjQqVJE1a6T8fCkyUoqLs7oaAAAAoAKOrJEc+VJgpFSHcAsAAADPl5ZZNJtC79jeqhNQx+JqAAAAah8aFaqIc9mHXr0km83aWgAAAIAKcS77EEG4BQAAgHdIz0qXJKXGsewDAACAFWhUqCIXNioAAAAAHs3ZqBBOuAUAAIDnO3H2hL7ZU5RxU+JTLK4GAACgdqJRoQqcPy8tX170PY0KAAAA8GiO89Lh4nAbQbgFAACA51u0c5HOO86rdcPWatWgldXlAAAA1Eo0KlSBDRukvDypXj3p+uutrgYAAACogGMbpPN5kl89qR7hFgAAAJ4vLTNNkpQSx2wKAAAAVqFRoQo4l33o2VOyc4UBAADgyVzLPvSUbIRbAAAAeDaHcWh+1nxJUmp8qsXVAAAA1F78pbEKLF1a9JVlHwAAAODxcorDLcs+AAAAwAus2b9GOadzVDegrnrG9LS6HAAAgFqLRoVK5nDQqAAAAAAvYRxSNo0KAAAA8B7pWemSpH4t+8nPx8/iagAAAGovGhUq2Q8/SEePSsHBUqdOVlcDAAAAVMCJH6SCo5JPsNSAcAsAAADPl5aZJklKiUuxuBIAAIDajUaFSvZN8RK+3btLfjTkAgAAwJNlF4fb8O6SnXALAAAAz7Y/d782HNwgm2zqH9ff6nIAAABqNRoVKpmzUSEpydo6AAAAgApzNSoQbgEAAOD55mfNlyR1a9pNESERFlcDAABQu9GoUImM+blRoRdL+AIAAMCTGSPlFIfbCMItAAAAPF9aVtGyD6nxqRZXAgAAABoVKtHOndKBA0VLPiQkWF0NAAAAUAGndkpnDhQt+dCQcAsAAADPdvb8WX2580tJUkpcisXVAAAAgEaFSuScTaFbNykoyNpaAAAAgApxLvvQsJvkS7gFAACAZ1uye4lOnzutqDpR6tC4g9XlAAAA1Ho0KlQiln0AAACA13Au+xBOuAUAAIDnS89Ml1Q0m4LNZrO4GgAAANCoUIloVAAAAIDXcM6oEEG4BQAAgGczxigtK02SlBqfanE1AAAAkGhUqDQ//ijt3CnZ7VL37lZXAwAAAFTA6R+lUzslm10KJ9wCAADAs205vEW7j+9WgE+A+rToY3U5AAAAEI0KlWbp0qKvHTpIdetaWgoAAABQMdnF4bZeB8mPcAsAAADPlpZZNJvCzS1uVoh/iMXVAAAAQKJRodI4GxVY9gEAAAAeL6c43LLsAwAAALxAela6JCklLsXiSgAAAOBEo0Il+aZ4CV8aFQAAAODxsovDLY0KAAAA8HDHzhzT8r3LJdGoAAAAUJPQqFAJDh+W/vvfou979rS2FgAAAKBCzh6WThSH23DCLQAAADzbwh0LVWgK1Ta8rVrUb2F1OQAAAChGo0IlWLas6GvbtlJ4uLW1AAAAABWSUxxuw9pKgYRbAAAAeLa0zDRJUmpcqsWVAAAA4EI0KlQC57IPSUnW1gEAAABUmHPZh3DCLQAAADxboaNQn2//XJKUEs+yDwAAADUJjQqVwNmo0IslfAEAAODpcorDbQThFgAAAJ7t2x+/1dEzR1UvsJ66R3e3uhwAAABcgEaFCjp5Utqwoeh7ZlQAAACARzt3UjpWHG6ZUQEAAAAeLj0rXZLUv1V/+dp9La4GAAAAF6JRoYJWrJAcDqlFCyk62upqAAAAgArIWSEZhxTSQgoh3AIAAMCzpWWmSZJS4lj2AQAAoKahUaGCWPYBAAAAXoNlHwAAAOAl9p7Yq++yv5PdZtetrW61uhwAAABchEaFCqJRAQAAAF4jm0YFAAAAeIf0zKJlHxKbJaphcEOLqwEAAMDFaFSogDNnpNWri76nUQEAAAAe7fwZ6UhxuKVRAQAAAB4uPauoUSE1PtXiSgAAAFASGhUqYPVqqaBAatxYatnS6moAAACACjiyWnIUSIGNpVDCLQAAADzX6XOnlbErQ5KUEpdicTUAAAAoCY0KFXDhsg82m7W1AAAAABVy4bIPhFsAAAB4sMW7Fuvs+bOKCYvR9RHXW10OAAAASnBVjQrTp09XbGysAgMDlZCQoNXO9Q9KMW3aNLVu3VpBQUGKjo7WY489prNnz5a47R/+8AfZbDb97ne/u5rSqtXSpUVfWfYBAADAc5Fti+UUh1uWfQAAAICHS8tMk1Q0m4KNJlwAAIAaqdyNCnPnztW4ceP03HPPaf369Wrfvr369eun7OzsErf/8MMPNX78eD333HPasmWL3n77bc2dO1dPP/30JduuWbNGM2fO1A033FD+M6lm585JK1YUfU+jAgAAgGci2xZznJMOF4dbGhUAAADgwYwxSs9KlySlxqdaXA0AAABKU+5GhalTp2rUqFEaOXKk2rZtqxkzZig4OFizZs0qcfsVK1aoR48eGjx4sGJjY9W3b1/de++9l/yXaqdOndKQIUP01ltvqX79+ld3NtVowwYpL0+qX1+67jqrqwEAAMDVINsWO7pBOp8n+deXwgi3AAAA3qy8M4o5zZkzRzabTbfffnvVFlhB32V/p325+xTkG6SbY2+2uhwAAACUolyNCgUFBVq3bp2Sk5N/3oHdruTkZK1cubLEMd27d9e6detcgXfnzp2aP3++brvtNrftxowZo5SUFLd912TfFC/hm5Qk2a9qAQ0AAABYiWx7gZzicBueJNkItwAAAN6qvDOKOe3evVtPPPGEkpKSqqnSq5eeWTSbQp9r+ijIL8jiagAAAFAa3/JsfPjwYRUWFioyMtLt+cjISG3durXEMYMHD9bhw4fVs2dPGWN0/vx5Pfjgg27T486ZM0fr16/XmjVrrriW/Px85efnu37Ozc0tz6lU2K9/LYWHS40bV+thAQAAUEnIthdo/mspIFwKJNwCAAB4swtnFJOkGTNmKD09XbNmzdL48eNLHFNYWKghQ4bohRde0NKlS3X8+PFqrLj8ftvxt2oc2lhN6za1uhQAAACUocr/c6klS5Zo8uTJeuONN7R+/XrNmzdP6enpeumllyRJ+/bt06OPPqoPPvhAgYGBV7zfKVOmKCwszPWIjo6uqlMoUbNm0vDhUr9+1XpYAAAAWMhbs62Cm0nXDJeiCLcAAADe6mpmFJOkF198UREREbrvvvuu6Dj5+fnKzc11e1SnyNBIjew4Un1b9q3W4wIAAKB8yjWjQqNGjeTj46NDhw65PX/o0CE1LmVqgWeeeUZDhw7V/fffL0lq166d8vLyNHr0aE2cOFHr1q1Tdna2OnXq5BpTWFiob775Rn/729+Un58vHx+fS/Y7YcIEjRs3zvVzbm5u9f9BFwAAAB6LbAsAAIDa5GpmFFu2bJnefvttbdy48YqPM2XKFL3wwgsVKRUAAAC1QLlmVPD391fnzp2VkZHhes7hcCgjI0OJiYkljjl9+rTsdvfDOP84a4xRnz599N1332njxo2uR5cuXTRkyBBt3LixxD/kSlJAQIDq1q3r9gAAAACuFNkWAAAAKN3Jkyc1dOhQvfXWW2rUqNEVj5swYYJOnDjheuzbt68KqwQAAICnKteMCpI0btw4DR8+XF26dFG3bt00bdo05eXludY1GzZsmJo2baopU6ZIkgYMGKCpU6eqY8eOSkhI0Pbt2/XMM89owIAB8vHxUZ06dXT99de7HSMkJEQNGza85HkAAACgMpFtAQAAUFuUd0axHTt2aPfu3RowYIDrOYfDIUny9fXVtm3b1LJly0vGBQQEKCAgoJKrBwAAgLcpd6PCoEGDlJOTo2effVYHDx5Uhw4dtGDBAteUYXv37nX7r8wmTZokm82mSZMmaf/+/QoPD9eAAQP08ssvV95ZAAAAAFeBbAsAAIDa4sIZxW6//XZJP88oNnbs2Eu2b9Omjb777ju35yZNmqSTJ0/q9ddfZ6kyAAAAVIjNGGOsLqIy5ObmKiwsTCdOnGCqXAAAAC/n7dnP288PAAAAP6vO7Dd37lwNHz5cM2fOdM0o9vHHH2vr1q2KjIy8ZEaxi40YMULHjx/XJ598csXHJNsCAADUHuXJfuWeUQEAAAAAAAAA4HnKO6MYAAAAUFWYUQEAAAAex9uzn7efHwAAAH7m7dnP288PAAAAPytP9qM9FgAAAAAAAAAAAAAAVBsaFQAAAAAAAAAAAAAAQLWhUQEAAAAAAAAAAAAAAFQbGhUAAAAAAAAAAAAAAEC1oVEBAAAAAAAAAAAAAABUGxoVAAAAAAAAAAAAAABAtaFRAQAAAAAAAAAAAAAAVBsaFQAAAAAAAAAAAAAAQLXxtbqAymKMkSTl5uZaXAkAAACqmjPzOTOgtyHbAgAA1B5kWwAAAHiL8mRbr2lUOHnypCQpOjra4koAAABQXU6ePKmwsDCry6h0ZFsAAIDah2wLAAAAb3El2dZmvKRV1+Fw6KefflKdOnVks9mq5Zi5ubmKjo7Wvn37VLdu3Wo5phW87Tw9/Xw8pf6aWmdNqcvKOqr72JVxvKquuSr2X5n7vNp9VaSG6j5mdY4ra4yn12/Vsaz4TDPG6OTJk4qKipLd7n2rmZFtq463naenn4+n1F9T66wpdZFtq38f1b1/sm3NHUe2Jdt6ArJt1fG28/T08/GU+mtqnTWlLrJt9e+juvdPtq2548i2tS/bes2MCna7Xc2aNbPk2HXr1q1R/6BXFW87T08/H0+pv6bWWVPqsrKO6j52ZRyvqmuuiv1X5j6vdl8VqaG6j1md48oa4+n1W3Ws6v5c8cb/2syJbFv1vO08Pf18PKX+mlpnTamLbFv9+6ju/ZNta+44sm3ljyHbVh6ybdXztvP09PPxlPprap01pS6ybfXvo7r3T7atuePItpU/pqZmW+9r0QUAAAAAAAAAAAAAADUWjQoAAAAAAAAAAAAAAKDa0KhQAQEBAXruuecUEBBgdSlVytvO09PPx1Pqr6l11pS6rKyjuo9dGcer6pqrYv+Vuc+r3VdFaqjuY1bnuLLGeHr9Vh2rpny2omJqy+/R287T08/HU+qvqXXWlLrIttW/j+reP9m25o4j25JtUbLa8nv0tvP09PPxlPprap01pS6ybfXvo7r3T7atuePItrUv29qMMcbqIgAAAAAAAAAAAAAAQO3AjAoAAAAAAAAAAAAAAKDa0KgAAAAAAAAAAAAAAACqDY0KAAAAAAAAAAAAAACg2tCoUIrnn39eNpvN7dGmTZsyx/zzn/9UmzZtFBgYqHbt2mn+/PnVVO2V++abbzRgwABFRUXJZrPpk08+cb127tw5PfXUU2rXrp1CQkIUFRWlYcOG6aeffipzn1dzrSpTWeckSYcOHdKIESMUFRWl4OBg3XrrrcrKyipzn/PmzVOXLl1Ur149hYSEqEOHDvrHP/5RqXVPmTJFXbt2VZ06dRQREaHbb79d27Ztc9vmpptuuuTaPvjgg1d8jAcffFA2m03Tpk276jr//ve/64YbblDdunVVt25dJSYm6vPPP3e9fvbsWY0ZM0YNGzZUaGio7rrrLh06dKjMfZ46dUpjx45Vs2bNFBQUpLZt22rGjBmVXtvVXL/KqO0Pf/iDbDabfve737meK+91utr3Y0nHdjLGqH///iW+T6722Bcfb/fu3Zdcc+fjn//8p6SSPzPi4+Nd1z0wMFANGjRQaGjoFd9Txhg9++yzCg0NLfPz6IEHHlDLli0VFBSk8PBwDRw4UFu3bi1z388999wl+7zmmmtcr5f3Pivp/J2PP//5zzp48KCGDh2qxo0bKyQkRJ06ddK///1vSdL+/fv1m9/8Rg0bNlRQUJDatWuntWvXuj5PQkNDFRISosDAQAUGBio5Odn1eVfaWEn6y1/+orCwMNntdvn4+Cg8PNz1Oy9rnCTddttt8vPzk81mk6+vr7p166ZVq1aVOa6wsFDt27e/5PxvuummMo9V2nW77777ShwXGxtb4vYRERHKysoq8X0ZHR1d4piePXtKkmbOnKnY2FjZ7XbZbDb17t1bWVlZpR5rzJgxpb42ePDgMseNGDGixNfq1KlT6pisrKxSr1NERESp44wxGjdunIKCglzP+/v7KyAgQC1bttRLL70kY8wl7zlfX99S91mS6dOnKzY2VoGBgUpISNDq1avLfP+h8pBtybZk2yJkW7It2ZZsS7Yl25JtPR/ZlmxLti1CtiXbkm3JtmRbsq3HZ1uDEj333HPmuuuuMwcOHHA9cnJySt1++fLlxsfHx/zpT38yP/zwg5k0aZLx8/Mz3333XTVWfXnz5883EydONPPmzTOSzH/+8x/Xa8ePHzfJyclm7ty5ZuvWrWblypWmW7dupnPnzmXus7zXqrKVdU4Oh8PceOONJikpyaxevdps3brVjB492sTExJhTp06Vus/FixebefPmmR9++MFs377dTJs2zfj4+JgFCxZUWt39+vUzs2fPNt9//73ZuHGjue222y6pq3fv3mbUqFFu1/bEiRNXtP958+aZ9u3bm6ioKPPaa69ddZ2fffaZSU9PN5mZmWbbtm3m6aefNn5+fub77783xhjz4IMPmujoaJORkWHWrl1rbrzxRtO9e/cy9zlq1CjTsmVLs3jxYrNr1y4zc+ZM4+PjYz799NNKre1qrl9Fa1u9erWJjY01N9xwg3n00Uddz5f3Ol3N+7G0YztNnTrV9O/f/5L3ydUeu6TjnT9/3u16HzhwwLzwwgsmNDTUnDx50hhT8mfG0KFDXdd9yJAhpn79+sZut5tXX331iu6pP/zhDyYsLMwMGjTItGzZ0vTt29dER0ebXbt2uX0ezZw503z99ddm165dZt26dWbAgAEmOjranD9/vtR99+nTx9jtdjN79myTkZFh+vbta2JiYsyZM2eMMeW/z5577jnTunVrs2nTJtfj9ddfNzabzezYscP84he/MF27djWrVq0yO3bsMC+99JKx2+1myZIlpnnz5mbEiBFm1apVZufOnWbhwoVm+/btrs+Txx57zISGhprOnTubxo0bm5SUFNOiRQvz008/lTp2zpw5xs/Pz7Rt29a8+uqr5u677zahoaGmY8eOpn379qWOM8aYOXPmGB8fH/P444+bBQsWmLvuusv4+/ub0NBQEx0dXeq4l19+2QQEBJjOnTub1atXmzfffNMEBQWZevXqlTrGGGO2bNlimjVrZu655x4zf/5888c//tFIMpGRkSWOy87ONu+8845p1aqVad++vXnmmWeMJGOz2UyTJk3Mfffdd8n7smvXrubAgQNm/vz55qGHHjJPP/20kWTGjBljjDEmNTXVBAQEmKFDhxpJpn///qZFixZm7969bvfAokWLjCSzePFik52dbf70pz+ZefPmmdWrV5s33njDSDIRERGXvF8uHDd8+HBTv359M2TIENe9smXLFrNjx45Sxxw5csQkJSWZmTNnmqVLl5q0tDTTtGlTY7fbzc6dO0sd94c//MH4+vqauLg4c/fddxs/Pz8TEhJibDab+dOf/mRCQ0PN66+/fsl77t133zUZGRmmX79+JiYmxqSnp7v2ebE5c+YYf39/M2vWLPPf//7XjBo1ytSrV88cOnSozPc3KgfZlmxLti1CtiXbkm3JtmRbsi3Z1vORbcm2ZNsiZFuyLdmWbEu2Jdt6eralUaEUzz33nGnfvv0Vb3/PPfeYlJQUt+cSEhLMAw88UMmVVZ7L/aNnTNE/aJLMnj17St2mvNeqKl18Ttu2bTOSXAHIGGMKCwtNeHi4eeutt8q1744dO5pJkyZVVqmXyM7ONpLM119/7Xqud+/eJQaXy/nxxx9N06ZNzffff2+aN29eocBbkvr165v//d//NcePHzd+fn7mn//8p+u1LVu2GElm5cqVpY6/7rrrzIsvvuj2XKdOnczEiRMrrTZjru76VaS2kydPmri4OLNo0SK3Y1/tdbpYWe/H0o7ttGHDBtO0aVNz4MCBK3rvX+7YlzvehTp06GB++9vfun4u6TPDed0vvFbO6365a+VwOEzjxo3Nn//8Z9e+jx8/bgICAsxHH31U5nlt2rTJSHILVRfvOyQkxDRp0sT13MX7Lu99VtL5Dxw40Nxyyy3GGGNCQkLMe++95/Z6gwYNzK233mp69uxZ6n4vvA7Oz5P09HQTEBBgfvnLX5Y6tlu3bq4wZ0zRZ2RUVJR5+OGHjSTTtWvXUo9Z0tjGjRsbSeb6668vdVxKSopp1aqVGThwoOu5+Ph4Ex4eXuoYY4x56qmn3M5j4MCBJiYmpszrcuG/A48++qhp2bKlCQsLM6GhocbHx+ey78tHH33U+Pr6mqlTp7pd48WLFxtJZvfu3SXea85jORyOS2p69NFHTbNmzUq89y4cN3z4cNOwYcPL3l9lHcuYomtb0meHc5zz9+bv72/ee+89k5KSYn7zm9+YgIAAExoaat566y1z5513miFDhhhj3O81J+f74tZbby21ltLutSlTppR5fqgcZNsiZNufkW1/RrYtGdm2ZGRbd2Rbsi3ZtgjZtnqRbYuQbX9Gtv0Z2bZkZNuSkW3dkW3JtmTbItWZbVn6oQxZWVmKiorSNddcoyFDhmjv3r2lbrty5UolJye7PdevXz+tXLmyqsusUidOnJDNZlO9evXK3K4816o65efnS5ICAwNdz9ntdgUEBGjZsmVXtA9jjDIyMrRt2zb16tWrSuqUiq61JDVo0MDt+Q8++ECNGjXS9ddfrwkTJuj06dNl7sfhcGjo0KF68skndd1111VqjYWFhZozZ47y8vKUmJiodevW6dy5c273fps2bRQTE1Pmvd+9e3d99tln2r9/v4wxWrx4sTIzM9W3b99Kq82pvNevIrWNGTNGKSkpl3wWXO11ulhZ78fSji1Jp0+f1uDBgzV9+nQ1btz4io9X1rHLOt6F1q1bp40bN+q+++5ze/7iz4wbbrhBn332mRYuXKhz584pICDAdd0vd6127dqlgwcPumrJysrStddeK5vNpueff77Uz6O8vDzNnj1bLVq0UHR0dKn7zsvL07Fjx1z1Pvzww2rfvr1bPeW9zy48/7vuuktpaWmua9S9e3fNnTtXR48elcPh0Jw5c3T27FllZWWpS5cuuvvuuxUREaGOHTvqrbfeKvE6OD9PYmJilJCQoKVLl5Y4tqCgQOvWrXP7PdrtdiUnJ2vDhg2SpK5du5Z4zJLGnj9/Xk2bNpUk9ejRo9Rau3fvrgMHDuirr75SRESEYmNjlZWVpXbt2pU6RpI+++wz13k0atRIn376qXJzc8u8Ls5/B+x2u95//3116dJFZ86ckZ+fnwoLC8t8XxYUFOj99993TU138b0mSWFhYUpISHC7H5zjfvvb38pms7mdQ0FBgf7xj38oJibmknuvpHHHjx/XX/7yF/n4+KhBgwb63e9+53Z/lXUsqeg9mJmZKUlunx0Xjtu9e7cOHjyoTp06ae7cuerQoYOWLl2qpk2b6uzZs4qMjNSyZcvUv39/SZe+55zXoVu3blqyZEmp513avebpWcmTkG3JthLZ9kJk27KRbS9Fti0Z2ZZsS7Yl21qBbEu2lci2FyLblo1seymybcnItmRbsm01Z9sqb4XwUPPnzzcff/yx2bRpk1mwYIFJTEw0MTExJjc3t8Tt/fz8zIcffuj23PTp001ERER1lHtVdJnuvDNnzphOnTqZwYMHl7mf8l6rqnTxORUUFJiYmBhz9913m6NHj5r8/Hzzhz/8wUgyffv2LXNfx48fNyEhIcbX19cEBASYt99+u8rqLiwsNCkpKaZHjx5uz8+cOdMsWLDAbN682bz//vumadOm5o477ihzX5MnTza/+MUvXF1RldGZu3nzZhMSEmJ8fHxMWFiYSU9PN8YY88EHHxh/f/9Ltu/atav5/e9/X+r+zp49a4YNG2YkGV9fX+Pv72/efffdSq3NmKu7fldb20cffWSuv/56t2mlnN10V3udLlTW+7GsYxtjzOjRo819993n+vly7/3LHftyx7vQQw89ZK699lq350r6zIiOjjb33nuvkWQkXXLdy7pWy5cvN5LMTz/95LbvpKQk07Bhw0s+j6ZPn25CQkKMJNO6detSu3Iv3PfMmTPd6g0ODnbdS+W9zy4+/5iYGGO32012drYxxphjx46Zvn37uu7BunXrmoULF5qAgAATEBBgJkyYYNavX29mzpxpAgMDzTvvvONW648//uj2eXL33Xcbu91e4tjXXnvNSDIrVqxwq/Gxxx4zwcHBpY575513zP79+11j/+///s813VRoaKix2Wxl1lpYWGgGDBhgJBkfHx/X791ms5mnnnqqxDHGGLdr8Mgjj5jg4GDXdSrtWAUFBaZJkybGZrMZSSY0NNSMGDHCdbyLXXivzZ071/j4+JimTZua1157ze1ec3bmHjt2zNx9993mnnvuce3DOW7//v1u+54+fboJCAgwkkzLli0vufcuHvfRRx+Zhx9+2Pz9738306ZNM1FRUcbPz8/cfvvtlz2W0+jRo01gYOAlnx0XjnOe15YtW1z3nvN62Ww2Y7PZzOTJk11jL7wOF7rxxhuNzWYrsZYL75cLPfnkk6Zbt24l1o7KRbYl25Jtf0a2JduSbcm2ZFuyrRPZ1jORbcm2ZNufkW3JtmRbsi3Zlmzr5InZlkaFK3Ts2DFTt25d19REF/O2wFtQUGAGDBhgOnbseMVrazld7lpVpZLOae3ataZ9+/auD9Z+/fqZ/v37m1tvvbXMfRUWFpqsrCyzYcMG88orr5iwsLAS126pDA8++KBp3ry52bdvX5nbZWRklDnd0dq1a01kZKTbh01lBN78/HyTlZVl1q5da8aPH28aNWpk/vvf/151kPvzn/9s4uPjzWeffWY2bdpk/vrXv5rQ0FCzaNGiSqutJJe7fldb2969e01ERITZtGmT67nKDLxlvR8vd+xPP/3UtGrVyrXOmDHlC7wXH/tyx7vQ6dOnTVhYmHnllVfKPMaxY8dMYGCgiYyMNI8//rjx8/O75LpfaeC90N13321uv/32Sz6Pjh8/bjIzM83XX39tBgwYYDp16uQK71ey72PHjhlfX1/TpUuXEsdcyX12oVatWhl/f39XjWPHjjXdunUzX375pdm4caN5/vnnTVhYmPH19TWJiYluY//nf/7H3HjjjW61Dh061O3zxBl4SxrbqVOnS0JIQUGBadmypQkODjZ+fn6lHvPCAHPq1CmTlZVlVq5cadq1a2ckXXJ9Lqz1o48+Ms2aNTMfffSR2bx5s3nvvfdcoffLL78scYwxxq2e1q1bm7Fjxxq73W5CQ0NLPZYxxqxcudL1P3JsNpvx8/MzrVu3vmzg7du3r0lNTXV9jl5p4HWOu9jx48dNjx49TGJiYon3XmnjnHbs2OG6Ts77q6wxJ06cML6+viYqKuqSz44LxznPa+TIkaZbt25m4sSJJjIy0jRt2tT4+vqal19+2TRo0OCS/3F18XsuMjLSbbq9C1kdeHEpsu2VI9uWH9mWbFsWsi3ZlmxbhGxLtkXlIdteObJt+ZFtybZlIduSbcm2Rci2ZNurRaNCOXTp0sWMHz++xNeio6MvCRXPPvusueGGG6qhsqtT2j96BQUF5vbbbzc33HCDOXz48FXtu6xrVZXK+of8+PHjrs63bt26mYcffrhc+77vvvsu2817NcaMGWOaNWtmdu7cedltT506ZSSZBQsWlPj6a6+9Zmw2m/Hx8XE9JBm73W6aN29eaTX36dPHjB492vUP+7Fjx9xej4mJMVOnTi1x7OnTp42fn59JS0tze/6+++4z/fr1q7TaSnK563e1tf3nP/9x/Q+qC6+783fx5Zdflvs6OV3u/Xi5Y48dO7bUe6J3797lPvbljnf+/HnX+Pfee8/4+fm53nelOX36tLHZbOZXv/qV2z114XUv61o5Q8CGDRvcnu/Vq5d55JFHyvw8ys/PN8HBwZf8weJy+w4NDTWdO3cucczl7rMLffPNN0aSadu2rRk/frzZvn27kdzXZzSm6L4ODQ1167A2xpg33njDREVFudUaERHh9nnSq1cvU6dOnVLH+vj4uD43nb/z+vXrm1tvvdXExMSUOi4/P99trNOwYcOMzWa7JPBeWGuzZs3M3/72N7fXw8LCjM1mMzNmzChxjDHGVY/zum3cuNE0aNDABAcHl3osY4zZvXu3sdvt5oMPPjDZ2dmmT58+JiwsrMz3pXPMJ5984gq8F94PFwZe57124bE++eQTc7ELX7v43itr3IUaNmzour/KGlNQUGA6depkbDab2bp1a6l1GOMepL///nvX76dXr14mOjraPPDAA+all14yrVu3dtv+wvfF7t27jaRSw3dZ98svf/nLMs8ZVYdse+XItleObFuEbFsysi3Z1hiyrRPZlmyLykW2vXJk2ytHti1Cti0Z2ZZsawzZ1olsS7a9Wnbhipw6dUo7duxQkyZNSnw9MTFRGRkZbs8tWrTIbc0lT3Du3Dndc889ysrK0pdffqmGDRuWex+Xu1ZWCQsLU3h4uLKysrR27VoNHDiwXOMdDodrzZzKYIzR2LFj9Z///EdfffWVWrRocdkxGzdulKRSr+3QoUO1efNmbdy40fWIiorSk08+qYULF1Za7c5r0blzZ/n5+bnd+9u2bdPevXtLvffPnTunc+fOyW53//jx8fGRw+GotNpKcrnrd7W19enTR999953bde/SpYuGDBni+r6818lZz+Xej5c79sSJEy+5JyTptdde0+zZs8t97Msdz8fHx7WPt99+W7/85S8VHh5e6nEk6dixYzLGqGHDhm73lPO6X+5atWjRQo0bN3a7vrm5uVq1apU6duxY5ueRKWrYK/WeKWnfP/30k06dOqXrr7++xDGXu88u9Pbbb6tDhw46cOCAmjRp4lrDqqR7MDIyUtu2bXN7PjMzU82bN5cxRq+++qrsdrtGjhzp+jxxXod27dqVOrZz587KyMhw+50HBASod+/e6tGjR6nj/P39XWOdHA6HMjIy5Ofnp+zs7BLHSUXr7118jlFRUTLGuF23C8dIctXz9ttvq3Pnzmrfvr3Cw8Pd7ruSxs2ePVsRERG65557FB4erlOnTunEiRPy9fUt9X3pHJOSkuJ6vax7zXl/ljTu4jpSUlIuuffKGuf0448/6siRI5KK7q/Sxjh/l1u3blVKSopat25dah3O83K+x+12u06fPq38/HytWrVK9evXl8PhcPscLOk6zJgxQ5L061//usTay7pfPC0reQuy7ZUj214Zsi3ZlmxbhGxLtpXItmRbVDey7ZUj214Zsi3ZlmxbhGxLtpXItmTbKlblrRAe6vHHHzdLliwxu3btMsuXLzfJycmmUaNGrg6zoUOHunV6LV++3Pj6+ppXXnnFbNmyxTz33HPGz8/PfPfdd1adQolOnjxpNmzYYDZs2GAkmalTp5oNGzaYPXv2mIKCAvPLX/7SNGvWzGzcuNEcOHDA9cjPz3ft45ZbbjF//etfXT9f7lpZeU7GGPPxxx+bxYsXmx07drg6rO688063fVz8+5w8ebL54osvzI4dO8wPP/xgXnnlFePr62veeuutSqv7oYceMmFhYWbJkiVu1/r06dPGGGO2b99uXnzxRbN27Vqza9cu8+mnn5prrrnG9OrVy20/rVu3NvPmzSv1OBWdQmz8+PHm66+/Nrt27TKbN28248ePNzabzXzxxRfGmKLpz2JiYsxXX31l1q5daxITEy+ZcujiGnv37m2uu+46s3jxYrNz504ze/ZsExgYaN54441Kq+1qr19l1XbxtFrlvU5X+n68kmNfTCV0sFfk2CUdLysry9hsNvP5559fsv3jjz9uoqOjzYwZM1yfGc4pnRYvXmwGDx5sGjZsaPz8/Mz48eOv6J76wx/+YOrVq2duv/12M2vWLPOLX/zCNGnSxNxyyy2uz6MdO3aYyZMnm7Vr15o9e/aY5cuXmwEDBpgGDRqYQ4cOlbrvpKQkExoaat58803z3nvvmfDwcGO3283evXuv6j5zfmZu3rzZBAQEmDZt2rhqLCgoMK1atTJJSUlm1apVZvv27eaVV14xNpvNvPbaa67pnG688UYzfPhwExwcbN5//33X58no0aNNWFiYeeedd8xXX31lUlNTTYsWLczSpUtLHTtnzhzj7+9vOnbsaBo3bmzuuusuU7duXbN582bz+eefu8ZlZWWZtm3bGn9/f/P+++8bY4x55513jI+Pj5k0aZJZtGiRueOOO4y/v7/x8/Mrc9zgwYNNaGioeeWVV8zSpUvN888/b+x2u5FkXnjhBZOVlWU++OADY7fbzbBhw1zXcfXq1cbHx8f4+fmZF154wXzwwQcmICDA+Pj4lHqsp556yoSFhZlf/vKXZv78+ebOO+80kkzPnj3d3pe33Xabadq0qUlMTDSFhYUmJibGjBgxwsTGxpr69eubJ554wmzYsME89NBDJjQ01IwZM8a1n6ioKLN//37XuJiYGLd/J3fs2GFefvll07hxY/PQQw9dcu85xzVo0MB1n5w8edLcf//9ZtSoUeazzz4z77//vrnmmmuMn5+f6dmzp2vMU089VeL7t3HjxsZms5kPPvjA7f1b0rGMMebll182drvdtG3b1iQlJZmAgAATGhpqJJmJEyeaRo0amd///veuDOB8z3366adm48aNJigoyISFhblNiXZxXpgzZ44JCAgw77zzjvnhhx/M6NGjTb169czBgwcv+ZxA5SPbkm3JtkXItmRbsi3ZlmxLtiXbej6yLdmWbFuEbEu2JduSbcm2ZFtPz7Y0KpRi0KBBpkmTJsbf3980bdrUDBo0yG3dmt69e5vhw4e7jfn4449NfHy88ff3N9ddd51JT0+v5qovzznlycWP4cOHm127dpX4miS3Nb6aN29unnvuOdfPl7tWVp6TMca8/vrrplmzZsbPz8/ExMSYSZMmXfKP9sW/z4kTJ5pWrVqZwMBAU79+fZOYmGjmzJlTqXWXdq1nz55tjClaw6pXr16mQYMGJiAgwLRq1co8+eSTl6xXc+GYklQ08P72t781zZs3N/7+/iY8PNz06dPHFXaNMebMmTPm4YcfNvXr1zfBwcHmjjvuMAcOHCizxgMHDpgRI0aYqKgoExgYaFq3bm1effVV43A4Kq22q71+lVXbxSGwvNfpSt+PV3Lsi5UUeCty7JKON2HCBBMdHW0KCwsv2X7QoEFGkvH19XV9ZqxcudJ13QMCAky9evVMUFDQFd9TDofDPPPMMyYgIMA1pVlkZKTb59H+/ftN//79TUREhPHz8zPNmjUzgwcPvmR6pYv3PWjQINc//Cqeosu5BtvV3GfOz0xfX18jydx5551un5mZmZnmzjvvNBERESY4ONjccMMN5r333jPGGPN///d/5vrrrzeSTKNGjcybb77p2n9Jj7Zt25pt27aVOdYYY55//vlS9zF58mRz/fXXm4CAAOPr6+s2RdSZM2fMDTfc4JpKzs/PzyQlJZnVq1e7jlfSuEOHDpmYmBhXyPX19TUdOnQws2bNco1p06aNadCggdu/N8YUTbtos9mMv7+/adOmjXnzzTfLPFa/fv3czicwMNAMHjzY5Ofnu70v7Xa7iYmJMQcOHDALFy4s9XrExMSU+tntHBcVFeVW9/79+03Xrl1d1+jie+/C4znvk9OnT5tevXoZPz8/12t169Y1Dz/8sDlx4oRrzLZt28r1/i3pWM730MMPP+x6Dzl/L35+fuaaa64xEydONPn5+a4M4HzPRUZGumq8eNq8i/OCMcb89a9/NTExMcbf399069bNfPvttwbVg2xLtiXbFiHbkm3JtmRbsi3Zlmzr+ci2ZFuybRGyLdmWbEu2JduSbT0929qMMUYAAAAAAAAAAAAAAADVwH75TQAAAAAAAAAAAAAAACoHjQoAAAAAAAAAAAAAAKDa0KgAAAAAAAAAAAAAAACqDY0KAAAAAAAAAAAAAACg2tCoAAAAAAAAAAAAAAAAqg2NCgAAAAAAAAAAAAAAoNrQqAAAAAAAAAAAAAAAAKoNjQoAAAAAAAAAAAAAAKDa0KgAAF7u+eefV2RkpGw2mz755JMrGrNkyRLZbDYdP368SmurSWJjYzVt2jSrywAAAEAZyLZXhmwLAABQ85FtrwzZFvBeNCoAqHYjRoyQzWaTzWaTv7+/WrVqpRdffFHnz5+3urTLKk9orAm2bNmiF154QTNnztSBAwfUv3//KjvWTTfdpN/97ndVtn8AAICaiGxbfci2AAAAVYtsW33ItgAg+VpdAIDa6dZbb9Xs2bOVn5+v+fPna8yYMfLz89OECRPKva/CwkLZbDbZ7fReXWzHjh2SpIEDB8pms1lcDQAAgHci21YPsi0AAEDVI9tWD7ItADCjAgCLBAQEqHHjxmrevLkeeughJScn67PPPpMk5efn64knnlDTpk0VEhKihIQELVmyxDX2nXfeUb169fTZZ5+pbdu2CggI0N69e5Wfn6+nnnpK0dHRCggIUKtWrfT222+7xn3//ffq37+/QkNDFRkZqaFDh+rw4cOu12+66SY98sgj+v3vf68GDRqocePGev75512vx8bGSpLuuOMO2Ww21887duzQwIEDFRkZqdDQUHXt2lVffvml2/keOHBAKSkpCgoKUosWLfThhx9eMmXV8ePHdf/99ys8PFx169bVLbfcok2bNpV5Hb/77jvdcsstCgoKUsOGDTV69GidOnVKUtHUYQMGDJAk2e32MgPv/PnzFR8fr6CgIN18883avXu32+tHjhzRvffeq6ZNmyo4OFjt2rXTRx995Hp9xIgR+vrrr/X666+7uq53796twsJC3XfffWrRooWCgoLUunVrvf7662Wek/P3e6FPPvnErf5Nmzbp5ptvVp06dVS3bl117txZa9eudb2+bNkyJSUlKSgoSNHR0XrkkUeUl5fnej07O1sDBgxw/T4++OCDMmsCAAAoC9mWbFsasi0AAPA0ZFuybWnItgAqG40KAGqEoKAgFRQUSJLGjh2rlStXas6cOdq8ebPuvvtu3XrrrcrKynJtf/r0af3xj3/U//7v/+q///2vIiIiNGzYMH300Uf6y1/+oi1btmjmzJkKDQ2VVBQmb7nlFnXs2FFr167VggULdOjQId1zzz1udbz77rsKCQnRqlWr9Kc//UkvvviiFi1aJElas2aNJGn27Nk6cOCA6+dTp07ptttuU0ZGhjZs2KBbb71VAwYM0N69e137HTZsmH766SctWbJE//73v/Xmm28qOzvb7dh33323srOz9fnnn2vdunXq1KmT+vTpo6NHj5Z4zfLy8tSvXz/Vr19fa9as0T//+U99+eWXGjt2rCTpiSee0OzZsyUVBe4DBw6UuJ99+/bpzjvv1IABA7Rx40bdf//9Gj9+vNs2Z8+eVefOnZWenq7vv/9eo0eP1tChQ7V69WpJ0uuvv67ExESNGjXKdazo6Gg5HA41a9ZM//znP/XDDz/o2Wef1dNPP62PP/64xFqu1JAhQ9SsWTOtWbNG69at0/jx4+Xn5yep6H+A3Hrrrbrrrru0efNmzZ07V8uWLXNdF6kooO/bt0+LFy/Wv/71L73xxhuX/D4AAACuFtmWbFseZFsAAFCTkW3JtuVBtgVQLgYAqtnw4cPNwIEDjTHGOBwOs2jRIhMQEGCeeOIJs2fPHuPj42P279/vNqZPnz5mwoQJxhhjZs+ebSSZjRs3ul7ftm2bkWQWLVpU4jFfeukl07dvX7fn9u3bZySZbdu2GWOM6d27t+nZs6fbNl27djVPPfWU62dJ5j//+c9lz/G6664zf/3rX40xxmzZssVIMmvWrHG9npWVZSSZ1157zRhjzNKlS03dunXN2bNn3fbTsmVLM3PmzBKP8eabb5r69eubU6dOuZ5LT083drvdHDx40BhjzH/+8x9zuY/6CRMmmLZt27o999RTTxlJ5tixY6WOS0lJMY8//rjr5969e5tHH320zGMZY8yYMWPMXXfdVerrs2fPNmFhYW7PXXwederUMe+8806J4++77z4zevRot+eWLl1q7Ha7OXPmjOteWb16tet15+/I+fsAAAC4UmRbsi3ZFgAAeAuyLdmWbAugOvlWeScEAJQgLS1NoaGhOnfunBwOhwYPHqznn39eS5YsUWFhoeLj4922z8/PV8OGDV0/+/v764YbbnD9vHHjRvn4+Kh3794lHm/Tpk1avHixq1P3Qjt27HAd78J9SlKTJk0u27F56tQpPf/880pPT9eBAwd0/vx5nTlzxtWZu23bNvn6+qpTp06uMa1atVL9+vXd6jt16pTbOUrSmTNnXOuVXWzLli1q3769QkJCXM/16NFDDodD27ZtU2RkZJl1X7ifhIQEt+cSExPdfi4sLNTkyZP18ccfa//+/SooKFB+fr6Cg4Mvu//p06dr1qxZ2rt3r86cOaOCggJ16NDhimorzbhx43T//ffrH//4h5KTk3X33XerZcuWkoqu5ebNm92mBTPGyOFwaNeuXcrMzJSvr686d+7ser1NmzaXTFsGAABwpci2ZNuKINsCAICahGxLtq0Isi2A8qBRAYAlbr75Zv3973+Xv7+/oqKi5Otb9HF06tQp+fj4aN26dfLx8XEbc2FYDQoKclv7KigoqMzjnTp1SgMGDNAf//jHS15r0qSJ63vnNFRONptNDoejzH0/8cQTWrRokV555RW1atVKQUFB+tWvfuWaEu1KnDp1Sk2aNHFb082pJgSxP//5z3r99dc1bdo0tWvXTiEhIfrd73532XOcM2eOnnjiCb366qtKTExUnTp19Oc//1mrVq0qdYzdbpcxxu25c+fOuf38/PPPa/DgwUpPT9fnn3+u5557TnPmzNEdd9yhU6dO6YEHHtAjjzxyyb5jYmKUmZlZjjMHAAC4PLLtpfWRbYuQbQEAgKch215aH9m2CNkWQGWjUQGAJUJCQtSqVatLnu/YsaMKCwuVnZ2tpKSkK95fu3bt5HA49PXXXys5OfmS1zt16qR///vfio2NdYXrq+Hn56fCwkK355YvX64RI0bojjvukFQUXnfv3u16vXXr1jp//rw2bNjg6gbdvn27jh075lbfwYMH5evrq9jY2Cuq5dprr9U777yjvLw8V3fu8uXLZbfb1bp16ys+p2uvvVafffaZ23PffvvtJec4cOBA/eY3v5EkORwOZWZmqm3btq5t/P39S7w23bt318MPP+x6rrROY6fw8HCdPHnS7bw2btx4yXbx8fGKj4/XY489pnvvvVezZ8/WHXfcoU6dOumHH34o8f6Sirpwz58/r3Xr1qlr166Sirqnjx8/XmZdAAAApSHbkm1LQ7YFAACehmxLti0N2RZAZbNbXQAAXCg+Pl5DhgzRsGHDNG/ePO3atUurV6/WlClTlJ6eXuq42NhYDR8+XL/97W/1ySefaNeuXVqyZIk+/vhjSdKYMWN09OhR3XvvvVqzZo127NihhQsXauTIkZeEtLLExsYqIyNDBw8edAXWuLg4zZs3Txs3btSmTZs0ePBgt27eNm3aKDk5WaNHj9bq1au1YcMGjR492q27ODk5WYmJibr99tv1xRdfaPfu3VqxYoUmTpyotWvXlljLkCFDFBgYqOHDh+v777/X4sWL9T//8z8aOnToFU8fJkkPPvigsrKy9OSTT2rbtm368MMP9c4777htExcXp0WLFmnFihXasmWLHnjgAR06dOiSa7Nq1Srt3r1bhw8flsPhUFxcnNauXauFCxcqMzNTzzzzjNasWVNmPQkJCQoODtbTTz+tHTt2XFLPmTNnNHbsWC1ZskR79uzR8uXLtWbNGl177bWSpKeeekorVqzQ2LFjtXHjRmVlZenTTz/V2LFjJRX9D5Bbb71VDzzwgFatWqV169bp/vvvv2x3NwAAQHmRbcm2ZFsAAOAtyLZkW7ItgMpGowKAGmf27NkaNmyYHn/8cbVu3Vq333671qxZo5iYmDLH/f3vf9evfvUrPfzww2rTpo1GjRqlvLw8SVJUVJSWL1+uwsJC9e3bV+3atdPvfvc71atXT3b7lX8Uvvrqq1q0aJGio6PVsWNHSdLUqVNVv359de/eXQMGDFC/fv3c1jWTpPfee0+RkZHq1auX7rjjDo0aNUp16tRRYGCgpKKpyubPn69evXpp5MiRio+P169//Wvt2bOn1PAaHByshQsX6ujRo+ratat+9atfqU+fPvrb3/52xecjFU2r9e9//1uffPKJ2rdvrxkzZmjy5Mlu20yaNEmdOnVSv379dNNNN6lx48a6/fbb3bZ54okn5OPjo7Zt2yo8PFx79+7VAw88oDvvvFODBg1SQkKCjhw54talW5IGDRro/fff1/z589WuXTt99NFHev75512v+/j46MiRIxo2bJji4+N1zz33qH///nrhhRckFa1X9/XXXyszM1NJSUnq2LGjnn32WUVFRbn2MXv2bEVFRal379668847NXr0aEVERJTrugEAAFwJsi3ZlmwLAAC8BdmWbEu2BVCZbObiBWUAAFXuxx9/VHR0tL788kv16dPH6nIAAACAq0a2BQAAgLcg2wJA9aFRAQCqwVdffaVTp06pXbt2OnDggH7/+99r//79yszMlJ+fn9XlAQAAAFeMbAsAAABvQbYFAOv4Wl0AANQG586d09NPP62dO3eqTp066t69uz744APCLgAAADwO2RYAAADegmwLANZhRgUAAAAAAAAAAAAAAFBt7FYXAAAAAAAAAAAAAAAAag8aFQAAAAAAAAAAAAAAQLWhUQEAAAAAAAAAAAAAAFQbGhUAAAAAAAAAAAAAAEC1oVEBAAAAAAAAAAAAAABUGxoVAAAAAAAAAAAAAABAtaFRAQAAAAAAAAAAAAAAVBsaFQAAAAAAAAAAAAAAQLWhUQEAAAAAAAAAAAAAAFSb/w82zNMw7ojybAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f170ec6",
   "metadata": {
    "papermill": {
     "duration": 0.011006,
     "end_time": "2025-04-20T08:36:52.605223",
     "exception": false,
     "start_time": "2025-04-20T08:36:52.594217",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de40c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6846, Accuracy: 0.7771, F1 Micro: 0.873, F1 Macro: 0.8661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5356, Accuracy: 0.8012, F1 Micro: 0.8896, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4856, Accuracy: 0.8019, F1 Micro: 0.8899, F1 Macro: 0.8853\n",
      "Epoch 4/10, Train Loss: 0.4451, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Epoch 5/10, Train Loss: 0.447, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4104, Accuracy: 0.8038, F1 Micro: 0.8908, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4062, Accuracy: 0.8099, F1 Micro: 0.893, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4023, Accuracy: 0.8189, F1 Micro: 0.8974, F1 Macro: 0.8906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3668, Accuracy: 0.8349, F1 Micro: 0.9047, F1 Macro: 0.8978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3363, Accuracy: 0.8422, F1 Micro: 0.9091, F1 Macro: 0.9034\n",
      "\n",
      "Aspect detection accuracy: 0.8422, F1 Micro: 0.9091, F1 Macro: 0.9034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.80      1.00      0.89       462\n",
      "   air_panas       0.83      1.00      0.91       480\n",
      "         bau       0.86      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.66      0.86      0.75       317\n",
      "       linen       0.73      0.99      0.84       392\n",
      "     service       0.92      0.96      0.94       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.91      1.00      0.95       498\n",
      "\n",
      "   micro avg       0.84      0.99      0.91      4614\n",
      "   macro avg       0.84      0.98      0.90      4614\n",
      "weighted avg       0.85      0.99      0.91      4614\n",
      " samples avg       0.84      0.99      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6158, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4961, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4198, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4426, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3147, Accuracy: 0.7391, F1 Micro: 0.7391, F1 Macro: 0.6783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2361, Accuracy: 0.7636, F1 Micro: 0.7636, F1 Macro: 0.7349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2395, Accuracy: 0.7663, F1 Micro: 0.7663, F1 Macro: 0.7452\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2328, Accuracy: 0.7935, F1 Micro: 0.7935, F1 Macro: 0.781\n",
      "Epoch 9/10, Train Loss: 0.1405, Accuracy: 0.7799, F1 Micro: 0.7799, F1 Macro: 0.7604\n",
      "Epoch 10/10, Train Loss: 0.0903, Accuracy: 0.7745, F1 Micro: 0.7745, F1 Macro: 0.7461\n",
      "\n",
      "Sentiment analysis accuracy: 0.7935, F1 Micro: 0.7935, F1 Macro: 0.781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.84      0.83       226\n",
      "    positive       0.74      0.72      0.73       142\n",
      "\n",
      "    accuracy                           0.79       368\n",
      "   macro avg       0.78      0.78      0.78       368\n",
      "weighted avg       0.79      0.79      0.79       368\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8352, F1 Micro: 0.8352, F1 Macro: 0.4067\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        97\n",
      "     neutral       0.80      1.00      0.89       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.80       571\n",
      "   macro avg       0.27      0.33      0.30       571\n",
      "weighted avg       0.65      0.80      0.72       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.28      0.33      0.30       571\n",
      "weighted avg       0.69      0.83      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.03      0.05        78\n",
      "     neutral       0.86      1.00      0.93       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.51      0.34      0.32       571\n",
      "weighted avg       0.83      0.86      0.80       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.39      0.49       200\n",
      "     neutral       0.66      0.86      0.75       315\n",
      "    positive       0.23      0.18      0.20        56\n",
      "\n",
      "    accuracy                           0.63       571\n",
      "   macro avg       0.52      0.48      0.48       571\n",
      "weighted avg       0.62      0.63      0.60       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.23      0.37       162\n",
      "     neutral       0.72      0.99      0.84       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.74       571\n",
      "   macro avg       0.55      0.41      0.40       571\n",
      "weighted avg       0.75      0.74      0.67       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.69      0.74        85\n",
      "     neutral       0.92      0.96      0.94       418\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.36      0.52        74\n",
      "     neutral       0.91      1.00      0.95       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.61      0.45      0.49       571\n",
      "weighted avg       0.91      0.91      0.89       571\n",
      "\n",
      "Total train time: 80.81140923500061 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 215\n",
      "Sampling duration: 0.0002491474151611328 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5992, Accuracy: 0.8017, F1 Micro: 0.8898, F1 Macro: 0.8853\n",
      "Epoch 2/10, Train Loss: 0.4433, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4459, Accuracy: 0.8111, F1 Micro: 0.8939, F1 Macro: 0.8882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4012, Accuracy: 0.8417, F1 Micro: 0.9086, F1 Macro: 0.9018\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3472, Accuracy: 0.8766, F1 Micro: 0.9275, F1 Macro: 0.9228\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3132, Accuracy: 0.8927, F1 Micro: 0.9359, F1 Macro: 0.9307\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2645, Accuracy: 0.8932, F1 Micro: 0.9361, F1 Macro: 0.9302\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2435, Accuracy: 0.9076, F1 Micro: 0.9447, F1 Macro: 0.9418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.211, Accuracy: 0.9224, F1 Micro: 0.9529, F1 Macro: 0.9498\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1853, Accuracy: 0.9266, F1 Micro: 0.9554, F1 Macro: 0.9527\n",
      "\n",
      "Aspect detection accuracy: 0.9266, F1 Micro: 0.9554, F1 Macro: 0.9527\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.93      0.99      0.96       480\n",
      "         bau       0.96      0.97      0.96       496\n",
      "     general       0.87      0.98      0.92       500\n",
      "  kebersihan       0.88      0.91      0.90       317\n",
      "       linen       0.86      0.97      0.91       392\n",
      "     service       0.92      0.99      0.95       423\n",
      "sunrise_meal       0.93      1.00      0.96       530\n",
      "          tv       0.97      1.00      0.98       516\n",
      "        wifi       0.99      0.99      0.99       498\n",
      "\n",
      "   micro avg       0.93      0.98      0.96      4614\n",
      "   macro avg       0.93      0.98      0.95      4614\n",
      "weighted avg       0.93      0.98      0.96      4614\n",
      " samples avg       0.93      0.98      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4655, Accuracy: 0.7339, F1 Micro: 0.7339, F1 Macro: 0.4233\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3756, Accuracy: 0.7847, F1 Micro: 0.7847, F1 Macro: 0.6469\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2728, Accuracy: 0.8241, F1 Micro: 0.8241, F1 Macro: 0.7657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2503, Accuracy: 0.832, F1 Micro: 0.832, F1 Macro: 0.7409\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1838, Accuracy: 0.8467, F1 Micro: 0.8467, F1 Macro: 0.7836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1643, Accuracy: 0.8512, F1 Micro: 0.8512, F1 Macro: 0.7987\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1282, Accuracy: 0.8512, F1 Micro: 0.8512, F1 Macro: 0.7993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1182, Accuracy: 0.8613, F1 Micro: 0.8613, F1 Macro: 0.7896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0749, Accuracy: 0.8692, F1 Micro: 0.8692, F1 Macro: 0.8114\n",
      "Epoch 10/10, Train Loss: 0.0813, Accuracy: 0.8613, F1 Micro: 0.8613, F1 Macro: 0.7952\n",
      "\n",
      "Sentiment analysis accuracy: 0.8692, F1 Micro: 0.8692, F1 Macro: 0.8114\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.97      0.92       651\n",
      "    positive       0.88      0.59      0.71       236\n",
      "\n",
      "    accuracy                           0.87       887\n",
      "   macro avg       0.87      0.78      0.81       887\n",
      "weighted avg       0.87      0.87      0.86       887\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.6369\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.88      0.47      0.61        15\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.91      0.79      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.65      0.76        86\n",
      "     neutral       0.93      0.99      0.96       475\n",
      "    positive       1.00      0.20      0.33        10\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.94      0.61      0.68       571\n",
      "weighted avg       0.93      0.93      0.92       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.76      0.78        78\n",
      "     neutral       0.96      0.97      0.96       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      0.98      0.92       496\n",
      "    positive       0.25      0.04      0.07        68\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.37      0.34      0.33       571\n",
      "weighted avg       0.79      0.85      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.79      0.81       200\n",
      "     neutral       0.88      0.91      0.90       315\n",
      "    positive       0.82      0.82      0.82        56\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.85      0.84      0.84       571\n",
      "weighted avg       0.86      0.86      0.86       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.69      0.76       162\n",
      "     neutral       0.85      0.97      0.91       387\n",
      "    positive       1.00      0.09      0.17        22\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.90      0.58      0.61       571\n",
      "weighted avg       0.86      0.85      0.84       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.62      0.73        85\n",
      "     neutral       0.92      0.99      0.95       418\n",
      "    positive       0.87      0.78      0.82        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.80      0.84       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.07      0.12        29\n",
      "     neutral       0.93      1.00      0.96       525\n",
      "    positive       0.50      0.12      0.19        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.64      0.39      0.42       571\n",
      "weighted avg       0.90      0.92      0.90       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.72      0.80        54\n",
      "     neutral       0.97      1.00      0.98       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.62      0.57      0.59       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.92      0.91        74\n",
      "     neutral       0.99      0.99      0.99       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.63      0.64      0.63       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Total train time: 125.01561737060547 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 193\n",
      "Sampling duration: 0.0001919269561767578 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5538, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4519, Accuracy: 0.8045, F1 Micro: 0.8912, F1 Macro: 0.8867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.407, Accuracy: 0.8438, F1 Micro: 0.9101, F1 Macro: 0.904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3452, Accuracy: 0.8917, F1 Micro: 0.9356, F1 Macro: 0.9308\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2903, Accuracy: 0.9059, F1 Micro: 0.9437, F1 Macro: 0.9405\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2346, Accuracy: 0.9285, F1 Micro: 0.9564, F1 Macro: 0.9535\n",
      "Epoch 7/10, Train Loss: 0.1955, Accuracy: 0.9273, F1 Micro: 0.956, F1 Macro: 0.9538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1744, Accuracy: 0.9363, F1 Micro: 0.9612, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1545, Accuracy: 0.9415, F1 Micro: 0.9642, F1 Macro: 0.9622\n",
      "Epoch 10/10, Train Loss: 0.1385, Accuracy: 0.9408, F1 Micro: 0.9638, F1 Macro: 0.9616\n",
      "\n",
      "Aspect detection accuracy: 0.9415, F1 Micro: 0.9642, F1 Macro: 0.9622\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.95      0.97      0.96       496\n",
      "     general       0.88      0.99      0.93       500\n",
      "  kebersihan       0.89      0.94      0.92       317\n",
      "       linen       0.88      0.97      0.92       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.95      1.00      0.97       530\n",
      "          tv       0.98      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      4614\n",
      "   macro avg       0.94      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.96      4614\n",
      " samples avg       0.94      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4562, Accuracy: 0.7466, F1 Micro: 0.7466, F1 Macro: 0.4274\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3076, Accuracy: 0.8046, F1 Micro: 0.8046, F1 Macro: 0.7568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2484, Accuracy: 0.831, F1 Micro: 0.831, F1 Macro: 0.7119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1995, Accuracy: 0.8574, F1 Micro: 0.8574, F1 Macro: 0.8059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1416, Accuracy: 0.8817, F1 Micro: 0.8817, F1 Macro: 0.8293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1024, Accuracy: 0.8838, F1 Micro: 0.8838, F1 Macro: 0.8276\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0841, Accuracy: 0.8881, F1 Micro: 0.8881, F1 Macro: 0.8338\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0846, Accuracy: 0.8923, F1 Micro: 0.8923, F1 Macro: 0.8485\n",
      "Epoch 9/10, Train Loss: 0.084, Accuracy: 0.8617, F1 Micro: 0.8617, F1 Macro: 0.8218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0502, Accuracy: 0.8944, F1 Micro: 0.8944, F1 Macro: 0.8475\n",
      "\n",
      "Sentiment analysis accuracy: 0.8944, F1 Micro: 0.8944, F1 Macro: 0.8475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       707\n",
      "    positive       0.88      0.67      0.76       240\n",
      "\n",
      "    accuracy                           0.89       947\n",
      "   macro avg       0.89      0.82      0.85       947\n",
      "weighted avg       0.89      0.89      0.89       947\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.7131\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.93      0.92        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      0.67      0.74        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.91      0.86      0.88       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.75      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.73      0.75        78\n",
      "     neutral       0.95      0.97      0.96       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.58      0.57      0.57       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.88      0.99      0.93       496\n",
      "    positive       0.55      0.09      0.15        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.48      0.36      0.36       571\n",
      "weighted avg       0.83      0.87      0.83       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.85       200\n",
      "     neutral       0.91      0.92      0.92       315\n",
      "    positive       0.80      0.86      0.83        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.86      0.87      0.86       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.73      0.81       162\n",
      "     neutral       0.88      0.98      0.92       387\n",
      "    positive       0.75      0.27      0.40        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.84      0.66      0.71       571\n",
      "weighted avg       0.88      0.88      0.87       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.79      0.83        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.87      0.90      0.88        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.89      0.89       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.28      0.39        29\n",
      "     neutral       0.96      1.00      0.98       525\n",
      "    positive       0.58      0.41      0.48        17\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.74      0.56      0.62       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.89      0.91        54\n",
      "     neutral       0.98      1.00      0.99       511\n",
      "    positive       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.74      0.80       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.92      0.93        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.64      0.64      0.64       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 153.71899557113647 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 174\n",
      "Sampling duration: 0.0001590251922607422 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5299, Accuracy: 0.8014, F1 Micro: 0.8897, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4351, Accuracy: 0.8238, F1 Micro: 0.8989, F1 Macro: 0.8906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3618, Accuracy: 0.8854, F1 Micro: 0.932, F1 Macro: 0.9255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2974, Accuracy: 0.9069, F1 Micro: 0.9443, F1 Macro: 0.9413\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2331, Accuracy: 0.9309, F1 Micro: 0.9579, F1 Macro: 0.9551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2046, Accuracy: 0.9318, F1 Micro: 0.9587, F1 Macro: 0.9569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1755, Accuracy: 0.9438, F1 Micro: 0.9654, F1 Macro: 0.9632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1519, Accuracy: 0.9438, F1 Micro: 0.9655, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1302, Accuracy: 0.9469, F1 Micro: 0.9674, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.12, Accuracy: 0.9491, F1 Micro: 0.9688, F1 Macro: 0.9666\n",
      "\n",
      "Aspect detection accuracy: 0.9491, F1 Micro: 0.9688, F1 Macro: 0.9666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.96      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.91      0.98      0.94       500\n",
      "  kebersihan       0.92      0.92      0.92       317\n",
      "       linen       0.91      0.98      0.94       392\n",
      "     service       0.95      0.97      0.96       423\n",
      "sunrise_meal       0.96      1.00      0.98       530\n",
      "          tv       0.98      1.00      0.99       516\n",
      "        wifi       0.98      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      4614\n",
      "   macro avg       0.95      0.98      0.97      4614\n",
      "weighted avg       0.95      0.99      0.97      4614\n",
      " samples avg       0.95      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.429, Accuracy: 0.7894, F1 Micro: 0.7894, F1 Macro: 0.7491\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2864, Accuracy: 0.8525, F1 Micro: 0.8525, F1 Macro: 0.8032\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1995, Accuracy: 0.8555, F1 Micro: 0.8555, F1 Macro: 0.7796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1688, Accuracy: 0.8871, F1 Micro: 0.8871, F1 Macro: 0.8441\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1675, Accuracy: 0.8901, F1 Micro: 0.8901, F1 Macro: 0.8472\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1095, Accuracy: 0.9034, F1 Micro: 0.9034, F1 Macro: 0.8674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.081, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8695\n",
      "Epoch 8/10, Train Loss: 0.0491, Accuracy: 0.9044, F1 Micro: 0.9044, F1 Macro: 0.869\n",
      "Epoch 9/10, Train Loss: 0.0488, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8698\n",
      "Epoch 10/10, Train Loss: 0.0434, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8741\n",
      "\n",
      "Sentiment analysis accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       719\n",
      "    positive       0.94      0.70      0.80       264\n",
      "\n",
      "    accuracy                           0.91       983\n",
      "   macro avg       0.92      0.84      0.87       983\n",
      "weighted avg       0.91      0.91      0.90       983\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9413, F1 Micro: 0.9413, F1 Macro: 0.7782\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.80      0.86        86\n",
      "     neutral       0.96      0.99      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.77      0.81       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.72      0.79        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       0.25      0.50      0.33         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.69      0.73      0.70       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.91      0.98      0.94       496\n",
      "    positive       0.79      0.38      0.51        68\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.57      0.46      0.49       571\n",
      "weighted avg       0.88      0.90      0.88       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       200\n",
      "     neutral       0.92      0.92      0.92       315\n",
      "    positive       0.82      0.89      0.85        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.88      0.89      0.88       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.78      0.84       162\n",
      "     neutral       0.91      0.98      0.94       387\n",
      "    positive       0.67      0.45      0.54        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.83      0.74      0.77       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.69      0.78        85\n",
      "     neutral       0.95      0.98      0.96       418\n",
      "    positive       0.84      0.90      0.87        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.86      0.87       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.28      0.41        29\n",
      "     neutral       0.96      1.00      0.98       525\n",
      "    positive       0.67      0.59      0.62        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.81      0.62      0.67       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.87      0.92        54\n",
      "     neutral       0.98      1.00      0.99       511\n",
      "    positive       0.80      0.67      0.73         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.85      0.88       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.86      0.92        74\n",
      "     neutral       0.98      1.00      0.99       494\n",
      "    positive       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.82      0.73      0.77       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 179.4491069316864 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 156\n",
      "Sampling duration: 0.00019073486328125 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5176, Accuracy: 0.8083, F1 Micro: 0.8903, F1 Macro: 0.8773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4098, Accuracy: 0.8628, F1 Micro: 0.9198, F1 Macro: 0.9133\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3249, Accuracy: 0.904, F1 Micro: 0.9426, F1 Macro: 0.9391\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2436, Accuracy: 0.9224, F1 Micro: 0.9532, F1 Macro: 0.9507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2036, Accuracy: 0.938, F1 Micro: 0.962, F1 Macro: 0.9598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1705, Accuracy: 0.9434, F1 Micro: 0.9653, F1 Macro: 0.9632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1483, Accuracy: 0.9439, F1 Micro: 0.9656, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1283, Accuracy: 0.9462, F1 Micro: 0.967, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1137, Accuracy: 0.9517, F1 Micro: 0.9703, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1, Accuracy: 0.9545, F1 Micro: 0.9719, F1 Macro: 0.9695\n",
      "\n",
      "Aspect detection accuracy: 0.9545, F1 Micro: 0.9719, F1 Macro: 0.9695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.95      0.99      0.97       496\n",
      "     general       0.93      0.98      0.96       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.94      0.98      0.96       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4354, Accuracy: 0.8279, F1 Micro: 0.8279, F1 Macro: 0.7447\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2424, Accuracy: 0.881, F1 Micro: 0.881, F1 Macro: 0.8438\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2002, Accuracy: 0.8868, F1 Micro: 0.8868, F1 Macro: 0.8556\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1543, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8778\n",
      "Epoch 5/10, Train Loss: 0.1104, Accuracy: 0.8801, F1 Micro: 0.8801, F1 Macro: 0.8337\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0663, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.88\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0444, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8824\n",
      "Epoch 8/10, Train Loss: 0.0595, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0301, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8844\n",
      "Epoch 10/10, Train Loss: 0.0326, Accuracy: 0.8965, F1 Micro: 0.8965, F1 Macro: 0.8641\n",
      "\n",
      "Sentiment analysis accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       737\n",
      "    positive       0.93      0.75      0.83       297\n",
      "\n",
      "    accuracy                           0.91      1034\n",
      "   macro avg       0.92      0.86      0.88      1034\n",
      "weighted avg       0.91      0.91      0.91      1034\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9461, F1 Micro: 0.9461, F1 Macro: 0.7936\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.85      0.73      0.79        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.88      0.90       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.88        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.75      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.69      0.78        78\n",
      "     neutral       0.95      0.99      0.97       491\n",
      "    positive       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.78      0.73      0.75       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.82      0.59      0.68        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.58      0.52      0.55       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.83      0.93      0.87        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.88      0.91      0.89       571\n",
      "weighted avg       0.91      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       1.00      0.14      0.24        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.92      0.64      0.67       571\n",
      "weighted avg       0.90      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.72      0.79        85\n",
      "     neutral       0.94      0.98      0.96       418\n",
      "    positive       0.91      0.90      0.90        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.86      0.88       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.31      0.45        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.64      0.82      0.72        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.71      0.72       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.88      0.88      0.88       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 202.09642028808594 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 141\n",
      "Sampling duration: 0.00015473365783691406 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.504, Accuracy: 0.8089, F1 Micro: 0.8914, F1 Macro: 0.8817\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4101, Accuracy: 0.876, F1 Micro: 0.9275, F1 Macro: 0.9226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.301, Accuracy: 0.9076, F1 Micro: 0.9449, F1 Macro: 0.9418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.225, Accuracy: 0.9372, F1 Micro: 0.9617, F1 Macro: 0.9597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1894, Accuracy: 0.9394, F1 Micro: 0.963, F1 Macro: 0.9608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1645, Accuracy: 0.9491, F1 Micro: 0.9688, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1316, Accuracy: 0.9526, F1 Micro: 0.9708, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1166, Accuracy: 0.9524, F1 Micro: 0.9708, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.102, Accuracy: 0.9547, F1 Micro: 0.972, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0901, Accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.9711\n",
      "\n",
      "Aspect detection accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.9711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.97      0.96       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.88      0.98      0.93       392\n",
      "     service       0.96      0.97      0.96       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.396, Accuracy: 0.8261, F1 Micro: 0.8261, F1 Macro: 0.7939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.231, Accuracy: 0.8743, F1 Micro: 0.8743, F1 Macro: 0.8368\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1845, Accuracy: 0.8828, F1 Micro: 0.8828, F1 Macro: 0.8534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.133, Accuracy: 0.8828, F1 Micro: 0.8828, F1 Macro: 0.8458\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0903, Accuracy: 0.8922, F1 Micro: 0.8922, F1 Macro: 0.86\n",
      "Epoch 6/10, Train Loss: 0.0826, Accuracy: 0.8885, F1 Micro: 0.8885, F1 Macro: 0.8515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0821, Accuracy: 0.8979, F1 Micro: 0.8979, F1 Macro: 0.8695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0357, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8722\n",
      "Epoch 9/10, Train Loss: 0.041, Accuracy: 0.8998, F1 Micro: 0.8998, F1 Macro: 0.8725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0412, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8824\n",
      "\n",
      "Sentiment analysis accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       746\n",
      "    positive       0.93      0.74      0.83       312\n",
      "\n",
      "    accuracy                           0.91      1058\n",
      "   macro avg       0.92      0.86      0.88      1058\n",
      "weighted avg       0.91      0.91      0.91      1058\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.8532\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.81      0.87      0.84        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.85      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.76      0.79        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.97      0.96       496\n",
      "    positive       0.81      0.75      0.78        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.57      0.58       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.90      0.88       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.82      0.89      0.85        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.90      0.89       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.73      0.82       162\n",
      "     neutral       0.88      0.98      0.93       387\n",
      "    positive       0.64      0.32      0.42        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.81      0.68      0.72       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        85\n",
      "     neutral       0.96      0.97      0.97       418\n",
      "    positive       0.95      0.88      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.89      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.55      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.77      0.81       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 224.7968716621399 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 127\n",
      "Sampling duration: 0.0001811981201171875 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5003, Accuracy: 0.8023, F1 Micro: 0.8901, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3893, Accuracy: 0.887, F1 Micro: 0.9334, F1 Macro: 0.929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2837, Accuracy: 0.9207, F1 Micro: 0.9518, F1 Macro: 0.948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2134, Accuracy: 0.9391, F1 Micro: 0.9628, F1 Macro: 0.9607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.172, Accuracy: 0.9465, F1 Micro: 0.9672, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1512, Accuracy: 0.9502, F1 Micro: 0.9694, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1239, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1048, Accuracy: 0.9576, F1 Micro: 0.9739, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0954, Accuracy: 0.9599, F1 Micro: 0.9751, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.082, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9737\n",
      "\n",
      "Aspect detection accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.95      0.94       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4088, Accuracy: 0.8324, F1 Micro: 0.8324, F1 Macro: 0.76\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2356, Accuracy: 0.8706, F1 Micro: 0.8706, F1 Macro: 0.8319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.179, Accuracy: 0.8799, F1 Micro: 0.8799, F1 Macro: 0.8395\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1353, Accuracy: 0.8966, F1 Micro: 0.8966, F1 Macro: 0.8655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0972, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0737, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8717\n",
      "Epoch 7/10, Train Loss: 0.0662, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.87\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0502, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8731\n",
      "Epoch 9/10, Train Loss: 0.0379, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8709\n",
      "Epoch 10/10, Train Loss: 0.0362, Accuracy: 0.8957, F1 Micro: 0.8957, F1 Macro: 0.8618\n",
      "\n",
      "Sentiment analysis accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       763\n",
      "    positive       0.90      0.74      0.81       311\n",
      "\n",
      "    accuracy                           0.90      1074\n",
      "   macro avg       0.90      0.85      0.87      1074\n",
      "weighted avg       0.90      0.90      0.90      1074\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.8304\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.92      0.80      0.86        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.91      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.88        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.75      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.95      0.94       315\n",
      "    positive       0.87      0.84      0.85        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.89      0.89       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.75      0.14      0.23        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.84      0.65      0.67       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.80      0.83        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.93      0.91      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.90      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.48      0.60        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.82      0.74        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.77      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       0.99      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.87      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 238.50327730178833 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 114\n",
      "Sampling duration: 0.00017523765563964844 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5003, Accuracy: 0.8179, F1 Micro: 0.897, F1 Macro: 0.8908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3758, Accuracy: 0.8981, F1 Micro: 0.9391, F1 Macro: 0.9345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2604, Accuracy: 0.9266, F1 Micro: 0.9552, F1 Macro: 0.9515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1972, Accuracy: 0.9417, F1 Micro: 0.9644, F1 Macro: 0.9622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1725, Accuracy: 0.9493, F1 Micro: 0.9688, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1424, Accuracy: 0.9526, F1 Micro: 0.9709, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1196, Accuracy: 0.9531, F1 Micro: 0.9712, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1056, Accuracy: 0.9563, F1 Micro: 0.9731, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0845, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0758, Accuracy: 0.9615, F1 Micro: 0.9762, F1 Macro: 0.9741\n",
      "\n",
      "Aspect detection accuracy: 0.9615, F1 Micro: 0.9762, F1 Macro: 0.9741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.90      0.97      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3764, Accuracy: 0.8504, F1 Micro: 0.8504, F1 Macro: 0.8\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.24, Accuracy: 0.8769, F1 Micro: 0.8769, F1 Macro: 0.8387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1672, Accuracy: 0.8883, F1 Micro: 0.8883, F1 Macro: 0.856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1096, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0998, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0657, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0389, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8867\n",
      "Epoch 8/10, Train Loss: 0.0223, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8817\n",
      "Epoch 9/10, Train Loss: 0.0223, Accuracy: 0.892, F1 Micro: 0.892, F1 Macro: 0.8657\n",
      "Epoch 10/10, Train Loss: 0.0302, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8836\n",
      "\n",
      "Sentiment analysis accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       759\n",
      "    positive       0.93      0.75      0.83       297\n",
      "\n",
      "    accuracy                           0.91      1056\n",
      "   macro avg       0.92      0.87      0.89      1056\n",
      "weighted avg       0.91      0.91      0.91      1056\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9539, F1 Micro: 0.9539, F1 Macro: 0.8434\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.76      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.84      0.63      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.93      0.59      0.65       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.89       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.84      0.93      0.88        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.90       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.78      0.83       162\n",
      "     neutral       0.90      0.97      0.94       387\n",
      "    positive       0.67      0.45      0.54        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.82      0.73      0.77       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.80      0.83        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.48      0.58        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.73      0.76       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.93      0.96       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.88      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 253.55213022232056 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 103\n",
      "Sampling duration: 0.00016689300537109375 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4906, Accuracy: 0.8116, F1 Micro: 0.8943, F1 Macro: 0.889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3607, Accuracy: 0.8993, F1 Micro: 0.9401, F1 Macro: 0.9366\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2438, Accuracy: 0.9312, F1 Micro: 0.9583, F1 Macro: 0.9561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1956, Accuracy: 0.9417, F1 Micro: 0.9644, F1 Macro: 0.9623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.16, Accuracy: 0.9476, F1 Micro: 0.9679, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1358, Accuracy: 0.9507, F1 Micro: 0.9697, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1135, Accuracy: 0.955, F1 Micro: 0.9723, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0995, Accuracy: 0.9597, F1 Micro: 0.9752, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0826, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9743\n",
      "Epoch 10/10, Train Loss: 0.071, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9731\n",
      "\n",
      "Aspect detection accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3805, Accuracy: 0.8431, F1 Micro: 0.8431, F1 Macro: 0.7718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2431, Accuracy: 0.8849, F1 Micro: 0.8849, F1 Macro: 0.854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1416, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1203, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0686, Accuracy: 0.9034, F1 Micro: 0.9034, F1 Macro: 0.8739\n",
      "Epoch 6/10, Train Loss: 0.0521, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.868\n",
      "Epoch 7/10, Train Loss: 0.0407, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.871\n",
      "Epoch 8/10, Train Loss: 0.0283, Accuracy: 0.8979, F1 Micro: 0.8979, F1 Macro: 0.8699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0462, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8785\n",
      "Epoch 10/10, Train Loss: 0.0254, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.8746\n",
      "\n",
      "Sentiment analysis accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       767\n",
      "    positive       0.93      0.73      0.82       310\n",
      "\n",
      "    accuracy                           0.91      1077\n",
      "   macro avg       0.92      0.86      0.88      1077\n",
      "weighted avg       0.91      0.91      0.90      1077\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.8431\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.79      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.78      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.87      0.71      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.72      0.61      0.65       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.85       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.64      0.41      0.50        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.81      0.73      0.77       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.89      0.93      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.91      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.89      0.92        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       0.56      0.83      0.67         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.84      0.91      0.86       571\n",
      "weighted avg       0.99      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 261.92952942848206 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 62\n",
      "Sampling duration: 0.025026321411132812 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4923, Accuracy: 0.8201, F1 Micro: 0.8979, F1 Macro: 0.8915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3516, Accuracy: 0.9042, F1 Micro: 0.9426, F1 Macro: 0.9384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.242, Accuracy: 0.9311, F1 Micro: 0.9582, F1 Macro: 0.9558\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1876, Accuracy: 0.9455, F1 Micro: 0.9667, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1542, Accuracy: 0.9517, F1 Micro: 0.9703, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.133, Accuracy: 0.9549, F1 Micro: 0.9722, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1101, Accuracy: 0.9554, F1 Micro: 0.9725, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0927, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0814, Accuracy: 0.9609, F1 Micro: 0.9759, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0723, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9748\n",
      "\n",
      "Aspect detection accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.93      0.99      0.96       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.99      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3902, Accuracy: 0.8573, F1 Micro: 0.8573, F1 Macro: 0.8126\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2323, Accuracy: 0.8849, F1 Micro: 0.8849, F1 Macro: 0.8397\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1605, Accuracy: 0.8963, F1 Micro: 0.8963, F1 Macro: 0.858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1015, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.889\n",
      "Epoch 5/10, Train Loss: 0.0781, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8853\n",
      "Epoch 6/10, Train Loss: 0.0625, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8867\n",
      "Epoch 7/10, Train Loss: 0.0309, Accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.8806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0413, Accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.8926\n",
      "Epoch 9/10, Train Loss: 0.0443, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0408, Accuracy: 0.922, F1 Micro: 0.922, F1 Macro: 0.8963\n",
      "\n",
      "Sentiment analysis accuracy: 0.922, F1 Micro: 0.922, F1 Macro: 0.8963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       762\n",
      "    positive       0.93      0.77      0.84       289\n",
      "\n",
      "    accuracy                           0.92      1051\n",
      "   macro avg       0.93      0.88      0.90      1051\n",
      "weighted avg       0.92      0.92      0.92      1051\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9562, F1 Micro: 0.9562, F1 Macro: 0.8406\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.85      0.89        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.78      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.79      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.76      0.83       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.87      0.60      0.71        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.53      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.88      0.89      0.88        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.75      0.55      0.63        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.86      0.79      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.82      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.48      0.60        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.79      0.65      0.71        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.71      0.76       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      1.00      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.89      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 282.8022427558899 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 86\n",
      "Sampling duration: 0.0001354217529296875 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4842, Accuracy: 0.8188, F1 Micro: 0.8964, F1 Macro: 0.887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3385, Accuracy: 0.9123, F1 Micro: 0.9474, F1 Macro: 0.9442\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2347, Accuracy: 0.9401, F1 Micro: 0.9634, F1 Macro: 0.961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1855, Accuracy: 0.9418, F1 Micro: 0.9645, F1 Macro: 0.9622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1483, Accuracy: 0.9543, F1 Micro: 0.9719, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1249, Accuracy: 0.9568, F1 Micro: 0.9734, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1044, Accuracy: 0.9582, F1 Micro: 0.9742, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0905, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0771, Accuracy: 0.9615, F1 Micro: 0.9762, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0682, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.91      0.98      0.95       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4121, Accuracy: 0.8173, F1 Micro: 0.8173, F1 Macro: 0.7271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2596, Accuracy: 0.8687, F1 Micro: 0.8687, F1 Macro: 0.8201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1675, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8762\n",
      "Epoch 4/10, Train Loss: 0.112, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0782, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0586, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0542, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8898\n",
      "Epoch 8/10, Train Loss: 0.0405, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.887\n",
      "Epoch 9/10, Train Loss: 0.036, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8882\n",
      "Epoch 10/10, Train Loss: 0.0231, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8838\n",
      "\n",
      "Sentiment analysis accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       769\n",
      "    positive       0.93      0.76      0.84       320\n",
      "\n",
      "    accuracy                           0.91      1089\n",
      "   macro avg       0.92      0.87      0.89      1089\n",
      "weighted avg       0.91      0.91      0.91      1089\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.863\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.85      0.89        86\n",
      "     neutral       0.97      1.00      0.98       475\n",
      "    positive       0.86      0.60      0.71        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.81      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.29      0.36         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.83      0.79      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.76      0.69      0.72       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.94      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.80      0.84       162\n",
      "     neutral       0.91      0.98      0.95       387\n",
      "    positive       0.70      0.32      0.44        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.83      0.70      0.74       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.82      0.81        85\n",
      "     neutral       0.97      0.96      0.97       418\n",
      "    positive       0.89      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.55      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.72      0.76      0.74        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.77      0.79       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 290.2301971912384 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 77\n",
      "Sampling duration: 0.00011992454528808594 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4822, Accuracy: 0.8208, F1 Micro: 0.8989, F1 Macro: 0.8934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3345, Accuracy: 0.9116, F1 Micro: 0.9469, F1 Macro: 0.9438\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2316, Accuracy: 0.9391, F1 Micro: 0.9628, F1 Macro: 0.9604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1833, Accuracy: 0.9498, F1 Micro: 0.9692, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1515, Accuracy: 0.9547, F1 Micro: 0.972, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.123, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1051, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9733\n",
      "Epoch 8/10, Train Loss: 0.0881, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.074, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0639, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.97      0.97      0.97       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3532, Accuracy: 0.8613, F1 Micro: 0.8613, F1 Macro: 0.8223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2139, Accuracy: 0.8649, F1 Micro: 0.8649, F1 Macro: 0.8155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1566, Accuracy: 0.8946, F1 Micro: 0.8946, F1 Macro: 0.8662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1134, Accuracy: 0.9009, F1 Micro: 0.9009, F1 Macro: 0.8722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0839, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.8818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0657, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8868\n",
      "Epoch 7/10, Train Loss: 0.0442, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.8655\n",
      "Epoch 8/10, Train Loss: 0.0379, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8807\n",
      "Epoch 9/10, Train Loss: 0.0281, Accuracy: 0.8901, F1 Micro: 0.8901, F1 Macro: 0.854\n",
      "Epoch 10/10, Train Loss: 0.0318, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8823\n",
      "\n",
      "Sentiment analysis accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       779\n",
      "    positive       0.93      0.76      0.83       331\n",
      "\n",
      "    accuracy                           0.91      1110\n",
      "   macro avg       0.92      0.87      0.89      1110\n",
      "weighted avg       0.91      0.91      0.91      1110\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9578, F1 Micro: 0.9578, F1 Macro: 0.8594\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.81      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.29      0.40         7\n",
      "     neutral       0.97      0.97      0.97       496\n",
      "    positive       0.81      0.82      0.82        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.81      0.69      0.73       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.88      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.73      0.36      0.48        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.73      0.77       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.89      0.96      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      1.00      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.78      0.83       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 308.38996958732605 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 70\n",
      "Sampling duration: 0.00011944770812988281 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4788, Accuracy: 0.8382, F1 Micro: 0.9063, F1 Macro: 0.897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3133, Accuracy: 0.9208, F1 Micro: 0.9522, F1 Macro: 0.9489\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.223, Accuracy: 0.942, F1 Micro: 0.9644, F1 Macro: 0.962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.178, Accuracy: 0.9545, F1 Micro: 0.9719, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1455, Accuracy: 0.9545, F1 Micro: 0.972, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1195, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1008, Accuracy: 0.9601, F1 Micro: 0.9752, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.086, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9751\n",
      "Epoch 9/10, Train Loss: 0.0742, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0627, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9748\n",
      "\n",
      "Aspect detection accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.95      0.92      0.93       317\n",
      "       linen       0.95      0.97      0.96       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3636, Accuracy: 0.8545, F1 Micro: 0.8545, F1 Macro: 0.8071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2036, Accuracy: 0.8747, F1 Micro: 0.8747, F1 Macro: 0.8322\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1551, Accuracy: 0.8975, F1 Micro: 0.8975, F1 Macro: 0.8692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1041, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8773\n",
      "Epoch 5/10, Train Loss: 0.0657, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.8722\n",
      "Epoch 6/10, Train Loss: 0.057, Accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.8741\n",
      "Epoch 7/10, Train Loss: 0.0363, Accuracy: 0.8994, F1 Micro: 0.8994, F1 Macro: 0.868\n",
      "Epoch 8/10, Train Loss: 0.0396, Accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.8744\n",
      "Epoch 9/10, Train Loss: 0.0376, Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.8694\n",
      "Epoch 10/10, Train Loss: 0.0253, Accuracy: 0.8966, F1 Micro: 0.8966, F1 Macro: 0.867\n",
      "\n",
      "Sentiment analysis accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       780\n",
      "    positive       0.93      0.73      0.82       313\n",
      "\n",
      "    accuracy                           0.91      1093\n",
      "   macro avg       0.92      0.85      0.88      1093\n",
      "weighted avg       0.91      0.91      0.90      1093\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9546, F1 Micro: 0.9546, F1 Macro: 0.8511\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.83      0.89        86\n",
      "     neutral       0.97      1.00      0.98       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.84      0.85       571\n",
      "weighted avg       0.97      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.88      0.62      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.54      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.91      0.89       200\n",
      "     neutral       0.95      0.92      0.93       315\n",
      "    positive       0.88      0.88      0.88        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.90      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.87       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.50      0.55      0.52        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.78      0.78      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.89      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.91      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.48      0.61        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.68      0.88      0.77        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.79      0.79       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       0.71      0.83      0.77         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 306.1392459869385 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 52\n",
      "Sampling duration: 0.01664137840270996 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.482, Accuracy: 0.8325, F1 Micro: 0.9037, F1 Macro: 0.8956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3122, Accuracy: 0.9226, F1 Micro: 0.9532, F1 Macro: 0.9503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2209, Accuracy: 0.9403, F1 Micro: 0.9635, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1732, Accuracy: 0.95, F1 Micro: 0.9692, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1385, Accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1162, Accuracy: 0.9611, F1 Micro: 0.976, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1026, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "Epoch 8/10, Train Loss: 0.084, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.974\n",
      "Epoch 9/10, Train Loss: 0.0703, Accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.9724\n",
      "Epoch 10/10, Train Loss: 0.0615, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.99      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3657, Accuracy: 0.8486, F1 Micro: 0.8486, F1 Macro: 0.7891\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2341, Accuracy: 0.878, F1 Micro: 0.878, F1 Macro: 0.8393\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1464, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1023, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0883, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8904\n",
      "Epoch 6/10, Train Loss: 0.0568, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8782\n",
      "Epoch 7/10, Train Loss: 0.052, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8857\n",
      "Epoch 8/10, Train Loss: 0.0393, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8855\n",
      "Epoch 9/10, Train Loss: 0.0303, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8875\n",
      "Epoch 10/10, Train Loss: 0.0215, Accuracy: 0.9037, F1 Micro: 0.9037, F1 Macro: 0.8722\n",
      "\n",
      "Sentiment analysis accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8904\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       776\n",
      "    positive       0.92      0.77      0.84       314\n",
      "\n",
      "    accuracy                           0.91      1090\n",
      "   macro avg       0.92      0.87      0.89      1090\n",
      "weighted avg       0.92      0.91      0.91      1090\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.8589\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.79      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.79      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.25      0.29      0.27         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.68      0.66      0.67       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.91      0.89       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.89      0.86      0.87        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.90      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.88      0.32      0.47        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.72      0.76       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.59      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.65      0.69        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.74      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      1.00      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.89      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 307.1689450740814 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 58\n",
      "Sampling duration: 0.00011181831359863281 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4734, Accuracy: 0.8425, F1 Micro: 0.9095, F1 Macro: 0.9032\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3084, Accuracy: 0.9286, F1 Micro: 0.9568, F1 Macro: 0.9538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2082, Accuracy: 0.9436, F1 Micro: 0.9655, F1 Macro: 0.9637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1671, Accuracy: 0.947, F1 Micro: 0.9676, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.139, Accuracy: 0.9552, F1 Micro: 0.9724, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1181, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9746\n",
      "Epoch 7/10, Train Loss: 0.0956, Accuracy: 0.9608, F1 Micro: 0.9756, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0805, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0685, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0588, Accuracy: 0.9649, F1 Micro: 0.9783, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9783, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3702, Accuracy: 0.8553, F1 Micro: 0.8553, F1 Macro: 0.7897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2336, Accuracy: 0.8982, F1 Micro: 0.8982, F1 Macro: 0.8621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1566, Accuracy: 0.9085, F1 Micro: 0.9085, F1 Macro: 0.879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.12, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0763, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.8883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0576, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.8897\n",
      "Epoch 7/10, Train Loss: 0.0458, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.8883\n",
      "Epoch 8/10, Train Loss: 0.0362, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8809\n",
      "Epoch 9/10, Train Loss: 0.0239, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0301, Accuracy: 0.9178, F1 Micro: 0.9178, F1 Macro: 0.8916\n",
      "\n",
      "Sentiment analysis accuracy: 0.9178, F1 Micro: 0.9178, F1 Macro: 0.8916\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.94       773\n",
      "    positive       0.93      0.77      0.84       298\n",
      "\n",
      "    accuracy                           0.92      1071\n",
      "   macro avg       0.92      0.87      0.89      1071\n",
      "weighted avg       0.92      0.92      0.92      1071\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9587, F1 Micro: 0.9587, F1 Macro: 0.8762\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.83      0.89        86\n",
      "     neutral       0.97      1.00      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.29      0.36         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.89      0.69      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.78      0.65      0.70       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.88      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.86      0.76      0.80       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.82      0.87        85\n",
      "     neutral       0.96      0.99      0.97       418\n",
      "    positive       0.93      0.91      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.52      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.65      0.76      0.70        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.76      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 326.896710395813 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 52\n",
      "Sampling duration: 0.00013446807861328125 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4693, Accuracy: 0.855, F1 Micro: 0.9162, F1 Macro: 0.9113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3058, Accuracy: 0.928, F1 Micro: 0.9563, F1 Macro: 0.9533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2117, Accuracy: 0.9455, F1 Micro: 0.9666, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1624, Accuracy: 0.9547, F1 Micro: 0.9721, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1406, Accuracy: 0.9573, F1 Micro: 0.9736, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1151, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0974, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0858, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9754\n",
      "Epoch 9/10, Train Loss: 0.07, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0614, Accuracy: 0.9641, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9641, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.95      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.98      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3528, Accuracy: 0.8289, F1 Micro: 0.8289, F1 Macro: 0.7572\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2249, Accuracy: 0.8803, F1 Micro: 0.8803, F1 Macro: 0.8491\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1681, Accuracy: 0.8918, F1 Micro: 0.8918, F1 Macro: 0.8649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1216, Accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.8711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.087, Accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0648, Accuracy: 0.9007, F1 Micro: 0.9007, F1 Macro: 0.8759\n",
      "Epoch 7/10, Train Loss: 0.06, Accuracy: 0.8954, F1 Micro: 0.8954, F1 Macro: 0.8649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0501, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8784\n",
      "Epoch 9/10, Train Loss: 0.0422, Accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.87\n",
      "Epoch 10/10, Train Loss: 0.0296, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8739\n",
      "\n",
      "Sentiment analysis accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.93       788\n",
      "    positive       0.93      0.74      0.82       340\n",
      "\n",
      "    accuracy                           0.90      1128\n",
      "   macro avg       0.91      0.86      0.88      1128\n",
      "weighted avg       0.91      0.90      0.90      1128\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.958, F1 Micro: 0.958, F1 Macro: 0.8835\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.86      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.75      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.71      0.62      0.65       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.87      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.69      0.50      0.58        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.84      0.78      0.80       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.88      0.82        85\n",
      "     neutral       0.98      0.95      0.97       418\n",
      "    positive       0.92      0.90      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.84      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 334.3925325870514 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.822845458984375e-05 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4721, Accuracy: 0.8606, F1 Micro: 0.9186, F1 Macro: 0.9129\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.297, Accuracy: 0.9328, F1 Micro: 0.959, F1 Macro: 0.9562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2041, Accuracy: 0.9464, F1 Micro: 0.9671, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1667, Accuracy: 0.954, F1 Micro: 0.9717, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1388, Accuracy: 0.9566, F1 Micro: 0.9732, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1127, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.975\n",
      "Epoch 7/10, Train Loss: 0.0962, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.973\n",
      "Epoch 8/10, Train Loss: 0.08, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0672, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9758\n",
      "Epoch 10/10, Train Loss: 0.0579, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.93      0.99      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3502, Accuracy: 0.8562, F1 Micro: 0.8562, F1 Macro: 0.7951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2257, Accuracy: 0.8954, F1 Micro: 0.8954, F1 Macro: 0.8585\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1361, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8759\n",
      "Epoch 4/10, Train Loss: 0.1033, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0756, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.8897\n",
      "Epoch 6/10, Train Loss: 0.0552, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.8891\n",
      "Epoch 7/10, Train Loss: 0.0557, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8815\n",
      "Epoch 8/10, Train Loss: 0.0372, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8842\n",
      "Epoch 9/10, Train Loss: 0.0325, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.875\n",
      "Epoch 10/10, Train Loss: 0.0323, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8806\n",
      "\n",
      "Sentiment analysis accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.8897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       772\n",
      "    positive       0.92      0.77      0.84       299\n",
      "\n",
      "    accuracy                           0.92      1071\n",
      "   macro avg       0.92      0.87      0.89      1071\n",
      "weighted avg       0.92      0.92      0.91      1071\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.868\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.08      0.29      0.13         7\n",
      "     neutral       0.96      0.97      0.97       496\n",
      "    positive       0.87      0.57      0.69        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.64      0.61      0.60       571\n",
      "weighted avg       0.94      0.92      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.89      0.88       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.87      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.73      0.77       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.93      0.96       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 333.8767075538635 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.00010752677917480469 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.469, Accuracy: 0.8705, F1 Micro: 0.9239, F1 Macro: 0.9174\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2884, Accuracy: 0.9332, F1 Micro: 0.9593, F1 Macro: 0.9564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2067, Accuracy: 0.9472, F1 Micro: 0.9676, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1607, Accuracy: 0.9507, F1 Micro: 0.9697, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1324, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9733\n",
      "Epoch 6/10, Train Loss: 0.1151, Accuracy: 0.9602, F1 Micro: 0.9755, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0914, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.0795, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9731\n",
      "Epoch 9/10, Train Loss: 0.0645, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9745\n",
      "Epoch 10/10, Train Loss: 0.0564, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.96      0.92      0.94       317\n",
      "       linen       0.95      0.97      0.96       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.348, Accuracy: 0.8608, F1 Micro: 0.8608, F1 Macro: 0.8093\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2248, Accuracy: 0.8931, F1 Micro: 0.8931, F1 Macro: 0.857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1529, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1121, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8868\n",
      "Epoch 5/10, Train Loss: 0.0954, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0597, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8863\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0516, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8855\n",
      "Epoch 8/10, Train Loss: 0.0484, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0443, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.889\n",
      "Epoch 10/10, Train Loss: 0.0268, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8831\n",
      "\n",
      "Sentiment analysis accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       775\n",
      "    positive       0.92      0.76      0.84       310\n",
      "\n",
      "    accuracy                           0.91      1085\n",
      "   macro avg       0.92      0.87      0.89      1085\n",
      "weighted avg       0.91      0.91      0.91      1085\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.8555\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.78      0.93      0.85        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.94      0.92       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.83      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.87      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.95      0.94       571\n",
      "weighted avg       0.96      0.95      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.17      0.14      0.15         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.87      0.68      0.76        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.66      0.60      0.63       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.92      0.90       200\n",
      "     neutral       0.96      0.92      0.94       315\n",
      "    positive       0.84      0.95      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.88       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.69      0.50      0.58        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.84      0.78      0.80       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.52      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.82      0.74        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.81      0.78      0.78       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.92        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.62      0.83      0.71         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.85      0.91      0.88       571\n",
      "weighted avg       0.99      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 339.48647475242615 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.00010371208190917969 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4665, Accuracy: 0.8726, F1 Micro: 0.9251, F1 Macro: 0.9195\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2935, Accuracy: 0.9286, F1 Micro: 0.9568, F1 Macro: 0.9545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1996, Accuracy: 0.9462, F1 Micro: 0.9671, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1615, Accuracy: 0.9535, F1 Micro: 0.9714, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1288, Accuracy: 0.9573, F1 Micro: 0.9737, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1127, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0898, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "Epoch 8/10, Train Loss: 0.0794, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9758\n",
      "Epoch 9/10, Train Loss: 0.0651, Accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0559, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3338, Accuracy: 0.8689, F1 Micro: 0.8689, F1 Macro: 0.8326\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2181, Accuracy: 0.8937, F1 Micro: 0.8937, F1 Macro: 0.8597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.152, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1173, Accuracy: 0.9166, F1 Micro: 0.9166, F1 Macro: 0.8923\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0774, Accuracy: 0.9193, F1 Micro: 0.9193, F1 Macro: 0.8955\n",
      "Epoch 6/10, Train Loss: 0.052, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8915\n",
      "Epoch 7/10, Train Loss: 0.0565, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8941\n",
      "Epoch 8/10, Train Loss: 0.0533, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8913\n",
      "Epoch 9/10, Train Loss: 0.0277, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8818\n",
      "Epoch 10/10, Train Loss: 0.0349, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8844\n",
      "\n",
      "Sentiment analysis accuracy: 0.9193, F1 Micro: 0.9193, F1 Macro: 0.8955\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       778\n",
      "    positive       0.94      0.77      0.85       313\n",
      "\n",
      "    accuracy                           0.92      1091\n",
      "   macro avg       0.93      0.87      0.90      1091\n",
      "weighted avg       0.92      0.92      0.92      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9578, F1 Micro: 0.9578, F1 Macro: 0.8586\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.76      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.81      0.71      0.76        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.75      0.61      0.65       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.89       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.84      0.91      0.87        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.69      0.50      0.58        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.84      0.77      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.82      0.74        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.78      0.79       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.89      0.93       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 353.6910798549652 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 25\n",
      "Sampling duration: 0.017950057983398438 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4649, Accuracy: 0.8689, F1 Micro: 0.9235, F1 Macro: 0.9182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2842, Accuracy: 0.9332, F1 Micro: 0.9592, F1 Macro: 0.9564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1941, Accuracy: 0.9498, F1 Micro: 0.9693, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1593, Accuracy: 0.9549, F1 Micro: 0.9722, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1334, Accuracy: 0.9549, F1 Micro: 0.9722, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1103, Accuracy: 0.9618, F1 Micro: 0.9764, F1 Macro: 0.974\n",
      "Epoch 7/10, Train Loss: 0.0901, Accuracy: 0.9611, F1 Micro: 0.976, F1 Macro: 0.9737\n",
      "Epoch 8/10, Train Loss: 0.0756, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0627, Accuracy: 0.9625, F1 Micro: 0.9766, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0552, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "\n",
      "Aspect detection accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.92      0.98      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3477, Accuracy: 0.8596, F1 Micro: 0.8596, F1 Macro: 0.8255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2122, Accuracy: 0.8901, F1 Micro: 0.8901, F1 Macro: 0.8601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1304, Accuracy: 0.8947, F1 Micro: 0.8947, F1 Macro: 0.8597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.113, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0715, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8863\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0596, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.89\n",
      "Epoch 7/10, Train Loss: 0.048, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8849\n",
      "Epoch 8/10, Train Loss: 0.0411, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.887\n",
      "Epoch 9/10, Train Loss: 0.0397, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8825\n",
      "Epoch 10/10, Train Loss: 0.0225, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8852\n",
      "\n",
      "Sentiment analysis accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       766\n",
      "    positive       0.95      0.75      0.84       317\n",
      "\n",
      "    accuracy                           0.92      1083\n",
      "   macro avg       0.93      0.87      0.89      1083\n",
      "weighted avg       0.92      0.92      0.91      1083\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.87\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.98      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.86      0.90        86\n",
      "     neutral       0.97      1.00      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.81      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.87      0.69      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.89      0.88       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       1.00      0.27      0.43        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.69      0.74       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.72      0.76        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.83      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 355.9733703136444 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.0001361370086669922 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4613, Accuracy: 0.8703, F1 Micro: 0.9238, F1 Macro: 0.9172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2801, Accuracy: 0.933, F1 Micro: 0.9592, F1 Macro: 0.9568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2036, Accuracy: 0.9469, F1 Micro: 0.9675, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1561, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1268, Accuracy: 0.959, F1 Micro: 0.9747, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.108, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0908, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0763, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.976\n",
      "Epoch 9/10, Train Loss: 0.0653, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Epoch 10/10, Train Loss: 0.0546, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.96      0.90      0.93       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3473, Accuracy: 0.8732, F1 Micro: 0.8732, F1 Macro: 0.8305\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2024, Accuracy: 0.8922, F1 Micro: 0.8922, F1 Macro: 0.8637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1505, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0971, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.881\n",
      "Epoch 5/10, Train Loss: 0.0848, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0597, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0428, Accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.8891\n",
      "Epoch 8/10, Train Loss: 0.0293, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8857\n",
      "Epoch 9/10, Train Loss: 0.0332, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8825\n",
      "Epoch 10/10, Train Loss: 0.0305, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8849\n",
      "\n",
      "Sentiment analysis accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.8891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       786\n",
      "    positive       0.94      0.75      0.84       318\n",
      "\n",
      "    accuracy                           0.91      1104\n",
      "   macro avg       0.92      0.87      0.89      1104\n",
      "weighted avg       0.92      0.91      0.91      1104\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.8826\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.92      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.25      0.14      0.18         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.68      0.61      0.64       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89       200\n",
      "     neutral       0.96      0.90      0.93       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.93      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.78      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.84      0.83        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.95      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.90      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.69      0.78        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.84      0.94      0.89        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.88      0.89       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 362.45064210891724 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.00015425682067871094 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4582, Accuracy: 0.8731, F1 Micro: 0.9255, F1 Macro: 0.9201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2749, Accuracy: 0.9361, F1 Micro: 0.961, F1 Macro: 0.9586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.195, Accuracy: 0.9505, F1 Micro: 0.9696, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1595, Accuracy: 0.951, F1 Micro: 0.97, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1309, Accuracy: 0.958, F1 Micro: 0.9742, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1053, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9759\n",
      "Epoch 7/10, Train Loss: 0.0896, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0757, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "Epoch 9/10, Train Loss: 0.0632, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.0536, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.93      0.98      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3401, Accuracy: 0.8705, F1 Micro: 0.8705, F1 Macro: 0.8349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1996, Accuracy: 0.8944, F1 Micro: 0.8944, F1 Macro: 0.8613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1563, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.8836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0943, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0819, Accuracy: 0.9155, F1 Micro: 0.9155, F1 Macro: 0.8912\n",
      "Epoch 6/10, Train Loss: 0.0557, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.883\n",
      "Epoch 7/10, Train Loss: 0.0596, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0497, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8918\n",
      "Epoch 9/10, Train Loss: 0.0351, Accuracy: 0.9155, F1 Micro: 0.9155, F1 Macro: 0.8907\n",
      "Epoch 10/10, Train Loss: 0.0246, Accuracy: 0.9155, F1 Micro: 0.9155, F1 Macro: 0.8912\n",
      "\n",
      "Sentiment analysis accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8918\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       773\n",
      "    positive       0.94      0.76      0.84       316\n",
      "\n",
      "    accuracy                           0.92      1089\n",
      "   macro avg       0.93      0.87      0.89      1089\n",
      "weighted avg       0.92      0.92      0.91      1089\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.8813\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.75      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.71      0.62      0.65       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       162\n",
      "     neutral       0.93      0.98      0.95       387\n",
      "    positive       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.94      0.75      0.80       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 365.51655197143555 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.00014781951904296875 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4559, Accuracy: 0.8877, F1 Micro: 0.9329, F1 Macro: 0.9263\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2768, Accuracy: 0.9396, F1 Micro: 0.963, F1 Macro: 0.9609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1968, Accuracy: 0.9502, F1 Micro: 0.9694, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1502, Accuracy: 0.9531, F1 Micro: 0.9713, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1246, Accuracy: 0.9604, F1 Micro: 0.9756, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1022, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0866, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0719, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9765\n",
      "Epoch 9/10, Train Loss: 0.0619, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.976\n",
      "Epoch 10/10, Train Loss: 0.0521, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.96      0.91      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3406, Accuracy: 0.8659, F1 Micro: 0.8659, F1 Macro: 0.8344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1895, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1433, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8792\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1129, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8779\n",
      "Epoch 5/10, Train Loss: 0.0692, Accuracy: 0.904, F1 Micro: 0.904, F1 Macro: 0.8744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0546, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8871\n",
      "Epoch 7/10, Train Loss: 0.0526, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8833\n",
      "Epoch 8/10, Train Loss: 0.0386, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8769\n",
      "Epoch 9/10, Train Loss: 0.0286, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0239, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8886\n",
      "\n",
      "Sentiment analysis accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       783\n",
      "    positive       0.94      0.75      0.84       321\n",
      "\n",
      "    accuracy                           0.91      1104\n",
      "   macro avg       0.92      0.87      0.89      1104\n",
      "weighted avg       0.92      0.91      0.91      1104\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.8734\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.76      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.87      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.95      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.20      0.14      0.17         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.86      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.67      0.62      0.64       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.90       200\n",
      "     neutral       0.96      0.91      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.92      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.89      0.88       162\n",
      "     neutral       0.95      0.95      0.95       387\n",
      "    positive       0.67      0.55      0.60        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.83      0.80      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.86      0.83        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.95      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.95      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.84      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 374.0496563911438 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.00012564659118652344 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4533, Accuracy: 0.8851, F1 Micro: 0.932, F1 Macro: 0.9263\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2679, Accuracy: 0.9368, F1 Micro: 0.9616, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1883, Accuracy: 0.9519, F1 Micro: 0.9705, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1511, Accuracy: 0.9568, F1 Micro: 0.9734, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.122, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9748\n",
      "Epoch 6/10, Train Loss: 0.0983, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0869, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0686, Accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "Epoch 9/10, Train Loss: 0.0601, Accuracy: 0.9646, F1 Micro: 0.9781, F1 Macro: 0.9761\n",
      "Epoch 10/10, Train Loss: 0.0508, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3336, Accuracy: 0.8601, F1 Micro: 0.8601, F1 Macro: 0.814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1953, Accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.8593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1334, Accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.8596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0985, Accuracy: 0.8987, F1 Micro: 0.8987, F1 Macro: 0.8679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0706, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8773\n",
      "Epoch 6/10, Train Loss: 0.0575, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8733\n",
      "Epoch 7/10, Train Loss: 0.0502, Accuracy: 0.904, F1 Micro: 0.904, F1 Macro: 0.8743\n",
      "Epoch 8/10, Train Loss: 0.0294, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8701\n",
      "Epoch 9/10, Train Loss: 0.0151, Accuracy: 0.9022, F1 Micro: 0.9022, F1 Macro: 0.8743\n",
      "Epoch 10/10, Train Loss: 0.0234, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8721\n",
      "\n",
      "Sentiment analysis accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       790\n",
      "    positive       0.94      0.73      0.82       325\n",
      "\n",
      "    accuracy                           0.91      1115\n",
      "   macro avg       0.92      0.85      0.88      1115\n",
      "weighted avg       0.91      0.91      0.90      1115\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9587, F1 Micro: 0.9587, F1 Macro: 0.8781\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.92      0.93        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.78      0.70      0.74        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.87      0.89       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.87      0.82        78\n",
      "     neutral       0.98      0.96      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.08      0.14      0.10         7\n",
      "     neutral       0.96      0.97      0.96       496\n",
      "    positive       0.87      0.69      0.77        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.63      0.60      0.61       571\n",
      "weighted avg       0.94      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.92      0.89       200\n",
      "     neutral       0.96      0.92      0.94       315\n",
      "    positive       0.88      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.89      0.87       162\n",
      "     neutral       0.95      0.97      0.96       387\n",
      "    positive       1.00      0.36      0.53        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.93      0.74      0.79       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.69      0.77        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.86      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 386.2070691585541 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.1552734375e-05 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.45, Accuracy: 0.884, F1 Micro: 0.9317, F1 Macro: 0.9276\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2689, Accuracy: 0.9365, F1 Micro: 0.9613, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1855, Accuracy: 0.9524, F1 Micro: 0.9708, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1488, Accuracy: 0.9536, F1 Micro: 0.9715, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1218, Accuracy: 0.9613, F1 Micro: 0.9761, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0974, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0817, Accuracy: 0.9648, F1 Micro: 0.9782, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0706, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9764\n",
      "Epoch 9/10, Train Loss: 0.0585, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9756\n",
      "Epoch 10/10, Train Loss: 0.0501, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3374, Accuracy: 0.8631, F1 Micro: 0.8631, F1 Macro: 0.8244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1995, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.8761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1279, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8869\n",
      "Epoch 4/10, Train Loss: 0.1, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0666, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8913\n",
      "Epoch 6/10, Train Loss: 0.0569, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8819\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0398, Accuracy: 0.9166, F1 Micro: 0.9166, F1 Macro: 0.8933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0316, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.8957\n",
      "Epoch 9/10, Train Loss: 0.0306, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8883\n",
      "Epoch 10/10, Train Loss: 0.0255, Accuracy: 0.9166, F1 Micro: 0.9166, F1 Macro: 0.8945\n",
      "\n",
      "Sentiment analysis accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.8957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       780\n",
      "    positive       0.94      0.77      0.85       323\n",
      "\n",
      "    accuracy                           0.92      1103\n",
      "   macro avg       0.93      0.88      0.90      1103\n",
      "weighted avg       0.92      0.92      0.92      1103\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9592, F1 Micro: 0.9592, F1 Macro: 0.86\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.83      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.82      0.93      0.87       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.80      0.78      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.59      0.59       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.94      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.60      0.55      0.57        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.81      0.79      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.88        85\n",
      "     neutral       0.98      0.97      0.98       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 391.50819182395935 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 36\n",
      "Sampling duration: 0.020090341567993164 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4524, Accuracy: 0.8858, F1 Micro: 0.9322, F1 Macro: 0.9264\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2643, Accuracy: 0.9417, F1 Micro: 0.9644, F1 Macro: 0.962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1808, Accuracy: 0.9531, F1 Micro: 0.9711, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1452, Accuracy: 0.9559, F1 Micro: 0.9728, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1214, Accuracy: 0.9611, F1 Micro: 0.976, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0981, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0823, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "Epoch 8/10, Train Loss: 0.0685, Accuracy: 0.9637, F1 Micro: 0.9774, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0598, Accuracy: 0.9667, F1 Micro: 0.9793, F1 Macro: 0.977\n",
      "Epoch 10/10, Train Loss: 0.0511, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9667, F1 Micro: 0.9793, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.97      0.90      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.98      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3303, Accuracy: 0.8708, F1 Micro: 0.8708, F1 Macro: 0.8281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1873, Accuracy: 0.8979, F1 Micro: 0.8979, F1 Macro: 0.8645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1452, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.094, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0782, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8832\n",
      "Epoch 6/10, Train Loss: 0.0571, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0418, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8902\n",
      "Epoch 8/10, Train Loss: 0.0393, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8801\n",
      "Epoch 9/10, Train Loss: 0.0195, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8855\n",
      "Epoch 10/10, Train Loss: 0.0281, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8829\n",
      "\n",
      "Sentiment analysis accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       787\n",
      "    positive       0.93      0.76      0.84       320\n",
      "\n",
      "    accuracy                           0.92      1107\n",
      "   macro avg       0.92      0.87      0.89      1107\n",
      "weighted avg       0.92      0.92      0.91      1107\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9609, F1 Micro: 0.9609, F1 Macro: 0.8719\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.86      0.87       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.88      0.74      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.57      0.59       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.94      0.90       200\n",
      "     neutral       0.97      0.90      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.78      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.89      0.91        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.56      0.83      0.67         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.82      0.91      0.86       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 400.43018770217896 s\n",
      "Total runtime: 7715.982215642929 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba466d3",
   "metadata": {
    "papermill": {
     "duration": 0.011021,
     "end_time": "2025-04-20T08:36:52.654736",
     "exception": false,
     "start_time": "2025-04-20T08:36:52.643715",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa81a3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6341, Accuracy: 0.7974, F1 Micro: 0.8859, F1 Macro: 0.8768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5134, Accuracy: 0.8014, F1 Micro: 0.8897, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4829, Accuracy: 0.8017, F1 Micro: 0.8897, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4632, Accuracy: 0.8045, F1 Micro: 0.8906, F1 Macro: 0.8847\n",
      "Epoch 5/10, Train Loss: 0.4642, Accuracy: 0.8047, F1 Micro: 0.8903, F1 Macro: 0.8835\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4501, Accuracy: 0.8075, F1 Micro: 0.891, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.451, Accuracy: 0.8149, F1 Micro: 0.8947, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4034, Accuracy: 0.8273, F1 Micro: 0.9007, F1 Macro: 0.892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3957, Accuracy: 0.8345, F1 Micro: 0.9041, F1 Macro: 0.8954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3562, Accuracy: 0.8448, F1 Micro: 0.9097, F1 Macro: 0.9016\n",
      "\n",
      "Aspect detection accuracy: 0.8448, F1 Micro: 0.9097, F1 Macro: 0.9016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.83      1.00      0.90       462\n",
      "   air_panas       0.83      1.00      0.91       480\n",
      "         bau       0.86      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.70      0.75      0.73       317\n",
      "       linen       0.77      0.94      0.85       392\n",
      "     service       0.90      0.98      0.94       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.88      1.00      0.94       498\n",
      "\n",
      "   micro avg       0.85      0.98      0.91      4614\n",
      "   macro avg       0.85      0.97      0.90      4614\n",
      "weighted avg       0.85      0.98      0.91      4614\n",
      " samples avg       0.85      0.97      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7316, Accuracy: 0.5412, F1 Micro: 0.5412, F1 Macro: 0.3512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.612, Accuracy: 0.5412, F1 Micro: 0.5412, F1 Macro: 0.3512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5437, Accuracy: 0.5645, F1 Micro: 0.5645, F1 Macro: 0.4185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5596, Accuracy: 0.5751, F1 Micro: 0.5751, F1 Macro: 0.4522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4998, Accuracy: 0.5877, F1 Micro: 0.5877, F1 Macro: 0.5659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.478, Accuracy: 0.6025, F1 Micro: 0.6025, F1 Macro: 0.5626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3806, Accuracy: 0.666, F1 Micro: 0.666, F1 Macro: 0.6564\n",
      "Epoch 8/10, Train Loss: 0.3522, Accuracy: 0.6195, F1 Micro: 0.6195, F1 Macro: 0.5823\n",
      "Epoch 9/10, Train Loss: 0.3548, Accuracy: 0.6575, F1 Micro: 0.6575, F1 Macro: 0.6482\n",
      "Epoch 10/10, Train Loss: 0.3088, Accuracy: 0.6237, F1 Micro: 0.6237, F1 Macro: 0.6009\n",
      "\n",
      "Sentiment analysis accuracy: 0.666, F1 Micro: 0.666, F1 Macro: 0.6564\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.77      0.71       256\n",
      "    positive       0.67      0.54      0.60       217\n",
      "\n",
      "    accuracy                           0.67       473\n",
      "   macro avg       0.67      0.66      0.66       473\n",
      "weighted avg       0.67      0.67      0.66       473\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8275, F1 Micro: 0.8275, F1 Macro: 0.4031\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.16      0.28        97\n",
      "     neutral       0.83      1.00      0.91       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.61      0.39      0.40       571\n",
      "weighted avg       0.83      0.83      0.78       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.28      0.33      0.30       571\n",
      "weighted avg       0.69      0.83      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        78\n",
      "     neutral       0.86      1.00      0.92       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.74      0.86      0.80       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.55      0.45      0.49       200\n",
      "     neutral       0.70      0.75      0.73       315\n",
      "    positive       0.28      0.36      0.31        56\n",
      "\n",
      "    accuracy                           0.61       571\n",
      "   macro avg       0.51      0.52      0.51       571\n",
      "weighted avg       0.61      0.61      0.60       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.31      0.43       162\n",
      "     neutral       0.76      0.94      0.84       387\n",
      "    positive       0.21      0.18      0.20        22\n",
      "\n",
      "    accuracy                           0.73       571\n",
      "   macro avg       0.55      0.48      0.49       571\n",
      "weighted avg       0.72      0.73      0.70       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.44      0.50        85\n",
      "     neutral       0.90      0.98      0.93       418\n",
      "    positive       0.73      0.56      0.63        68\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.74      0.66      0.69       571\n",
      "weighted avg       0.83      0.85      0.83       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.24        74\n",
      "     neutral       0.88      1.00      0.94       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.63      0.38      0.39       571\n",
      "weighted avg       0.89      0.88      0.84       571\n",
      "\n",
      "Total train time: 85.21513199806213 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 215\n",
      "Sampling duration: 0.0002429485321044922 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5639, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4543, Accuracy: 0.8036, F1 Micro: 0.8898, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4359, Accuracy: 0.8073, F1 Micro: 0.8917, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4245, Accuracy: 0.8266, F1 Micro: 0.9004, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3844, Accuracy: 0.8556, F1 Micro: 0.9168, F1 Macro: 0.912\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3337, Accuracy: 0.8835, F1 Micro: 0.9311, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2951, Accuracy: 0.8988, F1 Micro: 0.9395, F1 Macro: 0.9355\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2478, Accuracy: 0.908, F1 Micro: 0.9444, F1 Macro: 0.9396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.226, Accuracy: 0.9155, F1 Micro: 0.9491, F1 Macro: 0.9454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1953, Accuracy: 0.9233, F1 Micro: 0.9537, F1 Macro: 0.9503\n",
      "\n",
      "Aspect detection accuracy: 0.9233, F1 Micro: 0.9537, F1 Macro: 0.9503\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.92      0.99      0.95       480\n",
      "         bau       0.94      0.98      0.96       496\n",
      "     general       0.87      0.99      0.93       500\n",
      "  kebersihan       0.83      0.92      0.87       317\n",
      "       linen       0.85      0.97      0.90       392\n",
      "     service       0.92      0.99      0.95       423\n",
      "sunrise_meal       0.94      1.00      0.97       530\n",
      "          tv       0.98      1.00      0.99       516\n",
      "        wifi       0.98      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.92      0.99      0.95      4614\n",
      "   macro avg       0.92      0.98      0.95      4614\n",
      "weighted avg       0.93      0.99      0.95      4614\n",
      " samples avg       0.92      0.99      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.533, Accuracy: 0.7406, F1 Micro: 0.7406, F1 Macro: 0.4255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.434, Accuracy: 0.7964, F1 Micro: 0.7964, F1 Macro: 0.6789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3794, Accuracy: 0.8339, F1 Micro: 0.8339, F1 Macro: 0.7688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3054, Accuracy: 0.8485, F1 Micro: 0.8485, F1 Macro: 0.7988\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2712, Accuracy: 0.863, F1 Micro: 0.863, F1 Macro: 0.8119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1872, Accuracy: 0.8788, F1 Micro: 0.8788, F1 Macro: 0.8367\n",
      "Epoch 7/10, Train Loss: 0.1709, Accuracy: 0.8691, F1 Micro: 0.8691, F1 Macro: 0.8119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1355, Accuracy: 0.8885, F1 Micro: 0.8885, F1 Macro: 0.8427\n",
      "Epoch 9/10, Train Loss: 0.1061, Accuracy: 0.8703, F1 Micro: 0.8703, F1 Macro: 0.832\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1328, Accuracy: 0.8945, F1 Micro: 0.8945, F1 Macro: 0.8537\n",
      "\n",
      "Sentiment analysis accuracy: 0.8945, F1 Micro: 0.8945, F1 Macro: 0.8537\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93       611\n",
      "    positive       0.86      0.71      0.78       214\n",
      "\n",
      "    accuracy                           0.89       825\n",
      "   macro avg       0.88      0.83      0.85       825\n",
      "weighted avg       0.89      0.89      0.89       825\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.709\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.90      0.93        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.80      0.80      0.80        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.90      0.91       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.53      0.67        86\n",
      "     neutral       0.91      0.99      0.95       475\n",
      "    positive       0.75      0.30      0.43        10\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.61      0.68       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.60      0.70        78\n",
      "     neutral       0.94      0.98      0.96       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.53      0.55       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      0.99      0.93       496\n",
      "    positive       0.50      0.04      0.08        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.46      0.35      0.34       571\n",
      "weighted avg       0.82      0.87      0.82       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.68      0.77       200\n",
      "     neutral       0.83      0.92      0.87       315\n",
      "    positive       0.62      0.75      0.68        56\n",
      "\n",
      "    accuracy                           0.82       571\n",
      "   macro avg       0.78      0.78      0.77       571\n",
      "weighted avg       0.83      0.82      0.82       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.65      0.74       162\n",
      "     neutral       0.85      0.97      0.90       387\n",
      "    positive       0.56      0.23      0.32        22\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.76      0.61      0.66       571\n",
      "weighted avg       0.84      0.85      0.84       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.64      0.72        85\n",
      "     neutral       0.92      0.99      0.95       418\n",
      "    positive       0.96      0.78      0.86        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.80      0.84       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.24        29\n",
      "     neutral       0.94      1.00      0.97       525\n",
      "    positive       0.90      0.53      0.67        17\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.95      0.56      0.63       571\n",
      "weighted avg       0.94      0.94      0.92       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.80      0.86        54\n",
      "     neutral       0.98      1.00      0.99       511\n",
      "    positive       0.40      0.33      0.36         6\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.77      0.71      0.74       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.88      0.93        74\n",
      "     neutral       0.98      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.99      0.96      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 124.74606251716614 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 193\n",
      "Sampling duration: 0.0001761913299560547 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5308, Accuracy: 0.8012, F1 Micro: 0.8896, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4609, Accuracy: 0.809, F1 Micro: 0.8929, F1 Macro: 0.887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4111, Accuracy: 0.8514, F1 Micro: 0.914, F1 Macro: 0.9081\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3575, Accuracy: 0.8819, F1 Micro: 0.9302, F1 Macro: 0.9245\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3007, Accuracy: 0.9116, F1 Micro: 0.9468, F1 Macro: 0.9427\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2469, Accuracy: 0.9201, F1 Micro: 0.952, F1 Macro: 0.9487\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2131, Accuracy: 0.9339, F1 Micro: 0.9596, F1 Macro: 0.9565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1825, Accuracy: 0.9378, F1 Micro: 0.9621, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1565, Accuracy: 0.9391, F1 Micro: 0.9629, F1 Macro: 0.9602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1452, Accuracy: 0.9406, F1 Micro: 0.9637, F1 Macro: 0.9606\n",
      "\n",
      "Aspect detection accuracy: 0.9406, F1 Micro: 0.9637, F1 Macro: 0.9606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.95      0.99      0.97       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.89      0.99      0.94       500\n",
      "  kebersihan       0.87      0.92      0.89       317\n",
      "       linen       0.87      0.96      0.92       392\n",
      "     service       0.95      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      4614\n",
      "   macro avg       0.94      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.96      4614\n",
      " samples avg       0.94      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5035, Accuracy: 0.7558, F1 Micro: 0.7558, F1 Macro: 0.5332\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3589, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2657, Accuracy: 0.86, F1 Micro: 0.86, F1 Macro: 0.8072\n",
      "Epoch 4/10, Train Loss: 0.1978, Accuracy: 0.8505, F1 Micro: 0.8505, F1 Macro: 0.8106\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2087, Accuracy: 0.8789, F1 Micro: 0.8789, F1 Macro: 0.8274\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1581, Accuracy: 0.8842, F1 Micro: 0.8842, F1 Macro: 0.8373\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1326, Accuracy: 0.8895, F1 Micro: 0.8895, F1 Macro: 0.8455\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1067, Accuracy: 0.8895, F1 Micro: 0.8895, F1 Macro: 0.8464\n",
      "Epoch 9/10, Train Loss: 0.087, Accuracy: 0.8874, F1 Micro: 0.8874, F1 Macro: 0.8384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0726, Accuracy: 0.8895, F1 Micro: 0.8895, F1 Macro: 0.8464\n",
      "\n",
      "Sentiment analysis accuracy: 0.8895, F1 Micro: 0.8895, F1 Macro: 0.8464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93       696\n",
      "    positive       0.89      0.67      0.77       254\n",
      "\n",
      "    accuracy                           0.89       950\n",
      "   macro avg       0.89      0.82      0.85       950\n",
      "weighted avg       0.89      0.89      0.88       950\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.7551\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.87      0.87      0.87        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.78      0.84        86\n",
      "     neutral       0.95      0.99      0.97       475\n",
      "    positive       1.00      0.20      0.33        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.66      0.71       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.76      0.80        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.60      0.58      0.59       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.89      0.99      0.94       496\n",
      "    positive       0.76      0.19      0.31        68\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.55      0.39      0.41       571\n",
      "weighted avg       0.86      0.88      0.85       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.78      0.82       200\n",
      "     neutral       0.87      0.92      0.89       315\n",
      "    positive       0.74      0.82      0.78        56\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.83      0.84      0.83       571\n",
      "weighted avg       0.86      0.86      0.86       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.71      0.76       162\n",
      "     neutral       0.87      0.96      0.92       387\n",
      "    positive       0.75      0.14      0.23        22\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.82      0.60      0.64       571\n",
      "weighted avg       0.85      0.86      0.85       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.73      0.79        85\n",
      "     neutral       0.95      0.98      0.97       418\n",
      "    positive       0.86      0.87      0.86        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.89      0.86      0.87       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.28      0.41        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.72      0.76      0.74        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.83      0.68      0.71       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.81      0.86       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 154.4459686279297 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 174\n",
      "Sampling duration: 0.00018668174743652344 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.517, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4266, Accuracy: 0.824, F1 Micro: 0.9005, F1 Macro: 0.8957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3722, Accuracy: 0.8785, F1 Micro: 0.9286, F1 Macro: 0.9237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2956, Accuracy: 0.9142, F1 Micro: 0.9485, F1 Macro: 0.9452\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2481, Accuracy: 0.9274, F1 Micro: 0.9559, F1 Macro: 0.9529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2096, Accuracy: 0.9352, F1 Micro: 0.9605, F1 Macro: 0.9577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1781, Accuracy: 0.9387, F1 Micro: 0.9625, F1 Macro: 0.9593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1551, Accuracy: 0.9443, F1 Micro: 0.9658, F1 Macro: 0.9629\n",
      "Epoch 9/10, Train Loss: 0.1358, Accuracy: 0.9439, F1 Micro: 0.9657, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1221, Accuracy: 0.95, F1 Micro: 0.9692, F1 Macro: 0.9661\n",
      "\n",
      "Aspect detection accuracy: 0.95, F1 Micro: 0.9692, F1 Macro: 0.9661\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.95      0.99      0.97       496\n",
      "     general       0.92      0.98      0.95       500\n",
      "  kebersihan       0.92      0.90      0.91       317\n",
      "       linen       0.88      0.98      0.93       392\n",
      "     service       0.96      0.97      0.96       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4962, Accuracy: 0.7931, F1 Micro: 0.7931, F1 Macro: 0.7224\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2988, Accuracy: 0.8647, F1 Micro: 0.8647, F1 Macro: 0.8241\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2515, Accuracy: 0.8716, F1 Micro: 0.8716, F1 Macro: 0.8276\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.173, Accuracy: 0.8824, F1 Micro: 0.8824, F1 Macro: 0.8485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1246, Accuracy: 0.8931, F1 Micro: 0.8931, F1 Macro: 0.8577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0831, Accuracy: 0.8931, F1 Micro: 0.8931, F1 Macro: 0.855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0789, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8813\n",
      "Epoch 8/10, Train Loss: 0.0693, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0292, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8796\n",
      "Epoch 10/10, Train Loss: 0.031, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8764\n",
      "\n",
      "Sentiment analysis accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       725\n",
      "    positive       0.94      0.73      0.82       295\n",
      "\n",
      "    accuracy                           0.91      1020\n",
      "   macro avg       0.92      0.86      0.88      1020\n",
      "weighted avg       0.91      0.91      0.90      1020\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9441, F1 Micro: 0.9441, F1 Macro: 0.7991\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.85        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.85      0.77      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.69      0.78        78\n",
      "     neutral       0.95      0.99      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.56      0.58       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.98      0.95       496\n",
      "    positive       0.81      0.50      0.62        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.58      0.49      0.52       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.84      0.85       200\n",
      "     neutral       0.92      0.90      0.91       315\n",
      "    positive       0.83      0.95      0.88        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.87      0.90      0.88       571\n",
      "weighted avg       0.89      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.82       162\n",
      "     neutral       0.88      0.98      0.92       387\n",
      "    positive       0.67      0.18      0.29        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.82      0.64      0.68       571\n",
      "weighted avg       0.88      0.88      0.87       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.80      0.84        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.90      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.48      0.60        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.73      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.80      0.67      0.73         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.87      0.89       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 171.21474313735962 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 156\n",
      "Sampling duration: 0.0001952648162841797 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5005, Accuracy: 0.804, F1 Micro: 0.8909, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4199, Accuracy: 0.8516, F1 Micro: 0.9144, F1 Macro: 0.9094\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3332, Accuracy: 0.9016, F1 Micro: 0.9411, F1 Macro: 0.9368\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2633, Accuracy: 0.9288, F1 Micro: 0.9568, F1 Macro: 0.9539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.223, Accuracy: 0.9339, F1 Micro: 0.9597, F1 Macro: 0.9574\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.18, Accuracy: 0.9448, F1 Micro: 0.9661, F1 Macro: 0.9633\n",
      "Epoch 7/10, Train Loss: 0.1492, Accuracy: 0.942, F1 Micro: 0.9646, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1344, Accuracy: 0.9523, F1 Micro: 0.9705, F1 Macro: 0.968\n",
      "Epoch 9/10, Train Loss: 0.1137, Accuracy: 0.9509, F1 Micro: 0.9697, F1 Macro: 0.9668\n",
      "Epoch 10/10, Train Loss: 0.0993, Accuracy: 0.9521, F1 Micro: 0.9705, F1 Macro: 0.9676\n",
      "\n",
      "Aspect detection accuracy: 0.9523, F1 Micro: 0.9705, F1 Macro: 0.968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.96      0.97      0.97       496\n",
      "     general       0.90      0.99      0.94       500\n",
      "  kebersihan       0.90      0.93      0.91       317\n",
      "       linen       0.92      0.95      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4637, Accuracy: 0.7894, F1 Micro: 0.7894, F1 Macro: 0.6905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3543, Accuracy: 0.8454, F1 Micro: 0.8454, F1 Macro: 0.7971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2587, Accuracy: 0.8599, F1 Micro: 0.8599, F1 Macro: 0.8136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1855, Accuracy: 0.8783, F1 Micro: 0.8783, F1 Macro: 0.841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1354, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1016, Accuracy: 0.8918, F1 Micro: 0.8918, F1 Macro: 0.8554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0586, Accuracy: 0.8918, F1 Micro: 0.8918, F1 Macro: 0.8523\n",
      "Epoch 8/10, Train Loss: 0.0666, Accuracy: 0.8879, F1 Micro: 0.8879, F1 Macro: 0.8431\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.056, Accuracy: 0.8986, F1 Micro: 0.8986, F1 Macro: 0.8614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0438, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8662\n",
      "\n",
      "Sentiment analysis accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8662\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       747\n",
      "    positive       0.91      0.71      0.80       288\n",
      "\n",
      "    accuracy                           0.90      1035\n",
      "   macro avg       0.91      0.84      0.87      1035\n",
      "weighted avg       0.90      0.90      0.90      1035\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9452, F1 Micro: 0.9452, F1 Macro: 0.8288\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        86\n",
      "     neutral       0.98      0.98      0.98       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.79      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.78      0.80        78\n",
      "     neutral       0.96      0.97      0.97       491\n",
      "    positive       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.75      0.76       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.98      0.95       496\n",
      "    positive       0.79      0.28      0.41        68\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.57      0.42      0.46       571\n",
      "weighted avg       0.90      0.89      0.88       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85       200\n",
      "     neutral       0.91      0.91      0.91       315\n",
      "    positive       0.81      0.89      0.85        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.86      0.88      0.87       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.83      0.84       162\n",
      "     neutral       0.92      0.95      0.94       387\n",
      "    positive       0.62      0.45      0.53        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.80      0.74      0.77       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.78      0.81       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 185.301171541214 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 141\n",
      "Sampling duration: 0.00015306472778320312 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4976, Accuracy: 0.8016, F1 Micro: 0.8897, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3981, Accuracy: 0.8705, F1 Micro: 0.924, F1 Macro: 0.9189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3096, Accuracy: 0.9156, F1 Micro: 0.9491, F1 Macro: 0.9454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2389, Accuracy: 0.9266, F1 Micro: 0.9556, F1 Macro: 0.9529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1898, Accuracy: 0.9354, F1 Micro: 0.9608, F1 Macro: 0.9583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1662, Accuracy: 0.9431, F1 Micro: 0.9652, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1423, Accuracy: 0.9486, F1 Micro: 0.9685, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1213, Accuracy: 0.9503, F1 Micro: 0.9695, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1039, Accuracy: 0.9519, F1 Micro: 0.9704, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0903, Accuracy: 0.9523, F1 Micro: 0.9706, F1 Macro: 0.9676\n",
      "\n",
      "Aspect detection accuracy: 0.9523, F1 Micro: 0.9706, F1 Macro: 0.9676\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.93      0.98      0.96       500\n",
      "  kebersihan       0.91      0.91      0.91       317\n",
      "       linen       0.87      0.98      0.92       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      0.99      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4926, Accuracy: 0.8215, F1 Micro: 0.8215, F1 Macro: 0.7871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2764, Accuracy: 0.8644, F1 Micro: 0.8644, F1 Macro: 0.8302\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1962, Accuracy: 0.8868, F1 Micro: 0.8868, F1 Macro: 0.8559\n",
      "Epoch 4/10, Train Loss: 0.1411, Accuracy: 0.8771, F1 Micro: 0.8771, F1 Macro: 0.8347\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1329, Accuracy: 0.8985, F1 Micro: 0.8985, F1 Macro: 0.867\n",
      "Epoch 6/10, Train Loss: 0.086, Accuracy: 0.8839, F1 Micro: 0.8839, F1 Macro: 0.858\n",
      "Epoch 7/10, Train Loss: 0.07, Accuracy: 0.8956, F1 Micro: 0.8956, F1 Macro: 0.8672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0517, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0342, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8776\n",
      "Epoch 10/10, Train Loss: 0.0342, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8694\n",
      "\n",
      "Sentiment analysis accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       725\n",
      "    positive       0.93      0.73      0.82       300\n",
      "\n",
      "    accuracy                           0.91      1025\n",
      "   macro avg       0.91      0.85      0.88      1025\n",
      "weighted avg       0.91      0.91      0.90      1025\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9452, F1 Micro: 0.9452, F1 Macro: 0.8323\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.90      0.78      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.73      0.78        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.90      0.92       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.83      0.56      0.67        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.51      0.54       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.83      0.84       200\n",
      "     neutral       0.91      0.91      0.91       315\n",
      "    positive       0.89      0.91      0.90        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.88      0.89      0.88       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.73      0.81       162\n",
      "     neutral       0.87      0.98      0.92       387\n",
      "    positive       0.67      0.18      0.29        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.81      0.63      0.67       571\n",
      "weighted avg       0.87      0.88      0.87       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.87      0.97      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.38      0.50        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.80      0.69      0.73       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.97      0.97        74\n",
      "     neutral       1.00      0.99      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 205.24147009849548 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 127\n",
      "Sampling duration: 0.0001575946807861328 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4803, Accuracy: 0.8042, F1 Micro: 0.891, F1 Macro: 0.8863\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3841, Accuracy: 0.8882, F1 Micro: 0.9337, F1 Macro: 0.9286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2901, Accuracy: 0.9267, F1 Micro: 0.9556, F1 Macro: 0.9528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2161, Accuracy: 0.9382, F1 Micro: 0.9623, F1 Macro: 0.9597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1899, Accuracy: 0.9441, F1 Micro: 0.9659, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1561, Accuracy: 0.9509, F1 Micro: 0.9698, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1295, Accuracy: 0.9512, F1 Micro: 0.97, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1117, Accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0992, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9711\n",
      "Epoch 10/10, Train Loss: 0.0826, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.9708\n",
      "\n",
      "Aspect detection accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.90      0.94      0.92       317\n",
      "       linen       0.90      0.97      0.93       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4403, Accuracy: 0.8441, F1 Micro: 0.8441, F1 Macro: 0.7806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2759, Accuracy: 0.8739, F1 Micro: 0.8739, F1 Macro: 0.8454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1916, Accuracy: 0.8912, F1 Micro: 0.8912, F1 Macro: 0.8567\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1384, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.8909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1103, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0757, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8933\n",
      "Epoch 7/10, Train Loss: 0.0404, Accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.8763\n",
      "Epoch 8/10, Train Loss: 0.0423, Accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0304, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8931\n",
      "Epoch 10/10, Train Loss: 0.0199, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.8915\n",
      "\n",
      "Sentiment analysis accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       734\n",
      "    positive       0.94      0.77      0.84       305\n",
      "\n",
      "    accuracy                           0.92      1039\n",
      "   macro avg       0.92      0.87      0.89      1039\n",
      "weighted avg       0.92      0.92      0.91      1039\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.8524\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.75      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.77      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.87       200\n",
      "     neutral       0.92      0.92      0.92       315\n",
      "    positive       0.90      0.96      0.93        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.90      0.91      0.91       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.80      0.83       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.86      0.27      0.41        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.88      0.68      0.73       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.41      0.55        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.68      0.88      0.77        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.76      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 218.0298535823822 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 114\n",
      "Sampling duration: 0.00015044212341308594 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4881, Accuracy: 0.8092, F1 Micro: 0.8933, F1 Macro: 0.8881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3816, Accuracy: 0.8918, F1 Micro: 0.9357, F1 Macro: 0.9308\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2726, Accuracy: 0.9274, F1 Micro: 0.9561, F1 Macro: 0.9534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2126, Accuracy: 0.9398, F1 Micro: 0.9632, F1 Macro: 0.9607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1725, Accuracy: 0.9474, F1 Micro: 0.9677, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1452, Accuracy: 0.9517, F1 Micro: 0.9702, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1242, Accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1059, Accuracy: 0.9589, F1 Micro: 0.9745, F1 Macro: 0.9715\n",
      "Epoch 9/10, Train Loss: 0.0867, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9712\n",
      "Epoch 10/10, Train Loss: 0.0756, Accuracy: 0.9559, F1 Micro: 0.9727, F1 Macro: 0.97\n",
      "\n",
      "Aspect detection accuracy: 0.9589, F1 Micro: 0.9745, F1 Macro: 0.9715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.92      0.91      0.91       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4232, Accuracy: 0.8276, F1 Micro: 0.8276, F1 Macro: 0.7979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2592, Accuracy: 0.859, F1 Micro: 0.859, F1 Macro: 0.8327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1924, Accuracy: 0.8793, F1 Micro: 0.8793, F1 Macro: 0.855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1544, Accuracy: 0.8903, F1 Micro: 0.8903, F1 Macro: 0.8586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1116, Accuracy: 0.8931, F1 Micro: 0.8931, F1 Macro: 0.8638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0835, Accuracy: 0.9041, F1 Micro: 0.9041, F1 Macro: 0.8779\n",
      "Epoch 7/10, Train Loss: 0.0713, Accuracy: 0.9014, F1 Micro: 0.9014, F1 Macro: 0.8742\n",
      "Epoch 8/10, Train Loss: 0.041, Accuracy: 0.8931, F1 Micro: 0.8931, F1 Macro: 0.8629\n",
      "Epoch 9/10, Train Loss: 0.0493, Accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.8694\n",
      "Epoch 10/10, Train Loss: 0.039, Accuracy: 0.8986, F1 Micro: 0.8986, F1 Macro: 0.8722\n",
      "\n",
      "Sentiment analysis accuracy: 0.9041, F1 Micro: 0.9041, F1 Macro: 0.8779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       758\n",
      "    positive       0.94      0.73      0.82       327\n",
      "\n",
      "    accuracy                           0.90      1085\n",
      "   macro avg       0.92      0.85      0.88      1085\n",
      "weighted avg       0.91      0.90      0.90      1085\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.8472\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.79      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.85      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86       200\n",
      "     neutral       0.92      0.90      0.91       315\n",
      "    positive       0.80      0.98      0.88        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.86      0.91      0.88       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.59      0.45      0.51        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.79      0.74      0.77       571\n",
      "weighted avg       0.89      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.89      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.90      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.99      0.97        74\n",
      "     neutral       1.00      0.99      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 233.65637636184692 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 103\n",
      "Sampling duration: 0.00015878677368164062 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4791, Accuracy: 0.8165, F1 Micro: 0.8971, F1 Macro: 0.8927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3478, Accuracy: 0.9036, F1 Micro: 0.9426, F1 Macro: 0.9394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2519, Accuracy: 0.933, F1 Micro: 0.959, F1 Macro: 0.9553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1968, Accuracy: 0.9439, F1 Micro: 0.9657, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1622, Accuracy: 0.951, F1 Micro: 0.9699, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1366, Accuracy: 0.9535, F1 Micro: 0.9713, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1129, Accuracy: 0.9559, F1 Micro: 0.9728, F1 Macro: 0.9704\n",
      "Epoch 8/10, Train Loss: 0.0942, Accuracy: 0.955, F1 Micro: 0.9723, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0821, Accuracy: 0.958, F1 Micro: 0.974, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0726, Accuracy: 0.9599, F1 Micro: 0.9751, F1 Macro: 0.9729\n",
      "\n",
      "Aspect detection accuracy: 0.9599, F1 Micro: 0.9751, F1 Macro: 0.9729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.93      0.99      0.96       500\n",
      "  kebersihan       0.93      0.92      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.427, Accuracy: 0.8372, F1 Micro: 0.8372, F1 Macro: 0.7664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.249, Accuracy: 0.8837, F1 Micro: 0.8837, F1 Macro: 0.8441\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1704, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8727\n",
      "Epoch 4/10, Train Loss: 0.1093, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0841, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8873\n",
      "Epoch 6/10, Train Loss: 0.0613, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8733\n",
      "Epoch 7/10, Train Loss: 0.0408, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.879\n",
      "Epoch 8/10, Train Loss: 0.0405, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8757\n",
      "Epoch 9/10, Train Loss: 0.03, Accuracy: 0.8977, F1 Micro: 0.8977, F1 Macro: 0.8663\n",
      "Epoch 10/10, Train Loss: 0.0195, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8707\n",
      "\n",
      "Sentiment analysis accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       768\n",
      "    positive       0.91      0.77      0.83       307\n",
      "\n",
      "    accuracy                           0.91      1075\n",
      "   macro avg       0.91      0.87      0.89      1075\n",
      "weighted avg       0.91      0.91      0.91      1075\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.833\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.92      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.95      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.89        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.75      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.77      0.82        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.99      0.96       496\n",
      "    positive       0.86      0.56      0.68        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.60      0.51      0.55       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88       200\n",
      "     neutral       0.93      0.92      0.93       315\n",
      "    positive       0.82      0.98      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.69      0.50      0.58        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.83      0.78      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.85        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.38      0.50        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.57      0.76      0.65        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.76      0.71      0.71       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 242.50906014442444 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 62\n",
      "Sampling duration: 0.025480031967163086 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.477, Accuracy: 0.829, F1 Micro: 0.9026, F1 Macro: 0.8966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3465, Accuracy: 0.9002, F1 Micro: 0.9407, F1 Macro: 0.9374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2528, Accuracy: 0.9326, F1 Micro: 0.9591, F1 Macro: 0.9568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1945, Accuracy: 0.9451, F1 Micro: 0.9665, F1 Macro: 0.9639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1578, Accuracy: 0.9495, F1 Micro: 0.9691, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1337, Accuracy: 0.9552, F1 Micro: 0.9723, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1114, Accuracy: 0.9563, F1 Micro: 0.9729, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0932, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0805, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0687, Accuracy: 0.9611, F1 Micro: 0.9758, F1 Macro: 0.9733\n",
      "\n",
      "Aspect detection accuracy: 0.9611, F1 Micro: 0.9758, F1 Macro: 0.9733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.92      0.93       317\n",
      "       linen       0.94      0.95      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4306, Accuracy: 0.8237, F1 Micro: 0.8237, F1 Macro: 0.7421\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2478, Accuracy: 0.8685, F1 Micro: 0.8685, F1 Macro: 0.8248\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1667, Accuracy: 0.8941, F1 Micro: 0.8941, F1 Macro: 0.8677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1255, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8817\n",
      "Epoch 5/10, Train Loss: 0.0955, Accuracy: 0.8941, F1 Micro: 0.8941, F1 Macro: 0.8624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0706, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8817\n",
      "Epoch 7/10, Train Loss: 0.0558, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8744\n",
      "Epoch 8/10, Train Loss: 0.0383, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8699\n",
      "Epoch 9/10, Train Loss: 0.0359, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8738\n",
      "Epoch 10/10, Train Loss: 0.0284, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8693\n",
      "\n",
      "Sentiment analysis accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       770\n",
      "    positive       0.92      0.75      0.83       325\n",
      "\n",
      "    accuracy                           0.91      1095\n",
      "   macro avg       0.91      0.86      0.88      1095\n",
      "weighted avg       0.91      0.91      0.90      1095\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9539, F1 Micro: 0.9539, F1 Macro: 0.843\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.50      0.20      0.29        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.78      0.69      0.71       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       200\n",
      "     neutral       0.93      0.92      0.93       315\n",
      "    positive       0.88      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.88      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.67      0.27      0.39        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.82      0.70      0.73       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.90      0.97      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.78      0.79       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 253.55890321731567 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 86\n",
      "Sampling duration: 0.0001385211944580078 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4731, Accuracy: 0.845, F1 Micro: 0.9106, F1 Macro: 0.905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3342, Accuracy: 0.9153, F1 Micro: 0.949, F1 Macro: 0.9454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2277, Accuracy: 0.9406, F1 Micro: 0.9637, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1789, Accuracy: 0.9469, F1 Micro: 0.9674, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1558, Accuracy: 0.9514, F1 Micro: 0.9701, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1273, Accuracy: 0.9559, F1 Micro: 0.9728, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1085, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0903, Accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.973\n",
      "Epoch 9/10, Train Loss: 0.0754, Accuracy: 0.9566, F1 Micro: 0.9732, F1 Macro: 0.9706\n",
      "Epoch 10/10, Train Loss: 0.0646, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9729\n",
      "\n",
      "Aspect detection accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.973\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.414, Accuracy: 0.8574, F1 Micro: 0.8574, F1 Macro: 0.8173\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2455, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.18, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1309, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8803\n",
      "Epoch 5/10, Train Loss: 0.0881, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.075, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.884\n",
      "Epoch 7/10, Train Loss: 0.0526, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8816\n",
      "Epoch 8/10, Train Loss: 0.0464, Accuracy: 0.8972, F1 Micro: 0.8972, F1 Macro: 0.8641\n",
      "Epoch 9/10, Train Loss: 0.0483, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8824\n",
      "Epoch 10/10, Train Loss: 0.0231, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8757\n",
      "\n",
      "Sentiment analysis accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       766\n",
      "    positive       0.91      0.76      0.83       314\n",
      "\n",
      "    accuracy                           0.91      1080\n",
      "   macro avg       0.91      0.87      0.88      1080\n",
      "weighted avg       0.91      0.91      0.91      1080\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9536, F1 Micro: 0.9536, F1 Macro: 0.8496\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.86      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.82      0.84       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.79      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.84      0.63      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.54      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.89      0.88       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.86      0.88      0.87        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.89      0.89       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.60      0.41      0.49        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.80      0.74      0.77       571\n",
      "weighted avg       0.90      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.55      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.75      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.67      0.67      0.67         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.86      0.86      0.86       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 259.7569417953491 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 77\n",
      "Sampling duration: 0.00012755393981933594 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4673, Accuracy: 0.8406, F1 Micro: 0.9082, F1 Macro: 0.9019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3373, Accuracy: 0.9151, F1 Micro: 0.9489, F1 Macro: 0.9457\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2323, Accuracy: 0.9408, F1 Micro: 0.9637, F1 Macro: 0.9607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1797, Accuracy: 0.9434, F1 Micro: 0.9655, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1459, Accuracy: 0.954, F1 Micro: 0.9716, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1259, Accuracy: 0.9576, F1 Micro: 0.9738, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1055, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.974\n",
      "Epoch 8/10, Train Loss: 0.0904, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0733, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.066, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.91      0.97      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3899, Accuracy: 0.8666, F1 Micro: 0.8666, F1 Macro: 0.8182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2273, Accuracy: 0.8974, F1 Micro: 0.8974, F1 Macro: 0.8635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1771, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1248, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8877\n",
      "Epoch 5/10, Train Loss: 0.094, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0646, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0425, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.8925\n",
      "Epoch 8/10, Train Loss: 0.0344, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8874\n",
      "Epoch 9/10, Train Loss: 0.0389, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8898\n",
      "Epoch 10/10, Train Loss: 0.0351, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8881\n",
      "\n",
      "Sentiment analysis accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.8925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94       764\n",
      "    positive       0.92      0.78      0.84       308\n",
      "\n",
      "    accuracy                           0.92      1072\n",
      "   macro avg       0.92      0.88      0.89      1072\n",
      "weighted avg       0.92      0.92      0.91      1072\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9581, F1 Micro: 0.9581, F1 Macro: 0.8545\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.92      0.91        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.77      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.78      0.81        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.59       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.90      0.95      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87       162\n",
      "     neutral       0.96      0.96      0.96       387\n",
      "    positive       1.00      0.23      0.37        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.93      0.70      0.73       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.93      0.97      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.66      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.59      0.69        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.75      0.79       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 270.8658330440521 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 70\n",
      "Sampling duration: 0.00012159347534179688 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4714, Accuracy: 0.8465, F1 Micro: 0.9119, F1 Macro: 0.9069\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.319, Accuracy: 0.9205, F1 Micro: 0.9521, F1 Macro: 0.9487\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2252, Accuracy: 0.9427, F1 Micro: 0.965, F1 Macro: 0.9629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.173, Accuracy: 0.9519, F1 Micro: 0.9705, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1494, Accuracy: 0.954, F1 Micro: 0.9717, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1154, Accuracy: 0.9545, F1 Micro: 0.972, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1045, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.974\n",
      "Epoch 8/10, Train Loss: 0.0871, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9725\n",
      "Epoch 9/10, Train Loss: 0.0731, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9739\n",
      "Epoch 10/10, Train Loss: 0.0613, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9736\n",
      "\n",
      "Aspect detection accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.92      0.92      0.92       317\n",
      "       linen       0.95      0.96      0.96       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      0.99      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4151, Accuracy: 0.8555, F1 Micro: 0.8555, F1 Macro: 0.8084\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2446, Accuracy: 0.8773, F1 Micro: 0.8773, F1 Macro: 0.8345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1476, Accuracy: 0.9018, F1 Micro: 0.9018, F1 Macro: 0.8747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1213, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0968, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8773\n",
      "Epoch 6/10, Train Loss: 0.0617, Accuracy: 0.8991, F1 Micro: 0.8991, F1 Macro: 0.8705\n",
      "Epoch 7/10, Train Loss: 0.0757, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8751\n",
      "Epoch 8/10, Train Loss: 0.0387, Accuracy: 0.9009, F1 Micro: 0.9009, F1 Macro: 0.872\n",
      "Epoch 9/10, Train Loss: 0.0355, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8721\n",
      "Epoch 10/10, Train Loss: 0.0267, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8712\n",
      "\n",
      "Sentiment analysis accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       774\n",
      "    positive       0.92      0.74      0.82       326\n",
      "\n",
      "    accuracy                           0.90      1100\n",
      "   macro avg       0.91      0.86      0.88      1100\n",
      "weighted avg       0.90      0.90      0.90      1100\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9564, F1 Micro: 0.9564, F1 Macro: 0.8612\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       200\n",
      "     neutral       0.94      0.91      0.92       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.91      0.88       162\n",
      "     neutral       0.95      0.96      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.77      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.45      0.58        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.64      0.82      0.72        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.76      0.76       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      1.00      0.98        74\n",
      "     neutral       1.00      0.99      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 277.92710423469543 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 52\n",
      "Sampling duration: 0.01705026626586914 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4697, Accuracy: 0.8438, F1 Micro: 0.91, F1 Macro: 0.9048\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.311, Accuracy: 0.9201, F1 Micro: 0.9519, F1 Macro: 0.9491\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2181, Accuracy: 0.9424, F1 Micro: 0.9649, F1 Macro: 0.9625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1701, Accuracy: 0.9526, F1 Micro: 0.9708, F1 Macro: 0.9685\n",
      "Epoch 5/10, Train Loss: 0.1436, Accuracy: 0.9517, F1 Micro: 0.9704, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1167, Accuracy: 0.958, F1 Micro: 0.974, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0992, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0842, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9748\n",
      "Epoch 9/10, Train Loss: 0.0659, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9742\n",
      "Epoch 10/10, Train Loss: 0.06, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9738\n",
      "\n",
      "Aspect detection accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.92      0.95      0.93       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3895, Accuracy: 0.8606, F1 Micro: 0.8606, F1 Macro: 0.8161\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2296, Accuracy: 0.8868, F1 Micro: 0.8868, F1 Macro: 0.8465\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1648, Accuracy: 0.9018, F1 Micro: 0.9018, F1 Macro: 0.8671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1228, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0821, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8858\n",
      "Epoch 6/10, Train Loss: 0.0631, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0588, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.039, Accuracy: 0.9196, F1 Micro: 0.9196, F1 Macro: 0.8947\n",
      "Epoch 9/10, Train Loss: 0.0209, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8762\n",
      "Epoch 10/10, Train Loss: 0.0445, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.8928\n",
      "\n",
      "Sentiment analysis accuracy: 0.9196, F1 Micro: 0.9196, F1 Macro: 0.8947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       766\n",
      "    positive       0.94      0.77      0.84       303\n",
      "\n",
      "    accuracy                           0.92      1069\n",
      "   macro avg       0.93      0.87      0.89      1069\n",
      "weighted avg       0.92      0.92      0.92      1069\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9548, F1 Micro: 0.9548, F1 Macro: 0.8677\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.81      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.06      0.14      0.09         7\n",
      "     neutral       0.95      0.97      0.96       496\n",
      "    positive       0.88      0.62      0.72        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.63      0.58      0.59       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.88       200\n",
      "     neutral       0.93      0.92      0.93       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.90      0.88       162\n",
      "     neutral       0.96      0.96      0.96       387\n",
      "    positive       0.64      0.41      0.50        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.82      0.76      0.78       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.86      0.84        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.95      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 285.5931751728058 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 58\n",
      "Sampling duration: 0.00013017654418945312 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4657, Accuracy: 0.8583, F1 Micro: 0.9181, F1 Macro: 0.9137\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3061, Accuracy: 0.929, F1 Micro: 0.9567, F1 Macro: 0.9532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2122, Accuracy: 0.9441, F1 Micro: 0.9657, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1716, Accuracy: 0.9521, F1 Micro: 0.9705, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1339, Accuracy: 0.9554, F1 Micro: 0.9725, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1168, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0949, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "Epoch 8/10, Train Loss: 0.0792, Accuracy: 0.9585, F1 Micro: 0.9743, F1 Macro: 0.9721\n",
      "Epoch 9/10, Train Loss: 0.0705, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9743\n",
      "Epoch 10/10, Train Loss: 0.0571, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9734\n",
      "\n",
      "Aspect detection accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3803, Accuracy: 0.8638, F1 Micro: 0.8638, F1 Macro: 0.8228\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2523, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.163, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8819\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1324, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8871\n",
      "Epoch 5/10, Train Loss: 0.0915, Accuracy: 0.9034, F1 Micro: 0.9034, F1 Macro: 0.8718\n",
      "Epoch 6/10, Train Loss: 0.0682, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.883\n",
      "Epoch 7/10, Train Loss: 0.051, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8759\n",
      "Epoch 8/10, Train Loss: 0.0447, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.88\n",
      "Epoch 9/10, Train Loss: 0.053, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0276, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8859\n",
      "\n",
      "Sentiment analysis accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8859\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       776\n",
      "    positive       0.93      0.75      0.83       311\n",
      "\n",
      "    accuracy                           0.91      1087\n",
      "   macro avg       0.92      0.86      0.89      1087\n",
      "weighted avg       0.91      0.91      0.91      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.8737\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.92      0.91        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.84      0.62      0.71        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.53      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.83      0.96      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.90      0.87       162\n",
      "     neutral       0.95      0.95      0.95       387\n",
      "    positive       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.78      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 285.39997696876526 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 52\n",
      "Sampling duration: 0.00013208389282226562 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4623, Accuracy: 0.8559, F1 Micro: 0.9151, F1 Macro: 0.9048\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3041, Accuracy: 0.9271, F1 Micro: 0.9555, F1 Macro: 0.9519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2118, Accuracy: 0.9427, F1 Micro: 0.965, F1 Macro: 0.9626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1669, Accuracy: 0.9531, F1 Micro: 0.9712, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1366, Accuracy: 0.9543, F1 Micro: 0.9719, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1169, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9741\n",
      "Epoch 7/10, Train Loss: 0.094, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0836, Accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9771\n",
      "Epoch 9/10, Train Loss: 0.0689, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9752\n",
      "Epoch 10/10, Train Loss: 0.0587, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3688, Accuracy: 0.8634, F1 Micro: 0.8634, F1 Macro: 0.8308\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2206, Accuracy: 0.8944, F1 Micro: 0.8944, F1 Macro: 0.8635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1748, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1238, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0876, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0859, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0595, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8863\n",
      "Epoch 8/10, Train Loss: 0.0384, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8808\n",
      "Epoch 9/10, Train Loss: 0.0355, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8826\n",
      "Epoch 10/10, Train Loss: 0.0389, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.885\n",
      "\n",
      "Sentiment analysis accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       783\n",
      "    positive       0.93      0.75      0.83       315\n",
      "\n",
      "    accuracy                           0.91      1098\n",
      "   macro avg       0.92      0.86      0.89      1098\n",
      "weighted avg       0.91      0.91      0.91      1098\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.8668\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.76      0.79       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.20      0.14      0.17         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.67      0.61      0.64       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.73      0.77       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.87      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.84      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 299.2190499305725 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.00010633468627929688 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.461, Accuracy: 0.8613, F1 Micro: 0.9187, F1 Macro: 0.9123\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2984, Accuracy: 0.9297, F1 Micro: 0.9572, F1 Macro: 0.954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2044, Accuracy: 0.9443, F1 Micro: 0.9658, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1602, Accuracy: 0.954, F1 Micro: 0.9716, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.131, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1098, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9738\n",
      "Epoch 7/10, Train Loss: 0.0916, Accuracy: 0.9615, F1 Micro: 0.9762, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0789, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9754\n",
      "Epoch 9/10, Train Loss: 0.0674, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0561, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.95      0.97      0.96       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3703, Accuracy: 0.8353, F1 Micro: 0.8353, F1 Macro: 0.7544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2116, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1372, Accuracy: 0.9034, F1 Micro: 0.9034, F1 Macro: 0.8702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0937, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8869\n",
      "Epoch 5/10, Train Loss: 0.0959, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8785\n",
      "Epoch 6/10, Train Loss: 0.0582, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8832\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0428, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8875\n",
      "Epoch 8/10, Train Loss: 0.0286, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8775\n",
      "Epoch 9/10, Train Loss: 0.039, Accuracy: 0.9034, F1 Micro: 0.9034, F1 Macro: 0.877\n",
      "Epoch 10/10, Train Loss: 0.0272, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8843\n",
      "\n",
      "Sentiment analysis accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       779\n",
      "    positive       0.94      0.75      0.83       308\n",
      "\n",
      "    accuracy                           0.91      1087\n",
      "   macro avg       0.92      0.86      0.89      1087\n",
      "weighted avg       0.92      0.91      0.91      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9578, F1 Micro: 0.9578, F1 Macro: 0.8692\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.90      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.75      1.00      0.86        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.96      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.77      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.83      0.92      0.86       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.93      0.99      0.96       496\n",
      "    positive       0.85      0.59      0.70        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.93      0.57      0.64       571\n",
      "weighted avg       0.93      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89       162\n",
      "     neutral       0.95      0.97      0.96       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.77      0.82       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.88      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 306.7923300266266 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.00010347366333007812 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4527, Accuracy: 0.8653, F1 Micro: 0.9218, F1 Macro: 0.9175\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2868, Accuracy: 0.9276, F1 Micro: 0.9561, F1 Macro: 0.9529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2064, Accuracy: 0.9467, F1 Micro: 0.9673, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1555, Accuracy: 0.953, F1 Micro: 0.971, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1245, Accuracy: 0.9609, F1 Micro: 0.9757, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1083, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9741\n",
      "Epoch 7/10, Train Loss: 0.0891, Accuracy: 0.9602, F1 Micro: 0.9755, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0746, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0628, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.053, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.92      0.95      0.93       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3821, Accuracy: 0.8682, F1 Micro: 0.8682, F1 Macro: 0.823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2164, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1527, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1018, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.898\n",
      "Epoch 5/10, Train Loss: 0.0718, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8914\n",
      "Epoch 6/10, Train Loss: 0.052, Accuracy: 0.9178, F1 Micro: 0.9178, F1 Macro: 0.8938\n",
      "Epoch 7/10, Train Loss: 0.0451, Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.8921\n",
      "Epoch 8/10, Train Loss: 0.0392, Accuracy: 0.9187, F1 Micro: 0.9187, F1 Macro: 0.8954\n",
      "Epoch 9/10, Train Loss: 0.0244, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8842\n",
      "Epoch 10/10, Train Loss: 0.0195, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.8906\n",
      "\n",
      "Sentiment analysis accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       763\n",
      "    positive       0.93      0.79      0.85       307\n",
      "\n",
      "    accuracy                           0.92      1070\n",
      "   macro avg       0.92      0.88      0.90      1070\n",
      "weighted avg       0.92      0.92      0.92      1070\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9573, F1 Micro: 0.9573, F1 Macro: 0.8707\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.85      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.55      0.60      0.57        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.81      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.83      0.88       200\n",
      "     neutral       0.92      0.95      0.93       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.75      0.79       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.88      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 311.2458815574646 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.751319885253906e-05 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4475, Accuracy: 0.878, F1 Micro: 0.9276, F1 Macro: 0.9217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2821, Accuracy: 0.9335, F1 Micro: 0.9593, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1995, Accuracy: 0.9469, F1 Micro: 0.9674, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1609, Accuracy: 0.9521, F1 Micro: 0.9706, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1319, Accuracy: 0.9549, F1 Micro: 0.9721, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1064, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0845, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9746\n",
      "Epoch 8/10, Train Loss: 0.0764, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0627, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0529, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.93       317\n",
      "       linen       0.95      0.96      0.96       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3725, Accuracy: 0.8557, F1 Micro: 0.8557, F1 Macro: 0.8253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2152, Accuracy: 0.8986, F1 Micro: 0.8986, F1 Macro: 0.8719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1386, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8799\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0976, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0856, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8901\n",
      "Epoch 6/10, Train Loss: 0.0511, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8898\n",
      "Epoch 7/10, Train Loss: 0.0399, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0324, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.8924\n",
      "Epoch 9/10, Train Loss: 0.0241, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8851\n",
      "Epoch 10/10, Train Loss: 0.0199, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.885\n",
      "\n",
      "Sentiment analysis accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.8924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       776\n",
      "    positive       0.93      0.77      0.84       319\n",
      "\n",
      "    accuracy                           0.92      1095\n",
      "   macro avg       0.92      0.87      0.89      1095\n",
      "weighted avg       0.92      0.92      0.91      1095\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9571, F1 Micro: 0.9571, F1 Macro: 0.866\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.97      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.58      0.70      0.64        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.86      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.78      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.67      0.73       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.88       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.88       162\n",
      "     neutral       0.95      0.97      0.96       387\n",
      "    positive       0.60      0.55      0.57        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.81      0.79      0.80       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.89      0.77      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.83      0.88        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.45      0.83      0.59         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.79      0.89      0.82       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 316.89110350608826 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 25\n",
      "Sampling duration: 0.020001888275146484 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4487, Accuracy: 0.8689, F1 Micro: 0.9235, F1 Macro: 0.919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2804, Accuracy: 0.9314, F1 Micro: 0.9582, F1 Macro: 0.9553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1979, Accuracy: 0.9415, F1 Micro: 0.9644, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1575, Accuracy: 0.9516, F1 Micro: 0.9702, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1283, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1051, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "Epoch 7/10, Train Loss: 0.0925, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0735, Accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9771\n",
      "Epoch 9/10, Train Loss: 0.0619, Accuracy: 0.9637, F1 Micro: 0.9774, F1 Macro: 0.9752\n",
      "Epoch 10/10, Train Loss: 0.0514, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.96      0.92      0.94       317\n",
      "       linen       0.95      0.97      0.96       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3674, Accuracy: 0.8279, F1 Micro: 0.8279, F1 Macro: 0.8039\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2311, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1753, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8894\n",
      "Epoch 4/10, Train Loss: 0.1332, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0861, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8949\n",
      "Epoch 6/10, Train Loss: 0.0854, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8859\n",
      "Epoch 7/10, Train Loss: 0.0551, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0493, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.8974\n",
      "Epoch 9/10, Train Loss: 0.0501, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8846\n",
      "Epoch 10/10, Train Loss: 0.034, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8934\n",
      "\n",
      "Sentiment analysis accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.8974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       779\n",
      "    positive       0.94      0.78      0.85       325\n",
      "\n",
      "    accuracy                           0.92      1104\n",
      "   macro avg       0.93      0.88      0.90      1104\n",
      "weighted avg       0.92      0.92      0.92      1104\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9587, F1 Micro: 0.9587, F1 Macro: 0.8692\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.78      0.80        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.94      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.20      0.14      0.17         7\n",
      "     neutral       0.97      0.97      0.97       496\n",
      "    positive       0.84      0.82      0.83        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.67      0.65      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.92      0.91       200\n",
      "     neutral       0.96      0.92      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.94      0.93       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.87       162\n",
      "     neutral       0.95      0.97      0.96       387\n",
      "    positive       0.75      0.41      0.53        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.86      0.75      0.79       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.52      0.61        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.68      0.76      0.72        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.76      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 315.81645607948303 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.00016808509826660156 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4485, Accuracy: 0.8726, F1 Micro: 0.9253, F1 Macro: 0.9199\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2741, Accuracy: 0.9267, F1 Micro: 0.9554, F1 Macro: 0.9513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1979, Accuracy: 0.95, F1 Micro: 0.9693, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1555, Accuracy: 0.9545, F1 Micro: 0.9719, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1222, Accuracy: 0.9611, F1 Micro: 0.976, F1 Macro: 0.9736\n",
      "Epoch 6/10, Train Loss: 0.1065, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.088, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9761\n",
      "Epoch 8/10, Train Loss: 0.0703, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9751\n",
      "Epoch 9/10, Train Loss: 0.0591, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0511, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.94      0.97      0.96       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3708, Accuracy: 0.8684, F1 Micro: 0.8684, F1 Macro: 0.8186\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2094, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1358, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0846, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8894\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0707, Accuracy: 0.9236, F1 Micro: 0.9236, F1 Macro: 0.9003\n",
      "Epoch 6/10, Train Loss: 0.0495, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8897\n",
      "Epoch 7/10, Train Loss: 0.0346, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8899\n",
      "Epoch 8/10, Train Loss: 0.0379, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8909\n",
      "Epoch 9/10, Train Loss: 0.0358, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8883\n",
      "Epoch 10/10, Train Loss: 0.0134, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8924\n",
      "\n",
      "Sentiment analysis accuracy: 0.9236, F1 Micro: 0.9236, F1 Macro: 0.9003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       780\n",
      "    positive       0.94      0.78      0.85       307\n",
      "\n",
      "    accuracy                           0.92      1087\n",
      "   macro avg       0.93      0.88      0.90      1087\n",
      "weighted avg       0.92      0.92      0.92      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9587, F1 Micro: 0.9587, F1 Macro: 0.8689\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.54      0.70      0.61        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.86      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.78      0.69      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.60      0.65       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.87      0.89       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.77      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.84      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.90      0.93      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.82      0.74        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.77      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 322.91667079925537 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.703636169433594e-05 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.448, Accuracy: 0.8701, F1 Micro: 0.9238, F1 Macro: 0.9177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2735, Accuracy: 0.9339, F1 Micro: 0.9598, F1 Macro: 0.9576\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1911, Accuracy: 0.9495, F1 Micro: 0.969, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1526, Accuracy: 0.9585, F1 Micro: 0.9743, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1192, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.105, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0826, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9761\n",
      "Epoch 8/10, Train Loss: 0.0705, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0603, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "Epoch 10/10, Train Loss: 0.0499, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.94      0.97      0.96       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3748, Accuracy: 0.872, F1 Micro: 0.872, F1 Macro: 0.8302\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1921, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1312, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1009, Accuracy: 0.9162, F1 Micro: 0.9162, F1 Macro: 0.8921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0543, Accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8925\n",
      "Epoch 6/10, Train Loss: 0.0527, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8832\n",
      "Epoch 7/10, Train Loss: 0.0427, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8874\n",
      "Epoch 8/10, Train Loss: 0.0289, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8898\n",
      "Epoch 9/10, Train Loss: 0.0339, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.8896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0175, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.8933\n",
      "\n",
      "Sentiment analysis accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.8933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       774\n",
      "    positive       0.94      0.76      0.84       312\n",
      "\n",
      "    accuracy                           0.92      1086\n",
      "   macro avg       0.93      0.87      0.89      1086\n",
      "weighted avg       0.92      0.92      0.92      1086\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8759\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.92      0.92        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.80      0.40      0.53        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.77      0.82       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.12      0.14      0.13         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.64      0.61      0.62       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.89       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.89      0.77      0.81       571\n",
      "weighted avg       0.93      0.93      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 331.6263473033905 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.0001227855682373047 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4427, Accuracy: 0.8724, F1 Micro: 0.9251, F1 Macro: 0.9199\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2676, Accuracy: 0.9347, F1 Micro: 0.9603, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1853, Accuracy: 0.9451, F1 Micro: 0.9664, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1461, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9722\n",
      "Epoch 5/10, Train Loss: 0.1196, Accuracy: 0.9576, F1 Micro: 0.9739, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0966, Accuracy: 0.962, F1 Micro: 0.9765, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0817, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.975\n",
      "Epoch 8/10, Train Loss: 0.0684, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0568, Accuracy: 0.9642, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0475, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.99      0.97       500\n",
      "  kebersihan       0.95      0.94      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3539, Accuracy: 0.8634, F1 Micro: 0.8634, F1 Macro: 0.8231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.193, Accuracy: 0.8834, F1 Micro: 0.8834, F1 Macro: 0.842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1392, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0942, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0741, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0661, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8857\n",
      "Epoch 7/10, Train Loss: 0.05, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0269, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8865\n",
      "Epoch 9/10, Train Loss: 0.03, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0193, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8868\n",
      "\n",
      "Sentiment analysis accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       781\n",
      "    positive       0.95      0.74      0.83       317\n",
      "\n",
      "    accuracy                           0.91      1098\n",
      "   macro avg       0.93      0.86      0.89      1098\n",
      "weighted avg       0.92      0.91      0.91      1098\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.8791\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.92      0.93        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.86      0.84      0.85       571\n",
      "weighted avg       0.97      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.99      0.97       496\n",
      "    positive       0.88      0.75      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.63      0.68       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.90       200\n",
      "     neutral       0.95      0.94      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.94      0.75      0.80       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        85\n",
      "     neutral       0.97      0.96      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.55      0.63        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.77      0.59      0.67        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.71      0.76       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 347.0479118824005 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.131431579589844e-05 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4437, Accuracy: 0.8793, F1 Micro: 0.9285, F1 Macro: 0.9218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2667, Accuracy: 0.9332, F1 Micro: 0.9594, F1 Macro: 0.957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1901, Accuracy: 0.9464, F1 Micro: 0.9672, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1511, Accuracy: 0.9571, F1 Micro: 0.9736, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1192, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.098, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0843, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0707, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0572, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0477, Accuracy: 0.9674, F1 Micro: 0.9797, F1 Macro: 0.9777\n",
      "\n",
      "Aspect detection accuracy: 0.9674, F1 Micro: 0.9797, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3548, Accuracy: 0.8621, F1 Micro: 0.8621, F1 Macro: 0.8123\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2051, Accuracy: 0.9014, F1 Micro: 0.9014, F1 Macro: 0.8707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1403, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1097, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8888\n",
      "Epoch 5/10, Train Loss: 0.0546, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.053, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.8969\n",
      "Epoch 7/10, Train Loss: 0.0388, Accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.8855\n",
      "Epoch 8/10, Train Loss: 0.0328, Accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.8867\n",
      "Epoch 9/10, Train Loss: 0.0265, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.8924\n",
      "Epoch 10/10, Train Loss: 0.0198, Accuracy: 0.9196, F1 Micro: 0.9196, F1 Macro: 0.8959\n",
      "\n",
      "Sentiment analysis accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.8969\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       780\n",
      "    positive       0.95      0.77      0.85       315\n",
      "\n",
      "    accuracy                           0.92      1095\n",
      "   macro avg       0.93      0.88      0.90      1095\n",
      "weighted avg       0.92      0.92      0.92      1095\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9611, F1 Micro: 0.9611, F1 Macro: 0.8852\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.77      0.79       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.76      0.80        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.68      0.74       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.87      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       1.00      0.36      0.53        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.93      0.73      0.78       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.84      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 343.55405378341675 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.00011587142944335938 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4393, Accuracy: 0.8884, F1 Micro: 0.9335, F1 Macro: 0.9278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2603, Accuracy: 0.9375, F1 Micro: 0.9618, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1888, Accuracy: 0.9498, F1 Micro: 0.9693, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1447, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1142, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0976, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.08, Accuracy: 0.9639, F1 Micro: 0.9775, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0673, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9767\n",
      "Epoch 9/10, Train Loss: 0.0569, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0485, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3462, Accuracy: 0.8807, F1 Micro: 0.8807, F1 Macro: 0.8435\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.199, Accuracy: 0.8962, F1 Micro: 0.8962, F1 Macro: 0.8614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1415, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8892\n",
      "Epoch 4/10, Train Loss: 0.0905, Accuracy: 0.8953, F1 Micro: 0.8953, F1 Macro: 0.8714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0855, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.8907\n",
      "Epoch 6/10, Train Loss: 0.0588, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0454, Accuracy: 0.9199, F1 Micro: 0.9199, F1 Macro: 0.8971\n",
      "Epoch 8/10, Train Loss: 0.0335, Accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8935\n",
      "Epoch 9/10, Train Loss: 0.0211, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8828\n",
      "Epoch 10/10, Train Loss: 0.0319, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8908\n",
      "\n",
      "Sentiment analysis accuracy: 0.9199, F1 Micro: 0.9199, F1 Macro: 0.8971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       781\n",
      "    positive       0.93      0.78      0.85       317\n",
      "\n",
      "    accuracy                           0.92      1098\n",
      "   macro avg       0.92      0.88      0.90      1098\n",
      "weighted avg       0.92      0.92      0.92      1098\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.8762\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.78      0.93      0.85        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.85      0.84      0.84       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.83      0.79      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.64      0.68       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.89       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.82      0.98      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.87       162\n",
      "     neutral       0.93      0.98      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.74      0.79       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.89      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.76      0.80       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 351.09715032577515 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 36\n",
      "Sampling duration: 0.02053046226501465 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4284, Accuracy: 0.8872, F1 Micro: 0.9329, F1 Macro: 0.927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2627, Accuracy: 0.9429, F1 Micro: 0.965, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1816, Accuracy: 0.951, F1 Micro: 0.9699, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1406, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1149, Accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0967, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0805, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "Epoch 8/10, Train Loss: 0.0658, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9758\n",
      "Epoch 9/10, Train Loss: 0.0569, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9756\n",
      "Epoch 10/10, Train Loss: 0.0468, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.92      0.98      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3478, Accuracy: 0.8647, F1 Micro: 0.8647, F1 Macro: 0.8157\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1862, Accuracy: 0.8921, F1 Micro: 0.8921, F1 Macro: 0.856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1361, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1037, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.893\n",
      "Epoch 5/10, Train Loss: 0.0715, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.8905\n",
      "Epoch 6/10, Train Loss: 0.0738, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8845\n",
      "Epoch 7/10, Train Loss: 0.0444, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8853\n",
      "Epoch 8/10, Train Loss: 0.0335, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8853\n",
      "Epoch 9/10, Train Loss: 0.0327, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8869\n",
      "Epoch 10/10, Train Loss: 0.0173, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8835\n",
      "\n",
      "Sentiment analysis accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       778\n",
      "    positive       0.95      0.76      0.84       316\n",
      "\n",
      "    accuracy                           0.92      1094\n",
      "   macro avg       0.93      0.87      0.89      1094\n",
      "weighted avg       0.92      0.92      0.91      1094\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9578, F1 Micro: 0.9578, F1 Macro: 0.8721\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.86      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.20      0.14      0.17         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.86      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.67      0.62      0.64       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.73      0.77       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.92      0.90      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.72      0.74        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.59      0.69        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.77      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 344.3136372566223 s\n",
      "Total runtime: 7022.898129701614 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2682b001",
   "metadata": {
    "papermill": {
     "duration": 0.011773,
     "end_time": "2025-04-20T08:36:52.742201",
     "exception": false,
     "start_time": "2025-04-20T08:36:52.730428",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5226bf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:36:52.766816Z",
     "iopub.status.busy": "2025-04-20T08:36:52.766605Z",
     "iopub.status.idle": "2025-04-20T10:29:31.127793Z",
     "shell.execute_reply": "2025-04-20T10:29:31.126919Z"
    },
    "papermill": {
     "duration": 6758.374969,
     "end_time": "2025-04-20T10:29:31.129250",
     "exception": false,
     "start_time": "2025-04-20T08:36:52.754281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6072, Accuracy: 0.7955, F1 Micro: 0.8818, F1 Macro: 0.8546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4916, Accuracy: 0.8016, F1 Micro: 0.8877, F1 Macro: 0.8774\n",
      "Epoch 3/10, Train Loss: 0.453, Accuracy: 0.8024, F1 Micro: 0.8857, F1 Macro: 0.8609\n",
      "Epoch 4/10, Train Loss: 0.4515, Accuracy: 0.8021, F1 Micro: 0.8849, F1 Macro: 0.8543\n",
      "Epoch 5/10, Train Loss: 0.417, Accuracy: 0.8047, F1 Micro: 0.8868, F1 Macro: 0.862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4402, Accuracy: 0.8092, F1 Micro: 0.8902, F1 Macro: 0.874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3799, Accuracy: 0.8141, F1 Micro: 0.8937, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3851, Accuracy: 0.8252, F1 Micro: 0.899, F1 Macro: 0.8873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3532, Accuracy: 0.8361, F1 Micro: 0.9044, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3254, Accuracy: 0.8502, F1 Micro: 0.9121, F1 Macro: 0.9018\n",
      "\n",
      "Aspect detection accuracy: 0.8502, F1 Micro: 0.9121, F1 Macro: 0.9018\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.86      1.00      0.93       462\n",
      "   air_panas       0.90      0.99      0.94       480\n",
      "         bau       0.87      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.77      0.66      0.71       317\n",
      "       linen       0.74      0.98      0.84       392\n",
      "     service       0.82      0.98      0.89       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.89      1.00      0.94       498\n",
      "\n",
      "   micro avg       0.86      0.97      0.91      4614\n",
      "   macro avg       0.85      0.96      0.90      4614\n",
      "weighted avg       0.86      0.97      0.91      4614\n",
      " samples avg       0.86      0.97      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5988, Accuracy: 0.6204, F1 Micro: 0.6204, F1 Macro: 0.3829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5281, Accuracy: 0.6204, F1 Micro: 0.6204, F1 Macro: 0.3829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4888, Accuracy: 0.6259, F1 Micro: 0.6259, F1 Macro: 0.4027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3707, Accuracy: 0.6861, F1 Micro: 0.6861, F1 Macro: 0.5752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3492, Accuracy: 0.7336, F1 Micro: 0.7336, F1 Macro: 0.6917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2739, Accuracy: 0.7372, F1 Micro: 0.7372, F1 Macro: 0.7005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3739, Accuracy: 0.7409, F1 Micro: 0.7409, F1 Macro: 0.7103\n",
      "Epoch 8/10, Train Loss: 0.2974, Accuracy: 0.7281, F1 Micro: 0.7281, F1 Macro: 0.6718\n",
      "Epoch 9/10, Train Loss: 0.18, Accuracy: 0.7372, F1 Micro: 0.7372, F1 Macro: 0.703\n",
      "Epoch 10/10, Train Loss: 0.1429, Accuracy: 0.7281, F1 Micro: 0.7281, F1 Macro: 0.6706\n",
      "\n",
      "Sentiment analysis accuracy: 0.7409, F1 Micro: 0.7409, F1 Macro: 0.7103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.86      0.80       340\n",
      "    positive       0.70      0.55      0.62       208\n",
      "\n",
      "    accuracy                           0.74       548\n",
      "   macro avg       0.73      0.70      0.71       548\n",
      "weighted avg       0.74      0.74      0.73       548\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8408, F1 Micro: 0.8408, F1 Macro: 0.4385\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.36      0.51        97\n",
      "     neutral       0.87      1.00      0.93       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.58      0.45      0.48       571\n",
      "weighted avg       0.84      0.86      0.83       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.48      0.60        86\n",
      "     neutral       0.90      0.99      0.94       475\n",
      "    positive       1.00      0.10      0.18        10\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.90      0.52      0.57       571\n",
      "weighted avg       0.89      0.89      0.88       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.12      0.20        78\n",
      "     neutral       0.87      1.00      0.93       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.59      0.37      0.38       571\n",
      "weighted avg       0.87      0.87      0.83       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.73      0.66       200\n",
      "     neutral       0.77      0.66      0.71       315\n",
      "    positive       0.32      0.36      0.34        56\n",
      "\n",
      "    accuracy                           0.65       571\n",
      "   macro avg       0.57      0.58      0.57       571\n",
      "weighted avg       0.67      0.65      0.66       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.30      0.44       162\n",
      "     neutral       0.74      0.98      0.84       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.75       571\n",
      "   macro avg       0.53      0.43      0.43       571\n",
      "weighted avg       0.74      0.75      0.70       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.20      0.32        85\n",
      "     neutral       0.81      0.98      0.89       418\n",
      "    positive       0.61      0.41      0.49        68\n",
      "\n",
      "    accuracy                           0.80       571\n",
      "   macro avg       0.74      0.53      0.57       571\n",
      "weighted avg       0.79      0.80      0.76       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.24      0.39        74\n",
      "     neutral       0.89      1.00      0.94       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.61      0.41      0.44       571\n",
      "weighted avg       0.90      0.89      0.87       571\n",
      "\n",
      "Total train time: 79.21548271179199 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 215\n",
      "Sampling duration: 0.00023794174194335938 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5367, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4661, Accuracy: 0.8064, F1 Micro: 0.892, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4394, Accuracy: 0.808, F1 Micro: 0.8929, F1 Macro: 0.8882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3944, Accuracy: 0.8491, F1 Micro: 0.9122, F1 Macro: 0.9038\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3347, Accuracy: 0.8793, F1 Micro: 0.9282, F1 Macro: 0.9206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.293, Accuracy: 0.8922, F1 Micro: 0.9353, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2488, Accuracy: 0.9089, F1 Micro: 0.9451, F1 Macro: 0.9406\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2165, Accuracy: 0.9153, F1 Micro: 0.9488, F1 Macro: 0.9451\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1902, Accuracy: 0.9233, F1 Micro: 0.9536, F1 Macro: 0.9507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1639, Accuracy: 0.9288, F1 Micro: 0.9567, F1 Macro: 0.9533\n",
      "\n",
      "Aspect detection accuracy: 0.9288, F1 Micro: 0.9567, F1 Macro: 0.9533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.98       462\n",
      "   air_panas       0.96      0.99      0.97       480\n",
      "         bau       0.95      0.98      0.96       496\n",
      "     general       0.89      0.99      0.93       500\n",
      "  kebersihan       0.87      0.90      0.88       317\n",
      "       linen       0.84      0.98      0.90       392\n",
      "     service       0.94      0.96      0.95       423\n",
      "sunrise_meal       0.94      1.00      0.97       530\n",
      "          tv       0.96      1.00      0.98       516\n",
      "        wifi       0.98      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.93      0.98      0.96      4614\n",
      "   macro avg       0.93      0.98      0.95      4614\n",
      "weighted avg       0.93      0.98      0.96      4614\n",
      " samples avg       0.93      0.98      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5315, Accuracy: 0.7316, F1 Micro: 0.7316, F1 Macro: 0.4225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4009, Accuracy: 0.8018, F1 Micro: 0.8018, F1 Macro: 0.7148\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3026, Accuracy: 0.8363, F1 Micro: 0.8363, F1 Macro: 0.7532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2403, Accuracy: 0.8552, F1 Micro: 0.8552, F1 Macro: 0.8031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2202, Accuracy: 0.8586, F1 Micro: 0.8586, F1 Macro: 0.8109\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1653, Accuracy: 0.863, F1 Micro: 0.863, F1 Macro: 0.7982\n",
      "Epoch 7/10, Train Loss: 0.1368, Accuracy: 0.8541, F1 Micro: 0.8541, F1 Macro: 0.7866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0687, Accuracy: 0.8753, F1 Micro: 0.8753, F1 Macro: 0.8265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1194, Accuracy: 0.8753, F1 Micro: 0.8753, F1 Macro: 0.8304\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0983, Accuracy: 0.8786, F1 Micro: 0.8786, F1 Macro: 0.8391\n",
      "\n",
      "Sentiment analysis accuracy: 0.8786, F1 Micro: 0.8786, F1 Macro: 0.8391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92       657\n",
      "    positive       0.81      0.71      0.76       241\n",
      "\n",
      "    accuracy                           0.88       898\n",
      "   macro avg       0.86      0.83      0.84       898\n",
      "weighted avg       0.88      0.88      0.88       898\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.7032\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        97\n",
      "     neutral       0.98      0.99      0.98       459\n",
      "    positive       0.80      0.53      0.64        15\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.90      0.81      0.85       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.78      0.84        86\n",
      "     neutral       0.96      0.99      0.97       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.84      0.72      0.77       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.65      0.74        78\n",
      "     neutral       0.95      0.98      0.96       491\n",
      "    positive       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.71      0.71      0.70       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.89      0.99      0.94       496\n",
      "    positive       0.68      0.19      0.30        68\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.52      0.39      0.41       571\n",
      "weighted avg       0.85      0.88      0.85       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.78      0.82       200\n",
      "     neutral       0.87      0.90      0.88       315\n",
      "    positive       0.62      0.73      0.67        56\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.78      0.80      0.79       571\n",
      "weighted avg       0.84      0.84      0.84       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.64      0.75       162\n",
      "     neutral       0.84      0.98      0.90       387\n",
      "    positive       0.50      0.09      0.15        22\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.75      0.57      0.60       571\n",
      "weighted avg       0.85      0.85      0.83       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.60      0.72        85\n",
      "     neutral       0.94      0.96      0.95       418\n",
      "    positive       0.66      0.84      0.74        68\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.84      0.80      0.80       571\n",
      "weighted avg       0.90      0.89      0.89       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.10      0.19        29\n",
      "     neutral       0.94      1.00      0.97       525\n",
      "    positive       0.75      0.53      0.62        17\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.54      0.59       571\n",
      "weighted avg       0.94      0.94      0.92       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.65      0.77        54\n",
      "     neutral       0.96      1.00      0.98       511\n",
      "    positive       0.50      0.33      0.40         6\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.80      0.66      0.72       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        74\n",
      "     neutral       0.98      1.00      0.99       494\n",
      "    positive       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.97      0.74      0.80       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 120.3307511806488 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 193\n",
      "Sampling duration: 0.00020194053649902344 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5227, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.444, Accuracy: 0.817, F1 Micro: 0.8966, F1 Macro: 0.8908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3887, Accuracy: 0.8648, F1 Micro: 0.9204, F1 Macro: 0.9127\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3207, Accuracy: 0.8925, F1 Micro: 0.9359, F1 Macro: 0.9299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2635, Accuracy: 0.9155, F1 Micro: 0.9491, F1 Macro: 0.9453\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2238, Accuracy: 0.9288, F1 Micro: 0.9568, F1 Macro: 0.954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1881, Accuracy: 0.9392, F1 Micro: 0.9628, F1 Macro: 0.96\n",
      "Epoch 8/10, Train Loss: 0.166, Accuracy: 0.9387, F1 Micro: 0.9626, F1 Macro: 0.9597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1422, Accuracy: 0.9422, F1 Micro: 0.9645, F1 Macro: 0.9616\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1263, Accuracy: 0.9458, F1 Micro: 0.9667, F1 Macro: 0.9639\n",
      "\n",
      "Aspect detection accuracy: 0.9458, F1 Micro: 0.9667, F1 Macro: 0.9639\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.95      0.98      0.97       496\n",
      "     general       0.90      0.98      0.94       500\n",
      "  kebersihan       0.90      0.91      0.91       317\n",
      "       linen       0.91      0.95      0.93       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.95      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.97      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4715, Accuracy: 0.741, F1 Micro: 0.741, F1 Macro: 0.4965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3552, Accuracy: 0.8303, F1 Micro: 0.8303, F1 Macro: 0.7381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.26, Accuracy: 0.8414, F1 Micro: 0.8414, F1 Macro: 0.7556\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2172, Accuracy: 0.8474, F1 Micro: 0.8474, F1 Macro: 0.7683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.136, Accuracy: 0.8484, F1 Micro: 0.8484, F1 Macro: 0.7694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1183, Accuracy: 0.8715, F1 Micro: 0.8715, F1 Macro: 0.8133\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0806, Accuracy: 0.8956, F1 Micro: 0.8956, F1 Macro: 0.8569\n",
      "Epoch 8/10, Train Loss: 0.0815, Accuracy: 0.8524, F1 Micro: 0.8524, F1 Macro: 0.7779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0796, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8663\n",
      "Epoch 10/10, Train Loss: 0.0437, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8612\n",
      "\n",
      "Sentiment analysis accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       725\n",
      "    positive       0.91      0.71      0.80       271\n",
      "\n",
      "    accuracy                           0.90       996\n",
      "   macro avg       0.90      0.84      0.87       996\n",
      "weighted avg       0.90      0.90      0.90       996\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.7746\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.91      0.67      0.77        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.95      0.86      0.90       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.79      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.71      0.78        78\n",
      "     neutral       0.95      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.73      0.80       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.90      0.98      0.94       496\n",
      "    positive       0.73      0.32      0.45        68\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.55      0.44      0.46       571\n",
      "weighted avg       0.87      0.89      0.87       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.82      0.85       200\n",
      "     neutral       0.90      0.91      0.91       315\n",
      "    positive       0.80      0.88      0.84        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.86      0.87      0.86       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.83      0.84       162\n",
      "     neutral       0.91      0.95      0.93       387\n",
      "    positive       0.67      0.18      0.29        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.80      0.65      0.68       571\n",
      "weighted avg       0.88      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.79      0.84        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.88      0.88      0.88        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.88      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.21      0.33        29\n",
      "     neutral       0.95      1.00      0.97       525\n",
      "    positive       0.79      0.65      0.71        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.87      0.62      0.67       571\n",
      "weighted avg       0.94      0.95      0.93       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.69      0.73       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.86      0.91       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 142.60848784446716 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 174\n",
      "Sampling duration: 0.00015878677368164062 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.515, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4217, Accuracy: 0.8384, F1 Micro: 0.9076, F1 Macro: 0.9025\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3506, Accuracy: 0.8962, F1 Micro: 0.9377, F1 Macro: 0.9322\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2723, Accuracy: 0.9181, F1 Micro: 0.9504, F1 Macro: 0.9461\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2176, Accuracy: 0.9276, F1 Micro: 0.9562, F1 Macro: 0.9536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1831, Accuracy: 0.9411, F1 Micro: 0.9639, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.16, Accuracy: 0.9425, F1 Micro: 0.9648, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1398, Accuracy: 0.9453, F1 Micro: 0.9665, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1177, Accuracy: 0.9517, F1 Micro: 0.9702, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1032, Accuracy: 0.9535, F1 Micro: 0.9712, F1 Macro: 0.9681\n",
      "\n",
      "Aspect detection accuracy: 0.9535, F1 Micro: 0.9712, F1 Macro: 0.9681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.97      0.95       500\n",
      "  kebersihan       0.92      0.90      0.91       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      0.99      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.97      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4741, Accuracy: 0.7804, F1 Micro: 0.7804, F1 Macro: 0.661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.276, Accuracy: 0.8411, F1 Micro: 0.8411, F1 Macro: 0.7835\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2383, Accuracy: 0.8449, F1 Micro: 0.8449, F1 Macro: 0.8143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1788, Accuracy: 0.872, F1 Micro: 0.872, F1 Macro: 0.8305\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1358, Accuracy: 0.8832, F1 Micro: 0.8832, F1 Macro: 0.8527\n",
      "Epoch 6/10, Train Loss: 0.1155, Accuracy: 0.8673, F1 Micro: 0.8673, F1 Macro: 0.8224\n",
      "Epoch 7/10, Train Loss: 0.0892, Accuracy: 0.8654, F1 Micro: 0.8654, F1 Macro: 0.819\n",
      "Epoch 8/10, Train Loss: 0.0816, Accuracy: 0.8682, F1 Micro: 0.8682, F1 Macro: 0.8211\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0508, Accuracy: 0.885, F1 Micro: 0.885, F1 Macro: 0.8504\n",
      "Epoch 10/10, Train Loss: 0.0408, Accuracy: 0.8804, F1 Micro: 0.8804, F1 Macro: 0.8456\n",
      "\n",
      "Sentiment analysis accuracy: 0.885, F1 Micro: 0.885, F1 Macro: 0.8504\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.97      0.92       751\n",
      "    positive       0.92      0.68      0.78       319\n",
      "\n",
      "    accuracy                           0.89      1070\n",
      "   macro avg       0.90      0.83      0.85      1070\n",
      "weighted avg       0.89      0.89      0.88      1070\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.7719\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.92      0.73      0.81        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.89      0.91       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.50      0.20      0.29        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.79      0.69      0.72       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.79      0.79        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.58      0.59      0.59       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.97      0.95       496\n",
      "    positive       0.73      0.63      0.68        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.56      0.53      0.54       571\n",
      "weighted avg       0.90      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85       200\n",
      "     neutral       0.92      0.90      0.91       315\n",
      "    positive       0.84      0.93      0.88        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.87      0.89      0.88       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.81      0.84       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.44      0.32      0.37        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.75      0.70      0.72       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.74      0.81        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.86      0.90      0.88        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.87      0.89       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.34      0.45        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.71      0.59      0.65        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.78      0.64      0.69       571\n",
      "weighted avg       0.94      0.95      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.82      0.87       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        74\n",
      "     neutral       0.99      0.99      0.99       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 163.3433301448822 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 156\n",
      "Sampling duration: 0.00015854835510253906 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.489, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3986, Accuracy: 0.8731, F1 Micro: 0.9255, F1 Macro: 0.9201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3021, Accuracy: 0.9019, F1 Micro: 0.9417, F1 Macro: 0.9377\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2408, Accuracy: 0.929, F1 Micro: 0.9569, F1 Macro: 0.954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1953, Accuracy: 0.9396, F1 Micro: 0.963, F1 Macro: 0.9604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1685, Accuracy: 0.9465, F1 Micro: 0.9672, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1405, Accuracy: 0.9469, F1 Micro: 0.9675, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1241, Accuracy: 0.9502, F1 Micro: 0.9694, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1025, Accuracy: 0.9538, F1 Micro: 0.9715, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0941, Accuracy: 0.9545, F1 Micro: 0.9719, F1 Macro: 0.9695\n",
      "\n",
      "Aspect detection accuracy: 0.9545, F1 Micro: 0.9719, F1 Macro: 0.9695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.96      0.97      0.96       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.93      0.91      0.92       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4189, Accuracy: 0.7855, F1 Micro: 0.7855, F1 Macro: 0.6377\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2716, Accuracy: 0.8484, F1 Micro: 0.8484, F1 Macro: 0.7856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1854, Accuracy: 0.8847, F1 Micro: 0.8847, F1 Macro: 0.8475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1438, Accuracy: 0.8904, F1 Micro: 0.8904, F1 Macro: 0.8524\n",
      "Epoch 5/10, Train Loss: 0.1165, Accuracy: 0.857, F1 Micro: 0.857, F1 Macro: 0.7944\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.095, Accuracy: 0.8904, F1 Micro: 0.8904, F1 Macro: 0.8512\n",
      "Epoch 7/10, Train Loss: 0.0675, Accuracy: 0.8847, F1 Micro: 0.8847, F1 Macro: 0.8414\n",
      "Epoch 8/10, Train Loss: 0.0564, Accuracy: 0.8837, F1 Micro: 0.8837, F1 Macro: 0.8424\n",
      "Epoch 9/10, Train Loss: 0.0469, Accuracy: 0.8827, F1 Micro: 0.8827, F1 Macro: 0.85\n",
      "Epoch 10/10, Train Loss: 0.053, Accuracy: 0.8789, F1 Micro: 0.8789, F1 Macro: 0.8321\n",
      "\n",
      "Sentiment analysis accuracy: 0.8904, F1 Micro: 0.8904, F1 Macro: 0.8512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93       751\n",
      "    positive       0.93      0.66      0.77       298\n",
      "\n",
      "    accuracy                           0.89      1049\n",
      "   macro avg       0.90      0.82      0.85      1049\n",
      "weighted avg       0.89      0.89      0.88      1049\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.761\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.40      0.20      0.27        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.75      0.69      0.71       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.73      0.76        78\n",
      "     neutral       0.96      0.97      0.96       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.58      0.57      0.57       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.92      0.99      0.95       496\n",
      "    positive       0.86      0.44      0.58        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.70      0.52      0.58       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87       200\n",
      "     neutral       0.93      0.91      0.92       315\n",
      "    positive       0.83      0.88      0.85        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.87      0.89      0.88       571\n",
      "weighted avg       0.90      0.89      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.84       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.60      0.14      0.22        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.79      0.64      0.67       571\n",
      "weighted avg       0.88      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.88      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.95      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.38      0.49        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.75      0.53      0.62        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.80      0.64      0.70       571\n",
      "weighted avg       0.94      0.95      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.70      0.73       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.95      0.95        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 177.62544441223145 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 141\n",
      "Sampling duration: 0.0001506805419921875 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4858, Accuracy: 0.8024, F1 Micro: 0.8902, F1 Macro: 0.8858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3817, Accuracy: 0.8847, F1 Micro: 0.9311, F1 Macro: 0.923\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2768, Accuracy: 0.9198, F1 Micro: 0.9514, F1 Macro: 0.9473\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2124, Accuracy: 0.934, F1 Micro: 0.96, F1 Macro: 0.9574\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1764, Accuracy: 0.9439, F1 Micro: 0.9656, F1 Macro: 0.9629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1462, Accuracy: 0.9469, F1 Micro: 0.9674, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1294, Accuracy: 0.9531, F1 Micro: 0.9711, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1108, Accuracy: 0.9535, F1 Micro: 0.9713, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0949, Accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0821, Accuracy: 0.9564, F1 Micro: 0.9731, F1 Macro: 0.9708\n",
      "\n",
      "Aspect detection accuracy: 0.9564, F1 Micro: 0.9731, F1 Macro: 0.9708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.92      0.99      0.96       500\n",
      "  kebersihan       0.90      0.95      0.92       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.99      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4429, Accuracy: 0.8293, F1 Micro: 0.8293, F1 Macro: 0.7719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2549, Accuracy: 0.8712, F1 Micro: 0.8712, F1 Macro: 0.8249\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.168, Accuracy: 0.8937, F1 Micro: 0.8937, F1 Macro: 0.8611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1264, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0968, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0987, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0591, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8817\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0563, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8805\n",
      "Epoch 9/10, Train Loss: 0.0358, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8724\n",
      "Epoch 10/10, Train Loss: 0.0209, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.874\n",
      "\n",
      "Sentiment analysis accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       745\n",
      "    positive       0.92      0.74      0.82       280\n",
      "\n",
      "    accuracy                           0.91      1025\n",
      "   macro avg       0.91      0.86      0.88      1025\n",
      "weighted avg       0.91      0.91      0.91      1025\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.7987\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.92      0.80      0.86        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.91      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.76      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.73      0.78        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.57      0.58       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.96       496\n",
      "    positive       0.89      0.49      0.63        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.60      0.49      0.53       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.84      0.88       200\n",
      "     neutral       0.90      0.95      0.92       315\n",
      "    positive       0.88      0.88      0.88        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.90      0.89      0.89       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.75      0.27      0.40        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.84      0.69      0.73       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.81      0.85        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.95      0.88      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.89      0.91       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.38      0.52        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.75      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.82      0.87       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 198.4694893360138 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 127\n",
      "Sampling duration: 0.00015306472778320312 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4809, Accuracy: 0.8012, F1 Micro: 0.8896, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.37, Accuracy: 0.8934, F1 Micro: 0.9367, F1 Macro: 0.9317\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2613, Accuracy: 0.9311, F1 Micro: 0.958, F1 Macro: 0.9552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2016, Accuracy: 0.9413, F1 Micro: 0.964, F1 Macro: 0.9614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1653, Accuracy: 0.9469, F1 Micro: 0.9674, F1 Macro: 0.9647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.136, Accuracy: 0.9523, F1 Micro: 0.9706, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1163, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9703\n",
      "Epoch 8/10, Train Loss: 0.103, Accuracy: 0.955, F1 Micro: 0.9723, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0863, Accuracy: 0.9587, F1 Micro: 0.9744, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.079, Accuracy: 0.9587, F1 Micro: 0.9745, F1 Macro: 0.9723\n",
      "\n",
      "Aspect detection accuracy: 0.9587, F1 Micro: 0.9745, F1 Macro: 0.9723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.93      0.98      0.96       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4172, Accuracy: 0.8275, F1 Micro: 0.8275, F1 Macro: 0.7934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2581, Accuracy: 0.8742, F1 Micro: 0.8742, F1 Macro: 0.8346\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1882, Accuracy: 0.8894, F1 Micro: 0.8894, F1 Macro: 0.8485\n",
      "Epoch 4/10, Train Loss: 0.1335, Accuracy: 0.8875, F1 Micro: 0.8875, F1 Macro: 0.8442\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0831, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.8696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0711, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0631, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0609, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.8934\n",
      "Epoch 9/10, Train Loss: 0.0342, Accuracy: 0.9018, F1 Micro: 0.9018, F1 Macro: 0.8668\n",
      "Epoch 10/10, Train Loss: 0.0194, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.883\n",
      "\n",
      "Sentiment analysis accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.8934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       755\n",
      "    positive       0.93      0.77      0.84       294\n",
      "\n",
      "    accuracy                           0.92      1049\n",
      "   macro avg       0.92      0.87      0.89      1049\n",
      "weighted avg       0.92      0.92      0.92      1049\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.8247\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.92      0.80      0.86        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.91      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.86      0.89        86\n",
      "     neutral       0.97      1.00      0.98       475\n",
      "    positive       0.80      0.40      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.90      0.75      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.77      0.82        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.81      0.57      0.67        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.75      0.57      0.62       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.85      0.93      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.62      0.36      0.46        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.81      0.72      0.75       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.34      0.50        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.90      0.72      0.77       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.76      0.81       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.88      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 214.49218702316284 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 114\n",
      "Sampling duration: 0.00015234947204589844 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4761, Accuracy: 0.8156, F1 Micro: 0.8963, F1 Macro: 0.8911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3487, Accuracy: 0.909, F1 Micro: 0.9452, F1 Macro: 0.9403\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2443, Accuracy: 0.9368, F1 Micro: 0.9613, F1 Macro: 0.9583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1889, Accuracy: 0.9436, F1 Micro: 0.9655, F1 Macro: 0.9632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1614, Accuracy: 0.9486, F1 Micro: 0.9685, F1 Macro: 0.9664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1371, Accuracy: 0.9547, F1 Micro: 0.9721, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1152, Accuracy: 0.955, F1 Micro: 0.9723, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0956, Accuracy: 0.9564, F1 Micro: 0.973, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0856, Accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.9727\n",
      "Epoch 10/10, Train Loss: 0.0741, Accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.973\n",
      "\n",
      "Aspect detection accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.9727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.92      0.93      0.92       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3948, Accuracy: 0.8377, F1 Micro: 0.8377, F1 Macro: 0.7835\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2524, Accuracy: 0.8646, F1 Micro: 0.8646, F1 Macro: 0.8135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1551, Accuracy: 0.885, F1 Micro: 0.885, F1 Macro: 0.8457\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1292, Accuracy: 0.8961, F1 Micro: 0.8961, F1 Macro: 0.8606\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0785, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8727\n",
      "Epoch 6/10, Train Loss: 0.0675, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.863\n",
      "Epoch 7/10, Train Loss: 0.0623, Accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.8668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0464, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8716\n",
      "Epoch 9/10, Train Loss: 0.024, Accuracy: 0.8905, F1 Micro: 0.8905, F1 Macro: 0.852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0244, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.881\n",
      "\n",
      "Sentiment analysis accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       772\n",
      "    positive       0.92      0.75      0.82       306\n",
      "\n",
      "    accuracy                           0.91      1078\n",
      "   macro avg       0.91      0.86      0.88      1078\n",
      "weighted avg       0.91      0.91      0.91      1078\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.8458\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.82      0.84       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.14      0.14      0.14         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.83      0.65      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.64      0.59      0.61       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.89      0.88       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.84      0.86      0.85        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.88      0.89      0.89       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86       162\n",
      "     neutral       0.93      0.96      0.94       387\n",
      "    positive       0.53      0.41      0.46        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.78      0.73      0.75       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.88        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.91      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.68      0.88      0.77        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.80      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.99      0.97        74\n",
      "     neutral       1.00      0.99      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.88      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 226.64149045944214 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 103\n",
      "Sampling duration: 0.0001468658447265625 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.476, Accuracy: 0.8333, F1 Micro: 0.9048, F1 Macro: 0.8989\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3381, Accuracy: 0.9089, F1 Micro: 0.9454, F1 Macro: 0.9417\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2393, Accuracy: 0.9366, F1 Micro: 0.9614, F1 Macro: 0.959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1872, Accuracy: 0.9458, F1 Micro: 0.9667, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1524, Accuracy: 0.9458, F1 Micro: 0.9669, F1 Macro: 0.9647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1295, Accuracy: 0.9549, F1 Micro: 0.9722, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1129, Accuracy: 0.9587, F1 Micro: 0.9744, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0938, Accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0815, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0717, Accuracy: 0.9622, F1 Micro: 0.9766, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9622, F1 Micro: 0.9766, F1 Macro: 0.9745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.93      0.99      0.96       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3873, Accuracy: 0.8374, F1 Micro: 0.8374, F1 Macro: 0.7962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2319, Accuracy: 0.8856, F1 Micro: 0.8856, F1 Macro: 0.8519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2025, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.8594\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1247, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0933, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0741, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0503, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0423, Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.8892\n",
      "Epoch 9/10, Train Loss: 0.0382, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8773\n",
      "Epoch 10/10, Train Loss: 0.0232, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8767\n",
      "\n",
      "Sentiment analysis accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.8892\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94       764\n",
      "    positive       0.92      0.77      0.83       294\n",
      "\n",
      "    accuracy                           0.92      1058\n",
      "   macro avg       0.92      0.87      0.89      1058\n",
      "weighted avg       0.92      0.92      0.91      1058\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9548, F1 Micro: 0.9548, F1 Macro: 0.8312\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.92      0.80      0.86        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.91      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.60      0.30      0.40        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.72      0.75       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.77      0.83       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.99      0.96       496\n",
      "    positive       0.89      0.59      0.71        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.61      0.53      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.90      0.95      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.85       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.71      0.23      0.34        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.83      0.68      0.71       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.55      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.71      0.73        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.75      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 240.17521715164185 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 62\n",
      "Sampling duration: 0.022454500198364258 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4721, Accuracy: 0.8314, F1 Micro: 0.9039, F1 Macro: 0.8981\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3322, Accuracy: 0.9205, F1 Micro: 0.9517, F1 Macro: 0.9474\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2333, Accuracy: 0.937, F1 Micro: 0.9616, F1 Macro: 0.959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1796, Accuracy: 0.9481, F1 Micro: 0.9682, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1488, Accuracy: 0.9505, F1 Micro: 0.9696, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1294, Accuracy: 0.9538, F1 Micro: 0.9716, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1066, Accuracy: 0.9583, F1 Micro: 0.9743, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0887, Accuracy: 0.9589, F1 Micro: 0.9745, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0784, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0658, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "\n",
      "Aspect detection accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.94      0.94      0.94       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3954, Accuracy: 0.8497, F1 Micro: 0.8497, F1 Macro: 0.7999\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2516, Accuracy: 0.8794, F1 Micro: 0.8794, F1 Macro: 0.844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1631, Accuracy: 0.8911, F1 Micro: 0.8911, F1 Macro: 0.8574\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1172, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0885, Accuracy: 0.9001, F1 Micro: 0.9001, F1 Macro: 0.8731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.062, Accuracy: 0.9019, F1 Micro: 0.9019, F1 Macro: 0.8738\n",
      "Epoch 7/10, Train Loss: 0.0394, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.861\n",
      "Epoch 8/10, Train Loss: 0.0631, Accuracy: 0.8956, F1 Micro: 0.8956, F1 Macro: 0.8659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0308, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0344, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8813\n",
      "\n",
      "Sentiment analysis accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       779\n",
      "    positive       0.93      0.75      0.83       332\n",
      "\n",
      "    accuracy                           0.91      1111\n",
      "   macro avg       0.91      0.86      0.88      1111\n",
      "weighted avg       0.91      0.91      0.90      1111\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9566, F1 Micro: 0.9566, F1 Macro: 0.8616\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.86      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.81      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.76      0.76      0.76       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.83      0.74      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85       162\n",
      "     neutral       0.94      0.95      0.94       387\n",
      "    positive       0.69      0.50      0.58        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.82      0.77      0.79       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.90        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.55      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.77      0.81       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 247.53666138648987 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 86\n",
      "Sampling duration: 0.00015592575073242188 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.473, Accuracy: 0.8354, F1 Micro: 0.9059, F1 Macro: 0.8999\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3131, Accuracy: 0.9222, F1 Micro: 0.9527, F1 Macro: 0.9483\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2154, Accuracy: 0.9415, F1 Micro: 0.9643, F1 Macro: 0.9619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1739, Accuracy: 0.9457, F1 Micro: 0.9667, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1445, Accuracy: 0.9505, F1 Micro: 0.9696, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1212, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1004, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0856, Accuracy: 0.9602, F1 Micro: 0.9755, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0744, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0616, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9741\n",
      "\n",
      "Aspect detection accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.94      0.95      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3842, Accuracy: 0.8616, F1 Micro: 0.8616, F1 Macro: 0.8057\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2257, Accuracy: 0.8831, F1 Micro: 0.8831, F1 Macro: 0.8362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1676, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8761\n",
      "Epoch 4/10, Train Loss: 0.1099, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0746, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8807\n",
      "Epoch 6/10, Train Loss: 0.0487, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8749\n",
      "Epoch 7/10, Train Loss: 0.033, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8768\n",
      "Epoch 8/10, Train Loss: 0.0241, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8683\n",
      "Epoch 9/10, Train Loss: 0.0203, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8752\n",
      "Epoch 10/10, Train Loss: 0.0305, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8825\n",
      "\n",
      "Sentiment analysis accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       775\n",
      "    positive       0.92      0.74      0.82       294\n",
      "\n",
      "    accuracy                           0.91      1069\n",
      "   macro avg       0.92      0.86      0.88      1069\n",
      "weighted avg       0.91      0.91      0.91      1069\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.8397\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.81      0.85        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.76      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.95       496\n",
      "    positive       0.87      0.49      0.62        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.60      0.49      0.53       571\n",
      "weighted avg       0.90      0.92      0.90       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.87       162\n",
      "     neutral       0.94      0.95      0.94       387\n",
      "    positive       0.67      0.64      0.65        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.83      0.81      0.82       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.81      0.86        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.78      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.55      1.00      0.71         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.83      0.95      0.87       571\n",
      "weighted avg       0.99      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 250.80240726470947 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 77\n",
      "Sampling duration: 0.00011897087097167969 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4641, Accuracy: 0.845, F1 Micro: 0.911, F1 Macro: 0.9057\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3085, Accuracy: 0.9222, F1 Micro: 0.953, F1 Macro: 0.9495\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2119, Accuracy: 0.9458, F1 Micro: 0.9667, F1 Macro: 0.9639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1729, Accuracy: 0.9488, F1 Micro: 0.9685, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1419, Accuracy: 0.9528, F1 Micro: 0.971, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1182, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9718\n",
      "Epoch 7/10, Train Loss: 0.0988, Accuracy: 0.9564, F1 Micro: 0.973, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0856, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.071, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0612, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9748\n",
      "\n",
      "Aspect detection accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.388, Accuracy: 0.8419, F1 Micro: 0.8419, F1 Macro: 0.7671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2198, Accuracy: 0.8865, F1 Micro: 0.8865, F1 Macro: 0.8453\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1501, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1038, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0632, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8863\n",
      "Epoch 6/10, Train Loss: 0.0705, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8843\n",
      "Epoch 7/10, Train Loss: 0.0488, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8727\n",
      "Epoch 8/10, Train Loss: 0.058, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0332, Accuracy: 0.9172, F1 Micro: 0.9172, F1 Macro: 0.8906\n",
      "Epoch 10/10, Train Loss: 0.0293, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8838\n",
      "\n",
      "Sentiment analysis accuracy: 0.9172, F1 Micro: 0.9172, F1 Macro: 0.8906\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       772\n",
      "    positive       0.94      0.75      0.84       303\n",
      "\n",
      "    accuracy                           0.92      1075\n",
      "   macro avg       0.93      0.87      0.89      1075\n",
      "weighted avg       0.92      0.92      0.91      1075\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.8393\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.76      0.80       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.85      0.84        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.60      0.61      0.60       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.86      0.62      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.93      0.58      0.64       571\n",
      "weighted avg       0.93      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.73      0.78       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.89      0.76      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 264.88055968284607 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 70\n",
      "Sampling duration: 0.00011205673217773438 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4575, Accuracy: 0.8531, F1 Micro: 0.9151, F1 Macro: 0.9095\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2996, Accuracy: 0.9304, F1 Micro: 0.9576, F1 Macro: 0.9546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2056, Accuracy: 0.9415, F1 Micro: 0.9642, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1638, Accuracy: 0.9516, F1 Micro: 0.9701, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1381, Accuracy: 0.9543, F1 Micro: 0.9719, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1152, Accuracy: 0.9568, F1 Micro: 0.9734, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0956, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0808, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0686, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9741\n",
      "Epoch 10/10, Train Loss: 0.058, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9736\n",
      "\n",
      "Aspect detection accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.92      0.98      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3642, Accuracy: 0.8505, F1 Micro: 0.8505, F1 Macro: 0.7895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2088, Accuracy: 0.8963, F1 Micro: 0.8963, F1 Macro: 0.8613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1574, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1304, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.888\n",
      "Epoch 5/10, Train Loss: 0.0779, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8827\n",
      "Epoch 6/10, Train Loss: 0.0554, Accuracy: 0.9131, F1 Micro: 0.9131, F1 Macro: 0.8847\n",
      "Epoch 7/10, Train Loss: 0.0629, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.882\n",
      "Epoch 8/10, Train Loss: 0.0314, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0436, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0258, Accuracy: 0.9168, F1 Micro: 0.9168, F1 Macro: 0.8904\n",
      "\n",
      "Sentiment analysis accuracy: 0.9168, F1 Micro: 0.9168, F1 Macro: 0.8904\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       770\n",
      "    positive       0.93      0.76      0.84       300\n",
      "\n",
      "    accuracy                           0.92      1070\n",
      "   macro avg       0.92      0.87      0.89      1070\n",
      "weighted avg       0.92      0.92      0.91      1070\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9574, F1 Micro: 0.9574, F1 Macro: 0.8499\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.77      0.83       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.83      0.63      0.72        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.54      0.56       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89       200\n",
      "     neutral       0.95      0.91      0.93       315\n",
      "    positive       0.90      0.98      0.94        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.82      0.86       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.75      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.59      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.78      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 266.7609405517578 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 52\n",
      "Sampling duration: 0.015653610229492188 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4541, Accuracy: 0.8634, F1 Micro: 0.9207, F1 Macro: 0.9158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2903, Accuracy: 0.9325, F1 Micro: 0.959, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1995, Accuracy: 0.9469, F1 Micro: 0.9674, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1654, Accuracy: 0.9505, F1 Micro: 0.9697, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.139, Accuracy: 0.9554, F1 Micro: 0.9725, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1127, Accuracy: 0.9576, F1 Micro: 0.9739, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0939, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9749\n",
      "Epoch 8/10, Train Loss: 0.0791, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9744\n",
      "Epoch 9/10, Train Loss: 0.0642, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0535, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.95      0.92      0.93       317\n",
      "       linen       0.94      0.95      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3654, Accuracy: 0.8688, F1 Micro: 0.8688, F1 Macro: 0.8211\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2011, Accuracy: 0.9009, F1 Micro: 0.9009, F1 Macro: 0.8717\n",
      "Epoch 3/10, Train Loss: 0.1513, Accuracy: 0.8826, F1 Micro: 0.8826, F1 Macro: 0.8366\n",
      "Epoch 4/10, Train Loss: 0.0986, Accuracy: 0.8862, F1 Micro: 0.8862, F1 Macro: 0.843\n",
      "Epoch 5/10, Train Loss: 0.0716, Accuracy: 0.8982, F1 Micro: 0.8982, F1 Macro: 0.8625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0561, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0459, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0365, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8809\n",
      "Epoch 9/10, Train Loss: 0.0236, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8791\n",
      "Epoch 10/10, Train Loss: 0.0269, Accuracy: 0.9037, F1 Micro: 0.9037, F1 Macro: 0.8737\n",
      "\n",
      "Sentiment analysis accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       778\n",
      "    positive       0.93      0.74      0.82       312\n",
      "\n",
      "    accuracy                           0.91      1090\n",
      "   macro avg       0.92      0.86      0.88      1090\n",
      "weighted avg       0.91      0.91      0.91      1090\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9564, F1 Micro: 0.9564, F1 Macro: 0.8497\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.99      0.96       496\n",
      "    positive       0.85      0.60      0.71        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.53      0.56       571\n",
      "weighted avg       0.91      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.64      0.32      0.42        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.81      0.71      0.74       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.84      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 270.5762948989868 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 58\n",
      "Sampling duration: 0.0001304149627685547 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.46, Accuracy: 0.8689, F1 Micro: 0.9226, F1 Macro: 0.915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.287, Accuracy: 0.9318, F1 Micro: 0.9585, F1 Macro: 0.956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1965, Accuracy: 0.945, F1 Micro: 0.9663, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.163, Accuracy: 0.9521, F1 Micro: 0.9706, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1304, Accuracy: 0.954, F1 Micro: 0.9717, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1122, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0884, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0762, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9753\n",
      "Epoch 9/10, Train Loss: 0.0672, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9739\n",
      "Epoch 10/10, Train Loss: 0.0563, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9741\n",
      "\n",
      "Aspect detection accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3691, Accuracy: 0.8743, F1 Micro: 0.8743, F1 Macro: 0.8346\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1904, Accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.8671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.145, Accuracy: 0.9156, F1 Micro: 0.9156, F1 Macro: 0.8915\n",
      "Epoch 4/10, Train Loss: 0.1193, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0785, Accuracy: 0.9212, F1 Micro: 0.9212, F1 Macro: 0.8968\n",
      "Epoch 6/10, Train Loss: 0.0612, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8738\n",
      "Epoch 7/10, Train Loss: 0.0409, Accuracy: 0.8987, F1 Micro: 0.8987, F1 Macro: 0.8612\n",
      "Epoch 8/10, Train Loss: 0.0423, Accuracy: 0.9193, F1 Micro: 0.9193, F1 Macro: 0.8934\n",
      "Epoch 9/10, Train Loss: 0.0258, Accuracy: 0.9165, F1 Micro: 0.9165, F1 Macro: 0.8903\n",
      "Epoch 10/10, Train Loss: 0.0243, Accuracy: 0.9034, F1 Micro: 0.9034, F1 Macro: 0.8682\n",
      "\n",
      "Sentiment analysis accuracy: 0.9212, F1 Micro: 0.9212, F1 Macro: 0.8968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       767\n",
      "    positive       0.93      0.78      0.85       299\n",
      "\n",
      "    accuracy                           0.92      1066\n",
      "   macro avg       0.92      0.88      0.90      1066\n",
      "weighted avg       0.92      0.92      0.92      1066\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9555, F1 Micro: 0.9555, F1 Macro: 0.8361\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.77      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.25      0.14      0.18         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.90      0.63      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.70      0.59      0.63       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.89      0.87       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.90      0.82      0.86        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.88      0.89       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.88      0.84       162\n",
      "     neutral       0.94      0.95      0.95       387\n",
      "    positive       0.67      0.09      0.16        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.81      0.64      0.65       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.94      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.66      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.85      0.65      0.73        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.77      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.57      0.67      0.62         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.83      0.86      0.85       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 274.82833909988403 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 52\n",
      "Sampling duration: 0.00011658668518066406 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4439, Accuracy: 0.8753, F1 Micro: 0.9266, F1 Macro: 0.9212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.278, Accuracy: 0.9335, F1 Micro: 0.9595, F1 Macro: 0.9566\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1974, Accuracy: 0.9498, F1 Micro: 0.9692, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1589, Accuracy: 0.9502, F1 Micro: 0.9695, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1317, Accuracy: 0.9533, F1 Micro: 0.9713, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1085, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9733\n",
      "Epoch 7/10, Train Loss: 0.0903, Accuracy: 0.9589, F1 Micro: 0.9746, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0773, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9745\n",
      "Epoch 9/10, Train Loss: 0.0652, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0534, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9748\n",
      "\n",
      "Aspect detection accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.91      0.98      0.94       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3568, Accuracy: 0.8736, F1 Micro: 0.8736, F1 Macro: 0.8319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2308, Accuracy: 0.9019, F1 Micro: 0.9019, F1 Macro: 0.8698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1599, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.8887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1037, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.896\n",
      "Epoch 5/10, Train Loss: 0.0697, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.884\n",
      "Epoch 6/10, Train Loss: 0.063, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8841\n",
      "Epoch 7/10, Train Loss: 0.0447, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.889\n",
      "Epoch 8/10, Train Loss: 0.0264, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.03, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.8955\n",
      "Epoch 10/10, Train Loss: 0.0168, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8832\n",
      "\n",
      "Sentiment analysis accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.8955\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.95       763\n",
      "    positive       0.92      0.78      0.85       297\n",
      "\n",
      "    accuracy                           0.92      1060\n",
      "   macro avg       0.92      0.88      0.90      1060\n",
      "weighted avg       0.92      0.92      0.92      1060\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9557, F1 Micro: 0.9557, F1 Macro: 0.8217\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.60      0.30      0.40        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.73      0.76       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.61      0.60      0.60       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.69      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.90       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.79      0.84       162\n",
      "     neutral       0.91      0.98      0.94       387\n",
      "    positive       0.67      0.27      0.39        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.82      0.68      0.72       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.48      0.58        29\n",
      "     neutral       0.97      1.00      0.99       525\n",
      "    positive       0.79      0.65      0.71        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.71      0.76       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 286.2092492580414 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.560585021972656e-05 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4448, Accuracy: 0.8745, F1 Micro: 0.9265, F1 Macro: 0.9216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2745, Accuracy: 0.9359, F1 Micro: 0.9609, F1 Macro: 0.958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.194, Accuracy: 0.9479, F1 Micro: 0.9681, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1533, Accuracy: 0.9503, F1 Micro: 0.9695, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1284, Accuracy: 0.9552, F1 Micro: 0.9723, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1081, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0911, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.0727, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9739\n",
      "Epoch 9/10, Train Loss: 0.062, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.974\n",
      "Epoch 10/10, Train Loss: 0.0517, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.95      0.92      0.93       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3796, Accuracy: 0.8604, F1 Micro: 0.8604, F1 Macro: 0.8224\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2186, Accuracy: 0.8762, F1 Micro: 0.8762, F1 Macro: 0.8313\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1401, Accuracy: 0.9131, F1 Micro: 0.9131, F1 Macro: 0.8873\n",
      "Epoch 4/10, Train Loss: 0.1117, Accuracy: 0.9085, F1 Micro: 0.9085, F1 Macro: 0.8789\n",
      "Epoch 5/10, Train Loss: 0.082, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8808\n",
      "Epoch 6/10, Train Loss: 0.0729, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8797\n",
      "Epoch 7/10, Train Loss: 0.0562, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8843\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0487, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8878\n",
      "Epoch 9/10, Train Loss: 0.0325, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8734\n",
      "Epoch 10/10, Train Loss: 0.0391, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8748\n",
      "\n",
      "Sentiment analysis accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       775\n",
      "    positive       0.92      0.76      0.83       307\n",
      "\n",
      "    accuracy                           0.91      1082\n",
      "   macro avg       0.92      0.87      0.89      1082\n",
      "weighted avg       0.91      0.91      0.91      1082\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.958, F1 Micro: 0.958, F1 Macro: 0.8623\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.50      0.30      0.37        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.80      0.73      0.76       571\n",
      "weighted avg       0.96      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.20      0.14      0.17         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.90      0.63      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.68      0.59      0.62       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.90      0.89       200\n",
      "     neutral       0.95      0.92      0.93       315\n",
      "    positive       0.88      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.70      0.32      0.44        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.83      0.71      0.75       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 285.73733854293823 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.00011229515075683594 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4441, Accuracy: 0.878, F1 Micro: 0.9281, F1 Macro: 0.9226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2706, Accuracy: 0.9394, F1 Micro: 0.9629, F1 Macro: 0.9601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1925, Accuracy: 0.9505, F1 Micro: 0.9696, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1577, Accuracy: 0.9523, F1 Micro: 0.9706, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1188, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1055, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0876, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0733, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0627, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.0527, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      0.99      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3775, Accuracy: 0.8394, F1 Micro: 0.8394, F1 Macro: 0.7701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2167, Accuracy: 0.8791, F1 Micro: 0.8791, F1 Macro: 0.8414\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1551, Accuracy: 0.9007, F1 Micro: 0.9007, F1 Macro: 0.8707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1092, Accuracy: 0.9007, F1 Micro: 0.9007, F1 Macro: 0.8695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0813, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.8713\n",
      "Epoch 6/10, Train Loss: 0.0535, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0473, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8799\n",
      "Epoch 8/10, Train Loss: 0.0451, Accuracy: 0.9007, F1 Micro: 0.9007, F1 Macro: 0.871\n",
      "Epoch 9/10, Train Loss: 0.0232, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8742\n",
      "Epoch 10/10, Train Loss: 0.0223, Accuracy: 0.9007, F1 Micro: 0.9007, F1 Macro: 0.8716\n",
      "\n",
      "Sentiment analysis accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       784\n",
      "    positive       0.93      0.74      0.82       324\n",
      "\n",
      "    accuracy                           0.91      1108\n",
      "   macro avg       0.92      0.86      0.88      1108\n",
      "weighted avg       0.91      0.91      0.90      1108\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9571, F1 Micro: 0.9571, F1 Macro: 0.8534\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.40      0.20      0.27        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.75      0.70      0.72       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.60      0.64       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.76      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.68      0.88      0.77        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.81      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      1.00      0.98        74\n",
      "     neutral       1.00      0.99      1.00       494\n",
      "    positive       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.88      0.89      0.88       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 303.3772015571594 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.00020265579223632812 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4478, Accuracy: 0.8825, F1 Micro: 0.9303, F1 Macro: 0.9236\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.262, Accuracy: 0.9401, F1 Micro: 0.9634, F1 Macro: 0.9609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1884, Accuracy: 0.9474, F1 Micro: 0.9678, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1512, Accuracy: 0.9512, F1 Micro: 0.9701, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1247, Accuracy: 0.9533, F1 Micro: 0.9713, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0984, Accuracy: 0.959, F1 Micro: 0.9747, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0887, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.072, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0638, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0521, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.93      0.94      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3549, Accuracy: 0.8574, F1 Micro: 0.8574, F1 Macro: 0.818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2081, Accuracy: 0.896, F1 Micro: 0.896, F1 Macro: 0.8655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1453, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0975, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8837\n",
      "Epoch 5/10, Train Loss: 0.0664, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.057, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.894\n",
      "Epoch 7/10, Train Loss: 0.0326, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.8939\n",
      "Epoch 8/10, Train Loss: 0.0333, Accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8928\n",
      "Epoch 9/10, Train Loss: 0.0319, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8845\n",
      "Epoch 10/10, Train Loss: 0.0341, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8878\n",
      "\n",
      "Sentiment analysis accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.99      0.95       780\n",
      "    positive       0.95      0.75      0.84       307\n",
      "\n",
      "    accuracy                           0.92      1087\n",
      "   macro avg       0.93      0.87      0.89      1087\n",
      "weighted avg       0.92      0.92      0.92      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.8622\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.77      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.86      0.65      0.74        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.59      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.88       200\n",
      "     neutral       0.93      0.94      0.93       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.69      0.50      0.58        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.83      0.77      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 305.9617750644684 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 25\n",
      "Sampling duration: 0.019374370574951172 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4479, Accuracy: 0.8811, F1 Micro: 0.9293, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2693, Accuracy: 0.9377, F1 Micro: 0.962, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1822, Accuracy: 0.9472, F1 Micro: 0.9677, F1 Macro: 0.9657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1484, Accuracy: 0.953, F1 Micro: 0.9711, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.121, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0982, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0856, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.069, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.976\n",
      "Epoch 9/10, Train Loss: 0.0617, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9744\n",
      "Epoch 10/10, Train Loss: 0.051, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.95      0.94       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3623, Accuracy: 0.8673, F1 Micro: 0.8673, F1 Macro: 0.8228\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2051, Accuracy: 0.8811, F1 Micro: 0.8811, F1 Macro: 0.8381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1628, Accuracy: 0.8902, F1 Micro: 0.8902, F1 Macro: 0.8524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1074, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0798, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8908\n",
      "Epoch 6/10, Train Loss: 0.0628, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8858\n",
      "Epoch 7/10, Train Loss: 0.0433, Accuracy: 0.9131, F1 Micro: 0.9131, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0337, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.8934\n",
      "Epoch 9/10, Train Loss: 0.0198, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8824\n",
      "Epoch 10/10, Train Loss: 0.0392, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8819\n",
      "\n",
      "Sentiment analysis accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.8934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       777\n",
      "    positive       0.94      0.76      0.84       316\n",
      "\n",
      "    accuracy                           0.92      1093\n",
      "   macro avg       0.93      0.87      0.89      1093\n",
      "weighted avg       0.92      0.92      0.91      1093\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9578, F1 Micro: 0.9578, F1 Macro: 0.856\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.77      0.79       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.87      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.78      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.60      0.64       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.85       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.75      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.98      0.97      0.98       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.93        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.80      0.67      0.73         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.87      0.88       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 304.33139276504517 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.000102996826171875 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.442, Accuracy: 0.88, F1 Micro: 0.9295, F1 Macro: 0.9246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2634, Accuracy: 0.9384, F1 Micro: 0.9625, F1 Macro: 0.9602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1837, Accuracy: 0.9509, F1 Micro: 0.9698, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1491, Accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1202, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.101, Accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0848, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9758\n",
      "Epoch 8/10, Train Loss: 0.0685, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0605, Accuracy: 0.9653, F1 Micro: 0.9785, F1 Macro: 0.9765\n",
      "Epoch 10/10, Train Loss: 0.0508, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9748\n",
      "\n",
      "Aspect detection accuracy: 0.9653, F1 Micro: 0.9785, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3466, Accuracy: 0.873, F1 Micro: 0.873, F1 Macro: 0.8245\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2053, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1372, Accuracy: 0.9085, F1 Micro: 0.9085, F1 Macro: 0.8759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0793, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.8948\n",
      "Epoch 5/10, Train Loss: 0.0714, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0624, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.8935\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0364, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.8989\n",
      "Epoch 8/10, Train Loss: 0.0337, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.8863\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0263, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.8991\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0242, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.901\n",
      "\n",
      "Sentiment analysis accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.901\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       773\n",
      "    positive       0.93      0.79      0.85       298\n",
      "\n",
      "    accuracy                           0.92      1071\n",
      "   macro avg       0.93      0.88      0.90      1071\n",
      "weighted avg       0.92      0.92      0.92      1071\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8641\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.76      0.79       571\n",
      "weighted avg       0.96      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.94      0.88       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.29      0.36         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.86      0.65      0.74        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.64      0.69       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.91      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.80      0.55      0.65        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.79      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.69      0.78        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.86      0.88       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.67      0.67      0.67         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.86      0.86      0.86       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 313.210506439209 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.988380432128906e-05 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4336, Accuracy: 0.8837, F1 Micro: 0.9311, F1 Macro: 0.9254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2532, Accuracy: 0.9417, F1 Micro: 0.9643, F1 Macro: 0.9619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.179, Accuracy: 0.95, F1 Micro: 0.9693, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1475, Accuracy: 0.9517, F1 Micro: 0.9704, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1236, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9744\n",
      "Epoch 6/10, Train Loss: 0.1015, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0843, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.068, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9752\n",
      "Epoch 9/10, Train Loss: 0.0572, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9734\n",
      "Epoch 10/10, Train Loss: 0.0481, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.94      0.93       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3603, Accuracy: 0.8665, F1 Micro: 0.8665, F1 Macro: 0.8202\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2119, Accuracy: 0.8849, F1 Micro: 0.8849, F1 Macro: 0.8469\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1415, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0999, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0763, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.8923\n",
      "Epoch 6/10, Train Loss: 0.0471, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8888\n",
      "Epoch 7/10, Train Loss: 0.0383, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8888\n",
      "Epoch 8/10, Train Loss: 0.0346, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0286, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.8898\n",
      "Epoch 10/10, Train Loss: 0.0253, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8773\n",
      "\n",
      "Sentiment analysis accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.8898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       771\n",
      "    positive       0.95      0.75      0.84       315\n",
      "\n",
      "    accuracy                           0.92      1086\n",
      "   macro avg       0.93      0.87      0.89      1086\n",
      "weighted avg       0.92      0.92      0.91      1086\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9571, F1 Micro: 0.9571, F1 Macro: 0.8611\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.25      0.14      0.18         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.82      0.66      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.67      0.59      0.63       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.86      0.27      0.41        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.88      0.69      0.73       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.85        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.88      0.96      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.66      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      1.00      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.89      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 314.5488030910492 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.441375732421875e-05 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4336, Accuracy: 0.8918, F1 Micro: 0.9353, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2457, Accuracy: 0.9438, F1 Micro: 0.9656, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1776, Accuracy: 0.95, F1 Micro: 0.9694, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1433, Accuracy: 0.9564, F1 Micro: 0.9731, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.114, Accuracy: 0.9566, F1 Micro: 0.9733, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0997, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9746\n",
      "Epoch 7/10, Train Loss: 0.0801, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9737\n",
      "Epoch 8/10, Train Loss: 0.0645, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0556, Accuracy: 0.9642, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0482, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3424, Accuracy: 0.8794, F1 Micro: 0.8794, F1 Macro: 0.8464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.177, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.897\n",
      "Epoch 3/10, Train Loss: 0.1384, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8828\n",
      "Epoch 4/10, Train Loss: 0.0796, Accuracy: 0.9156, F1 Micro: 0.9156, F1 Macro: 0.8883\n",
      "Epoch 5/10, Train Loss: 0.0618, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8772\n",
      "Epoch 6/10, Train Loss: 0.0576, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.8958\n",
      "Epoch 7/10, Train Loss: 0.0368, Accuracy: 0.9165, F1 Micro: 0.9165, F1 Macro: 0.8917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.032, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.8972\n",
      "Epoch 9/10, Train Loss: 0.022, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.8785\n",
      "Epoch 10/10, Train Loss: 0.0127, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8883\n",
      "\n",
      "Sentiment analysis accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.8972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.95       775\n",
      "    positive       0.91      0.80      0.85       303\n",
      "\n",
      "    accuracy                           0.92      1078\n",
      "   macro avg       0.92      0.88      0.90      1078\n",
      "weighted avg       0.92      0.92      0.92      1078\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.843\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.79      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.79      0.93      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.69      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.84      0.89       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.76      0.98      0.86        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.92      0.90       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.85       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.63      0.55      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.82      0.78      0.79       571\n",
      "weighted avg       0.90      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.84      0.87        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.87      0.97      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.96      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.78      0.79       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.82      0.87       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.86      0.99      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 324.2974636554718 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.107589721679688e-05 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4232, Accuracy: 0.8852, F1 Micro: 0.9324, F1 Macro: 0.9278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2472, Accuracy: 0.9446, F1 Micro: 0.9661, F1 Macro: 0.9639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1839, Accuracy: 0.953, F1 Micro: 0.9711, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1446, Accuracy: 0.9582, F1 Micro: 0.9742, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1205, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1008, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0808, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0651, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0559, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0473, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.97      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3375, Accuracy: 0.8726, F1 Micro: 0.8726, F1 Macro: 0.8369\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2052, Accuracy: 0.8961, F1 Micro: 0.8961, F1 Macro: 0.8664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1464, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8804\n",
      "Epoch 4/10, Train Loss: 0.0998, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8823\n",
      "Epoch 5/10, Train Loss: 0.0722, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.88\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0418, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8822\n",
      "Epoch 7/10, Train Loss: 0.0344, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0446, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0261, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.021, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8896\n",
      "\n",
      "Sentiment analysis accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8896\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       781\n",
      "    positive       0.93      0.76      0.84       326\n",
      "\n",
      "    accuracy                           0.91      1107\n",
      "   macro avg       0.92      0.87      0.89      1107\n",
      "weighted avg       0.91      0.91      0.91      1107\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9592, F1 Micro: 0.9592, F1 Macro: 0.8697\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.81      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.25      0.14      0.18         7\n",
      "     neutral       0.96      0.97      0.96       496\n",
      "    positive       0.80      0.75      0.77        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.67      0.62      0.64       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.63      0.55      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.82      0.78      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 337.5684623718262 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.00013113021850585938 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4323, Accuracy: 0.891, F1 Micro: 0.9349, F1 Macro: 0.9283\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2458, Accuracy: 0.9429, F1 Micro: 0.9651, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1765, Accuracy: 0.9528, F1 Micro: 0.971, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1432, Accuracy: 0.954, F1 Micro: 0.9718, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1129, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9751\n",
      "Epoch 6/10, Train Loss: 0.0937, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0806, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0665, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0543, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9762\n",
      "Epoch 10/10, Train Loss: 0.0471, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3492, Accuracy: 0.8578, F1 Micro: 0.8578, F1 Macro: 0.8039\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1802, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8679\n",
      "Epoch 3/10, Train Loss: 0.1299, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0807, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8862\n",
      "Epoch 5/10, Train Loss: 0.0663, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0553, Accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.8899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0429, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.8933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0303, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.8921\n",
      "Epoch 9/10, Train Loss: 0.0236, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8897\n",
      "Epoch 10/10, Train Loss: 0.0188, Accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.8914\n",
      "\n",
      "Sentiment analysis accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.8921\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.99      0.94       782\n",
      "    positive       0.96      0.75      0.84       315\n",
      "\n",
      "    accuracy                           0.92      1097\n",
      "   macro avg       0.93      0.87      0.89      1097\n",
      "weighted avg       0.92      0.92      0.91      1097\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9594, F1 Micro: 0.9594, F1 Macro: 0.8842\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.29      0.36         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.66      0.70       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.95      0.92      0.93       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.93      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.86      0.55      0.67        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.79      0.83       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.94      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.82      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 336.5308835506439 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 36\n",
      "Sampling duration: 0.020132064819335938 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4268, Accuracy: 0.8906, F1 Micro: 0.9351, F1 Macro: 0.9297\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2488, Accuracy: 0.9462, F1 Micro: 0.9671, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1807, Accuracy: 0.9516, F1 Micro: 0.9702, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1418, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1129, Accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.095, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.975\n",
      "Epoch 7/10, Train Loss: 0.0793, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0649, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9764\n",
      "Epoch 9/10, Train Loss: 0.0528, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "Epoch 10/10, Train Loss: 0.0464, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3574, Accuracy: 0.8791, F1 Micro: 0.8791, F1 Macro: 0.842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1988, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.8642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1269, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8785\n",
      "Epoch 4/10, Train Loss: 0.0927, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0826, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0537, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0379, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.881\n",
      "Epoch 8/10, Train Loss: 0.0382, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0292, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.8821\n",
      "Epoch 10/10, Train Loss: 0.0291, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8802\n",
      "\n",
      "Sentiment analysis accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.8821\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       785\n",
      "    positive       0.93      0.74      0.82       315\n",
      "\n",
      "    accuracy                           0.91      1100\n",
      "   macro avg       0.92      0.86      0.88      1100\n",
      "weighted avg       0.91      0.91      0.91      1100\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9578, F1 Micro: 0.9578, F1 Macro: 0.8756\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.15      0.29      0.20         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.65      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.66      0.64      0.63       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.92      0.88       200\n",
      "     neutral       0.96      0.90      0.93       315\n",
      "    positive       0.86      0.89      0.88        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.90      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.71      0.45      0.56        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.84      0.76      0.79       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.89      0.88        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.93      0.97      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.66      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 338.3248698711395 s\n",
      "Total runtime: 6757.301274776459 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f11605",
   "metadata": {
    "papermill": {
     "duration": 0.167077,
     "end_time": "2025-04-20T10:29:31.465657",
     "exception": false,
     "start_time": "2025-04-20T10:29:31.298580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a6e1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6222, Accuracy: 0.7984, F1 Micro: 0.8875, F1 Macro: 0.8819\n",
      "Epoch 2/10, Train Loss: 0.4944, Accuracy: 0.7981, F1 Micro: 0.8873, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4566, Accuracy: 0.7997, F1 Micro: 0.8881, F1 Macro: 0.8821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4288, Accuracy: 0.8017, F1 Micro: 0.8893, F1 Macro: 0.8836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4243, Accuracy: 0.804, F1 Micro: 0.8907, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4161, Accuracy: 0.8135, F1 Micro: 0.8944, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4005, Accuracy: 0.8179, F1 Micro: 0.8965, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3794, Accuracy: 0.8247, F1 Micro: 0.9001, F1 Macro: 0.8939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3213, Accuracy: 0.8417, F1 Micro: 0.9083, F1 Macro: 0.9019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3264, Accuracy: 0.8519, F1 Micro: 0.9131, F1 Macro: 0.9062\n",
      "\n",
      "Aspect detection accuracy: 0.8519, F1 Micro: 0.9131, F1 Macro: 0.9062\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.88      1.00      0.94       462\n",
      "   air_panas       0.83      1.00      0.91       480\n",
      "         bau       0.87      0.98      0.92       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.78      0.78      0.78       317\n",
      "       linen       0.79      0.92      0.85       392\n",
      "     service       0.87      0.96      0.91       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.86      1.00      0.93       498\n",
      "\n",
      "   micro avg       0.86      0.97      0.91      4614\n",
      "   macro avg       0.86      0.96      0.91      4614\n",
      "weighted avg       0.86      0.97      0.91      4614\n",
      " samples avg       0.86      0.97      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5506, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4796, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4879, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4287, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3515, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3279, Accuracy: 0.7, F1 Micro: 0.7, F1 Macro: 0.6242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2793, Accuracy: 0.7073, F1 Micro: 0.7073, F1 Macro: 0.6432\n",
      "Epoch 8/10, Train Loss: 0.202, Accuracy: 0.6873, F1 Micro: 0.6873, F1 Macro: 0.6008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2003, Accuracy: 0.7309, F1 Micro: 0.7309, F1 Macro: 0.6829\n",
      "Epoch 10/10, Train Loss: 0.1315, Accuracy: 0.7109, F1 Micro: 0.7109, F1 Macro: 0.649\n",
      "\n",
      "Sentiment analysis accuracy: 0.7309, F1 Micro: 0.7309, F1 Macro: 0.6829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.93      0.81       332\n",
      "    positive       0.80      0.43      0.56       218\n",
      "\n",
      "    accuracy                           0.73       550\n",
      "   macro avg       0.75      0.68      0.68       550\n",
      "weighted avg       0.75      0.73      0.71       550\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8427, F1 Micro: 0.8427, F1 Macro: 0.4234\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.46      0.61        97\n",
      "     neutral       0.88      1.00      0.94       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.59      0.49      0.51       571\n",
      "weighted avg       0.86      0.88      0.86       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.28      0.33      0.30       571\n",
      "weighted avg       0.69      0.83      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.08      0.12        78\n",
      "     neutral       0.87      0.98      0.92       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.40      0.35      0.35       571\n",
      "weighted avg       0.79      0.85      0.81       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.69      0.70       200\n",
      "     neutral       0.78      0.77      0.78       315\n",
      "    positive       0.40      0.43      0.41        56\n",
      "\n",
      "    accuracy                           0.71       571\n",
      "   macro avg       0.63      0.63      0.63       571\n",
      "weighted avg       0.72      0.71      0.71       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.48      0.56       162\n",
      "     neutral       0.78      0.92      0.85       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.76       571\n",
      "   macro avg       0.48      0.47      0.47       571\n",
      "weighted avg       0.72      0.76      0.73       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.52      0.58        85\n",
      "     neutral       0.87      0.96      0.91       418\n",
      "    positive       0.90      0.53      0.67        68\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.81      0.67      0.72       571\n",
      "weighted avg       0.84      0.84      0.83       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        74\n",
      "     neutral       0.87      1.00      0.93       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.80       571\n",
      "\n",
      "Total train time: 87.82489204406738 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 215\n",
      "Sampling duration: 0.00026345252990722656 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5637, Accuracy: 0.8009, F1 Micro: 0.8894, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4819, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4491, Accuracy: 0.8068, F1 Micro: 0.8921, F1 Macro: 0.8874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4209, Accuracy: 0.8363, F1 Micro: 0.9058, F1 Macro: 0.9001\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3726, Accuracy: 0.8618, F1 Micro: 0.9188, F1 Macro: 0.9133\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3253, Accuracy: 0.8814, F1 Micro: 0.9299, F1 Macro: 0.9253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2751, Accuracy: 0.8938, F1 Micro: 0.9366, F1 Macro: 0.9328\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2382, Accuracy: 0.9085, F1 Micro: 0.9451, F1 Macro: 0.942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2154, Accuracy: 0.916, F1 Micro: 0.9494, F1 Macro: 0.9466\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1797, Accuracy: 0.9271, F1 Micro: 0.9555, F1 Macro: 0.9529\n",
      "\n",
      "Aspect detection accuracy: 0.9271, F1 Micro: 0.9555, F1 Macro: 0.9529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.97      0.99      0.98       462\n",
      "   air_panas       0.94      0.98      0.96       480\n",
      "         bau       0.94      0.96      0.95       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.90      0.89      0.90       317\n",
      "       linen       0.87      0.97      0.92       392\n",
      "     service       0.95      0.95      0.95       423\n",
      "sunrise_meal       0.93      1.00      0.96       530\n",
      "          tv       0.96      1.00      0.98       516\n",
      "        wifi       0.98      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.93      0.98      0.96      4614\n",
      "   macro avg       0.93      0.97      0.95      4614\n",
      "weighted avg       0.94      0.98      0.96      4614\n",
      " samples avg       0.93      0.98      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5157, Accuracy: 0.7174, F1 Micro: 0.7174, F1 Macro: 0.4177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.409, Accuracy: 0.8076, F1 Micro: 0.8076, F1 Macro: 0.7424\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3045, Accuracy: 0.8163, F1 Micro: 0.8163, F1 Macro: 0.7533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.218, Accuracy: 0.8261, F1 Micro: 0.8261, F1 Macro: 0.7618\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2022, Accuracy: 0.838, F1 Micro: 0.838, F1 Macro: 0.7743\n",
      "Epoch 6/10, Train Loss: 0.1404, Accuracy: 0.8217, F1 Micro: 0.8217, F1 Macro: 0.7644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1343, Accuracy: 0.8391, F1 Micro: 0.8391, F1 Macro: 0.7645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0959, Accuracy: 0.8402, F1 Micro: 0.8402, F1 Macro: 0.7773\n",
      "Epoch 9/10, Train Loss: 0.0887, Accuracy: 0.8315, F1 Micro: 0.8315, F1 Macro: 0.7795\n",
      "Epoch 10/10, Train Loss: 0.1224, Accuracy: 0.8293, F1 Micro: 0.8293, F1 Macro: 0.7796\n",
      "\n",
      "Sentiment analysis accuracy: 0.8402, F1 Micro: 0.8402, F1 Macro: 0.7773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.96      0.90       660\n",
      "    positive       0.83      0.55      0.66       260\n",
      "\n",
      "    accuracy                           0.84       920\n",
      "   macro avg       0.84      0.75      0.78       920\n",
      "weighted avg       0.84      0.84      0.83       920\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.6551\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.89        97\n",
      "     neutral       0.98      0.99      0.98       459\n",
      "    positive       0.69      0.60      0.64        15\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.82      0.84       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.66      0.73        86\n",
      "     neutral       0.94      0.98      0.96       475\n",
      "    positive       0.67      0.20      0.31        10\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.80      0.62      0.66       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.64      0.68        78\n",
      "     neutral       0.94      0.96      0.95       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.78      0.87      0.81       571\n",
      "weighted avg       0.91      0.92      0.92       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       1.00      0.04      0.08        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.62      0.35      0.34       571\n",
      "weighted avg       0.88      0.87      0.82       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.80      0.82       200\n",
      "     neutral       0.90      0.89      0.90       315\n",
      "    positive       0.71      0.95      0.81        56\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.82      0.88      0.84       571\n",
      "weighted avg       0.87      0.86      0.86       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.62      0.74       162\n",
      "     neutral       0.87      0.97      0.92       387\n",
      "    positive       0.29      0.36      0.32        22\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.69      0.65      0.66       571\n",
      "weighted avg       0.86      0.85      0.84       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.54      0.64        85\n",
      "     neutral       0.95      0.95      0.95       418\n",
      "    positive       0.64      0.88      0.74        68\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.79      0.79      0.78       571\n",
      "weighted avg       0.89      0.88      0.88       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.07      0.13        29\n",
      "     neutral       0.93      1.00      0.96       525\n",
      "    positive       0.50      0.06      0.11        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.81      0.38      0.40       571\n",
      "weighted avg       0.92      0.92      0.89       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.69      0.78        54\n",
      "     neutral       0.96      1.00      0.98       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.62      0.56      0.59       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.86      0.90        74\n",
      "     neutral       0.98      1.00      0.99       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.64      0.62      0.63       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Total train time: 123.16664695739746 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 193\n",
      "Sampling duration: 0.0002067089080810547 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.525, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.449, Accuracy: 0.8043, F1 Micro: 0.891, F1 Macro: 0.8866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4149, Accuracy: 0.8451, F1 Micro: 0.9106, F1 Macro: 0.9059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3454, Accuracy: 0.8917, F1 Micro: 0.9354, F1 Macro: 0.9305\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2791, Accuracy: 0.913, F1 Micro: 0.9473, F1 Macro: 0.9425\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2353, Accuracy: 0.9245, F1 Micro: 0.9542, F1 Macro: 0.9513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1981, Accuracy: 0.9325, F1 Micro: 0.9589, F1 Macro: 0.9564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1768, Accuracy: 0.9359, F1 Micro: 0.9608, F1 Macro: 0.9582\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1562, Accuracy: 0.9387, F1 Micro: 0.9624, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.136, Accuracy: 0.9418, F1 Micro: 0.9644, F1 Macro: 0.9618\n",
      "\n",
      "Aspect detection accuracy: 0.9418, F1 Micro: 0.9644, F1 Macro: 0.9618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.95      0.99      0.97       480\n",
      "         bau       0.96      0.96      0.96       496\n",
      "     general       0.89      1.00      0.94       500\n",
      "  kebersihan       0.90      0.92      0.91       317\n",
      "       linen       0.86      0.98      0.92       392\n",
      "     service       0.96      0.97      0.96       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      4614\n",
      "   macro avg       0.95      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.96      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.479, Accuracy: 0.7244, F1 Micro: 0.7244, F1 Macro: 0.4201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3305, Accuracy: 0.8311, F1 Micro: 0.8311, F1 Macro: 0.7857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2406, Accuracy: 0.8528, F1 Micro: 0.8528, F1 Macro: 0.7868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1892, Accuracy: 0.8632, F1 Micro: 0.8632, F1 Macro: 0.8149\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1577, Accuracy: 0.8777, F1 Micro: 0.8777, F1 Macro: 0.8306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.109, Accuracy: 0.8819, F1 Micro: 0.8819, F1 Macro: 0.8358\n",
      "Epoch 7/10, Train Loss: 0.0951, Accuracy: 0.8767, F1 Micro: 0.8767, F1 Macro: 0.8284\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0795, Accuracy: 0.8902, F1 Micro: 0.8902, F1 Macro: 0.855\n",
      "Epoch 9/10, Train Loss: 0.061, Accuracy: 0.8684, F1 Micro: 0.8684, F1 Macro: 0.809\n",
      "Epoch 10/10, Train Loss: 0.0388, Accuracy: 0.8788, F1 Micro: 0.8788, F1 Macro: 0.8323\n",
      "\n",
      "Sentiment analysis accuracy: 0.8902, F1 Micro: 0.8902, F1 Macro: 0.855\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93       699\n",
      "    positive       0.86      0.72      0.78       266\n",
      "\n",
      "    accuracy                           0.89       965\n",
      "   macro avg       0.88      0.84      0.86       965\n",
      "weighted avg       0.89      0.89      0.89       965\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9329, F1 Micro: 0.9329, F1 Macro: 0.7516\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.91      0.67      0.77        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.87      0.90       571\n",
      "weighted avg       0.98      0.98      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.76      0.82        86\n",
      "     neutral       0.95      0.99      0.97       475\n",
      "    positive       1.00      0.30      0.46        10\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.95      0.68      0.75       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.77      0.75        78\n",
      "     neutral       0.96      0.96      0.96       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.90      0.74      0.79       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.89      1.00      0.94       496\n",
      "    positive       0.93      0.19      0.32        68\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.61      0.40      0.42       571\n",
      "weighted avg       0.88      0.89      0.85       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.82      0.84       200\n",
      "     neutral       0.90      0.92      0.91       315\n",
      "    positive       0.84      0.93      0.88        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.87      0.89      0.88       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.65      0.77       162\n",
      "     neutral       0.86      0.98      0.92       387\n",
      "    positive       0.36      0.23      0.28        22\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.71      0.62      0.65       571\n",
      "weighted avg       0.86      0.86      0.85       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82        85\n",
      "     neutral       0.96      0.97      0.96       418\n",
      "    positive       0.90      0.90      0.90        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.89      0.89       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.34      0.48        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.69      0.65      0.67        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.81      0.66      0.71       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.89      0.88        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.68      0.72       571\n",
      "weighted avg       0.98      0.98      0.97       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.74      0.81       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 146.20100736618042 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 174\n",
      "Sampling duration: 0.00016689300537109375 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5147, Accuracy: 0.8019, F1 Micro: 0.8898, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4308, Accuracy: 0.817, F1 Micro: 0.8974, F1 Macro: 0.8932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3786, Accuracy: 0.8806, F1 Micro: 0.9297, F1 Macro: 0.9254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2948, Accuracy: 0.9142, F1 Micro: 0.9484, F1 Macro: 0.9449\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2369, Accuracy: 0.934, F1 Micro: 0.9598, F1 Macro: 0.9572\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1925, Accuracy: 0.9382, F1 Micro: 0.9623, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1758, Accuracy: 0.9424, F1 Micro: 0.9649, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1471, Accuracy: 0.9479, F1 Micro: 0.968, F1 Macro: 0.9658\n",
      "Epoch 9/10, Train Loss: 0.1304, Accuracy: 0.9444, F1 Micro: 0.966, F1 Macro: 0.9637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1139, Accuracy: 0.9524, F1 Micro: 0.9706, F1 Macro: 0.9682\n",
      "\n",
      "Aspect detection accuracy: 0.9524, F1 Micro: 0.9706, F1 Macro: 0.9682\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.96      0.97      0.97       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.90      0.95      0.92       317\n",
      "       linen       0.92      0.94      0.93       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.452, Accuracy: 0.7988, F1 Micro: 0.7988, F1 Macro: 0.7643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2699, Accuracy: 0.854, F1 Micro: 0.854, F1 Macro: 0.8101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1881, Accuracy: 0.8617, F1 Micro: 0.8617, F1 Macro: 0.8235\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.181, Accuracy: 0.881, F1 Micro: 0.881, F1 Macro: 0.8446\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1486, Accuracy: 0.8849, F1 Micro: 0.8849, F1 Macro: 0.8492\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1103, Accuracy: 0.8956, F1 Micro: 0.8956, F1 Macro: 0.8609\n",
      "Epoch 7/10, Train Loss: 0.112, Accuracy: 0.8723, F1 Micro: 0.8723, F1 Macro: 0.8215\n",
      "Epoch 8/10, Train Loss: 0.0677, Accuracy: 0.8849, F1 Micro: 0.8849, F1 Macro: 0.8458\n",
      "Epoch 9/10, Train Loss: 0.0457, Accuracy: 0.8868, F1 Micro: 0.8868, F1 Macro: 0.8491\n",
      "Epoch 10/10, Train Loss: 0.0339, Accuracy: 0.8791, F1 Micro: 0.8791, F1 Macro: 0.8354\n",
      "\n",
      "Sentiment analysis accuracy: 0.8956, F1 Micro: 0.8956, F1 Macro: 0.8609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       737\n",
      "    positive       0.93      0.69      0.79       297\n",
      "\n",
      "    accuracy                           0.90      1034\n",
      "   macro avg       0.91      0.83      0.86      1034\n",
      "weighted avg       0.90      0.90      0.89      1034\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.7501\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.84      0.88        86\n",
      "     neutral       0.97      1.00      0.98       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.74      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.77      0.78        78\n",
      "     neutral       0.96      0.97      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.58      0.58      0.58       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.95       496\n",
      "    positive       0.85      0.49      0.62        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.49      0.52       571\n",
      "weighted avg       0.90      0.92      0.90       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.81      0.86       200\n",
      "     neutral       0.90      0.95      0.92       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.85      0.82       162\n",
      "     neutral       0.92      0.94      0.93       387\n",
      "    positive       0.50      0.09      0.15        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.74      0.63      0.64       571\n",
      "weighted avg       0.87      0.88      0.87       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        85\n",
      "     neutral       0.96      0.97      0.97       418\n",
      "    positive       0.95      0.88      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.89      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.34      0.40        29\n",
      "     neutral       0.96      1.00      0.98       525\n",
      "    positive       0.50      0.24      0.32        17\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.65      0.53      0.57       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.69      0.72       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.98      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 164.24412536621094 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 156\n",
      "Sampling duration: 0.0001544952392578125 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5003, Accuracy: 0.8012, F1 Micro: 0.8895, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4084, Accuracy: 0.8536, F1 Micro: 0.9155, F1 Macro: 0.9113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3323, Accuracy: 0.9109, F1 Micro: 0.9463, F1 Macro: 0.9419\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2669, Accuracy: 0.9295, F1 Micro: 0.9571, F1 Macro: 0.9545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1979, Accuracy: 0.9427, F1 Micro: 0.9649, F1 Macro: 0.9627\n",
      "Epoch 6/10, Train Loss: 0.1738, Accuracy: 0.9403, F1 Micro: 0.9636, F1 Macro: 0.9615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1503, Accuracy: 0.9455, F1 Micro: 0.9664, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.128, Accuracy: 0.9542, F1 Micro: 0.9716, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1115, Accuracy: 0.9542, F1 Micro: 0.9716, F1 Macro: 0.9689\n",
      "Epoch 10/10, Train Loss: 0.099, Accuracy: 0.9514, F1 Micro: 0.9701, F1 Macro: 0.9677\n",
      "\n",
      "Aspect detection accuracy: 0.9542, F1 Micro: 0.9716, F1 Macro: 0.9689\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.96      0.97      0.97       496\n",
      "     general       0.93      0.99      0.96       500\n",
      "  kebersihan       0.93      0.91      0.92       317\n",
      "       linen       0.91      0.96      0.93       392\n",
      "     service       0.97      0.96      0.96       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4577, Accuracy: 0.8227, F1 Micro: 0.8227, F1 Macro: 0.7546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.297, Accuracy: 0.8512, F1 Micro: 0.8512, F1 Macro: 0.7984\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1908, Accuracy: 0.8512, F1 Micro: 0.8512, F1 Macro: 0.7928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.124, Accuracy: 0.8834, F1 Micro: 0.8834, F1 Macro: 0.8448\n",
      "Epoch 5/10, Train Loss: 0.1209, Accuracy: 0.8815, F1 Micro: 0.8815, F1 Macro: 0.8475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0828, Accuracy: 0.8863, F1 Micro: 0.8863, F1 Macro: 0.8499\n",
      "Epoch 7/10, Train Loss: 0.0933, Accuracy: 0.8796, F1 Micro: 0.8796, F1 Macro: 0.8377\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0682, Accuracy: 0.89, F1 Micro: 0.89, F1 Macro: 0.8539\n",
      "Epoch 9/10, Train Loss: 0.0415, Accuracy: 0.8863, F1 Micro: 0.8863, F1 Macro: 0.8503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0621, Accuracy: 0.891, F1 Micro: 0.891, F1 Macro: 0.8564\n",
      "\n",
      "Sentiment analysis accuracy: 0.891, F1 Micro: 0.891, F1 Macro: 0.8564\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93       744\n",
      "    positive       0.93      0.68      0.79       311\n",
      "\n",
      "    accuracy                           0.89      1055\n",
      "   macro avg       0.91      0.83      0.86      1055\n",
      "weighted avg       0.90      0.89      0.89      1055\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9469, F1 Micro: 0.9469, F1 Macro: 0.8269\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.92      0.80      0.86        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.91      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.80      0.86        86\n",
      "     neutral       0.97      1.00      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.77      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.79      0.80        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.75      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.99      0.96       496\n",
      "    positive       0.87      0.57      0.69        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.60      0.52      0.55       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87       200\n",
      "     neutral       0.93      0.91      0.92       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.80      0.82       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.57      0.18      0.28        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.78      0.65      0.68       571\n",
      "weighted avg       0.88      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83        85\n",
      "     neutral       0.97      0.96      0.97       418\n",
      "    positive       0.91      0.90      0.90        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.90      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.48      0.61        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.73      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 181.07684016227722 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 141\n",
      "Sampling duration: 0.0001506805419921875 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4935, Accuracy: 0.8064, F1 Micro: 0.8916, F1 Macro: 0.8859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4103, Accuracy: 0.8729, F1 Micro: 0.9256, F1 Macro: 0.922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3008, Accuracy: 0.9219, F1 Micro: 0.9529, F1 Macro: 0.9501\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2388, Accuracy: 0.9314, F1 Micro: 0.9584, F1 Macro: 0.9557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.188, Accuracy: 0.9446, F1 Micro: 0.9661, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1677, Accuracy: 0.9486, F1 Micro: 0.9684, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1357, Accuracy: 0.9514, F1 Micro: 0.9701, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1115, Accuracy: 0.9564, F1 Micro: 0.9731, F1 Macro: 0.9708\n",
      "Epoch 9/10, Train Loss: 0.1053, Accuracy: 0.9512, F1 Micro: 0.97, F1 Macro: 0.9674\n",
      "Epoch 10/10, Train Loss: 0.0883, Accuracy: 0.9566, F1 Micro: 0.9731, F1 Macro: 0.9704\n",
      "\n",
      "Aspect detection accuracy: 0.9564, F1 Micro: 0.9731, F1 Macro: 0.9708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.93      0.99      0.96       500\n",
      "  kebersihan       0.92      0.94      0.93       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4389, Accuracy: 0.8479, F1 Micro: 0.8479, F1 Macro: 0.7908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2851, Accuracy: 0.8691, F1 Micro: 0.8691, F1 Macro: 0.8363\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1975, Accuracy: 0.8778, F1 Micro: 0.8778, F1 Macro: 0.8348\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1486, Accuracy: 0.8999, F1 Micro: 0.8999, F1 Macro: 0.8673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1195, Accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.8748\n",
      "Epoch 6/10, Train Loss: 0.0987, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.8633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0591, Accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.8786\n",
      "Epoch 8/10, Train Loss: 0.0571, Accuracy: 0.9018, F1 Micro: 0.9018, F1 Macro: 0.8695\n",
      "Epoch 9/10, Train Loss: 0.0378, Accuracy: 0.8999, F1 Micro: 0.8999, F1 Macro: 0.8726\n",
      "Epoch 10/10, Train Loss: 0.0384, Accuracy: 0.8903, F1 Micro: 0.8903, F1 Macro: 0.8511\n",
      "\n",
      "Sentiment analysis accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.8786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.93       743\n",
      "    positive       0.88      0.77      0.82       296\n",
      "\n",
      "    accuracy                           0.90      1039\n",
      "   macro avg       0.90      0.87      0.88      1039\n",
      "weighted avg       0.90      0.90      0.90      1039\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.765\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.75      0.30      0.43        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.88      0.72      0.76       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.77      0.79        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.58      0.59       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.60      0.71        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.53      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87       200\n",
      "     neutral       0.94      0.91      0.92       315\n",
      "    positive       0.88      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.85      0.84       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.58      0.61      0.59       571\n",
      "weighted avg       0.86      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.88      0.80        85\n",
      "     neutral       0.98      0.94      0.96       418\n",
      "    positive       0.91      0.90      0.90        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.91      0.89       571\n",
      "weighted avg       0.93      0.92      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.52      0.59        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.57      0.47      0.52        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.74      0.66      0.70       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.96      0.91        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.71      0.73       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 196.65819692611694 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 127\n",
      "Sampling duration: 0.000152587890625 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4979, Accuracy: 0.8038, F1 Micro: 0.8908, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3864, Accuracy: 0.8854, F1 Micro: 0.9318, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2783, Accuracy: 0.9252, F1 Micro: 0.9546, F1 Macro: 0.9519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2136, Accuracy: 0.9347, F1 Micro: 0.9601, F1 Macro: 0.9574\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1851, Accuracy: 0.9474, F1 Micro: 0.9676, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1503, Accuracy: 0.9502, F1 Micro: 0.9694, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1303, Accuracy: 0.9535, F1 Micro: 0.9713, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1068, Accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9713\n",
      "Epoch 9/10, Train Loss: 0.0917, Accuracy: 0.9549, F1 Micro: 0.9721, F1 Macro: 0.9698\n",
      "Epoch 10/10, Train Loss: 0.0848, Accuracy: 0.955, F1 Micro: 0.9722, F1 Macro: 0.9696\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.96      0.97      0.96       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.91      0.96      0.94       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4306, Accuracy: 0.8343, F1 Micro: 0.8343, F1 Macro: 0.7765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.239, Accuracy: 0.8481, F1 Micro: 0.8481, F1 Macro: 0.7901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1878, Accuracy: 0.8731, F1 Micro: 0.8731, F1 Macro: 0.8327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1336, Accuracy: 0.8917, F1 Micro: 0.8917, F1 Macro: 0.8617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1, Accuracy: 0.8917, F1 Micro: 0.8917, F1 Macro: 0.861\n",
      "Epoch 6/10, Train Loss: 0.0842, Accuracy: 0.8796, F1 Micro: 0.8796, F1 Macro: 0.8433\n",
      "Epoch 7/10, Train Loss: 0.0655, Accuracy: 0.887, F1 Micro: 0.887, F1 Macro: 0.8553\n",
      "Epoch 8/10, Train Loss: 0.0597, Accuracy: 0.8852, F1 Micro: 0.8852, F1 Macro: 0.8529\n",
      "Epoch 9/10, Train Loss: 0.0379, Accuracy: 0.888, F1 Micro: 0.888, F1 Macro: 0.8563\n",
      "Epoch 10/10, Train Loss: 0.0532, Accuracy: 0.8907, F1 Micro: 0.8907, F1 Macro: 0.8621\n",
      "\n",
      "Sentiment analysis accuracy: 0.8917, F1 Micro: 0.8917, F1 Macro: 0.861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93       759\n",
      "    positive       0.90      0.71      0.80       321\n",
      "\n",
      "    accuracy                           0.89      1080\n",
      "   macro avg       0.90      0.84      0.86      1080\n",
      "weighted avg       0.89      0.89      0.89      1080\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9497, F1 Micro: 0.9497, F1 Macro: 0.836\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.80      0.40      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.89      0.75      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.79      0.78        78\n",
      "     neutral       0.97      0.96      0.96       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.75      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.87      0.66      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.87       200\n",
      "     neutral       0.94      0.91      0.93       315\n",
      "    positive       0.83      0.96      0.89        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.88      0.92      0.90       571\n",
      "weighted avg       0.91      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.60      0.41      0.49        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.80      0.73      0.75       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        85\n",
      "     neutral       0.97      0.96      0.97       418\n",
      "    positive       0.84      0.94      0.89        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.38      0.52        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.59      0.94      0.73        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.77      0.75       571\n",
      "weighted avg       0.97      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 210.198077917099 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 114\n",
      "Sampling duration: 0.00015735626220703125 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4855, Accuracy: 0.8019, F1 Micro: 0.89, F1 Macro: 0.8856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3736, Accuracy: 0.8977, F1 Micro: 0.9391, F1 Macro: 0.9351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2584, Accuracy: 0.9356, F1 Micro: 0.9608, F1 Macro: 0.9586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2079, Accuracy: 0.9375, F1 Micro: 0.962, F1 Macro: 0.9598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1665, Accuracy: 0.9443, F1 Micro: 0.966, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1458, Accuracy: 0.9531, F1 Micro: 0.9711, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1173, Accuracy: 0.9531, F1 Micro: 0.9711, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1052, Accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.9729\n",
      "Epoch 9/10, Train Loss: 0.0865, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9729\n",
      "Epoch 10/10, Train Loss: 0.0746, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9717\n",
      "\n",
      "Aspect detection accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.9729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.96      0.97      0.97       500\n",
      "  kebersihan       0.92      0.93      0.93       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3996, Accuracy: 0.8541, F1 Micro: 0.8541, F1 Macro: 0.8107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2719, Accuracy: 0.8643, F1 Micro: 0.8643, F1 Macro: 0.8163\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1886, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1333, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0906, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.081, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8796\n",
      "Epoch 7/10, Train Loss: 0.0487, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8752\n",
      "Epoch 8/10, Train Loss: 0.0428, Accuracy: 0.8978, F1 Micro: 0.8978, F1 Macro: 0.8672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0539, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8825\n",
      "Epoch 10/10, Train Loss: 0.0342, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.876\n",
      "\n",
      "Sentiment analysis accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       758\n",
      "    positive       0.93      0.75      0.83       318\n",
      "\n",
      "    accuracy                           0.91      1076\n",
      "   macro avg       0.91      0.86      0.88      1076\n",
      "weighted avg       0.91      0.91      0.90      1076\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9517, F1 Micro: 0.9517, F1 Macro: 0.8368\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.78      0.93      0.85        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.79      0.79        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.75      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.29      0.33         7\n",
      "     neutral       0.96      0.97      0.97       496\n",
      "    positive       0.79      0.76      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.72      0.67      0.69       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.83      0.84       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.67      0.18      0.29        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.81      0.66      0.69       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.87      0.83        85\n",
      "     neutral       0.98      0.95      0.97       418\n",
      "    positive       0.90      0.91      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.52      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.74      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.86      0.99      0.90       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 229.0527868270874 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 103\n",
      "Sampling duration: 0.00015425682067871094 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4808, Accuracy: 0.821, F1 Micro: 0.899, F1 Macro: 0.8942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3698, Accuracy: 0.9066, F1 Micro: 0.9441, F1 Macro: 0.94\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2508, Accuracy: 0.9345, F1 Micro: 0.9601, F1 Macro: 0.9577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1915, Accuracy: 0.9455, F1 Micro: 0.9667, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.162, Accuracy: 0.9497, F1 Micro: 0.9691, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1357, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1134, Accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0981, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0799, Accuracy: 0.9601, F1 Micro: 0.9752, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.073, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.973\n",
      "\n",
      "Aspect detection accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.973\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.92      0.94      0.93       317\n",
      "       linen       0.91      0.96      0.94       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      0.99      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3865, Accuracy: 0.8628, F1 Micro: 0.8628, F1 Macro: 0.8172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2236, Accuracy: 0.8846, F1 Micro: 0.8846, F1 Macro: 0.8504\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1706, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1128, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8831\n",
      "Epoch 5/10, Train Loss: 0.0825, Accuracy: 0.894, F1 Micro: 0.894, F1 Macro: 0.8568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0658, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8919\n",
      "Epoch 7/10, Train Loss: 0.0475, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8829\n",
      "Epoch 8/10, Train Loss: 0.0382, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8845\n",
      "Epoch 9/10, Train Loss: 0.029, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8761\n",
      "Epoch 10/10, Train Loss: 0.0212, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8801\n",
      "\n",
      "Sentiment analysis accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8919\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       756\n",
      "    positive       0.93      0.77      0.84       301\n",
      "\n",
      "    accuracy                           0.92      1057\n",
      "   macro avg       0.92      0.87      0.89      1057\n",
      "weighted avg       0.92      0.92      0.91      1057\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9532, F1 Micro: 0.9532, F1 Macro: 0.8388\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.85      0.90        86\n",
      "     neutral       0.97      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.78      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.56      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.87       200\n",
      "     neutral       0.92      0.94      0.93       315\n",
      "    positive       0.85      0.93      0.89        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.90      0.90       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85       162\n",
      "     neutral       0.91      0.96      0.94       387\n",
      "    positive       0.62      0.23      0.33        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.80      0.67      0.71       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.84        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.93      0.91      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.90      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.41      0.53        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.82      0.74        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.80      0.74      0.75       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      1.00      0.98        74\n",
      "     neutral       1.00      0.99      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 241.82619333267212 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 62\n",
      "Sampling duration: 0.02222728729248047 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4772, Accuracy: 0.817, F1 Micro: 0.8973, F1 Macro: 0.893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3489, Accuracy: 0.9111, F1 Micro: 0.9465, F1 Macro: 0.9423\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2393, Accuracy: 0.9401, F1 Micro: 0.9633, F1 Macro: 0.9607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1905, Accuracy: 0.9483, F1 Micro: 0.9684, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1581, Accuracy: 0.9524, F1 Micro: 0.9708, F1 Macro: 0.9688\n",
      "Epoch 6/10, Train Loss: 0.1308, Accuracy: 0.9509, F1 Micro: 0.9699, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1121, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9731\n",
      "Epoch 8/10, Train Loss: 0.0947, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.973\n",
      "Epoch 9/10, Train Loss: 0.08, Accuracy: 0.9587, F1 Micro: 0.9744, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0671, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9735\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.94      0.95      0.94       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3911, Accuracy: 0.8593, F1 Micro: 0.8593, F1 Macro: 0.8193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2173, Accuracy: 0.8793, F1 Micro: 0.8793, F1 Macro: 0.8491\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1644, Accuracy: 0.8938, F1 Micro: 0.8938, F1 Macro: 0.8633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.121, Accuracy: 0.8966, F1 Micro: 0.8966, F1 Macro: 0.8672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0787, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8706\n",
      "Epoch 6/10, Train Loss: 0.0507, Accuracy: 0.8775, F1 Micro: 0.8775, F1 Macro: 0.8371\n",
      "Epoch 7/10, Train Loss: 0.0453, Accuracy: 0.8875, F1 Micro: 0.8875, F1 Macro: 0.8543\n",
      "Epoch 8/10, Train Loss: 0.0374, Accuracy: 0.8956, F1 Micro: 0.8956, F1 Macro: 0.8662\n",
      "Epoch 9/10, Train Loss: 0.0332, Accuracy: 0.892, F1 Micro: 0.892, F1 Macro: 0.8594\n",
      "Epoch 10/10, Train Loss: 0.017, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.8619\n",
      "\n",
      "Sentiment analysis accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       774\n",
      "    positive       0.93      0.72      0.81       328\n",
      "\n",
      "    accuracy                           0.90      1102\n",
      "   macro avg       0.91      0.85      0.87      1102\n",
      "weighted avg       0.90      0.90      0.90      1102\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9536, F1 Micro: 0.9536, F1 Macro: 0.8456\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.59       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87       200\n",
      "     neutral       0.92      0.93      0.93       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86       162\n",
      "     neutral       0.94      0.95      0.94       387\n",
      "    positive       0.56      0.45      0.50        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.79      0.75      0.77       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.87      0.82        85\n",
      "     neutral       0.97      0.96      0.97       418\n",
      "    positive       0.94      0.85      0.89        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.90      0.89       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.77      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.71      0.83      0.77         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.88      0.92      0.90       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 244.19914484024048 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 86\n",
      "Sampling duration: 0.00014495849609375 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4741, Accuracy: 0.8089, F1 Micro: 0.8933, F1 Macro: 0.8886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3411, Accuracy: 0.9201, F1 Micro: 0.9518, F1 Macro: 0.9485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2298, Accuracy: 0.9398, F1 Micro: 0.9633, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1847, Accuracy: 0.9434, F1 Micro: 0.9655, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1483, Accuracy: 0.9514, F1 Micro: 0.9701, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1224, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1061, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9735\n",
      "Epoch 8/10, Train Loss: 0.0884, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0755, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.064, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3809, Accuracy: 0.8602, F1 Micro: 0.8602, F1 Macro: 0.8234\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2246, Accuracy: 0.8865, F1 Micro: 0.8865, F1 Macro: 0.8459\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1615, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.116, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8848\n",
      "Epoch 5/10, Train Loss: 0.0778, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0587, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.8949\n",
      "Epoch 7/10, Train Loss: 0.0551, Accuracy: 0.9156, F1 Micro: 0.9156, F1 Macro: 0.8889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0339, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.8935\n",
      "Epoch 9/10, Train Loss: 0.014, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8889\n",
      "Epoch 10/10, Train Loss: 0.025, Accuracy: 0.9156, F1 Micro: 0.9156, F1 Macro: 0.8881\n",
      "\n",
      "Sentiment analysis accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.8935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.94       765\n",
      "    positive       0.93      0.77      0.84       301\n",
      "\n",
      "    accuracy                           0.92      1066\n",
      "   macro avg       0.92      0.87      0.89      1066\n",
      "weighted avg       0.92      0.92      0.92      1066\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9562, F1 Micro: 0.9562, F1 Macro: 0.8654\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.85      0.90        86\n",
      "     neutral       0.97      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.78      0.82       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86       162\n",
      "     neutral       0.91      0.98      0.94       387\n",
      "    positive       0.86      0.27      0.41        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.69      0.74       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.87      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.90      0.90        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.78      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.88      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 263.12225437164307 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 77\n",
      "Sampling duration: 0.00012826919555664062 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4693, Accuracy: 0.8163, F1 Micro: 0.8967, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3296, Accuracy: 0.9252, F1 Micro: 0.9546, F1 Macro: 0.9514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2174, Accuracy: 0.9436, F1 Micro: 0.9656, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1771, Accuracy: 0.9538, F1 Micro: 0.9715, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1485, Accuracy: 0.954, F1 Micro: 0.9717, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1205, Accuracy: 0.9611, F1 Micro: 0.9758, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1002, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0872, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9748\n",
      "Epoch 9/10, Train Loss: 0.0702, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9738\n",
      "Epoch 10/10, Train Loss: 0.0629, Accuracy: 0.962, F1 Micro: 0.9765, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.93      0.94      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3772, Accuracy: 0.8544, F1 Micro: 0.8544, F1 Macro: 0.8038\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2383, Accuracy: 0.8829, F1 Micro: 0.8829, F1 Macro: 0.8433\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.162, Accuracy: 0.8912, F1 Micro: 0.8912, F1 Macro: 0.8523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1042, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0753, Accuracy: 0.9041, F1 Micro: 0.9041, F1 Macro: 0.8746\n",
      "Epoch 6/10, Train Loss: 0.0565, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0439, Accuracy: 0.9041, F1 Micro: 0.9041, F1 Macro: 0.8731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.04, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8794\n",
      "Epoch 9/10, Train Loss: 0.0285, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.878\n",
      "Epoch 10/10, Train Loss: 0.0217, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8651\n",
      "\n",
      "Sentiment analysis accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       774\n",
      "    positive       0.93      0.74      0.82       311\n",
      "\n",
      "    accuracy                           0.91      1085\n",
      "   macro avg       0.91      0.86      0.88      1085\n",
      "weighted avg       0.91      0.91      0.90      1085\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9559, F1 Micro: 0.9559, F1 Macro: 0.8415\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       1.00      0.40      0.57        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.97      0.76      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.82      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.76      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.71      0.61      0.64       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.86      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.90      0.88       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.62      0.23      0.33        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.81      0.70      0.72       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.59      0.63        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.47      0.57        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.79      0.68      0.73       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 267.6734354496002 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 70\n",
      "Sampling duration: 0.00011873245239257812 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4755, Accuracy: 0.838, F1 Micro: 0.9078, F1 Macro: 0.9038\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3076, Accuracy: 0.9264, F1 Micro: 0.9553, F1 Macro: 0.9522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2164, Accuracy: 0.9444, F1 Micro: 0.9659, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1774, Accuracy: 0.9524, F1 Micro: 0.9707, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1416, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1179, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9742\n",
      "Epoch 7/10, Train Loss: 0.103, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9742\n",
      "Epoch 8/10, Train Loss: 0.0854, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9732\n",
      "Epoch 9/10, Train Loss: 0.0726, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0631, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9748\n",
      "\n",
      "Aspect detection accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.97      0.97       500\n",
      "  kebersihan       0.94      0.93      0.93       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3696, Accuracy: 0.8463, F1 Micro: 0.8463, F1 Macro: 0.7917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.222, Accuracy: 0.8776, F1 Micro: 0.8776, F1 Macro: 0.8415\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1535, Accuracy: 0.8847, F1 Micro: 0.8847, F1 Macro: 0.849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1108, Accuracy: 0.8972, F1 Micro: 0.8972, F1 Macro: 0.8669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0669, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.055, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.877\n",
      "Epoch 7/10, Train Loss: 0.0432, Accuracy: 0.8972, F1 Micro: 0.8972, F1 Macro: 0.8684\n",
      "Epoch 8/10, Train Loss: 0.0366, Accuracy: 0.891, F1 Micro: 0.891, F1 Macro: 0.859\n",
      "Epoch 9/10, Train Loss: 0.0305, Accuracy: 0.8928, F1 Micro: 0.8928, F1 Macro: 0.8631\n",
      "Epoch 10/10, Train Loss: 0.0129, Accuracy: 0.8972, F1 Micro: 0.8972, F1 Macro: 0.8726\n",
      "\n",
      "Sentiment analysis accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       781\n",
      "    positive       0.94      0.73      0.82       338\n",
      "\n",
      "    accuracy                           0.90      1119\n",
      "   macro avg       0.92      0.85      0.88      1119\n",
      "weighted avg       0.91      0.90      0.90      1119\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.8554\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.84      0.89        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.83      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.96      0.97      0.96       496\n",
      "    positive       0.77      0.81      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.69      0.64      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.84      0.95      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.71      0.45      0.56        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.85      0.76      0.80       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.81      0.83        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.83      0.94      0.88        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.88      0.90      0.89       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.41      0.57        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.65      1.00      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.78       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 269.1266191005707 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 52\n",
      "Sampling duration: 0.01573038101196289 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4697, Accuracy: 0.8411, F1 Micro: 0.9084, F1 Macro: 0.9023\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3066, Accuracy: 0.9311, F1 Micro: 0.9582, F1 Macro: 0.9557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2088, Accuracy: 0.9462, F1 Micro: 0.967, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1692, Accuracy: 0.9519, F1 Micro: 0.9705, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1347, Accuracy: 0.9578, F1 Micro: 0.974, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1138, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0979, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.975\n",
      "Epoch 8/10, Train Loss: 0.0793, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0702, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9748\n",
      "Epoch 10/10, Train Loss: 0.06, Accuracy: 0.9604, F1 Micro: 0.9754, F1 Macro: 0.9731\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.96      0.91      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3508, Accuracy: 0.828, F1 Micro: 0.828, F1 Macro: 0.7422\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2335, Accuracy: 0.8708, F1 Micro: 0.8708, F1 Macro: 0.823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1718, Accuracy: 0.8972, F1 Micro: 0.8972, F1 Macro: 0.8645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1203, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8739\n",
      "Epoch 5/10, Train Loss: 0.099, Accuracy: 0.8999, F1 Micro: 0.8999, F1 Macro: 0.8694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0985, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8762\n",
      "Epoch 7/10, Train Loss: 0.0701, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0553, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8815\n",
      "Epoch 9/10, Train Loss: 0.0584, Accuracy: 0.8972, F1 Micro: 0.8972, F1 Macro: 0.8632\n",
      "Epoch 10/10, Train Loss: 0.0331, Accuracy: 0.8972, F1 Micro: 0.8972, F1 Macro: 0.8666\n",
      "\n",
      "Sentiment analysis accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       782\n",
      "    positive       0.95      0.73      0.82       317\n",
      "\n",
      "    accuracy                           0.91      1099\n",
      "   macro avg       0.92      0.86      0.88      1099\n",
      "weighted avg       0.91      0.91      0.91      1099\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9541, F1 Micro: 0.9541, F1 Macro: 0.8362\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.97      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.85      0.89        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.78      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.86      0.63      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.54      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.91      0.89       200\n",
      "     neutral       0.96      0.90      0.93       315\n",
      "    positive       0.83      0.95      0.88        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.87      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.70      0.32      0.44        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.83      0.72      0.75       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.87      0.87        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.89      0.93      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.89      0.91        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.60      1.00      0.75         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.85      0.96      0.89       571\n",
      "weighted avg       0.99      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 271.1184277534485 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 58\n",
      "Sampling duration: 0.0001087188720703125 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4677, Accuracy: 0.8467, F1 Micro: 0.9117, F1 Macro: 0.9071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3028, Accuracy: 0.9307, F1 Micro: 0.9579, F1 Macro: 0.9554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2102, Accuracy: 0.9446, F1 Micro: 0.966, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1641, Accuracy: 0.95, F1 Micro: 0.9694, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1432, Accuracy: 0.9576, F1 Micro: 0.9738, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1134, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9747\n",
      "Epoch 7/10, Train Loss: 0.0973, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9742\n",
      "Epoch 8/10, Train Loss: 0.0811, Accuracy: 0.9609, F1 Micro: 0.9757, F1 Macro: 0.9733\n",
      "Epoch 9/10, Train Loss: 0.0665, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.974\n",
      "Epoch 10/10, Train Loss: 0.0578, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.95      0.95      0.95       392\n",
      "     service       0.98      0.95      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3997, Accuracy: 0.8439, F1 Micro: 0.8439, F1 Macro: 0.7953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.262, Accuracy: 0.8724, F1 Micro: 0.8724, F1 Macro: 0.8316\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1703, Accuracy: 0.8894, F1 Micro: 0.8894, F1 Macro: 0.8592\n",
      "Epoch 4/10, Train Loss: 0.1275, Accuracy: 0.8822, F1 Micro: 0.8822, F1 Macro: 0.844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0971, Accuracy: 0.8903, F1 Micro: 0.8903, F1 Macro: 0.8578\n",
      "Epoch 6/10, Train Loss: 0.0904, Accuracy: 0.8894, F1 Micro: 0.8894, F1 Macro: 0.8555\n",
      "Epoch 7/10, Train Loss: 0.0554, Accuracy: 0.8894, F1 Micro: 0.8894, F1 Macro: 0.8595\n",
      "Epoch 8/10, Train Loss: 0.0575, Accuracy: 0.8876, F1 Micro: 0.8876, F1 Macro: 0.8554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0427, Accuracy: 0.8903, F1 Micro: 0.8903, F1 Macro: 0.8584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0243, Accuracy: 0.9001, F1 Micro: 0.9001, F1 Macro: 0.8723\n",
      "\n",
      "Sentiment analysis accuracy: 0.9001, F1 Micro: 0.9001, F1 Macro: 0.8723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93       787\n",
      "    positive       0.92      0.73      0.81       334\n",
      "\n",
      "    accuracy                           0.90      1121\n",
      "   macro avg       0.91      0.85      0.87      1121\n",
      "weighted avg       0.90      0.90      0.90      1121\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9559, F1 Micro: 0.9559, F1 Macro: 0.8602\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.87      0.80        78\n",
      "     neutral       0.98      0.95      0.96       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.77      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.14      0.29      0.19         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.85      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.65      0.65      0.64       571\n",
      "weighted avg       0.94      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.94      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.90      0.88       162\n",
      "     neutral       0.96      0.95      0.95       387\n",
      "    positive       0.61      0.50      0.55        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.81      0.78      0.79       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        85\n",
      "     neutral       0.98      0.95      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.95      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.81      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 278.9046895503998 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 52\n",
      "Sampling duration: 0.00011014938354492188 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.464, Accuracy: 0.8377, F1 Micro: 0.907, F1 Macro: 0.9021\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3, Accuracy: 0.9286, F1 Micro: 0.9566, F1 Macro: 0.9533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2089, Accuracy: 0.9488, F1 Micro: 0.9684, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1688, Accuracy: 0.9497, F1 Micro: 0.9691, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.14, Accuracy: 0.9573, F1 Micro: 0.9736, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1156, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "Epoch 7/10, Train Loss: 0.0931, Accuracy: 0.9611, F1 Micro: 0.9758, F1 Macro: 0.9726\n",
      "Epoch 8/10, Train Loss: 0.0813, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0679, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0585, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.96      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.95      0.92      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3776, Accuracy: 0.8594, F1 Micro: 0.8594, F1 Macro: 0.819\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2171, Accuracy: 0.8731, F1 Micro: 0.8731, F1 Macro: 0.824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.138, Accuracy: 0.8886, F1 Micro: 0.8886, F1 Macro: 0.8597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1184, Accuracy: 0.8986, F1 Micro: 0.8986, F1 Macro: 0.8651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.074, Accuracy: 0.8986, F1 Micro: 0.8986, F1 Macro: 0.8648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0499, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8694\n",
      "Epoch 7/10, Train Loss: 0.0626, Accuracy: 0.8913, F1 Micro: 0.8913, F1 Macro: 0.8633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.042, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8769\n",
      "Epoch 9/10, Train Loss: 0.0328, Accuracy: 0.8941, F1 Micro: 0.8941, F1 Macro: 0.8595\n",
      "Epoch 10/10, Train Loss: 0.0393, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8696\n",
      "\n",
      "Sentiment analysis accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       780\n",
      "    positive       0.93      0.73      0.82       315\n",
      "\n",
      "    accuracy                           0.91      1095\n",
      "   macro avg       0.91      0.85      0.88      1095\n",
      "weighted avg       0.91      0.91      0.90      1095\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.8669\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.83      0.81        78\n",
      "     neutral       0.97      0.96      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.90      0.63      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.61      0.54      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90       200\n",
      "     neutral       0.95      0.92      0.93       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       1.00      0.36      0.53        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.73      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.87      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.88      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.62      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.65      0.69        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.75      0.79       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 296.3389413356781 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.918212890625e-05 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.46, Accuracy: 0.854, F1 Micro: 0.9153, F1 Macro: 0.9111\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2901, Accuracy: 0.9326, F1 Micro: 0.9589, F1 Macro: 0.956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.205, Accuracy: 0.9477, F1 Micro: 0.9679, F1 Macro: 0.9657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.164, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.128, Accuracy: 0.959, F1 Micro: 0.9747, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1101, Accuracy: 0.9622, F1 Micro: 0.9766, F1 Macro: 0.9744\n",
      "Epoch 7/10, Train Loss: 0.0907, Accuracy: 0.9611, F1 Micro: 0.976, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0766, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.067, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9761\n",
      "Epoch 10/10, Train Loss: 0.0547, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3605, Accuracy: 0.8489, F1 Micro: 0.8489, F1 Macro: 0.8167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2016, Accuracy: 0.8813, F1 Micro: 0.8813, F1 Macro: 0.8421\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.17, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1127, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.8669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0772, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8857\n",
      "Epoch 6/10, Train Loss: 0.0609, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8785\n",
      "Epoch 7/10, Train Loss: 0.0527, Accuracy: 0.9029, F1 Micro: 0.9029, F1 Macro: 0.8746\n",
      "Epoch 8/10, Train Loss: 0.0405, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8795\n",
      "Epoch 9/10, Train Loss: 0.0326, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8818\n",
      "Epoch 10/10, Train Loss: 0.0185, Accuracy: 0.9029, F1 Micro: 0.9029, F1 Macro: 0.8735\n",
      "\n",
      "Sentiment analysis accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       784\n",
      "    positive       0.94      0.75      0.83       328\n",
      "\n",
      "    accuracy                           0.91      1112\n",
      "   macro avg       0.92      0.86      0.89      1112\n",
      "weighted avg       0.91      0.91      0.91      1112\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.8687\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.80      0.85       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.83      0.78      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.63      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.91      0.88       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.89      0.86      0.87        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.90      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.90      0.86       162\n",
      "     neutral       0.95      0.95      0.95       387\n",
      "    positive       0.88      0.32      0.47        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.72      0.76       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.87      0.96      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 299.03035831451416 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.00012302398681640625 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4536, Accuracy: 0.8601, F1 Micro: 0.9186, F1 Macro: 0.9133\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2773, Accuracy: 0.9377, F1 Micro: 0.9619, F1 Macro: 0.9595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.202, Accuracy: 0.9486, F1 Micro: 0.9685, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1565, Accuracy: 0.953, F1 Micro: 0.9711, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1292, Accuracy: 0.9602, F1 Micro: 0.9755, F1 Macro: 0.973\n",
      "Epoch 6/10, Train Loss: 0.1057, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0892, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.076, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9756\n",
      "Epoch 9/10, Train Loss: 0.0658, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0545, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.95      0.95      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.353, Accuracy: 0.85, F1 Micro: 0.85, F1 Macro: 0.8176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2157, Accuracy: 0.8717, F1 Micro: 0.8717, F1 Macro: 0.822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1532, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8658\n",
      "Epoch 4/10, Train Loss: 0.1144, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.8644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0725, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8824\n",
      "Epoch 6/10, Train Loss: 0.0646, Accuracy: 0.8997, F1 Micro: 0.8997, F1 Macro: 0.8678\n",
      "Epoch 7/10, Train Loss: 0.0523, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8795\n",
      "Epoch 8/10, Train Loss: 0.0343, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8706\n",
      "Epoch 9/10, Train Loss: 0.0417, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8711\n",
      "Epoch 10/10, Train Loss: 0.0243, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8742\n",
      "\n",
      "Sentiment analysis accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       785\n",
      "    positive       0.94      0.74      0.83       322\n",
      "\n",
      "    accuracy                           0.91      1107\n",
      "   macro avg       0.92      0.86      0.88      1107\n",
      "weighted avg       0.91      0.91      0.91      1107\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.8684\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.78      0.80        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.94      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.85      0.66      0.74        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.55      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.90      0.88       162\n",
      "     neutral       0.95      0.95      0.95       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.86      0.77      0.80       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.91      0.86        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 303.71300411224365 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.00010848045349121094 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4566, Accuracy: 0.8679, F1 Micro: 0.9224, F1 Macro: 0.9174\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2757, Accuracy: 0.9377, F1 Micro: 0.962, F1 Macro: 0.9597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1922, Accuracy: 0.9491, F1 Micro: 0.9689, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1576, Accuracy: 0.951, F1 Micro: 0.9699, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1255, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1093, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0903, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "Epoch 8/10, Train Loss: 0.0755, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0625, Accuracy: 0.9648, F1 Micro: 0.9782, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0526, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.96      0.91      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3415, Accuracy: 0.8629, F1 Micro: 0.8629, F1 Macro: 0.8201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2092, Accuracy: 0.8837, F1 Micro: 0.8837, F1 Macro: 0.8461\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.15, Accuracy: 0.8999, F1 Micro: 0.8999, F1 Macro: 0.8717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1162, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8799\n",
      "Epoch 5/10, Train Loss: 0.0752, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8792\n",
      "Epoch 6/10, Train Loss: 0.0664, Accuracy: 0.9044, F1 Micro: 0.9044, F1 Macro: 0.8743\n",
      "Epoch 7/10, Train Loss: 0.0463, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8767\n",
      "Epoch 8/10, Train Loss: 0.0226, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8735\n",
      "Epoch 9/10, Train Loss: 0.0307, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8731\n",
      "Epoch 10/10, Train Loss: 0.0323, Accuracy: 0.9044, F1 Micro: 0.9044, F1 Macro: 0.8751\n",
      "\n",
      "Sentiment analysis accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       784\n",
      "    positive       0.92      0.75      0.82       325\n",
      "\n",
      "    accuracy                           0.91      1109\n",
      "   macro avg       0.91      0.86      0.88      1109\n",
      "weighted avg       0.91      0.91      0.90      1109\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8737\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.88      0.78      0.83        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.73      0.63      0.67       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.92      0.89       200\n",
      "     neutral       0.96      0.91      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.87      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.89      0.36      0.52        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.73      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.88        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.92      0.90      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.72      0.76      0.74        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.76      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 315.6568777561188 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 25\n",
      "Sampling duration: 0.01846170425415039 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4555, Accuracy: 0.8703, F1 Micro: 0.9236, F1 Macro: 0.9187\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2782, Accuracy: 0.9384, F1 Micro: 0.9622, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1948, Accuracy: 0.9453, F1 Micro: 0.9666, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1568, Accuracy: 0.9549, F1 Micro: 0.9721, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1266, Accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1041, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0897, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0739, Accuracy: 0.9651, F1 Micro: 0.9784, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0618, Accuracy: 0.967, F1 Micro: 0.9795, F1 Macro: 0.9774\n",
      "Epoch 10/10, Train Loss: 0.0555, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.967, F1 Micro: 0.9795, F1 Macro: 0.9774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.95      0.96      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.98      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3587, Accuracy: 0.8657, F1 Micro: 0.8657, F1 Macro: 0.8265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2012, Accuracy: 0.8863, F1 Micro: 0.8863, F1 Macro: 0.8499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1223, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.8674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1086, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0674, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0595, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8709\n",
      "Epoch 7/10, Train Loss: 0.0486, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.8686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0327, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0325, Accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0228, Accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.8836\n",
      "\n",
      "Sentiment analysis accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.8836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       793\n",
      "    positive       0.92      0.75      0.83       324\n",
      "\n",
      "    accuracy                           0.91      1117\n",
      "   macro avg       0.91      0.86      0.88      1117\n",
      "weighted avg       0.91      0.91      0.91      1117\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9594, F1 Micro: 0.9594, F1 Macro: 0.8721\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.87      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.95      0.94       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.88      0.72      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.57      0.59       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.92      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88       162\n",
      "     neutral       0.95      0.96      0.95       387\n",
      "    positive       0.62      0.59      0.60        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.82      0.81      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.89      0.93      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 320.05225443840027 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.989738464355469e-05 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4549, Accuracy: 0.8656, F1 Micro: 0.9213, F1 Macro: 0.9163\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2673, Accuracy: 0.9372, F1 Micro: 0.9616, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1913, Accuracy: 0.9509, F1 Micro: 0.9699, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1569, Accuracy: 0.9543, F1 Micro: 0.972, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1284, Accuracy: 0.9609, F1 Micro: 0.9759, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1021, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9753\n",
      "Epoch 7/10, Train Loss: 0.0861, Accuracy: 0.9618, F1 Micro: 0.9764, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0725, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.0625, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0516, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.99      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3436, Accuracy: 0.8584, F1 Micro: 0.8584, F1 Macro: 0.8093\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2176, Accuracy: 0.8922, F1 Micro: 0.8922, F1 Macro: 0.8557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1348, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1041, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8859\n",
      "Epoch 5/10, Train Loss: 0.0763, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8822\n",
      "Epoch 6/10, Train Loss: 0.0629, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.879\n",
      "Epoch 7/10, Train Loss: 0.053, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8817\n",
      "Epoch 8/10, Train Loss: 0.0366, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.884\n",
      "Epoch 9/10, Train Loss: 0.0302, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8807\n",
      "Epoch 10/10, Train Loss: 0.0303, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.871\n",
      "\n",
      "Sentiment analysis accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8859\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       777\n",
      "    positive       0.94      0.74      0.83       318\n",
      "\n",
      "    accuracy                           0.91      1095\n",
      "   macro avg       0.92      0.86      0.89      1095\n",
      "weighted avg       0.91      0.91      0.91      1095\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.8709\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.76      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.82      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.29      0.40         7\n",
      "     neutral       0.96      0.99      0.97       496\n",
      "    positive       0.89      0.75      0.82        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.84      0.67      0.73       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.89       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.90      0.93      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.85       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       1.00      0.18      0.31        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.93      0.66      0.70       571\n",
      "weighted avg       0.91      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.88      0.86        85\n",
      "     neutral       0.98      0.97      0.98       418\n",
      "    positive       0.91      0.88      0.90        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.66      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 320.53859972953796 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.489059448242188e-05 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4487, Accuracy: 0.8696, F1 Micro: 0.9232, F1 Macro: 0.9169\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2676, Accuracy: 0.9451, F1 Micro: 0.9664, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1893, Accuracy: 0.951, F1 Micro: 0.9699, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1509, Accuracy: 0.9568, F1 Micro: 0.9733, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1234, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1024, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0852, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0718, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9765\n",
      "Epoch 9/10, Train Loss: 0.0593, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "Epoch 10/10, Train Loss: 0.0489, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.99      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.91      0.98      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3542, Accuracy: 0.8599, F1 Micro: 0.8599, F1 Macro: 0.8229\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1867, Accuracy: 0.8878, F1 Micro: 0.8878, F1 Macro: 0.8546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1457, Accuracy: 0.8998, F1 Micro: 0.8998, F1 Macro: 0.8642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1079, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0733, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0618, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.8958\n",
      "Epoch 7/10, Train Loss: 0.0388, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.8941\n",
      "Epoch 8/10, Train Loss: 0.0334, Accuracy: 0.9165, F1 Micro: 0.9165, F1 Macro: 0.8917\n",
      "Epoch 9/10, Train Loss: 0.0216, Accuracy: 0.9165, F1 Micro: 0.9165, F1 Macro: 0.8902\n",
      "Epoch 10/10, Train Loss: 0.0258, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8839\n",
      "\n",
      "Sentiment analysis accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.8958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       771\n",
      "    positive       0.94      0.77      0.85       307\n",
      "\n",
      "    accuracy                           0.92      1078\n",
      "   macro avg       0.93      0.87      0.90      1078\n",
      "weighted avg       0.92      0.92      0.92      1078\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.8698\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.43      0.40         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.90      0.76      0.83        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.74      0.72      0.73       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.88      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.91      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.87      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       1.00      0.32      0.48        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.72      0.76       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.87      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.91      0.91      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 326.0886552333832 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.274482727050781e-05 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.446, Accuracy: 0.8745, F1 Micro: 0.9264, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2627, Accuracy: 0.9405, F1 Micro: 0.9636, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1849, Accuracy: 0.9497, F1 Micro: 0.9691, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1478, Accuracy: 0.9561, F1 Micro: 0.9729, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1156, Accuracy: 0.962, F1 Micro: 0.9765, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0987, Accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9766\n",
      "Epoch 7/10, Train Loss: 0.0836, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9753\n",
      "Epoch 8/10, Train Loss: 0.0684, Accuracy: 0.9651, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "Epoch 9/10, Train Loss: 0.0578, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9758\n",
      "Epoch 10/10, Train Loss: 0.0492, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.92      0.96      0.94       317\n",
      "       linen       0.95      0.97      0.96       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3215, Accuracy: 0.8641, F1 Micro: 0.8641, F1 Macro: 0.834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.206, Accuracy: 0.8983, F1 Micro: 0.8983, F1 Macro: 0.8669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1438, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1217, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0779, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.8927\n",
      "Epoch 6/10, Train Loss: 0.0584, Accuracy: 0.9085, F1 Micro: 0.9085, F1 Macro: 0.8809\n",
      "Epoch 7/10, Train Loss: 0.0595, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.874\n",
      "Epoch 8/10, Train Loss: 0.0429, Accuracy: 0.9131, F1 Micro: 0.9131, F1 Macro: 0.886\n",
      "Epoch 9/10, Train Loss: 0.0483, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8841\n",
      "Epoch 10/10, Train Loss: 0.0413, Accuracy: 0.9131, F1 Micro: 0.9131, F1 Macro: 0.8881\n",
      "\n",
      "Sentiment analysis accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.8927\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       775\n",
      "    positive       0.93      0.77      0.84       307\n",
      "\n",
      "    accuracy                           0.92      1082\n",
      "   macro avg       0.92      0.87      0.89      1082\n",
      "weighted avg       0.92      0.92      0.92      1082\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9581, F1 Micro: 0.9581, F1 Macro: 0.878\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        78\n",
      "     neutral       0.98      0.96      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.29      0.29      0.29         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.87      0.71      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.71      0.66      0.68       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.83      0.96      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.87      0.86       162\n",
      "     neutral       0.95      0.96      0.95       387\n",
      "    positive       0.60      0.41      0.49        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.80      0.75      0.77       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.83      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      1.00      0.98        74\n",
      "     neutral       1.00      0.99      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 322.0600309371948 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.846687316894531e-05 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4392, Accuracy: 0.8823, F1 Micro: 0.9305, F1 Macro: 0.9259\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.261, Accuracy: 0.9406, F1 Micro: 0.9637, F1 Macro: 0.9616\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1864, Accuracy: 0.9498, F1 Micro: 0.9692, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1474, Accuracy: 0.9564, F1 Micro: 0.9731, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1236, Accuracy: 0.9582, F1 Micro: 0.9742, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1001, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "Epoch 7/10, Train Loss: 0.085, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9744\n",
      "Epoch 8/10, Train Loss: 0.0709, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0589, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0488, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3356, Accuracy: 0.8652, F1 Micro: 0.8652, F1 Macro: 0.8118\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1881, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1294, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.8895\n",
      "Epoch 4/10, Train Loss: 0.0954, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8887\n",
      "Epoch 5/10, Train Loss: 0.0676, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0615, Accuracy: 0.9178, F1 Micro: 0.9178, F1 Macro: 0.8927\n",
      "Epoch 7/10, Train Loss: 0.0413, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8895\n",
      "Epoch 8/10, Train Loss: 0.0395, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8843\n",
      "Epoch 9/10, Train Loss: 0.0284, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8812\n",
      "Epoch 10/10, Train Loss: 0.0264, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.886\n",
      "\n",
      "Sentiment analysis accuracy: 0.9178, F1 Micro: 0.9178, F1 Macro: 0.8927\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94       781\n",
      "    positive       0.91      0.78      0.84       302\n",
      "\n",
      "    accuracy                           0.92      1083\n",
      "   macro avg       0.92      0.87      0.89      1083\n",
      "weighted avg       0.92      0.92      0.92      1083\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9587, F1 Micro: 0.9587, F1 Macro: 0.8738\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.87      0.87      0.87        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.90      0.93        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.86      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.66      0.74        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.60      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.84      0.95      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.87      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.73      0.77       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.89      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.94      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.59      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.76      0.79       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 330.3649060726166 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.00010275840759277344 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4382, Accuracy: 0.8832, F1 Micro: 0.9312, F1 Macro: 0.9275\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2583, Accuracy: 0.9422, F1 Micro: 0.9647, F1 Macro: 0.9623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1769, Accuracy: 0.954, F1 Micro: 0.9716, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1447, Accuracy: 0.9594, F1 Micro: 0.9748, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1171, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "Epoch 6/10, Train Loss: 0.0961, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0786, Accuracy: 0.9672, F1 Micro: 0.9796, F1 Macro: 0.9778\n",
      "Epoch 8/10, Train Loss: 0.0661, Accuracy: 0.9646, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.0564, Accuracy: 0.9639, F1 Micro: 0.9775, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0475, Accuracy: 0.9672, F1 Micro: 0.9796, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9672, F1 Micro: 0.9796, F1 Macro: 0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.95      0.95       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.347, Accuracy: 0.8718, F1 Micro: 0.8718, F1 Macro: 0.8216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1913, Accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.8815\n",
      "Epoch 3/10, Train Loss: 0.1175, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0907, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0713, Accuracy: 0.9207, F1 Micro: 0.9207, F1 Macro: 0.896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0382, Accuracy: 0.9253, F1 Micro: 0.9253, F1 Macro: 0.9026\n",
      "Epoch 7/10, Train Loss: 0.049, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.8938\n",
      "Epoch 8/10, Train Loss: 0.0304, Accuracy: 0.9207, F1 Micro: 0.9207, F1 Macro: 0.8952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0264, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9052\n",
      "Epoch 10/10, Train Loss: 0.0203, Accuracy: 0.9253, F1 Micro: 0.9253, F1 Macro: 0.9012\n",
      "\n",
      "Sentiment analysis accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9052\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       781\n",
      "    positive       0.95      0.78      0.86       303\n",
      "\n",
      "    accuracy                           0.93      1084\n",
      "   macro avg       0.94      0.88      0.91      1084\n",
      "weighted avg       0.93      0.93      0.93      1084\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9618, F1 Micro: 0.9618, F1 Macro: 0.8854\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.86      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.82      0.72      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.92       200\n",
      "     neutral       0.94      0.95      0.95       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.87      0.87       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.75      0.79       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.95      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.69      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 336.9285659790039 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 36\n",
      "Sampling duration: 0.02077960968017578 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4387, Accuracy: 0.8825, F1 Micro: 0.9304, F1 Macro: 0.9254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2566, Accuracy: 0.942, F1 Micro: 0.9645, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1797, Accuracy: 0.9538, F1 Micro: 0.9715, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1432, Accuracy: 0.9563, F1 Micro: 0.973, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1153, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9743\n",
      "Epoch 6/10, Train Loss: 0.1005, Accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0795, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0687, Accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.977\n",
      "Epoch 9/10, Train Loss: 0.0569, Accuracy: 0.9661, F1 Micro: 0.9789, F1 Macro: 0.9768\n",
      "Epoch 10/10, Train Loss: 0.0465, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.93      0.96      0.94       317\n",
      "       linen       0.94      0.95      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.329, Accuracy: 0.8653, F1 Micro: 0.8653, F1 Macro: 0.807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1943, Accuracy: 0.8921, F1 Micro: 0.8921, F1 Macro: 0.8526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1546, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1022, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0715, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.8942\n",
      "Epoch 6/10, Train Loss: 0.0713, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8793\n",
      "Epoch 7/10, Train Loss: 0.0516, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.886\n",
      "Epoch 8/10, Train Loss: 0.0462, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8893\n",
      "Epoch 9/10, Train Loss: 0.0303, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8826\n",
      "Epoch 10/10, Train Loss: 0.0251, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8828\n",
      "\n",
      "Sentiment analysis accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.8942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       781\n",
      "    positive       0.94      0.77      0.84       303\n",
      "\n",
      "    accuracy                           0.92      1084\n",
      "   macro avg       0.93      0.87      0.89      1084\n",
      "weighted avg       0.92      0.92      0.92      1084\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9581, F1 Micro: 0.9581, F1 Macro: 0.865\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.80      0.85       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.86      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.29      0.29      0.29         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.88      0.66      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.71      0.64      0.67       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.76      0.80       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.87      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.52      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.82      0.74        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.81      0.78      0.78       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.93        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.80      0.67      0.73         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.87      0.88       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 338.6872990131378 s\n",
      "Total runtime: 6854.130194425583 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6765120,
     "sourceId": 10886992,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6792.290101,
   "end_time": "2025-04-20T10:29:34.996639",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-20T08:36:22.706538",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01b44cef93bc4e9eb74ea3bd406581ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0e3fdfa255cd4e0e9e60047bf225ce4d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0f876e65d87b41698b430792a8784e75": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "120a02cfee6b46ac85743b38c9d680a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_18d57cab447f4a14898345c0a6de082f",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_51a3a0f86a974cb08adf7cee06f1722b",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "18d57cab447f4a14898345c0a6de082f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ac0da29747d45df8ea07dcc0a9126c3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2699b9e7e8694807b8f13ba38deda977": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28b7336dbaef45fabd8462e6375c4287": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2699b9e7e8694807b8f13ba38deda977",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c968ff74c4a24139a4f0d9091a2554ae",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     },
     "29cd67563b214c2cac546521fa029912": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2bcad7fe12bd46a7925c7398c9daf4d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2ec2d3c669514c029a3f9cc5fa62b05e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3080416b58b94cd593cb9208fb43ab09": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3c5a8b84164c496ba35c0aa9dbbfc998": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b8ac543a570a4756a27d34d158ec974e",
       "placeholder": "​",
       "style": "IPY_MODEL_c94b05a405ee4490b0cac3051677ed36",
       "tabbable": null,
       "tooltip": null,
       "value": " 229k/229k [00:00&lt;00:00, 6.16MB/s]"
      }
     },
     "3e199a70bd6f4203b6b829e4a280bb6b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "44c9998a7cb44b058f1d3038b2f73da0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4ffb4fe149014c19a087caee932a7c79": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0f876e65d87b41698b430792a8784e75",
       "placeholder": "​",
       "style": "IPY_MODEL_aa9a5bccc1f84a99854da7a227363697",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.00/2.00 [00:00&lt;00:00, 183B/s]"
      }
     },
     "51a3a0f86a974cb08adf7cee06f1722b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "61f40c4815a346339c6ea319b9fc43e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6511791cc6cc49e393c0704f248aad0c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "710de2a3621c4ea78cb1765bcb46bb47": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "785ec713556648c78caa6b982b219dcc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7c903cc9e8d0495cb068d554c3f9db53": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c111c8ef8c3c42b9abca11e6f4569655",
        "IPY_MODEL_bf9fe137edf94bcf90585aed9022abf8",
        "IPY_MODEL_3c5a8b84164c496ba35c0aa9dbbfc998"
       ],
       "layout": "IPY_MODEL_710de2a3621c4ea78cb1765bcb46bb47",
       "tabbable": null,
       "tooltip": null
      }
     },
     "81dff696d9ce48a1a11a96b2e9dc441b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "84b254c89b8a49e7820f02c88fb3ab10": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b464cd3dd381462fabd1f3c7e86c4dbe",
        "IPY_MODEL_120a02cfee6b46ac85743b38c9d680a6",
        "IPY_MODEL_4ffb4fe149014c19a087caee932a7c79"
       ],
       "layout": "IPY_MODEL_c8baa99cee62450f94ad8c9badeb4ab8",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8ba6739ac4254562aa74eb67e11d0cab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c9e7cc3ded27492085cf0df865320aeb",
       "placeholder": "​",
       "style": "IPY_MODEL_dd83fd4bd0b34ae190b6948c0671a1ce",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 13.2kB/s]"
      }
     },
     "97674fbaf032438881d63d36750b8783": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a25efea56466490ea6992b0724a57fa3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d209ed2d3db946289d5366d7a9d660c6",
        "IPY_MODEL_cea64d6a7eb24df690ea1e8e5886c6b4",
        "IPY_MODEL_8ba6739ac4254562aa74eb67e11d0cab"
       ],
       "layout": "IPY_MODEL_01b44cef93bc4e9eb74ea3bd406581ce",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a9a34b1e720e4e8d837177492e525858": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b5d66247e4cd4945b277dc7d4fa0651d",
        "IPY_MODEL_28b7336dbaef45fabd8462e6375c4287",
        "IPY_MODEL_e5b331e0ddf54b14bbcec4e4e78e8c02"
       ],
       "layout": "IPY_MODEL_e2e8e46d97074ba08d942055cce5b889",
       "tabbable": null,
       "tooltip": null
      }
     },
     "aa9a5bccc1f84a99854da7a227363697": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b464cd3dd381462fabd1f3c7e86c4dbe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1ac0da29747d45df8ea07dcc0a9126c3",
       "placeholder": "​",
       "style": "IPY_MODEL_6511791cc6cc49e393c0704f248aad0c",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "b5d66247e4cd4945b277dc7d4fa0651d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2ec2d3c669514c029a3f9cc5fa62b05e",
       "placeholder": "​",
       "style": "IPY_MODEL_29cd67563b214c2cac546521fa029912",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "b8ac543a570a4756a27d34d158ec974e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bf9fe137edf94bcf90585aed9022abf8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2bcad7fe12bd46a7925c7398c9daf4d1",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0e3fdfa255cd4e0e9e60047bf225ce4d",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "c111c8ef8c3c42b9abca11e6f4569655": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_81dff696d9ce48a1a11a96b2e9dc441b",
       "placeholder": "​",
       "style": "IPY_MODEL_97674fbaf032438881d63d36750b8783",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "c8baa99cee62450f94ad8c9badeb4ab8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c94b05a405ee4490b0cac3051677ed36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c968ff74c4a24139a4f0d9091a2554ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c9e7cc3ded27492085cf0df865320aeb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cea64d6a7eb24df690ea1e8e5886c6b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3080416b58b94cd593cb9208fb43ab09",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_61f40c4815a346339c6ea319b9fc43e2",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "d209ed2d3db946289d5366d7a9d660c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f498c110d2bd49ebb362db7a1d8f3d28",
       "placeholder": "​",
       "style": "IPY_MODEL_785ec713556648c78caa6b982b219dcc",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "dd83fd4bd0b34ae190b6948c0671a1ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e2e8e46d97074ba08d942055cce5b889": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e5b331e0ddf54b14bbcec4e4e78e8c02": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3e199a70bd6f4203b6b829e4a280bb6b",
       "placeholder": "​",
       "style": "IPY_MODEL_44c9998a7cb44b058f1d3038b2f73da0",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.53k/1.53k [00:00&lt;00:00, 167kB/s]"
      }
     },
     "f498c110d2bd49ebb362db7a1d8f3d28": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
