{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e1028fb",
   "metadata": {
    "papermill": {
     "duration": 0.012128,
     "end_time": "2025-03-31T11:39:54.515302",
     "exception": false,
     "start_time": "2025-03-31T11:39:54.503174",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "454cdc3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T11:39:54.537998Z",
     "iopub.status.busy": "2025-03-31T11:39:54.537673Z",
     "iopub.status.idle": "2025-03-31T11:40:18.383394Z",
     "shell.execute_reply": "2025-03-31T11:40:18.382513Z"
    },
    "papermill": {
     "duration": 23.858986,
     "end_time": "2025-03-31T11:40:18.384996",
     "exception": false,
     "start_time": "2025-03-31T11:39:54.526010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39aee5a",
   "metadata": {
    "papermill": {
     "duration": 0.010059,
     "end_time": "2025-03-31T11:40:18.406128",
     "exception": false,
     "start_time": "2025-03-31T11:40:18.396069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63fe657a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T11:40:18.428268Z",
     "iopub.status.busy": "2025-03-31T11:40:18.427802Z",
     "iopub.status.idle": "2025-03-31T11:40:18.431075Z",
     "shell.execute_reply": "2025-03-31T11:40:18.430427Z"
    },
    "papermill": {
     "duration": 0.015507,
     "end_time": "2025-03-31T11:40:18.432273",
     "exception": false,
     "start_time": "2025-03-31T11:40:18.416766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dddb6d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T11:40:18.453988Z",
     "iopub.status.busy": "2025-03-31T11:40:18.453768Z",
     "iopub.status.idle": "2025-03-31T11:40:18.457367Z",
     "shell.execute_reply": "2025-03-31T11:40:18.456743Z"
    },
    "papermill": {
     "duration": 0.015553,
     "end_time": "2025-03-31T11:40:18.458464",
     "exception": false,
     "start_time": "2025-03-31T11:40:18.442911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa8e9600",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T11:40:18.479949Z",
     "iopub.status.busy": "2025-03-31T11:40:18.479754Z",
     "iopub.status.idle": "2025-03-31T11:40:18.489517Z",
     "shell.execute_reply": "2025-03-31T11:40:18.488959Z"
    },
    "papermill": {
     "duration": 0.021804,
     "end_time": "2025-03-31T11:40:18.490759",
     "exception": false,
     "start_time": "2025-03-31T11:40:18.468955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3448fe78",
   "metadata": {
    "papermill": {
     "duration": 0.010746,
     "end_time": "2025-03-31T11:40:18.511936",
     "exception": false,
     "start_time": "2025-03-31T11:40:18.501190",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2623a6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T11:40:18.533055Z",
     "iopub.status.busy": "2025-03-31T11:40:18.532851Z",
     "iopub.status.idle": "2025-03-31T11:40:18.592051Z",
     "shell.execute_reply": "2025-03-31T11:40:18.590674Z"
    },
    "papermill": {
     "duration": 0.071572,
     "end_time": "2025-03-31T11:40:18.593792",
     "exception": false,
     "start_time": "2025-03-31T11:40:18.522220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "aspect_accuracies = manager.list()\n",
    "aspect_f1_micros = manager.list()\n",
    "aspect_f1_macros = manager.list()\n",
    "sentiment_accuracies = manager.list()\n",
    "sentiment_f1_micros = manager.list()\n",
    "sentiment_f1_macros = manager.list()\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'hoasa-random'\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "sequence_length = 48\n",
    "\n",
    "aspect_list = ['ac', 'air_panas', 'bau', 'general', 'kebersihan', 'linen', 'service', 'sunrise_meal', 'tv', 'wifi']\n",
    "aspect_mapping = {'ac': 0, 'air_panas': 1, 'bau': 2, 'general': 3, 'kebersihan': 4, 'linen': 5, 'service': 6, 'sunrise_meal': 7, 'tv': 8, 'wifi': 9}\n",
    "label_mapping = {\"neg\": 0, \"neut\": 1, 'neg_pos': 1, 'pos': 2}\n",
    "ignored_keys = ['labels', 'ori_text', 'ori_label', 'ori_indices', 'aspect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a1e1c9",
   "metadata": {
    "papermill": {
     "duration": 0.010564,
     "end_time": "2025-03-31T11:40:18.614896",
     "exception": false,
     "start_time": "2025-03-31T11:40:18.604332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d919ea0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T11:40:18.637473Z",
     "iopub.status.busy": "2025-03-31T11:40:18.637221Z",
     "iopub.status.idle": "2025-03-31T11:40:18.745911Z",
     "shell.execute_reply": "2025-03-31T11:40:18.744937Z"
    },
    "papermill": {
     "duration": 0.122154,
     "end_time": "2025-03-31T11:40:18.747493",
     "exception": false,
     "start_time": "2025-03-31T11:40:18.625339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>ac</th>\n",
       "      <th>air_panas</th>\n",
       "      <th>bau</th>\n",
       "      <th>general</th>\n",
       "      <th>kebersihan</th>\n",
       "      <th>linen</th>\n",
       "      <th>service</th>\n",
       "      <th>sunrise_meal</th>\n",
       "      <th>tv</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kebersihan kurang...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sangat mengecewakan... hotel bad image, kebers...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tempat nyaman bersih tapi tv terlalu tinggi ti...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>pos</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>semuanya bagus sesuai profile,dan harga promo ...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>pos</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tempat tidur sangat keras, bantal besar dan ke...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review    ac air_panas   bau  \\\n",
       "0                               kebersihan kurang...  neut      neut  neut   \n",
       "1  sangat mengecewakan... hotel bad image, kebers...  neut      neut  neut   \n",
       "2  Tempat nyaman bersih tapi tv terlalu tinggi ti...  neut      neut  neut   \n",
       "3  semuanya bagus sesuai profile,dan harga promo ...  neut       neg  neut   \n",
       "4  Tempat tidur sangat keras, bantal besar dan ke...   neg       neg  neut   \n",
       "\n",
       "  general kebersihan linen service sunrise_meal    tv  wifi  \n",
       "0    neut        neg  neut    neut         neut  neut  neut  \n",
       "1    neut        neg  neut    neut         neut  neut  neut  \n",
       "2    neut        pos  neut    neut         neut   neg  neut  \n",
       "3     pos       neut  neut    neut         neut  neut  neut  \n",
       "4    neut       neut   neg    neut         neut  neut  neut  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/hoasa-dataset/train_preprocess.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/hoasa-dataset/valid_preprocess.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('/kaggle/input/hoasa-dataset/test_preprocess.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data, test_data], ignore_index=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aa58101",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T11:40:18.773856Z",
     "iopub.status.busy": "2025-03-31T11:40:18.773598Z",
     "iopub.status.idle": "2025-03-31T11:40:18.781908Z",
     "shell.execute_reply": "2025-03-31T11:40:18.781217Z"
    },
    "papermill": {
     "duration": 0.02281,
     "end_time": "2025-03-31T11:40:18.783244",
     "exception": false,
     "start_time": "2025-03-31T11:40:18.760434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb164ff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T11:40:18.809296Z",
     "iopub.status.busy": "2025-03-31T11:40:18.809044Z",
     "iopub.status.idle": "2025-03-31T11:40:18.820185Z",
     "shell.execute_reply": "2025-03-31T11:40:18.819374Z"
    },
    "papermill": {
     "duration": 0.02572,
     "end_time": "2025-03-31T11:40:18.821466",
     "exception": false,
     "start_time": "2025-03-31T11:40:18.795746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2283,) (2283, 10)\n",
      "(571,) (571, 10)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[1:]\n",
    "val_labels = val_data.columns[1:]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['review'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['review'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f1746c",
   "metadata": {
    "papermill": {
     "duration": 0.010427,
     "end_time": "2025-03-31T11:40:18.843569",
     "exception": false,
     "start_time": "2025-03-31T11:40:18.833142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b83280e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T11:40:18.865294Z",
     "iopub.status.busy": "2025-03-31T11:40:18.865096Z",
     "iopub.status.idle": "2025-03-31T11:40:18.870817Z",
     "shell.execute_reply": "2025-03-31T11:40:18.870226Z"
    },
    "papermill": {
     "duration": 0.017875,
     "end_time": "2025-03-31T11:40:18.871902",
     "exception": false,
     "start_time": "2025-03-31T11:40:18.854027",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AspectDetectionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, label_mapping, tokenizer, max_length=sequence_length, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        \n",
    "        original_labels = [self.label_mapping[label] for label in self.labels[idx]]\n",
    "        encoded_labels = [1 if label == 1 else 0 for label in original_labels]\n",
    "        \n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['ori_indices'] = idx\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(original_labels, dtype=torch.float)\n",
    "        item['labels'] = torch.tensor(encoded_labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47445078",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T11:40:18.893946Z",
     "iopub.status.busy": "2025-03-31T11:40:18.893746Z",
     "iopub.status.idle": "2025-03-31T11:40:18.900454Z",
     "shell.execute_reply": "2025-03-31T11:40:18.899861Z"
    },
    "papermill": {
     "duration": 0.019323,
     "end_time": "2025-03-31T11:40:18.901781",
     "exception": false,
     "start_time": "2025-03-31T11:40:18.882458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, texts, labels, aspects, indices, label_mapping, tokenizer, max_length=96, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.aspects = aspects\n",
    "        self.indices = indices\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = aspect_token + ' ' + self.aspects[idx] + ' ' + review_token + ' ' + self.texts[idx] \n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        if isinstance(self.labels[idx], str):\n",
    "            self.labels[idx] = self.label_mapping[self.labels[idx]]\n",
    "        elif torch.is_tensor(self.labels[idx]):\n",
    "            self.labels[idx] = int(self.labels[idx].item())\n",
    "\n",
    "        encoded_label = 1 if self.labels[idx] == 2 else self.labels[idx]\n",
    "        one_hot_label = F.one_hot(torch.tensor(encoded_label, dtype=torch.long), num_classes=2).float()\n",
    "\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['aspect'] = self.aspects[idx]\n",
    "        item['labels'] = one_hot_label\n",
    "        item['ori_indices'] = self.indices[idx]\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8188b224",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T11:40:18.924011Z",
     "iopub.status.busy": "2025-03-31T11:40:18.923778Z",
     "iopub.status.idle": "2025-03-31T11:40:19.706448Z",
     "shell.execute_reply": "2025-03-31T11:40:19.705567Z"
    },
    "papermill": {
     "duration": 0.795435,
     "end_time": "2025-03-31T11:40:19.707916",
     "exception": false,
     "start_time": "2025-03-31T11:40:18.912481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8107c6437a8b4014b9c5247dd0734c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2043b1121ff346d7a29ba65ecce9c3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6b2cd13cef43cf998e7f0d1d3dcda8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a99e53d0e54426ae382523c0b9e0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "review_token = '[REVIEW]'\n",
    "aspect_token = '[ASPECT]'\n",
    "special_tokens_dict = {'additional_special_tokens': [review_token, aspect_token]}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e73465aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T11:40:19.731953Z",
     "iopub.status.busy": "2025-03-31T11:40:19.731657Z",
     "iopub.status.idle": "2025-03-31T11:40:19.736217Z",
     "shell.execute_reply": "2025-03-31T11:40:19.735299Z"
    },
    "papermill": {
     "duration": 0.017767,
     "end_time": "2025-03-31T11:40:19.737458",
     "exception": false,
     "start_time": "2025-03-31T11:40:19.719691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_aspect_dataset(X_train, y_train, X_val, y_val, sequence_length, num_workers=4):\n",
    "    train_dataset = AspectDetectionDataset(X_train, y_train, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = AspectDetectionDataset(X_val, y_val, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "358cd484",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T11:40:19.760585Z",
     "iopub.status.busy": "2025-03-31T11:40:19.760343Z",
     "iopub.status.idle": "2025-03-31T11:40:19.769821Z",
     "shell.execute_reply": "2025-03-31T11:40:19.769198Z"
    },
    "papermill": {
     "duration": 0.02235,
     "end_time": "2025-03-31T11:40:19.770992",
     "exception": false,
     "start_time": "2025-03-31T11:40:19.748642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sentiment_dataset(device, train_dataset, val_dataset, aspect_detection_model, tokenizer, max_length=sequence_length):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    aspect_detection_model.to(device)\n",
    "    aspect_detection_model.eval()\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    train_aspects = []\n",
    "    train_indices = []\n",
    "\n",
    "    val_data = []\n",
    "    val_labels = []\n",
    "    val_aspects = []\n",
    "    val_indices = []\n",
    "\n",
    "    # Transform train set\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        train_aspects.append(aspect_list[j])\n",
    "                        train_data.append(batch['ori_text'][i])\n",
    "                        train_labels.append(batch['ori_label'][i][j])\n",
    "                        train_indices.append(batch['ori_indices'][i])\n",
    "            \n",
    "        # Transform validation set\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        val_aspects.append(aspect_list[j])\n",
    "                        val_data.append(batch['ori_text'][i])\n",
    "                        val_labels.append(batch['ori_label'][i][j])\n",
    "                        val_indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    train_dataset = SentimentAnalysisDataset(train_data, train_labels, train_aspects, train_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "    val_dataset = SentimentAnalysisDataset(val_data, val_labels, val_aspects, val_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeed5e2",
   "metadata": {
    "papermill": {
     "duration": 0.011513,
     "end_time": "2025-03-31T11:40:19.802914",
     "exception": false,
     "start_time": "2025-03-31T11:40:19.791401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62f6f0eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T11:40:19.826036Z",
     "iopub.status.busy": "2025-03-31T11:40:19.825822Z",
     "iopub.status.idle": "2025-03-31T11:40:19.829252Z",
     "shell.execute_reply": "2025-03-31T11:40:19.828664Z"
    },
    "papermill": {
     "duration": 0.016218,
     "end_time": "2025-03-31T11:40:19.830387",
     "exception": false,
     "start_time": "2025-03-31T11:40:19.814169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28ebd713",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T11:40:19.853306Z",
     "iopub.status.busy": "2025-03-31T11:40:19.853109Z",
     "iopub.status.idle": "2025-03-31T11:40:19.857524Z",
     "shell.execute_reply": "2025-03-31T11:40:19.856910Z"
    },
    "papermill": {
     "duration": 0.01723,
     "end_time": "2025-03-31T11:40:19.858719",
     "exception": false,
     "start_time": "2025-03-31T11:40:19.841489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p, label, classes):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        labels=label,\n",
    "        target_names=classes,\n",
    "        zero_division=0\n",
    "    ) \n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2335e1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T11:40:19.881774Z",
     "iopub.status.busy": "2025-03-31T11:40:19.881567Z",
     "iopub.status.idle": "2025-03-31T11:40:19.887373Z",
     "shell.execute_reply": "2025-03-31T11:40:19.886810Z"
    },
    "papermill": {
     "duration": 0.018679,
     "end_time": "2025-03-31T11:40:19.888596",
     "exception": false,
     "start_time": "2025-03-31T11:40:19.869917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics_overall(p, classes):\n",
    "    preds = torch.tensor(p.predictions)\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Ensure it's in the correct shape\n",
    "    if preds.shape != labels.shape:\n",
    "        raise ValueError(\"Shape mismatch: predictions and labels must have the same shape.\")\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Compute per-label (column-wise) precision, recall, F1\n",
    "    precision_list, recall_list, f1_micro_list, f1_macro_list = [], [], [], []\n",
    "    \n",
    "    for i in range(labels.shape[1]):  # Loop through each column (multi-output)\n",
    "        prec, rec, f1_micro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='micro', zero_division=0\n",
    "        )\n",
    "        _, _, f1_macro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='macro', zero_division=0\n",
    "        )\n",
    "\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        f1_micro_list.append(f1_micro)\n",
    "        f1_macro_list.append(f1_macro)\n",
    "\n",
    "    # Compute average metrics across all outputs\n",
    "    precision = sum(precision_list) / len(precision_list)\n",
    "    recall = sum(recall_list) / len(recall_list)\n",
    "    f1_micro = sum(f1_micro_list) / len(f1_micro_list)\n",
    "    f1_macro = sum(f1_macro_list) / len(f1_macro_list)\n",
    "\n",
    "    # Generate classification report per output\n",
    "    reports = [classification_report(labels[:, i], preds[:, i], target_names=classes, zero_division=0) for i in range(labels.shape[1])]\n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'reports': reports  # Returns list of reports, one for each output label\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d6c5f96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T11:40:19.912054Z",
     "iopub.status.busy": "2025-03-31T11:40:19.911850Z",
     "iopub.status.idle": "2025-03-31T11:40:19.937527Z",
     "shell.execute_reply": "2025-03-31T11:40:19.936771Z"
    },
    "papermill": {
     "duration": 0.038875,
     "end_time": "2025-03-31T11:40:19.938726",
     "exception": false,
     "start_time": "2025-03-31T11:40:19.899851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, aspect_metrics, sentiment_metrics, metrics, trials, seed):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in aspect_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    aspect_optimizer = torch.optim.AdamW(aspect_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    aspect_train_loader, aspect_val_loader, aspect_train_dataset, aspect_val_dataset = build_aspect_dataset(current_X_train, current_y_train, X_val, y_val, sequence_length)\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader = accelerator.prepare(\n",
    "        aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader\n",
    "    )\n",
    "\n",
    "    aspect_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ASPECT DETECTION\n",
    "    accelerator.print(\"ASPECT DETECTION\")\n",
    "    for epoch in range(epochs):\n",
    "        aspect_model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in aspect_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            aspect_optimizer.zero_grad()\n",
    "            outputs = aspect_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            aspect_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        aspect_model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in aspect_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = aspect_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}),\n",
    "            None,\n",
    "            aspect_list,\n",
    "        )\n",
    "\n",
    "        if aspect_result is None or result['f1_micro'] >= aspect_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(aspect_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-aspect-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            aspect_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(aspect_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"\\nAspect detection accuracy: {round(aspect_result['accuracy'], 4)}, F1 Micro: {round(aspect_result['f1_micro'], 4)}, F1 Macro: {round(aspect_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(aspect_result['report'])\n",
    "\n",
    "    best_aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{trials + 1}-model')\n",
    "    best_aspect_model = accelerator.prepare(best_aspect_model)\n",
    "\n",
    "    # SENTIMENT ANALYSIS ON NON NEUTRAL ASPECTS\n",
    "    accelerator.print(\"--------------------------------------------------\")\n",
    "    accelerator.print(\"SENTIMENT ANALYSIS\")\n",
    "\n",
    "    sentiment_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=2,\n",
    "    )\n",
    "    sentiment_optimizer = torch.optim.AdamW(sentiment_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "    for name, param in sentiment_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    sentiment_train_loader, sentiment_val_loader, sentiment_train_dataset, sentiment_val_dataset = build_sentiment_dataset(\n",
    "        device, aspect_train_dataset, aspect_val_dataset, best_aspect_model, tokenizer, max_length=sequence_length\n",
    "    )\n",
    "    sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader = accelerator.prepare(\n",
    "        sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader\n",
    "    )\n",
    "    sentiment_result = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sentiment_model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in sentiment_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            sentiment_optimizer.zero_grad()\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            sentiment_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        sentiment_model.eval()\n",
    "        sentiment_val_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in sentiment_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                \n",
    "                outputs = sentiment_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                for i in range(len(preds)):\n",
    "                    val_output = {\n",
    "                        'label': batch['labels'][i],\n",
    "                        'aspect': batch['aspect'][i],\n",
    "                        'ori_indices': batch['ori_indices'][i],\n",
    "                        'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                    }\n",
    "                    sentiment_val_outputs.append(val_output)\n",
    "\n",
    "        sentiment_val_outputs = accelerator.gather_for_metrics(sentiment_val_outputs)\n",
    "        unique_val_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_val_outputs}\n",
    "        sentiment_val_outputs = list(unique_val_outputs.values())\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': [item['pred'] for item in sentiment_val_outputs], 'label_ids': [np.argmax(item['label'].cpu().numpy()) for item in sentiment_val_outputs]}),\n",
    "            [0, 1],\n",
    "            ['negative', 'positive']\n",
    "        )\n",
    "\n",
    "        if sentiment_result is None or result['f1_micro'] >= sentiment_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            sentiment_result = result\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(sentiment_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                 f'{filename}-sentiment-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(sentiment_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    accelerator.print(f\"\\nSentiment analysis accuracy: {round(sentiment_result['accuracy'], 4)}, F1 Micro: {round(sentiment_result['f1_micro'], 4)}, F1 Macro: {round(sentiment_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(sentiment_result['report'])\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    best_sentiment_model = BertForSequenceClassification.from_pretrained( f'{filename}-sentiment-{trials + 1}-model')\n",
    "    best_sentiment_model = accelerator.prepare(best_sentiment_model)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    aspect_labels = []\n",
    "    aspect_indices = []\n",
    "    aspect_preds = []\n",
    "\n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = []\n",
    "    \n",
    "    best_aspect_model.eval()\n",
    "    best_sentiment_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in aspect_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = aspect_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            aspect_indices.append(accelerator.gather(batch['ori_indices']))\n",
    "            aspect_labels.append(accelerator.gather(batch['ori_label']))\n",
    "            aspect_preds.append(accelerator.gather(preds))\n",
    "\n",
    "        aspect_indices = torch.cat(aspect_indices).cpu().numpy()\n",
    "        aspect_labels = torch.cat(aspect_labels).cpu().numpy()\n",
    "        aspect_preds = torch.cat(aspect_preds).cpu().numpy()\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        aspect_outputs = [\n",
    "            {'ori_indices': aspect_indices[i], \n",
    "             'ori_labels': aspect_labels[i], \n",
    "             'pred': aspect_preds[i]}\n",
    "            for i in range(len(aspect_preds))\n",
    "        ]\n",
    "        aspect_outputs = {x['ori_indices'].item(): x for x in aspect_outputs}\n",
    "    \n",
    "        for batch in sentiment_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "    \n",
    "            for i in range(len(preds)):\n",
    "                output = {\n",
    "                    'aspect': batch['aspect'][i],\n",
    "                    'ori_indices': batch['ori_indices'][i],\n",
    "                    'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                }\n",
    "                sentiment_outputs.append(output)\n",
    "\n",
    "        sentiment_outputs = accelerator.gather_for_metrics(sentiment_outputs)\n",
    "        sentiment_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_outputs}\n",
    "\n",
    "    # Replcae non neutral aspect to its predicted sentiment\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        i = -1\n",
    "        for (ori_index, aspect), value in sentiment_outputs.items():\n",
    "            aspect = aspect_mapping[aspect]\n",
    "            aspect_outputs[ori_index]['pred'][aspect] = 2 if value['pred'] == 1.0 else value['pred']\n",
    "\n",
    "        result = compute_metrics_overall(\n",
    "            type('EvalOutput', (object,), {'predictions': [output['pred'] for output in aspect_outputs.values()], 'label_ids': [output['ori_labels'] for output in aspect_outputs.values()]}),\n",
    "            ['negative', 'neutral', 'positive'],\n",
    "        )\n",
    "\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        for i in range(len(train_labels)):\n",
    "            accelerator.print(f\"Aspect {aspect_list[i]} report:\")\n",
    "            accelerator.print(result['reports'][i])\n",
    "       \n",
    "        \n",
    "        aspect_metrics[0].append(aspect_result['accuracy'])\n",
    "        aspect_metrics[1].append(aspect_result['f1_micro'])\n",
    "        aspect_metrics[2].append(aspect_result['f1_macro'])\n",
    "        sentiment_metrics[0].append(sentiment_result['accuracy'])\n",
    "        sentiment_metrics[1].append(sentiment_result['f1_micro'])\n",
    "        sentiment_metrics[2].append(sentiment_result['f1_macro'])\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(result['accuracy'])\n",
    "        metrics[2].append(result['f1_micro'])\n",
    "        metrics[3].append(result['f1_macro'])\n",
    "        \n",
    "    accelerator.print(f\"Total train time: {duration} s\")\n",
    "    accelerator.end_training()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb67c361",
   "metadata": {
    "papermill": {
     "duration": 0.010974,
     "end_time": "2025-03-31T11:40:19.961006",
     "exception": false,
     "start_time": "2025-03-31T11:40:19.950032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01eee6c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T11:40:19.985198Z",
     "iopub.status.busy": "2025-03-31T11:40:19.984996Z",
     "iopub.status.idle": "2025-03-31T11:40:19.989856Z",
     "shell.execute_reply": "2025-03-31T11:40:19.989288Z"
    },
    "papermill": {
     "duration": 0.018823,
     "end_time": "2025-03-31T11:40:19.990938",
     "exception": false,
     "start_time": "2025-03-31T11:40:19.972115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f371505",
   "metadata": {
    "papermill": {
     "duration": 0.011385,
     "end_time": "2025-03-31T11:40:20.013530",
     "exception": false,
     "start_time": "2025-03-31T11:40:20.002145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7816179",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T11:40:20.037039Z",
     "iopub.status.busy": "2025-03-31T11:40:20.036842Z",
     "iopub.status.idle": "2025-03-31T11:40:20.043596Z",
     "shell.execute_reply": "2025-03-31T11:40:20.043031Z"
    },
    "papermill": {
     "duration": 0.019729,
     "end_time": "2025-03-31T11:40:20.044653",
     "exception": false,
     "start_time": "2025-03-31T11:40:20.024924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_sampling(current_train_size, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, n_samples=min_increment):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    nearest_cp = 0\n",
    "    arrived_at_cp = False\n",
    "    for cp in checkpoints:\n",
    "        if cp > current_train_size:\n",
    "            nearest_cp = cp\n",
    "            break\n",
    "\n",
    "    num_of_candidates = math.ceil(0.1 * len(remaining_indices))\n",
    "\n",
    "    if num_of_candidates <= n_samples and n_samples < nearest_cp - current_train_size:\n",
    "        num_of_candidates = n_samples\n",
    "    elif num_of_candidates > n_samples and num_of_candidates < nearest_cp - current_train_size:\n",
    "        num_of_candidates = max(n_samples, num_of_candidates)\n",
    "    else:\n",
    "        num_of_candidates = nearest_cp - current_train_size\n",
    "        arrived_at_cp = True\n",
    "\n",
    "    random_indices = random.sample(range(len(X_pool)), num_of_candidates)\n",
    "\n",
    "    if arrived_at_cp:\n",
    "        temp = train_indices.copy()\n",
    "        temp.extend(random_indices)\n",
    "            \n",
    "        # Save acquired data up to checkpoint\n",
    "        acquired_data = pd.DataFrame({\n",
    "            'processed_text': [X_train[i] for i in temp],\n",
    "            'ac': [y_train[i][0] for i in temp],\n",
    "            'air_panas': [y_train[i][1] for i in temp],\n",
    "            'bau': [y_train[i][2] for i in temp],\n",
    "            'general': [y_train[i][3] for i in temp],\n",
    "            'kebersihan': [y_train[i][4] for i in temp],\n",
    "            'linen': [y_train[i][5] for i in temp],\n",
    "            'service': [y_train[i][6] for i in temp],\n",
    "            'sunrise_meal': [y_train[i][7] for i in temp],\n",
    "            'tv': [y_train[i][8] for i in temp],\n",
    "            'wifi': [y_train[i][9] for i in temp],\n",
    "        })\n",
    "\n",
    "        acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "    end_time = time.time() \n",
    "    duration = end_time - start_time\n",
    "\n",
    "    sampling_dur.append(duration)\n",
    "    for i in random_indices:\n",
    "        new_samples.append(remaining_indices[i])\n",
    "        \n",
    "    print(\"Nearest checkpoint:\", nearest_cp)\n",
    "    print(\"Acquired samples:\", len(random_indices))\n",
    "    print(f\"Sampling duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d725a22f",
   "metadata": {
    "papermill": {
     "duration": 0.011331,
     "end_time": "2025-03-31T11:40:20.067277",
     "exception": false,
     "start_time": "2025-03-31T11:40:20.055946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25b219b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T11:40:20.091127Z",
     "iopub.status.busy": "2025-03-31T11:40:20.090927Z",
     "iopub.status.idle": "2025-03-31T11:40:20.099875Z",
     "shell.execute_reply": "2025-03-31T11:40:20.099261Z"
    },
    "papermill": {
     "duration": 0.021808,
     "end_time": "2025-03-31T11:40:20.100952",
     "exception": false,
     "start_time": "2025-03-31T11:40:20.079144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    aspect_accuracies = manager.list()\n",
    "    aspect_f1_micros = manager.list()\n",
    "    aspect_f1_macros = manager.list()\n",
    "    sentiment_accuracies = manager.list()\n",
    "    sentiment_f1_micros = manager.list()\n",
    "    sentiment_f1_macros = manager.list()\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        # Train the model\n",
    "        args = (\n",
    "            current_train_size, \n",
    "            train_indices, \n",
    "            (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "            (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "            (data_used, accuracies, f1_micros, f1_macros), \n",
    "            i,\n",
    "            seed\n",
    "        )\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{i+1}-model')\n",
    "        sentiment_model = BertForSequenceClassification.from_pretrained(f'{filename}-sentiment-{i+1}-model')\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        random_sampling(\n",
    "            current_train_size, \n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices, \n",
    "            remaining_indices, \n",
    "            sampling_dur, \n",
    "            new_samples, \n",
    "            i\n",
    "        )\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    args = (\n",
    "        current_train_size, \n",
    "        train_indices, \n",
    "        (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "        (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "        (data_used, accuracies, f1_micros, f1_macros), \n",
    "        i,\n",
    "        seed\n",
    "    )\n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    aspect_accuracies, aspect_f1_micros, aspect_f1_macros = list(aspect_accuracies), list(aspect_f1_micros), list(aspect_f1_macros)\n",
    "    sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros = list(sentiment_accuracies), list(sentiment_f1_micros), list(sentiment_f1_macros)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Aspect Accuracy': aspect_accuracies,\n",
    "        'Aspect F1 Micro': aspect_f1_micros,\n",
    "        'Aspect F1 Macro': aspect_f1_macros,\n",
    "        'Sentiment Accuracy': sentiment_accuracies,\n",
    "        'Sentiment F1 Micro': sentiment_f1_micros,\n",
    "        'Sentiment F1 Macro': sentiment_f1_macros,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9bb3608",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T11:40:20.124333Z",
     "iopub.status.busy": "2025-03-31T11:40:20.124140Z",
     "iopub.status.idle": "2025-03-31T11:40:20.126958Z",
     "shell.execute_reply": "2025-03-31T11:40:20.126355Z"
    },
    "papermill": {
     "duration": 0.015952,
     "end_time": "2025-03-31T11:40:20.128097",
     "exception": false,
     "start_time": "2025-03-31T11:40:20.112145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821e9174",
   "metadata": {
    "papermill": {
     "duration": 0.011319,
     "end_time": "2025-03-31T11:40:20.150711",
     "exception": false,
     "start_time": "2025-03-31T11:40:20.139392",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64fde31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5865, Accuracy: 0.7995, F1 Micro: 0.8876, F1 Macro: 0.8805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4747, Accuracy: 0.801, F1 Micro: 0.8892, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4337, Accuracy: 0.8007, F1 Micro: 0.8893, F1 Macro: 0.8848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.425, Accuracy: 0.8033, F1 Micro: 0.8905, F1 Macro: 0.8856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4065, Accuracy: 0.8064, F1 Micro: 0.8916, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4121, Accuracy: 0.8101, F1 Micro: 0.8933, F1 Macro: 0.8874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3857, Accuracy: 0.8177, F1 Micro: 0.8971, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3725, Accuracy: 0.8321, F1 Micro: 0.9044, F1 Macro: 0.8994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3428, Accuracy: 0.841, F1 Micro: 0.9088, F1 Macro: 0.9042\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3197, Accuracy: 0.8507, F1 Micro: 0.9137, F1 Macro: 0.9092\n",
      "\n",
      "Aspect detection accuracy: 0.8507, F1 Micro: 0.9137, F1 Macro: 0.9092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.84      1.00      0.91       462\n",
      "   air_panas       0.84      1.00      0.91       480\n",
      "         bau       0.86      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.80      0.85      0.83       317\n",
      "       linen       0.71      0.99      0.83       392\n",
      "     service       0.88      0.97      0.93       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.86      1.00      0.93       498\n",
      "\n",
      "   micro avg       0.85      0.99      0.91      4614\n",
      "   macro avg       0.85      0.98      0.91      4614\n",
      "weighted avg       0.85      0.99      0.91      4614\n",
      " samples avg       0.85      0.99      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6014, Accuracy: 0.6293, F1 Micro: 0.6293, F1 Macro: 0.3862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5503, Accuracy: 0.6293, F1 Micro: 0.6293, F1 Macro: 0.3862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4934, Accuracy: 0.6293, F1 Micro: 0.6293, F1 Macro: 0.3862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3898, Accuracy: 0.6878, F1 Micro: 0.6878, F1 Macro: 0.5444\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3441, Accuracy: 0.7488, F1 Micro: 0.7488, F1 Macro: 0.6959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2311, Accuracy: 0.7634, F1 Micro: 0.7634, F1 Macro: 0.719\n",
      "Epoch 7/10, Train Loss: 0.181, Accuracy: 0.7439, F1 Micro: 0.7439, F1 Macro: 0.6915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2402, Accuracy: 0.7756, F1 Micro: 0.7756, F1 Macro: 0.7399\n",
      "Epoch 9/10, Train Loss: 0.1526, Accuracy: 0.7512, F1 Micro: 0.7512, F1 Macro: 0.6996\n",
      "Epoch 10/10, Train Loss: 0.1164, Accuracy: 0.7537, F1 Micro: 0.7537, F1 Macro: 0.7047\n",
      "\n",
      "Sentiment analysis accuracy: 0.7756, F1 Micro: 0.7756, F1 Macro: 0.7399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.91      0.84       258\n",
      "    positive       0.78      0.55      0.64       152\n",
      "\n",
      "    accuracy                           0.78       410\n",
      "   macro avg       0.78      0.73      0.74       410\n",
      "weighted avg       0.78      0.78      0.76       410\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8405, F1 Micro: 0.8405, F1 Macro: 0.4036\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.27      0.42        97\n",
      "     neutral       0.84      1.00      0.91       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.59      0.42      0.44       571\n",
      "weighted avg       0.84      0.85      0.81       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.01      0.02        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.44      0.34      0.31       571\n",
      "weighted avg       0.77      0.83      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        78\n",
      "     neutral       0.86      1.00      0.92       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.74      0.86      0.80       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.68      0.70       200\n",
      "     neutral       0.80      0.85      0.83       315\n",
      "    positive       0.35      0.29      0.31        56\n",
      "\n",
      "    accuracy                           0.74       571\n",
      "   macro avg       0.62      0.61      0.61       571\n",
      "weighted avg       0.73      0.74      0.73       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.18      0.30       162\n",
      "     neutral       0.71      0.99      0.83       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.72       571\n",
      "   macro avg       0.52      0.39      0.37       571\n",
      "weighted avg       0.72      0.72      0.64       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.54      0.61        85\n",
      "     neutral       0.88      0.98      0.93       418\n",
      "    positive       0.84      0.54      0.66        68\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.81      0.69      0.73       571\n",
      "weighted avg       0.85      0.86      0.85       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        74\n",
      "     neutral       0.87      1.00      0.93       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.80       571\n",
      "\n",
      "Total train time: 83.60265374183655 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 215\n",
      "Sampling duration: 0.0002219676971435547 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5476, Accuracy: 0.8033, F1 Micro: 0.8902, F1 Macro: 0.8847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4712, Accuracy: 0.8038, F1 Micro: 0.8908, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4386, Accuracy: 0.8189, F1 Micro: 0.8979, F1 Macro: 0.8925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.404, Accuracy: 0.8458, F1 Micro: 0.9113, F1 Macro: 0.907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3525, Accuracy: 0.8714, F1 Micro: 0.9247, F1 Macro: 0.9208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2998, Accuracy: 0.8901, F1 Micro: 0.9349, F1 Macro: 0.9318\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2574, Accuracy: 0.905, F1 Micro: 0.9431, F1 Macro: 0.9405\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2257, Accuracy: 0.9111, F1 Micro: 0.9463, F1 Macro: 0.9433\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.219, Accuracy: 0.9219, F1 Micro: 0.9528, F1 Macro: 0.9502\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1786, Accuracy: 0.9245, F1 Micro: 0.9544, F1 Macro: 0.9514\n",
      "\n",
      "Aspect detection accuracy: 0.9245, F1 Micro: 0.9544, F1 Macro: 0.9514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.97      0.99      0.98       462\n",
      "   air_panas       0.93      0.99      0.96       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.82      0.94      0.88       317\n",
      "       linen       0.82      0.98      0.90       392\n",
      "     service       0.95      0.96      0.96       423\n",
      "sunrise_meal       0.92      0.99      0.96       530\n",
      "          tv       0.98      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.92      0.99      0.95      4614\n",
      "   macro avg       0.92      0.98      0.95      4614\n",
      "weighted avg       0.93      0.99      0.96      4614\n",
      " samples avg       0.92      0.99      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5097, Accuracy: 0.7629, F1 Micro: 0.7629, F1 Macro: 0.4327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4266, Accuracy: 0.794, F1 Micro: 0.794, F1 Macro: 0.5695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3152, Accuracy: 0.824, F1 Micro: 0.824, F1 Macro: 0.7067\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2747, Accuracy: 0.8383, F1 Micro: 0.8383, F1 Macro: 0.7814\n",
      "Epoch 5/10, Train Loss: 0.2467, Accuracy: 0.812, F1 Micro: 0.812, F1 Macro: 0.7629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2119, Accuracy: 0.8683, F1 Micro: 0.8683, F1 Macro: 0.7932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2042, Accuracy: 0.879, F1 Micro: 0.879, F1 Macro: 0.8062\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1569, Accuracy: 0.8802, F1 Micro: 0.8802, F1 Macro: 0.8076\n",
      "Epoch 9/10, Train Loss: 0.1338, Accuracy: 0.8778, F1 Micro: 0.8778, F1 Macro: 0.8222\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0683, Accuracy: 0.885, F1 Micro: 0.885, F1 Macro: 0.8272\n",
      "\n",
      "Sentiment analysis accuracy: 0.885, F1 Micro: 0.885, F1 Macro: 0.8272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93       637\n",
      "    positive       0.83      0.65      0.73       198\n",
      "\n",
      "    accuracy                           0.89       835\n",
      "   macro avg       0.86      0.80      0.83       835\n",
      "weighted avg       0.88      0.89      0.88       835\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.685\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        97\n",
      "     neutral       0.97      0.99      0.98       459\n",
      "    positive       0.79      0.73      0.76        15\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.90      0.86      0.88       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.63      0.74        86\n",
      "     neutral       0.93      0.99      0.96       475\n",
      "    positive       0.50      0.30      0.37        10\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.78      0.64      0.69       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.74      0.78        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.67      0.03      0.06        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.51      0.34      0.33       571\n",
      "weighted avg       0.84      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.72      0.79       200\n",
      "     neutral       0.82      0.94      0.88       315\n",
      "    positive       0.72      0.59      0.65        56\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.81      0.75      0.77       571\n",
      "weighted avg       0.83      0.83      0.83       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.57      0.71       162\n",
      "     neutral       0.82      0.98      0.90       387\n",
      "    positive       0.29      0.09      0.14        22\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.68      0.55      0.58       571\n",
      "weighted avg       0.83      0.83      0.81       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.76      0.79        85\n",
      "     neutral       0.95      0.97      0.96       418\n",
      "    positive       0.84      0.82      0.83        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.85      0.86       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      0.99      0.96       525\n",
      "    positive       0.25      0.06      0.10        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.39      0.35      0.35       571\n",
      "weighted avg       0.86      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.81      0.86        54\n",
      "     neutral       0.98      1.00      0.99       511\n",
      "    positive       0.75      0.50      0.60         6\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.77      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.97      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 126.02837491035461 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 193\n",
      "Sampling duration: 0.0001423358917236328 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5065, Accuracy: 0.8019, F1 Micro: 0.8899, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4407, Accuracy: 0.8266, F1 Micro: 0.9015, F1 Macro: 0.8964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.392, Accuracy: 0.8611, F1 Micro: 0.9197, F1 Macro: 0.9164\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3291, Accuracy: 0.8903, F1 Micro: 0.9351, F1 Macro: 0.9322\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2594, Accuracy: 0.9016, F1 Micro: 0.9414, F1 Macro: 0.9388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2294, Accuracy: 0.9271, F1 Micro: 0.9558, F1 Macro: 0.9537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.199, Accuracy: 0.9306, F1 Micro: 0.9579, F1 Macro: 0.9556\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1738, Accuracy: 0.9349, F1 Micro: 0.9604, F1 Macro: 0.9583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1491, Accuracy: 0.9432, F1 Micro: 0.9652, F1 Macro: 0.963\n",
      "Epoch 10/10, Train Loss: 0.1317, Accuracy: 0.9431, F1 Micro: 0.9652, F1 Macro: 0.9629\n",
      "\n",
      "Aspect detection accuracy: 0.9432, F1 Micro: 0.9652, F1 Macro: 0.963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.94      0.99      0.97       480\n",
      "         bau       0.96      0.99      0.97       496\n",
      "     general       0.88      1.00      0.94       500\n",
      "  kebersihan       0.91      0.93      0.92       317\n",
      "       linen       0.90      0.96      0.93       392\n",
      "     service       0.96      0.96      0.96       423\n",
      "sunrise_meal       0.95      0.99      0.97       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.97      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4532, Accuracy: 0.7627, F1 Micro: 0.7627, F1 Macro: 0.5367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3418, Accuracy: 0.8218, F1 Micro: 0.8218, F1 Macro: 0.7226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2429, Accuracy: 0.8528, F1 Micro: 0.8528, F1 Macro: 0.8053\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.215, Accuracy: 0.8767, F1 Micro: 0.8767, F1 Macro: 0.8304\n",
      "Epoch 5/10, Train Loss: 0.1721, Accuracy: 0.8601, F1 Micro: 0.8601, F1 Macro: 0.7843\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1691, Accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.8537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1461, Accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.8523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1237, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8592\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0727, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8625\n",
      "Epoch 10/10, Train Loss: 0.0739, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8584\n",
      "\n",
      "Sentiment analysis accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.94       708\n",
      "    positive       0.94      0.68      0.79       257\n",
      "\n",
      "    accuracy                           0.90       965\n",
      "   macro avg       0.92      0.83      0.86       965\n",
      "weighted avg       0.91      0.90      0.90       965\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.7881\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.87      0.87      0.87        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.74      0.82        86\n",
      "     neutral       0.95      0.99      0.97       475\n",
      "    positive       0.75      0.30      0.43        10\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.87      0.68      0.74       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.77      0.82        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.89      1.00      0.94       496\n",
      "    positive       0.82      0.13      0.23        68\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.57      0.38      0.39       571\n",
      "weighted avg       0.87      0.88      0.84       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86       200\n",
      "     neutral       0.92      0.92      0.92       315\n",
      "    positive       0.88      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.90      0.90       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.78      0.83       162\n",
      "     neutral       0.90      0.96      0.93       387\n",
      "    positive       0.64      0.32      0.42        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.80      0.69      0.73       571\n",
      "weighted avg       0.88      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.82      0.81        85\n",
      "     neutral       0.96      0.96      0.96       418\n",
      "    positive       0.87      0.87      0.87        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.88      0.88      0.88       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.10      0.16        29\n",
      "     neutral       0.95      0.99      0.97       525\n",
      "    positive       0.83      0.59      0.69        17\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.71      0.56      0.61       571\n",
      "weighted avg       0.91      0.94      0.92       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.89      0.92        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.85      0.91       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 152.58614897727966 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 174\n",
      "Sampling duration: 0.0001323223114013672 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5047, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4196, Accuracy: 0.8413, F1 Micro: 0.9094, F1 Macro: 0.9057\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3485, Accuracy: 0.8847, F1 Micro: 0.9322, F1 Macro: 0.9295\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2724, Accuracy: 0.9135, F1 Micro: 0.9482, F1 Macro: 0.9458\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2261, Accuracy: 0.9262, F1 Micro: 0.9554, F1 Macro: 0.953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1912, Accuracy: 0.9342, F1 Micro: 0.96, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1724, Accuracy: 0.9387, F1 Micro: 0.9627, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1461, Accuracy: 0.9451, F1 Micro: 0.9664, F1 Macro: 0.9636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1318, Accuracy: 0.9462, F1 Micro: 0.967, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1154, Accuracy: 0.9491, F1 Micro: 0.9687, F1 Macro: 0.9659\n",
      "\n",
      "Aspect detection accuracy: 0.9491, F1 Micro: 0.9687, F1 Macro: 0.9659\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.90      0.99      0.94       500\n",
      "  kebersihan       0.90      0.91      0.91       317\n",
      "       linen       0.88      0.97      0.92       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.96      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.95      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4675, Accuracy: 0.8171, F1 Micro: 0.8171, F1 Macro: 0.7446\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2704, Accuracy: 0.8499, F1 Micro: 0.8499, F1 Macro: 0.8068\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2166, Accuracy: 0.8648, F1 Micro: 0.8648, F1 Macro: 0.8275\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1554, Accuracy: 0.8877, F1 Micro: 0.8877, F1 Macro: 0.8522\n",
      "Epoch 5/10, Train Loss: 0.1494, Accuracy: 0.8728, F1 Micro: 0.8728, F1 Macro: 0.8132\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0979, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8624\n",
      "Epoch 7/10, Train Loss: 0.0684, Accuracy: 0.8986, F1 Micro: 0.8986, F1 Macro: 0.8567\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0494, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.059, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8767\n",
      "Epoch 10/10, Train Loss: 0.0322, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8747\n",
      "\n",
      "Sentiment analysis accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       735\n",
      "    positive       0.92      0.73      0.81       271\n",
      "\n",
      "    accuracy                           0.91      1006\n",
      "   macro avg       0.91      0.85      0.88      1006\n",
      "weighted avg       0.91      0.91      0.91      1006\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.8157\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.85      0.89        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.75      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.90      0.99      0.94       496\n",
      "    positive       0.86      0.28      0.42        68\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.59      0.42      0.46       571\n",
      "weighted avg       0.88      0.90      0.87       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.86       200\n",
      "     neutral       0.90      0.91      0.91       315\n",
      "    positive       0.81      0.93      0.87        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.87      0.89      0.88       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.73      0.82       162\n",
      "     neutral       0.88      0.97      0.92       387\n",
      "    positive       0.38      0.27      0.32        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.72      0.66      0.68       571\n",
      "weighted avg       0.87      0.88      0.87       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        85\n",
      "     neutral       0.96      0.97      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.31      0.46        29\n",
      "     neutral       0.96      1.00      0.98       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.90      0.71      0.76       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.89      0.92        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.96      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 177.18520259857178 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 156\n",
      "Sampling duration: 0.00013303756713867188 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4982, Accuracy: 0.8016, F1 Micro: 0.8898, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4091, Accuracy: 0.871, F1 Micro: 0.9243, F1 Macro: 0.9205\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3133, Accuracy: 0.9078, F1 Micro: 0.9451, F1 Macro: 0.9427\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.243, Accuracy: 0.9295, F1 Micro: 0.9574, F1 Macro: 0.9554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1997, Accuracy: 0.9356, F1 Micro: 0.9608, F1 Macro: 0.9586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1697, Accuracy: 0.941, F1 Micro: 0.9641, F1 Macro: 0.9619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1475, Accuracy: 0.9469, F1 Micro: 0.9675, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1278, Accuracy: 0.9476, F1 Micro: 0.9679, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1106, Accuracy: 0.9488, F1 Micro: 0.9686, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.097, Accuracy: 0.9509, F1 Micro: 0.9699, F1 Macro: 0.9674\n",
      "\n",
      "Aspect detection accuracy: 0.9509, F1 Micro: 0.9699, F1 Macro: 0.9674\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.91      0.99      0.95       500\n",
      "  kebersihan       0.90      0.93      0.91       317\n",
      "       linen       0.89      0.98      0.93       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.95      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      4614\n",
      "   macro avg       0.95      0.98      0.97      4614\n",
      "weighted avg       0.95      0.99      0.97      4614\n",
      " samples avg       0.95      0.99      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4612, Accuracy: 0.8495, F1 Micro: 0.8495, F1 Macro: 0.8042\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2664, Accuracy: 0.8628, F1 Micro: 0.8628, F1 Macro: 0.8273\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2397, Accuracy: 0.8639, F1 Micro: 0.8639, F1 Macro: 0.7913\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.12, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1152, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8756\n",
      "Epoch 6/10, Train Loss: 0.0964, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0623, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8774\n",
      "Epoch 8/10, Train Loss: 0.0521, Accuracy: 0.8925, F1 Micro: 0.8925, F1 Macro: 0.8421\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0472, Accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8843\n",
      "Epoch 10/10, Train Loss: 0.0337, Accuracy: 0.8946, F1 Micro: 0.8946, F1 Macro: 0.8477\n",
      "\n",
      "Sentiment analysis accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       719\n",
      "    positive       0.94      0.73      0.82       258\n",
      "\n",
      "    accuracy                           0.92       977\n",
      "   macro avg       0.93      0.86      0.88       977\n",
      "weighted avg       0.92      0.92      0.91       977\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.7453\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.92      0.80      0.86        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.91      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        86\n",
      "     neutral       0.97      1.00      0.98       475\n",
      "    positive       0.50      0.10      0.17        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.79      0.65      0.68       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.73      0.79        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.74      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.91      0.99      0.95       496\n",
      "    positive       0.86      0.35      0.50        68\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.59      0.45      0.48       571\n",
      "weighted avg       0.89      0.90      0.88       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.81      0.85       200\n",
      "     neutral       0.90      0.93      0.91       315\n",
      "    positive       0.85      0.91      0.88        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.88      0.89      0.88       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.78      0.82       162\n",
      "     neutral       0.89      0.98      0.93       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.59      0.59      0.58       571\n",
      "weighted avg       0.85      0.88      0.86       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.80      0.82        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.92      0.84      0.88        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.87      0.89       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.21      0.28        29\n",
      "     neutral       0.95      1.00      0.98       525\n",
      "    positive       0.75      0.35      0.48        17\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.71      0.52      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.93      0.89        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.62      0.64      0.63       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 197.77260446548462 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 141\n",
      "Sampling duration: 0.00012135505676269531 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4904, Accuracy: 0.8035, F1 Micro: 0.8907, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3951, Accuracy: 0.8783, F1 Micro: 0.9287, F1 Macro: 0.9253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2998, Accuracy: 0.9122, F1 Micro: 0.9476, F1 Macro: 0.9455\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2264, Accuracy: 0.9361, F1 Micro: 0.9611, F1 Macro: 0.9589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1948, Accuracy: 0.942, F1 Micro: 0.9646, F1 Macro: 0.9624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1583, Accuracy: 0.9441, F1 Micro: 0.9659, F1 Macro: 0.9636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1331, Accuracy: 0.951, F1 Micro: 0.9699, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1146, Accuracy: 0.9543, F1 Micro: 0.9719, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1025, Accuracy: 0.9552, F1 Micro: 0.9724, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0861, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9715\n",
      "\n",
      "Aspect detection accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.93      0.92      0.93       317\n",
      "       linen       0.91      0.96      0.93       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3908, Accuracy: 0.8506, F1 Micro: 0.8506, F1 Macro: 0.8037\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2397, Accuracy: 0.8535, F1 Micro: 0.8535, F1 Macro: 0.8189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2197, Accuracy: 0.8934, F1 Micro: 0.8934, F1 Macro: 0.8631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1302, Accuracy: 0.8934, F1 Micro: 0.8934, F1 Macro: 0.8546\n",
      "Epoch 5/10, Train Loss: 0.0872, Accuracy: 0.8896, F1 Micro: 0.8896, F1 Macro: 0.8474\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0704, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.884\n",
      "Epoch 7/10, Train Loss: 0.0636, Accuracy: 0.8982, F1 Micro: 0.8982, F1 Macro: 0.8613\n",
      "Epoch 8/10, Train Loss: 0.0524, Accuracy: 0.8944, F1 Micro: 0.8944, F1 Macro: 0.855\n",
      "Epoch 9/10, Train Loss: 0.0263, Accuracy: 0.8953, F1 Micro: 0.8953, F1 Macro: 0.8565\n",
      "Epoch 10/10, Train Loss: 0.0327, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8762\n",
      "\n",
      "Sentiment analysis accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       755\n",
      "    positive       0.92      0.75      0.83       296\n",
      "\n",
      "    accuracy                           0.91      1051\n",
      "   macro avg       0.91      0.86      0.88      1051\n",
      "weighted avg       0.91      0.91      0.91      1051\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9518, F1 Micro: 0.9518, F1 Macro: 0.8364\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.86      0.89        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.75      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.81      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.95       496\n",
      "    positive       0.85      0.49      0.62        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.49      0.52       571\n",
      "weighted avg       0.90      0.92      0.90       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       200\n",
      "     neutral       0.93      0.92      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.80      0.82       162\n",
      "     neutral       0.91      0.96      0.93       387\n",
      "    positive       1.00      0.23      0.37        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.92      0.66      0.71       571\n",
      "weighted avg       0.89      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.81      0.86        85\n",
      "     neutral       0.97      0.99      0.98       418\n",
      "    positive       0.93      0.97      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.48      0.61        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.72      0.76      0.74        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.75      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 217.02255821228027 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 127\n",
      "Sampling duration: 0.00014710426330566406 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4883, Accuracy: 0.8056, F1 Micro: 0.8917, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.361, Accuracy: 0.8911, F1 Micro: 0.9355, F1 Macro: 0.9325\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2714, Accuracy: 0.9288, F1 Micro: 0.957, F1 Macro: 0.9546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2126, Accuracy: 0.9406, F1 Micro: 0.9637, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1802, Accuracy: 0.9411, F1 Micro: 0.9641, F1 Macro: 0.962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1474, Accuracy: 0.95, F1 Micro: 0.9693, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1259, Accuracy: 0.955, F1 Micro: 0.9723, F1 Macro: 0.9699\n",
      "Epoch 8/10, Train Loss: 0.1124, Accuracy: 0.954, F1 Micro: 0.9717, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0948, Accuracy: 0.9585, F1 Micro: 0.9743, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0839, Accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.9721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.93      0.94      0.93       317\n",
      "       linen       0.90      0.97      0.93       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4459, Accuracy: 0.8151, F1 Micro: 0.8151, F1 Macro: 0.7881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2656, Accuracy: 0.8736, F1 Micro: 0.8736, F1 Macro: 0.8269\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1986, Accuracy: 0.8975, F1 Micro: 0.8975, F1 Macro: 0.8639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1272, Accuracy: 0.8975, F1 Micro: 0.8975, F1 Macro: 0.8628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1165, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0875, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8929\n",
      "Epoch 7/10, Train Loss: 0.0463, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0366, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.8979\n",
      "Epoch 9/10, Train Loss: 0.0301, Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.88\n",
      "Epoch 10/10, Train Loss: 0.0412, Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8847\n",
      "\n",
      "Sentiment analysis accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.8979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       744\n",
      "    positive       0.93      0.78      0.85       300\n",
      "\n",
      "    accuracy                           0.92      1044\n",
      "   macro avg       0.92      0.88      0.90      1044\n",
      "weighted avg       0.92      0.92      0.92      1044\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9503, F1 Micro: 0.9503, F1 Macro: 0.8131\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.86      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.74      0.79        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.60      0.58      0.59       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.14      0.14      0.14         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.83      0.65      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.64      0.59      0.61       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.89       200\n",
      "     neutral       0.93      0.94      0.93       315\n",
      "    positive       0.79      0.95      0.86        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.91      0.89       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82       162\n",
      "     neutral       0.90      0.97      0.93       387\n",
      "    positive       0.50      0.36      0.42        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.76      0.70      0.72       571\n",
      "weighted avg       0.88      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.79      0.84        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.88      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.90      0.91       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.34      0.49        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.72      0.75       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 238.2361500263214 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 114\n",
      "Sampling duration: 0.00013208389282226562 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.474, Accuracy: 0.8257, F1 Micro: 0.9016, F1 Macro: 0.8972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3469, Accuracy: 0.9, F1 Micro: 0.9404, F1 Macro: 0.9379\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2489, Accuracy: 0.9323, F1 Micro: 0.9588, F1 Macro: 0.9565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1922, Accuracy: 0.9432, F1 Micro: 0.9653, F1 Macro: 0.9631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1627, Accuracy: 0.9535, F1 Micro: 0.9713, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1363, Accuracy: 0.9542, F1 Micro: 0.9718, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1131, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9729\n",
      "Epoch 8/10, Train Loss: 0.0984, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9726\n",
      "Epoch 9/10, Train Loss: 0.0848, Accuracy: 0.9575, F1 Micro: 0.9738, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0732, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.97      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.99      0.99      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4212, Accuracy: 0.856, F1 Micro: 0.856, F1 Macro: 0.8208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2218, Accuracy: 0.8651, F1 Micro: 0.8651, F1 Macro: 0.8193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1818, Accuracy: 0.9018, F1 Micro: 0.9018, F1 Macro: 0.8739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1384, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0875, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8859\n",
      "Epoch 6/10, Train Loss: 0.0638, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8836\n",
      "Epoch 7/10, Train Loss: 0.0581, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8817\n",
      "Epoch 8/10, Train Loss: 0.0459, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8779\n",
      "Epoch 9/10, Train Loss: 0.0339, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.02, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8849\n",
      "\n",
      "Sentiment analysis accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.99      0.94       771\n",
      "    positive       0.96      0.73      0.83       319\n",
      "\n",
      "    accuracy                           0.91      1090\n",
      "   macro avg       0.93      0.86      0.88      1090\n",
      "weighted avg       0.92      0.91      0.91      1090\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9564, F1 Micro: 0.9564, F1 Macro: 0.8601\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.98      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.60      0.30      0.40        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.73      0.76       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.97      0.96       496\n",
      "    positive       0.77      0.71      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.61      0.65       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.89       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.90      0.95      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.85       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.89      0.36      0.52        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.72      0.77       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.85        85\n",
      "     neutral       0.96      0.99      0.97       418\n",
      "    positive       0.95      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.90      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.66      0.73        29\n",
      "     neutral       0.98      0.99      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.84      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.93      0.96       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 253.13271641731262 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 103\n",
      "Sampling duration: 0.00013494491577148438 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.475, Accuracy: 0.8299, F1 Micro: 0.9035, F1 Macro: 0.8987\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3395, Accuracy: 0.9083, F1 Micro: 0.9453, F1 Macro: 0.9427\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2376, Accuracy: 0.9375, F1 Micro: 0.9621, F1 Macro: 0.9602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1891, Accuracy: 0.9483, F1 Micro: 0.9683, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1533, Accuracy: 0.9497, F1 Micro: 0.9692, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1303, Accuracy: 0.9575, F1 Micro: 0.9738, F1 Macro: 0.9715\n",
      "Epoch 7/10, Train Loss: 0.1096, Accuracy: 0.9571, F1 Micro: 0.9736, F1 Macro: 0.9714\n",
      "Epoch 8/10, Train Loss: 0.0939, Accuracy: 0.9571, F1 Micro: 0.9736, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0801, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9752\n",
      "Epoch 10/10, Train Loss: 0.0695, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4036, Accuracy: 0.859, F1 Micro: 0.859, F1 Macro: 0.8175\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.232, Accuracy: 0.8822, F1 Micro: 0.8822, F1 Macro: 0.8405\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1614, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0972, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.072, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0718, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8869\n",
      "Epoch 7/10, Train Loss: 0.0585, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0361, Accuracy: 0.9212, F1 Micro: 0.9212, F1 Macro: 0.8988\n",
      "Epoch 9/10, Train Loss: 0.035, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8866\n",
      "Epoch 10/10, Train Loss: 0.0109, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.8928\n",
      "\n",
      "Sentiment analysis accuracy: 0.9212, F1 Micro: 0.9212, F1 Macro: 0.8988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       765\n",
      "    positive       0.94      0.78      0.85       313\n",
      "\n",
      "    accuracy                           0.92      1078\n",
      "   macro avg       0.93      0.88      0.90      1078\n",
      "weighted avg       0.92      0.92      0.92      1078\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9578, F1 Micro: 0.9578, F1 Macro: 0.867\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.79      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.82      0.74      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.62      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84       162\n",
      "     neutral       0.92      0.95      0.94       387\n",
      "    positive       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.92      0.74      0.79       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.83      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 266.46969079971313 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 62\n",
      "Sampling duration: 0.021364927291870117 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.473, Accuracy: 0.8438, F1 Micro: 0.9104, F1 Macro: 0.9065\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3306, Accuracy: 0.904, F1 Micro: 0.9429, F1 Macro: 0.9406\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2297, Accuracy: 0.9384, F1 Micro: 0.9623, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1805, Accuracy: 0.9486, F1 Micro: 0.9685, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1502, Accuracy: 0.9519, F1 Micro: 0.9705, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1256, Accuracy: 0.9559, F1 Micro: 0.9728, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1059, Accuracy: 0.9564, F1 Micro: 0.9732, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0914, Accuracy: 0.9587, F1 Micro: 0.9744, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0769, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0668, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9736\n",
      "\n",
      "Aspect detection accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.93      0.95      0.94       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.388, Accuracy: 0.8326, F1 Micro: 0.8326, F1 Macro: 0.7543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.247, Accuracy: 0.8705, F1 Micro: 0.8705, F1 Macro: 0.8246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1631, Accuracy: 0.8751, F1 Micro: 0.8751, F1 Macro: 0.8241\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1366, Accuracy: 0.8964, F1 Micro: 0.8964, F1 Macro: 0.8621\n",
      "Epoch 5/10, Train Loss: 0.0914, Accuracy: 0.8936, F1 Micro: 0.8936, F1 Macro: 0.8561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0738, Accuracy: 0.9019, F1 Micro: 0.9019, F1 Macro: 0.8711\n",
      "Epoch 7/10, Train Loss: 0.037, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8673\n",
      "Epoch 8/10, Train Loss: 0.0456, Accuracy: 0.8945, F1 Micro: 0.8945, F1 Macro: 0.8564\n",
      "Epoch 9/10, Train Loss: 0.0243, Accuracy: 0.8945, F1 Micro: 0.8945, F1 Macro: 0.8596\n",
      "Epoch 10/10, Train Loss: 0.0316, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8666\n",
      "\n",
      "Sentiment analysis accuracy: 0.9019, F1 Micro: 0.9019, F1 Macro: 0.8711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       772\n",
      "    positive       0.92      0.72      0.81       309\n",
      "\n",
      "    accuracy                           0.90      1081\n",
      "   macro avg       0.91      0.85      0.87      1081\n",
      "weighted avg       0.90      0.90      0.90      1081\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9546, F1 Micro: 0.9546, F1 Macro: 0.8442\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.86      0.89        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.96      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.78      0.82        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.89      0.62      0.73        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.58      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.89      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.85      0.84       162\n",
      "     neutral       0.92      0.95      0.94       387\n",
      "    positive       0.83      0.23      0.36        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.86      0.68      0.71       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.94      0.97      0.96        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.48      0.60        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.73      0.76       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 276.930935382843 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 86\n",
      "Sampling duration: 0.00010371208190917969 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.465, Accuracy: 0.845, F1 Micro: 0.9107, F1 Macro: 0.9062\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3168, Accuracy: 0.9205, F1 Micro: 0.9523, F1 Macro: 0.9497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2205, Accuracy: 0.9422, F1 Micro: 0.9647, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1777, Accuracy: 0.9498, F1 Micro: 0.9692, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.148, Accuracy: 0.9578, F1 Micro: 0.974, F1 Macro: 0.9718\n",
      "Epoch 6/10, Train Loss: 0.124, Accuracy: 0.9573, F1 Micro: 0.9737, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1025, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0857, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9752\n",
      "Epoch 9/10, Train Loss: 0.0735, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0645, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.92      0.95      0.93       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3743, Accuracy: 0.8633, F1 Micro: 0.8633, F1 Macro: 0.8237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.231, Accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.8708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.161, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8843\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.098, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8832\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0865, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0579, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0435, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.8928\n",
      "Epoch 8/10, Train Loss: 0.0472, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8871\n",
      "Epoch 9/10, Train Loss: 0.0178, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8874\n",
      "Epoch 10/10, Train Loss: 0.0136, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8884\n",
      "\n",
      "Sentiment analysis accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.8928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.94       766\n",
      "    positive       0.92      0.77      0.84       302\n",
      "\n",
      "    accuracy                           0.92      1068\n",
      "   macro avg       0.92      0.87      0.89      1068\n",
      "weighted avg       0.92      0.92      0.92      1068\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9566, F1 Micro: 0.9566, F1 Macro: 0.8386\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.80      0.40      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.91      0.76      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.77      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.82      0.69      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.60      0.66       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.89       200\n",
      "     neutral       0.92      0.95      0.93       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.75      0.79       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.84      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.45      0.58        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.65      0.88      0.75        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.78      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       0.67      0.33      0.44         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.86      0.76      0.79       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 287.3170599937439 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 77\n",
      "Sampling duration: 0.00011277198791503906 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4665, Accuracy: 0.8521, F1 Micro: 0.9139, F1 Macro: 0.9084\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3112, Accuracy: 0.9194, F1 Micro: 0.9516, F1 Macro: 0.9488\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2283, Accuracy: 0.9392, F1 Micro: 0.9631, F1 Macro: 0.961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1743, Accuracy: 0.9505, F1 Micro: 0.9697, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1433, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1243, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1049, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9743\n",
      "Epoch 8/10, Train Loss: 0.0871, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9744\n",
      "Epoch 9/10, Train Loss: 0.0732, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9749\n",
      "Epoch 10/10, Train Loss: 0.0626, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.91      0.93       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3896, Accuracy: 0.8543, F1 Micro: 0.8543, F1 Macro: 0.8169\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2527, Accuracy: 0.8752, F1 Micro: 0.8752, F1 Macro: 0.836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1612, Accuracy: 0.8998, F1 Micro: 0.8998, F1 Macro: 0.87\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1139, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8742\n",
      "Epoch 5/10, Train Loss: 0.0931, Accuracy: 0.9007, F1 Micro: 0.9007, F1 Macro: 0.8698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.064, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8731\n",
      "Epoch 7/10, Train Loss: 0.054, Accuracy: 0.8998, F1 Micro: 0.8998, F1 Macro: 0.8731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0424, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.033, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8844\n",
      "Epoch 10/10, Train Loss: 0.0258, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8815\n",
      "\n",
      "Sentiment analysis accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       775\n",
      "    positive       0.91      0.76      0.83       323\n",
      "\n",
      "    accuracy                           0.91      1098\n",
      "   macro avg       0.91      0.87      0.88      1098\n",
      "weighted avg       0.91      0.91      0.91      1098\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9571, F1 Micro: 0.9571, F1 Macro: 0.8532\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.83      0.74      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.91      0.89       200\n",
      "     neutral       0.95      0.90      0.93       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.93      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.78      0.32      0.45        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.71      0.75       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.93      0.97      0.95        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.66      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.80      0.67      0.73         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.87      0.89       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 296.87690925598145 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 70\n",
      "Sampling duration: 9.369850158691406e-05 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4588, Accuracy: 0.8595, F1 Micro: 0.9179, F1 Macro: 0.9124\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.309, Accuracy: 0.9219, F1 Micro: 0.9529, F1 Macro: 0.9505\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2169, Accuracy: 0.9394, F1 Micro: 0.9632, F1 Macro: 0.961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1746, Accuracy: 0.9516, F1 Micro: 0.9702, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1458, Accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1182, Accuracy: 0.959, F1 Micro: 0.9747, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0973, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9747\n",
      "Epoch 8/10, Train Loss: 0.0851, Accuracy: 0.962, F1 Micro: 0.9765, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.0706, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9733\n",
      "Epoch 10/10, Train Loss: 0.0605, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.95      0.92      0.93       317\n",
      "       linen       0.90      0.99      0.95       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.99      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3806, Accuracy: 0.8707, F1 Micro: 0.8707, F1 Macro: 0.8378\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2266, Accuracy: 0.8983, F1 Micro: 0.8983, F1 Macro: 0.8635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1626, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1163, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.8887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0785, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9012\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0577, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9037\n",
      "Epoch 7/10, Train Loss: 0.0418, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8689\n",
      "Epoch 8/10, Train Loss: 0.0425, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.8964\n",
      "Epoch 9/10, Train Loss: 0.0388, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8882\n",
      "Epoch 10/10, Train Loss: 0.0252, Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.8979\n",
      "\n",
      "Sentiment analysis accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       763\n",
      "    positive       0.95      0.78      0.86       289\n",
      "\n",
      "    accuracy                           0.93      1052\n",
      "   macro avg       0.94      0.88      0.90      1052\n",
      "weighted avg       0.93      0.93      0.93      1052\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9555, F1 Micro: 0.9555, F1 Macro: 0.851\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.14      0.14      0.14         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.81      0.65      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.64      0.59      0.61       571\n",
      "weighted avg       0.92      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.89      0.88       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       0.78      0.32      0.45        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.71      0.75       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.55      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.79      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.93      0.96       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 299.9655952453613 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 52\n",
      "Sampling duration: 0.01491093635559082 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4528, Accuracy: 0.8628, F1 Micro: 0.9201, F1 Macro: 0.9154\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2996, Accuracy: 0.9286, F1 Micro: 0.9567, F1 Macro: 0.954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2158, Accuracy: 0.9476, F1 Micro: 0.9678, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1698, Accuracy: 0.9502, F1 Micro: 0.9694, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1364, Accuracy: 0.9563, F1 Micro: 0.9731, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1135, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0951, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.975\n",
      "Epoch 8/10, Train Loss: 0.0793, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0685, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "Epoch 10/10, Train Loss: 0.0617, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.93      0.98      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3688, Accuracy: 0.8583, F1 Micro: 0.8583, F1 Macro: 0.807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.241, Accuracy: 0.9019, F1 Micro: 0.9019, F1 Macro: 0.8682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.157, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8731\n",
      "Epoch 4/10, Train Loss: 0.1076, Accuracy: 0.9009, F1 Micro: 0.9009, F1 Macro: 0.8643\n",
      "Epoch 5/10, Train Loss: 0.0733, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8687\n",
      "Epoch 6/10, Train Loss: 0.0528, Accuracy: 0.9037, F1 Micro: 0.9037, F1 Macro: 0.8722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0524, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.884\n",
      "Epoch 8/10, Train Loss: 0.0593, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8723\n",
      "Epoch 9/10, Train Loss: 0.0365, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.88\n",
      "Epoch 10/10, Train Loss: 0.0293, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8734\n",
      "\n",
      "Sentiment analysis accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       779\n",
      "    positive       0.93      0.74      0.83       301\n",
      "\n",
      "    accuracy                           0.91      1080\n",
      "   macro avg       0.92      0.86      0.88      1080\n",
      "weighted avg       0.91      0.91      0.91      1080\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9557, F1 Micro: 0.9557, F1 Macro: 0.8329\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.97      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.80      0.84       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.83      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.76      0.77      0.77       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.08      0.14      0.11         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.83      0.56      0.67        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.62      0.56      0.58       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.89       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.88      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.86      0.85       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.67      0.09      0.16        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.81      0.64      0.65       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.88        85\n",
      "     neutral       0.98      0.97      0.98       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 309.6219093799591 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 58\n",
      "Sampling duration: 8.606910705566406e-05 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4504, Accuracy: 0.8608, F1 Micro: 0.9191, F1 Macro: 0.9151\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2875, Accuracy: 0.9339, F1 Micro: 0.9596, F1 Macro: 0.9568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2037, Accuracy: 0.9465, F1 Micro: 0.9673, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1591, Accuracy: 0.9557, F1 Micro: 0.9727, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1334, Accuracy: 0.9573, F1 Micro: 0.9737, F1 Macro: 0.9711\n",
      "Epoch 6/10, Train Loss: 0.1112, Accuracy: 0.9563, F1 Micro: 0.9731, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0972, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.974\n",
      "Epoch 8/10, Train Loss: 0.0802, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0664, Accuracy: 0.962, F1 Micro: 0.9765, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0569, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.90      0.98      0.94       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.99      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.357, Accuracy: 0.86, F1 Micro: 0.86, F1 Macro: 0.8285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2061, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1576, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1137, Accuracy: 0.9224, F1 Micro: 0.9224, F1 Macro: 0.8968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0854, Accuracy: 0.9224, F1 Micro: 0.9224, F1 Macro: 0.8975\n",
      "Epoch 6/10, Train Loss: 0.0602, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8892\n",
      "Epoch 7/10, Train Loss: 0.0471, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8877\n",
      "Epoch 8/10, Train Loss: 0.0361, Accuracy: 0.9215, F1 Micro: 0.9215, F1 Macro: 0.8972\n",
      "Epoch 9/10, Train Loss: 0.022, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8858\n",
      "Epoch 10/10, Train Loss: 0.0357, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.8914\n",
      "\n",
      "Sentiment analysis accuracy: 0.9224, F1 Micro: 0.9224, F1 Macro: 0.8975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       763\n",
      "    positive       0.94      0.77      0.85       294\n",
      "\n",
      "    accuracy                           0.92      1057\n",
      "   macro avg       0.93      0.88      0.90      1057\n",
      "weighted avg       0.92      0.92      0.92      1057\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9566, F1 Micro: 0.9566, F1 Macro: 0.8591\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.97      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.90      0.93        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.80      0.84       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.86      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.78      0.83       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.65      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.93      0.59      0.65       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.88      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.77      0.83       162\n",
      "     neutral       0.90      0.98      0.93       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.87      0.72      0.77       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.82      0.86        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.55      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.71      0.73        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.75      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.93      0.96       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 319.66911268234253 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 52\n",
      "Sampling duration: 0.00011944770812988281 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4583, Accuracy: 0.8601, F1 Micro: 0.9181, F1 Macro: 0.9121\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2984, Accuracy: 0.9299, F1 Micro: 0.9576, F1 Macro: 0.9558\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2025, Accuracy: 0.9455, F1 Micro: 0.9667, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1615, Accuracy: 0.9521, F1 Micro: 0.9706, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1291, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.973\n",
      "Epoch 6/10, Train Loss: 0.1094, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0928, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0777, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0663, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0562, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.374, Accuracy: 0.843, F1 Micro: 0.843, F1 Macro: 0.8106\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2189, Accuracy: 0.8962, F1 Micro: 0.8962, F1 Macro: 0.867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1468, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1006, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0728, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8832\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0548, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8843\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.039, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8908\n",
      "Epoch 8/10, Train Loss: 0.0216, Accuracy: 0.9034, F1 Micro: 0.9034, F1 Macro: 0.872\n",
      "Epoch 9/10, Train Loss: 0.0253, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8855\n",
      "Epoch 10/10, Train Loss: 0.0184, Accuracy: 0.9034, F1 Micro: 0.9034, F1 Macro: 0.8776\n",
      "\n",
      "Sentiment analysis accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8908\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.99      0.94       785\n",
      "    positive       0.96      0.75      0.84       323\n",
      "\n",
      "    accuracy                           0.92      1108\n",
      "   macro avg       0.93      0.87      0.89      1108\n",
      "weighted avg       0.92      0.92      0.91      1108\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.8479\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.80      0.75      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.58      0.58      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.83      0.96      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.75      0.80       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.80      0.84        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.84      0.96      0.90        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.90      0.91      0.90       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.84      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.86      0.99      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 335.91287875175476 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.724761962890625e-05 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4441, Accuracy: 0.8682, F1 Micro: 0.9229, F1 Macro: 0.9182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2876, Accuracy: 0.9328, F1 Micro: 0.9592, F1 Macro: 0.9568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1981, Accuracy: 0.9507, F1 Micro: 0.9697, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1575, Accuracy: 0.9576, F1 Micro: 0.9739, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1252, Accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.9722\n",
      "Epoch 6/10, Train Loss: 0.1059, Accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0876, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0745, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0607, Accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9769\n",
      "Epoch 10/10, Train Loss: 0.0532, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.94      0.94       317\n",
      "       linen       0.95      0.97      0.96       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3576, Accuracy: 0.8516, F1 Micro: 0.8516, F1 Macro: 0.7932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2133, Accuracy: 0.8876, F1 Micro: 0.8876, F1 Macro: 0.855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1469, Accuracy: 0.8966, F1 Micro: 0.8966, F1 Macro: 0.8648\n",
      "Epoch 4/10, Train Loss: 0.1004, Accuracy: 0.8903, F1 Micro: 0.8903, F1 Macro: 0.853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.067, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8816\n",
      "Epoch 6/10, Train Loss: 0.054, Accuracy: 0.8957, F1 Micro: 0.8957, F1 Macro: 0.8606\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0504, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0286, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8875\n",
      "Epoch 9/10, Train Loss: 0.0306, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8839\n",
      "Epoch 10/10, Train Loss: 0.0264, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8769\n",
      "\n",
      "Sentiment analysis accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       786\n",
      "    positive       0.94      0.75      0.83       326\n",
      "\n",
      "    accuracy                           0.91      1112\n",
      "   macro avg       0.92      0.86      0.89      1112\n",
      "weighted avg       0.92      0.91      0.91      1112\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9592, F1 Micro: 0.9592, F1 Macro: 0.868\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.86      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.78      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.29      0.33         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.74      0.67      0.70       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.92      0.98      0.95        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.87       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.75      0.79       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.88      0.84        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.52      0.60        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.71      0.69        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.79      0.74      0.76       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 338.7234447002411 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.843971252441406e-05 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4372, Accuracy: 0.8705, F1 Micro: 0.924, F1 Macro: 0.9189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2725, Accuracy: 0.9352, F1 Micro: 0.9604, F1 Macro: 0.9577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1987, Accuracy: 0.9486, F1 Micro: 0.9685, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1521, Accuracy: 0.9542, F1 Micro: 0.9718, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1317, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9743\n",
      "Epoch 6/10, Train Loss: 0.1, Accuracy: 0.9615, F1 Micro: 0.976, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0886, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0704, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.976\n",
      "Epoch 9/10, Train Loss: 0.0613, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9746\n",
      "Epoch 10/10, Train Loss: 0.0527, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3546, Accuracy: 0.8633, F1 Micro: 0.8633, F1 Macro: 0.8159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2171, Accuracy: 0.9018, F1 Micro: 0.9018, F1 Macro: 0.8701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.146, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1034, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8833\n",
      "Epoch 5/10, Train Loss: 0.0809, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0619, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8827\n",
      "Epoch 7/10, Train Loss: 0.0407, Accuracy: 0.8972, F1 Micro: 0.8972, F1 Macro: 0.8699\n",
      "Epoch 8/10, Train Loss: 0.0386, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8785\n",
      "Epoch 9/10, Train Loss: 0.035, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8772\n",
      "Epoch 10/10, Train Loss: 0.0302, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8763\n",
      "\n",
      "Sentiment analysis accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.99      0.94       779\n",
      "    positive       0.96      0.72      0.82       311\n",
      "\n",
      "    accuracy                           0.91      1090\n",
      "   macro avg       0.93      0.86      0.88      1090\n",
      "weighted avg       0.92      0.91      0.91      1090\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.8593\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.17      0.29      0.21         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.86      0.63      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.66      0.63      0.63       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.94      0.94       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.89      0.86       162\n",
      "     neutral       0.95      0.96      0.95       387\n",
      "    positive       0.88      0.32      0.47        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.72      0.76       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 338.3688941001892 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 6.198883056640625e-05 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4426, Accuracy: 0.8797, F1 Micro: 0.9291, F1 Macro: 0.9249\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.268, Accuracy: 0.9359, F1 Micro: 0.9611, F1 Macro: 0.959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1917, Accuracy: 0.9469, F1 Micro: 0.9675, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1493, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1273, Accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.9741\n",
      "Epoch 6/10, Train Loss: 0.1028, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0873, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0733, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0614, Accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "Epoch 10/10, Train Loss: 0.0522, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3581, Accuracy: 0.8471, F1 Micro: 0.8471, F1 Macro: 0.7813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.208, Accuracy: 0.895, F1 Micro: 0.895, F1 Macro: 0.8638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1428, Accuracy: 0.8977, F1 Micro: 0.8977, F1 Macro: 0.8657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1149, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0718, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8855\n",
      "Epoch 6/10, Train Loss: 0.0543, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0434, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8842\n",
      "Epoch 8/10, Train Loss: 0.0495, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.8795\n",
      "Epoch 9/10, Train Loss: 0.034, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.02, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8881\n",
      "\n",
      "Sentiment analysis accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       782\n",
      "    positive       0.90      0.78      0.84       323\n",
      "\n",
      "    accuracy                           0.91      1105\n",
      "   macro avg       0.91      0.87      0.89      1105\n",
      "weighted avg       0.91      0.91      0.91      1105\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9571, F1 Micro: 0.9571, F1 Macro: 0.8653\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.29      0.36         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.83      0.76      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.68      0.71       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.91      0.88       200\n",
      "     neutral       0.95      0.90      0.93       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.57      0.59      0.58        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.80      0.80      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.89      0.96      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.38      0.54        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.65      1.00      0.79        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.79      0.77       571\n",
      "weighted avg       0.97      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 356.79058837890625 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 25\n",
      "Sampling duration: 0.017548561096191406 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4474, Accuracy: 0.8773, F1 Micro: 0.9282, F1 Macro: 0.925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2639, Accuracy: 0.9356, F1 Micro: 0.9607, F1 Macro: 0.9583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1883, Accuracy: 0.9517, F1 Micro: 0.9703, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1525, Accuracy: 0.9536, F1 Micro: 0.9715, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1278, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1039, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0846, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9756\n",
      "Epoch 8/10, Train Loss: 0.0708, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0615, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9761\n",
      "Epoch 10/10, Train Loss: 0.0523, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3411, Accuracy: 0.8696, F1 Micro: 0.8696, F1 Macro: 0.8271\n",
      "Epoch 2/10, Train Loss: 0.2222, Accuracy: 0.8532, F1 Micro: 0.8532, F1 Macro: 0.7888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.134, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0775, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0555, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.8941\n",
      "Epoch 6/10, Train Loss: 0.0404, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8859\n",
      "Epoch 7/10, Train Loss: 0.0366, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.882\n",
      "Epoch 8/10, Train Loss: 0.0254, Accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.8902\n",
      "Epoch 9/10, Train Loss: 0.0215, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.891\n",
      "Epoch 10/10, Train Loss: 0.02, Accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.8914\n",
      "\n",
      "Sentiment analysis accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.8941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       776\n",
      "    positive       0.95      0.76      0.84       321\n",
      "\n",
      "    accuracy                           0.92      1097\n",
      "   macro avg       0.93      0.87      0.89      1097\n",
      "weighted avg       0.92      0.92      0.91      1097\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.8858\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.89       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.77      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 351.90548825263977 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.821487426757812e-05 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4457, Accuracy: 0.8809, F1 Micro: 0.9299, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2658, Accuracy: 0.9368, F1 Micro: 0.9615, F1 Macro: 0.9593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1875, Accuracy: 0.9472, F1 Micro: 0.9677, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1509, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1208, Accuracy: 0.9608, F1 Micro: 0.9758, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1032, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0821, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0706, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9767\n",
      "Epoch 9/10, Train Loss: 0.0604, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Epoch 10/10, Train Loss: 0.0536, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3621, Accuracy: 0.8785, F1 Micro: 0.8785, F1 Macro: 0.8389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2017, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1334, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0841, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8795\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.063, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0414, Accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8907\n",
      "Epoch 7/10, Train Loss: 0.053, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8805\n",
      "Epoch 8/10, Train Loss: 0.0348, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8872\n",
      "Epoch 9/10, Train Loss: 0.0185, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8872\n",
      "Epoch 10/10, Train Loss: 0.0108, Accuracy: 0.9162, F1 Micro: 0.9162, F1 Macro: 0.8894\n",
      "\n",
      "Sentiment analysis accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       779\n",
      "    positive       0.94      0.75      0.84       307\n",
      "\n",
      "    accuracy                           0.92      1086\n",
      "   macro avg       0.93      0.87      0.89      1086\n",
      "weighted avg       0.92      0.92      0.91      1086\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9581, F1 Micro: 0.9581, F1 Macro: 0.8646\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.77      0.83       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.14      0.14      0.14         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.85      0.66      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.65      0.59      0.62       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.75      0.80       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.88        85\n",
      "     neutral       0.98      0.97      0.98       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.62      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 358.72929525375366 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.128715515136719e-05 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4395, Accuracy: 0.884, F1 Micro: 0.9319, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.258, Accuracy: 0.938, F1 Micro: 0.9623, F1 Macro: 0.9601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1894, Accuracy: 0.953, F1 Micro: 0.9711, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.149, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1217, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.104, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0837, Accuracy: 0.9653, F1 Micro: 0.9785, F1 Macro: 0.9767\n",
      "Epoch 8/10, Train Loss: 0.0679, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0608, Accuracy: 0.9667, F1 Micro: 0.9793, F1 Macro: 0.9774\n",
      "Epoch 10/10, Train Loss: 0.0492, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.9667, F1 Micro: 0.9793, F1 Macro: 0.9774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.95      0.95       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.338, Accuracy: 0.8595, F1 Micro: 0.8595, F1 Macro: 0.8043\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1888, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1367, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0856, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0705, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8862\n",
      "Epoch 6/10, Train Loss: 0.0527, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0412, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.887\n",
      "Epoch 8/10, Train Loss: 0.0254, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0335, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8899\n",
      "Epoch 10/10, Train Loss: 0.0186, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.883\n",
      "\n",
      "Sentiment analysis accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       784\n",
      "    positive       0.94      0.75      0.84       312\n",
      "\n",
      "    accuracy                           0.92      1096\n",
      "   macro avg       0.92      0.87      0.89      1096\n",
      "weighted avg       0.92      0.92      0.91      1096\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9587, F1 Micro: 0.9587, F1 Macro: 0.8576\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.94      0.87       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.61      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91       200\n",
      "     neutral       0.95      0.94      0.94       315\n",
      "    positive       0.90      0.96      0.93        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.71      0.45      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.84      0.76      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.89      0.96      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.41      0.56        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.62      0.94      0.74        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.78      0.76       571\n",
      "weighted avg       0.97      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.97      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 366.60467004776 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.843971252441406e-05 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4287, Accuracy: 0.8877, F1 Micro: 0.9338, F1 Macro: 0.9307\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2632, Accuracy: 0.938, F1 Micro: 0.9623, F1 Macro: 0.9601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1846, Accuracy: 0.9531, F1 Micro: 0.9712, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1474, Accuracy: 0.9583, F1 Micro: 0.9744, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1168, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1008, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9758\n",
      "Epoch 7/10, Train Loss: 0.082, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "Epoch 8/10, Train Loss: 0.0698, Accuracy: 0.9641, F1 Micro: 0.9776, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0579, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9763\n",
      "Epoch 10/10, Train Loss: 0.0504, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9739\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3546, Accuracy: 0.8673, F1 Micro: 0.8673, F1 Macro: 0.821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2059, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.866\n",
      "Epoch 3/10, Train Loss: 0.126, Accuracy: 0.8957, F1 Micro: 0.8957, F1 Macro: 0.8598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.088, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0506, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0397, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8813\n",
      "Epoch 7/10, Train Loss: 0.0327, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8813\n",
      "Epoch 8/10, Train Loss: 0.037, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8795\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0207, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8837\n",
      "Epoch 10/10, Train Loss: 0.0156, Accuracy: 0.9085, F1 Micro: 0.9085, F1 Macro: 0.8808\n",
      "\n",
      "Sentiment analysis accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8837\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       777\n",
      "    positive       0.95      0.73      0.83       316\n",
      "\n",
      "    accuracy                           0.91      1093\n",
      "   macro avg       0.92      0.86      0.88      1093\n",
      "weighted avg       0.91      0.91      0.91      1093\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9573, F1 Micro: 0.9573, F1 Macro: 0.8572\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.77      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.25      0.14      0.18         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.88      0.72      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.69      0.62      0.65       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.91      0.89       200\n",
      "     neutral       0.94      0.91      0.93       315\n",
      "    positive       0.92      0.98      0.95        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       0.78      0.32      0.45        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.71      0.75       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.87      0.85        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.55      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.79      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 371.44817423820496 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.62939453125e-05 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4336, Accuracy: 0.8892, F1 Micro: 0.9344, F1 Macro: 0.9313\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.255, Accuracy: 0.9394, F1 Micro: 0.9631, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1794, Accuracy: 0.9488, F1 Micro: 0.9685, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.142, Accuracy: 0.9566, F1 Micro: 0.9733, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1202, Accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0975, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0796, Accuracy: 0.9648, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0684, Accuracy: 0.9651, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0584, Accuracy: 0.9668, F1 Micro: 0.9794, F1 Macro: 0.9774\n",
      "Epoch 10/10, Train Loss: 0.0499, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.9668, F1 Micro: 0.9794, F1 Macro: 0.9774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3367, Accuracy: 0.8751, F1 Micro: 0.8751, F1 Macro: 0.8372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2133, Accuracy: 0.895, F1 Micro: 0.895, F1 Macro: 0.8603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1154, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8857\n",
      "Epoch 4/10, Train Loss: 0.0861, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8839\n",
      "Epoch 5/10, Train Loss: 0.0739, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0493, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0415, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8849\n",
      "Epoch 8/10, Train Loss: 0.0223, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8823\n",
      "Epoch 9/10, Train Loss: 0.0179, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8792\n",
      "Epoch 10/10, Train Loss: 0.0209, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8836\n",
      "\n",
      "Sentiment analysis accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       788\n",
      "    positive       0.94      0.74      0.83       317\n",
      "\n",
      "    accuracy                           0.91      1105\n",
      "   macro avg       0.92      0.86      0.88      1105\n",
      "weighted avg       0.91      0.91      0.91      1105\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.8819\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.87      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.95      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.25      0.14      0.18         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.68      0.60      0.64       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90       200\n",
      "     neutral       0.96      0.92      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.74      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 378.78979754447937 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.295608520507812e-05 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4301, Accuracy: 0.892, F1 Micro: 0.936, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2503, Accuracy: 0.9411, F1 Micro: 0.964, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1745, Accuracy: 0.9542, F1 Micro: 0.9718, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1391, Accuracy: 0.9564, F1 Micro: 0.9731, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1194, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.096, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.975\n",
      "Epoch 7/10, Train Loss: 0.079, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0664, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9752\n",
      "Epoch 9/10, Train Loss: 0.0562, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0468, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.93       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3569, Accuracy: 0.8632, F1 Micro: 0.8632, F1 Macro: 0.8194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1863, Accuracy: 0.8956, F1 Micro: 0.8956, F1 Macro: 0.8673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1286, Accuracy: 0.8983, F1 Micro: 0.8983, F1 Macro: 0.8662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.106, Accuracy: 0.8983, F1 Micro: 0.8983, F1 Macro: 0.8677\n",
      "Epoch 5/10, Train Loss: 0.0656, Accuracy: 0.8965, F1 Micro: 0.8965, F1 Macro: 0.8638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0595, Accuracy: 0.9019, F1 Micro: 0.9019, F1 Macro: 0.873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0479, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8752\n",
      "Epoch 8/10, Train Loss: 0.0291, Accuracy: 0.8956, F1 Micro: 0.8956, F1 Macro: 0.8609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0304, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8821\n",
      "Epoch 10/10, Train Loss: 0.014, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8782\n",
      "\n",
      "Sentiment analysis accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8821\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       784\n",
      "    positive       0.93      0.74      0.83       327\n",
      "\n",
      "    accuracy                           0.91      1111\n",
      "   macro avg       0.92      0.86      0.88      1111\n",
      "weighted avg       0.91      0.91      0.90      1111\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.8619\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.88      0.72      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.57      0.59       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.73      0.77       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.87      0.86        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 394.5160126686096 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 36\n",
      "Sampling duration: 0.019915103912353516 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4282, Accuracy: 0.8934, F1 Micro: 0.9368, F1 Macro: 0.9335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2438, Accuracy: 0.942, F1 Micro: 0.9646, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1769, Accuracy: 0.9509, F1 Micro: 0.9699, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1352, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1128, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0886, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0771, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9763\n",
      "Epoch 8/10, Train Loss: 0.064, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.976\n",
      "Epoch 9/10, Train Loss: 0.0552, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0443, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.95      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3373, Accuracy: 0.8702, F1 Micro: 0.8702, F1 Macro: 0.8244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1901, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.8571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.125, Accuracy: 0.9002, F1 Micro: 0.9002, F1 Macro: 0.8683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0885, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0768, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0573, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8819\n",
      "Epoch 7/10, Train Loss: 0.0372, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8799\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0306, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8883\n",
      "Epoch 9/10, Train Loss: 0.025, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.883\n",
      "Epoch 10/10, Train Loss: 0.0261, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8778\n",
      "\n",
      "Sentiment analysis accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       784\n",
      "    positive       0.95      0.74      0.83       318\n",
      "\n",
      "    accuracy                           0.91      1102\n",
      "   macro avg       0.93      0.86      0.89      1102\n",
      "weighted avg       0.92      0.91      0.91      1102\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.8669\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.85      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.94      0.94       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.57      0.36      0.44        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.79      0.72      0.75       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 391.5032215118408 s\n",
      "Total runtime: 7658.515485286713 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc9517",
   "metadata": {
    "papermill": {
     "duration": 0.011328,
     "end_time": "2025-03-31T11:40:20.200660",
     "exception": false,
     "start_time": "2025-03-31T11:40:20.189332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05f5511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6846, Accuracy: 0.7771, F1 Micro: 0.873, F1 Macro: 0.8661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5356, Accuracy: 0.8012, F1 Micro: 0.8896, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4856, Accuracy: 0.8019, F1 Micro: 0.8899, F1 Macro: 0.8853\n",
      "Epoch 4/10, Train Loss: 0.4451, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Epoch 5/10, Train Loss: 0.447, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4104, Accuracy: 0.8038, F1 Micro: 0.8908, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4062, Accuracy: 0.8099, F1 Micro: 0.893, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4023, Accuracy: 0.8189, F1 Micro: 0.8974, F1 Macro: 0.8906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3668, Accuracy: 0.8349, F1 Micro: 0.9047, F1 Macro: 0.8978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3363, Accuracy: 0.8422, F1 Micro: 0.9091, F1 Macro: 0.9034\n",
      "\n",
      "Aspect detection accuracy: 0.8422, F1 Micro: 0.9091, F1 Macro: 0.9034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.80      1.00      0.89       462\n",
      "   air_panas       0.83      1.00      0.91       480\n",
      "         bau       0.86      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.66      0.86      0.75       317\n",
      "       linen       0.73      0.99      0.84       392\n",
      "     service       0.92      0.96      0.94       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.91      1.00      0.95       498\n",
      "\n",
      "   micro avg       0.84      0.99      0.91      4614\n",
      "   macro avg       0.84      0.98      0.90      4614\n",
      "weighted avg       0.85      0.99      0.91      4614\n",
      " samples avg       0.84      0.99      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6158, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4961, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4198, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4426, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3147, Accuracy: 0.7391, F1 Micro: 0.7391, F1 Macro: 0.6783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2361, Accuracy: 0.7636, F1 Micro: 0.7636, F1 Macro: 0.7349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2395, Accuracy: 0.7663, F1 Micro: 0.7663, F1 Macro: 0.7452\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2328, Accuracy: 0.7935, F1 Micro: 0.7935, F1 Macro: 0.781\n",
      "Epoch 9/10, Train Loss: 0.1405, Accuracy: 0.7799, F1 Micro: 0.7799, F1 Macro: 0.7604\n",
      "Epoch 10/10, Train Loss: 0.0903, Accuracy: 0.7745, F1 Micro: 0.7745, F1 Macro: 0.7461\n",
      "\n",
      "Sentiment analysis accuracy: 0.7935, F1 Micro: 0.7935, F1 Macro: 0.781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.84      0.83       226\n",
      "    positive       0.74      0.72      0.73       142\n",
      "\n",
      "    accuracy                           0.79       368\n",
      "   macro avg       0.78      0.78      0.78       368\n",
      "weighted avg       0.79      0.79      0.79       368\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8352, F1 Micro: 0.8352, F1 Macro: 0.4067\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        97\n",
      "     neutral       0.80      1.00      0.89       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.80       571\n",
      "   macro avg       0.27      0.33      0.30       571\n",
      "weighted avg       0.65      0.80      0.72       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.28      0.33      0.30       571\n",
      "weighted avg       0.69      0.83      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.03      0.05        78\n",
      "     neutral       0.86      1.00      0.93       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.51      0.34      0.32       571\n",
      "weighted avg       0.83      0.86      0.80       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.39      0.49       200\n",
      "     neutral       0.66      0.86      0.75       315\n",
      "    positive       0.23      0.18      0.20        56\n",
      "\n",
      "    accuracy                           0.63       571\n",
      "   macro avg       0.52      0.48      0.48       571\n",
      "weighted avg       0.62      0.63      0.60       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.23      0.37       162\n",
      "     neutral       0.72      0.99      0.84       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.74       571\n",
      "   macro avg       0.55      0.41      0.40       571\n",
      "weighted avg       0.75      0.74      0.67       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.69      0.74        85\n",
      "     neutral       0.92      0.96      0.94       418\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.36      0.52        74\n",
      "     neutral       0.91      1.00      0.95       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.61      0.45      0.49       571\n",
      "weighted avg       0.91      0.91      0.89       571\n",
      "\n",
      "Total train time: 78.99207925796509 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 215\n",
      "Sampling duration: 0.0001952648162841797 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5863, Accuracy: 0.8024, F1 Micro: 0.89, F1 Macro: 0.8852\n",
      "Epoch 2/10, Train Loss: 0.4496, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4409, Accuracy: 0.8095, F1 Micro: 0.8929, F1 Macro: 0.8867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4132, Accuracy: 0.8345, F1 Micro: 0.9055, F1 Macro: 0.8993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3585, Accuracy: 0.8674, F1 Micro: 0.9227, F1 Macro: 0.9172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3142, Accuracy: 0.8884, F1 Micro: 0.9333, F1 Macro: 0.9267\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2689, Accuracy: 0.8965, F1 Micro: 0.938, F1 Macro: 0.9332\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.234, Accuracy: 0.9042, F1 Micro: 0.9426, F1 Macro: 0.9389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2126, Accuracy: 0.9148, F1 Micro: 0.9487, F1 Macro: 0.9454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1957, Accuracy: 0.9259, F1 Micro: 0.9548, F1 Macro: 0.9512\n",
      "\n",
      "Aspect detection accuracy: 0.9259, F1 Micro: 0.9548, F1 Macro: 0.9512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.94      1.00      0.97       480\n",
      "         bau       0.94      0.98      0.96       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.90      0.85      0.88       317\n",
      "       linen       0.86      0.96      0.90       392\n",
      "     service       0.94      0.96      0.95       423\n",
      "sunrise_meal       0.93      1.00      0.96       530\n",
      "          tv       0.96      1.00      0.98       516\n",
      "        wifi       0.98      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.93      0.98      0.95      4614\n",
      "   macro avg       0.93      0.97      0.95      4614\n",
      "weighted avg       0.93      0.98      0.95      4614\n",
      " samples avg       0.93      0.98      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.498, Accuracy: 0.7218, F1 Micro: 0.7218, F1 Macro: 0.4192\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3627, Accuracy: 0.8258, F1 Micro: 0.8258, F1 Macro: 0.7738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2923, Accuracy: 0.839, F1 Micro: 0.839, F1 Macro: 0.7836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2102, Accuracy: 0.8434, F1 Micro: 0.8434, F1 Macro: 0.7982\n",
      "Epoch 5/10, Train Loss: 0.1889, Accuracy: 0.8412, F1 Micro: 0.8412, F1 Macro: 0.7948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1253, Accuracy: 0.8554, F1 Micro: 0.8554, F1 Macro: 0.8082\n",
      "Epoch 7/10, Train Loss: 0.1119, Accuracy: 0.8445, F1 Micro: 0.8445, F1 Macro: 0.8045\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0865, Accuracy: 0.8631, F1 Micro: 0.8631, F1 Macro: 0.8143\n",
      "Epoch 9/10, Train Loss: 0.0795, Accuracy: 0.8598, F1 Micro: 0.8598, F1 Macro: 0.8014\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0507, Accuracy: 0.8686, F1 Micro: 0.8686, F1 Macro: 0.8138\n",
      "\n",
      "Sentiment analysis accuracy: 0.8686, F1 Micro: 0.8686, F1 Macro: 0.8138\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.98      0.91       659\n",
      "    positive       0.91      0.59      0.71       254\n",
      "\n",
      "    accuracy                           0.87       913\n",
      "   macro avg       0.88      0.78      0.81       913\n",
      "weighted avg       0.87      0.87      0.86       913\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.7015\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.92      0.92        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.92      0.73      0.81        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.94      0.88      0.91       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.70      0.79        86\n",
      "     neutral       0.94      1.00      0.97       475\n",
      "    positive       1.00      0.40      0.57        10\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.95      0.70      0.78       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.63      0.72        78\n",
      "     neutral       0.94      0.98      0.96       491\n",
      "    positive       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.76      0.70      0.73       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.81      0.81       200\n",
      "     neutral       0.90      0.85      0.88       315\n",
      "    positive       0.65      0.86      0.74        56\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.79      0.84      0.81       571\n",
      "weighted avg       0.85      0.84      0.84       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.70      0.77       162\n",
      "     neutral       0.85      0.96      0.90       387\n",
      "    positive       0.75      0.14      0.23        22\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.82      0.60      0.63       571\n",
      "weighted avg       0.85      0.85      0.84       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.80      0.79        85\n",
      "     neutral       0.94      0.96      0.95       418\n",
      "    positive       0.90      0.76      0.83        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.84      0.85       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.10      0.19        29\n",
      "     neutral       0.93      1.00      0.96       525\n",
      "    positive       0.62      0.29      0.40        17\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.85      0.46      0.52       571\n",
      "weighted avg       0.93      0.93      0.91       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.65      0.75        54\n",
      "     neutral       0.96      1.00      0.98       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.62      0.55      0.58       571\n",
      "weighted avg       0.94      0.95      0.95       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.88      0.92        74\n",
      "     neutral       0.98      1.00      0.99       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.85      0.90       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 122.85441827774048 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 193\n",
      "Sampling duration: 0.00018715858459472656 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.546, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4559, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.403, Accuracy: 0.8464, F1 Micro: 0.9116, F1 Macro: 0.9059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3435, Accuracy: 0.8845, F1 Micro: 0.9311, F1 Macro: 0.924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2852, Accuracy: 0.9057, F1 Micro: 0.9435, F1 Macro: 0.9392\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2242, Accuracy: 0.9271, F1 Micro: 0.9559, F1 Macro: 0.9531\n",
      "Epoch 7/10, Train Loss: 0.201, Accuracy: 0.9269, F1 Micro: 0.9557, F1 Macro: 0.9532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1791, Accuracy: 0.9351, F1 Micro: 0.9604, F1 Macro: 0.9579\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1512, Accuracy: 0.9392, F1 Micro: 0.963, F1 Macro: 0.9607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1395, Accuracy: 0.941, F1 Micro: 0.964, F1 Macro: 0.9616\n",
      "\n",
      "Aspect detection accuracy: 0.941, F1 Micro: 0.964, F1 Macro: 0.9616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.95      1.00      0.97       480\n",
      "         bau       0.95      0.97      0.96       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.89      0.93      0.91       317\n",
      "       linen       0.87      0.98      0.92       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.96      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.94      0.99      0.96      4614\n",
      "   macro avg       0.94      0.98      0.96      4614\n",
      "weighted avg       0.95      0.99      0.96      4614\n",
      " samples avg       0.94      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4783, Accuracy: 0.7527, F1 Micro: 0.7527, F1 Macro: 0.4294\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.297, Accuracy: 0.8266, F1 Micro: 0.8266, F1 Macro: 0.7697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1749, Accuracy: 0.8694, F1 Micro: 0.8694, F1 Macro: 0.8107\n",
      "Epoch 4/10, Train Loss: 0.1477, Accuracy: 0.8683, F1 Micro: 0.8683, F1 Macro: 0.8054\n",
      "Epoch 5/10, Train Loss: 0.1337, Accuracy: 0.8619, F1 Micro: 0.8619, F1 Macro: 0.7766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0759, Accuracy: 0.8897, F1 Micro: 0.8897, F1 Macro: 0.8365\n",
      "Epoch 7/10, Train Loss: 0.0675, Accuracy: 0.8865, F1 Micro: 0.8865, F1 Macro: 0.8295\n",
      "Epoch 8/10, Train Loss: 0.0612, Accuracy: 0.8737, F1 Micro: 0.8737, F1 Macro: 0.8051\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0711, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.8404\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0484, Accuracy: 0.8961, F1 Micro: 0.8961, F1 Macro: 0.8482\n",
      "\n",
      "Sentiment analysis accuracy: 0.8961, F1 Micro: 0.8961, F1 Macro: 0.8482\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       703\n",
      "    positive       0.88      0.68      0.76       231\n",
      "\n",
      "    accuracy                           0.90       934\n",
      "   macro avg       0.89      0.82      0.85       934\n",
      "weighted avg       0.89      0.90      0.89       934\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.7637\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.92      0.92        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.91      0.67      0.77        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.94      0.86      0.89       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.73      0.82        86\n",
      "     neutral       0.95      1.00      0.97       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.85      0.71      0.77       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.71      0.74        78\n",
      "     neutral       0.95      0.97      0.96       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.80      0.89      0.83       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.85       200\n",
      "     neutral       0.89      0.93      0.91       315\n",
      "    positive       0.83      0.86      0.84        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.87      0.87      0.87       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.72      0.80       162\n",
      "     neutral       0.87      0.98      0.92       387\n",
      "    positive       0.50      0.14      0.21        22\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.76      0.61      0.64       571\n",
      "weighted avg       0.86      0.87      0.86       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.78      0.84        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.83      0.93      0.88        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.89      0.89       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.31      0.46        29\n",
      "     neutral       0.96      1.00      0.98       525\n",
      "    positive       0.79      0.65      0.71        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.88      0.65      0.72       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.70      0.73       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 148.38290357589722 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 174\n",
      "Sampling duration: 0.00013065338134765625 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5221, Accuracy: 0.8038, F1 Micro: 0.8908, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4434, Accuracy: 0.8205, F1 Micro: 0.8981, F1 Macro: 0.8911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3633, Accuracy: 0.884, F1 Micro: 0.9317, F1 Macro: 0.9269\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2841, Accuracy: 0.9064, F1 Micro: 0.944, F1 Macro: 0.9403\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2361, Accuracy: 0.9309, F1 Micro: 0.9579, F1 Macro: 0.9551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2006, Accuracy: 0.9366, F1 Micro: 0.9611, F1 Macro: 0.9581\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1758, Accuracy: 0.9436, F1 Micro: 0.9654, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1526, Accuracy: 0.9441, F1 Micro: 0.9657, F1 Macro: 0.9629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1305, Accuracy: 0.9455, F1 Micro: 0.9666, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1148, Accuracy: 0.9484, F1 Micro: 0.9683, F1 Macro: 0.966\n",
      "\n",
      "Aspect detection accuracy: 0.9484, F1 Micro: 0.9683, F1 Macro: 0.966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.95      0.97      0.96       496\n",
      "     general       0.89      0.99      0.94       500\n",
      "  kebersihan       0.93      0.91      0.92       317\n",
      "       linen       0.90      0.96      0.93       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.96      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.97      4614\n",
      "weighted avg       0.95      0.98      0.97      4614\n",
      " samples avg       0.95      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4425, Accuracy: 0.8044, F1 Micro: 0.8044, F1 Macro: 0.7454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2713, Accuracy: 0.8546, F1 Micro: 0.8546, F1 Macro: 0.8067\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2077, Accuracy: 0.8616, F1 Micro: 0.8616, F1 Macro: 0.8096\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1479, Accuracy: 0.8786, F1 Micro: 0.8786, F1 Macro: 0.8244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1316, Accuracy: 0.8806, F1 Micro: 0.8806, F1 Macro: 0.8306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.084, Accuracy: 0.8837, F1 Micro: 0.8837, F1 Macro: 0.8346\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.056, Accuracy: 0.8897, F1 Micro: 0.8897, F1 Macro: 0.846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0608, Accuracy: 0.8907, F1 Micro: 0.8907, F1 Macro: 0.8476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0284, Accuracy: 0.8927, F1 Micro: 0.8927, F1 Macro: 0.8513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0413, Accuracy: 0.8927, F1 Micro: 0.8927, F1 Macro: 0.8481\n",
      "\n",
      "Sentiment analysis accuracy: 0.8927, F1 Micro: 0.8927, F1 Macro: 0.8481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93       728\n",
      "    positive       0.93      0.65      0.77       269\n",
      "\n",
      "    accuracy                           0.89       997\n",
      "   macro avg       0.91      0.82      0.85       997\n",
      "weighted avg       0.90      0.89      0.89       997\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9413, F1 Micro: 0.9413, F1 Macro: 0.7949\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.93      0.94        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.92      0.80      0.86        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.91      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        86\n",
      "     neutral       0.97      1.00      0.98       475\n",
      "    positive       0.75      0.30      0.43        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.88      0.71      0.76       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.68      0.74        78\n",
      "     neutral       0.95      0.97      0.96       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.72      0.79       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.89      0.99      0.94       496\n",
      "    positive       0.87      0.19      0.31        68\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.58      0.40      0.42       571\n",
      "weighted avg       0.87      0.89      0.85       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86       200\n",
      "     neutral       0.93      0.91      0.92       315\n",
      "    positive       0.84      0.93      0.88        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.88      0.90      0.89       571\n",
      "weighted avg       0.90      0.89      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.78      0.81       162\n",
      "     neutral       0.90      0.97      0.93       387\n",
      "    positive       0.86      0.27      0.41        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.87      0.67      0.72       571\n",
      "weighted avg       0.88      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.24      0.34        29\n",
      "     neutral       0.96      1.00      0.98       525\n",
      "    positive       0.67      0.47      0.55        17\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.74      0.57      0.62       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.86      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 182.71081590652466 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 156\n",
      "Sampling duration: 0.0001327991485595703 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5195, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4162, Accuracy: 0.8446, F1 Micro: 0.911, F1 Macro: 0.9055\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3229, Accuracy: 0.899, F1 Micro: 0.9396, F1 Macro: 0.9351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2476, Accuracy: 0.9253, F1 Micro: 0.9547, F1 Macro: 0.9516\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2001, Accuracy: 0.9366, F1 Micro: 0.9614, F1 Macro: 0.959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1694, Accuracy: 0.9458, F1 Micro: 0.9668, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1484, Accuracy: 0.9484, F1 Micro: 0.9682, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1308, Accuracy: 0.9526, F1 Micro: 0.9708, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1085, Accuracy: 0.9535, F1 Micro: 0.9714, F1 Macro: 0.9696\n",
      "Epoch 10/10, Train Loss: 0.0961, Accuracy: 0.9535, F1 Micro: 0.9713, F1 Macro: 0.9691\n",
      "\n",
      "Aspect detection accuracy: 0.9535, F1 Micro: 0.9714, F1 Macro: 0.9696\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.89      1.00      0.94       500\n",
      "  kebersihan       0.91      0.95      0.93       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.96      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.99      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4246, Accuracy: 0.8368, F1 Micro: 0.8368, F1 Macro: 0.7799\n",
      "Epoch 2/10, Train Loss: 0.2162, Accuracy: 0.791, F1 Micro: 0.791, F1 Macro: 0.6097\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2106, Accuracy: 0.8706, F1 Micro: 0.8706, F1 Macro: 0.8044\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1483, Accuracy: 0.8826, F1 Micro: 0.8826, F1 Macro: 0.8272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1218, Accuracy: 0.8965, F1 Micro: 0.8965, F1 Macro: 0.8577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0723, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8598\n",
      "Epoch 7/10, Train Loss: 0.0653, Accuracy: 0.8905, F1 Micro: 0.8905, F1 Macro: 0.8384\n",
      "Epoch 8/10, Train Loss: 0.077, Accuracy: 0.8975, F1 Micro: 0.8975, F1 Macro: 0.8546\n",
      "Epoch 9/10, Train Loss: 0.0557, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8608\n",
      "Epoch 10/10, Train Loss: 0.0291, Accuracy: 0.8905, F1 Micro: 0.8905, F1 Macro: 0.8384\n",
      "\n",
      "Sentiment analysis accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8598\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       743\n",
      "    positive       0.92      0.68      0.78       262\n",
      "\n",
      "    accuracy                           0.90      1005\n",
      "   macro avg       0.91      0.83      0.86      1005\n",
      "weighted avg       0.90      0.90      0.90      1005\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9443, F1 Micro: 0.9443, F1 Macro: 0.7989\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.83      0.86        86\n",
      "     neutral       0.97      1.00      0.98       475\n",
      "    positive       0.67      0.20      0.31        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.67      0.72       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.79      0.79        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.90      0.99      0.94       496\n",
      "    positive       0.89      0.24      0.37        68\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.60      0.41      0.44       571\n",
      "weighted avg       0.89      0.89      0.86       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88       200\n",
      "     neutral       0.92      0.94      0.93       315\n",
      "    positive       0.88      0.89      0.88        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.90      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.86      0.83       162\n",
      "     neutral       0.93      0.95      0.94       387\n",
      "    positive       0.75      0.14      0.23        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.83      0.65      0.67       571\n",
      "weighted avg       0.89      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.86      0.82        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.95      0.81      0.87        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.88      0.89       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.52      0.58        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.53      0.64        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.68      0.74       571\n",
      "weighted avg       0.95      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.82      0.87       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 191.51517963409424 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 141\n",
      "Sampling duration: 0.00012350082397460938 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5089, Accuracy: 0.8043, F1 Micro: 0.8911, F1 Macro: 0.8865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4003, Accuracy: 0.8786, F1 Micro: 0.9286, F1 Macro: 0.9235\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.303, Accuracy: 0.9054, F1 Micro: 0.9435, F1 Macro: 0.94\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.235, Accuracy: 0.9323, F1 Micro: 0.959, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.191, Accuracy: 0.9425, F1 Micro: 0.965, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1646, Accuracy: 0.9484, F1 Micro: 0.9684, F1 Macro: 0.9663\n",
      "Epoch 7/10, Train Loss: 0.1378, Accuracy: 0.9483, F1 Micro: 0.9682, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1178, Accuracy: 0.9516, F1 Micro: 0.9702, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1003, Accuracy: 0.9543, F1 Micro: 0.9719, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.089, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9731\n",
      "\n",
      "Aspect detection accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.91      0.96      0.93       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4159, Accuracy: 0.8467, F1 Micro: 0.8467, F1 Macro: 0.8057\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2349, Accuracy: 0.8659, F1 Micro: 0.8659, F1 Macro: 0.8189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2092, Accuracy: 0.886, F1 Micro: 0.886, F1 Macro: 0.847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1576, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8683\n",
      "Epoch 5/10, Train Loss: 0.107, Accuracy: 0.8956, F1 Micro: 0.8956, F1 Macro: 0.8695\n",
      "Epoch 6/10, Train Loss: 0.1142, Accuracy: 0.8966, F1 Micro: 0.8966, F1 Macro: 0.8591\n",
      "Epoch 7/10, Train Loss: 0.0673, Accuracy: 0.8994, F1 Micro: 0.8994, F1 Macro: 0.8657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0537, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0515, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8761\n",
      "Epoch 10/10, Train Loss: 0.0358, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8687\n",
      "\n",
      "Sentiment analysis accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       751\n",
      "    positive       0.91      0.74      0.82       293\n",
      "\n",
      "    accuracy                           0.91      1044\n",
      "   macro avg       0.91      0.85      0.88      1044\n",
      "weighted avg       0.91      0.91      0.90      1044\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9517, F1 Micro: 0.9517, F1 Macro: 0.7865\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.91      0.67      0.77        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.87      0.90       571\n",
      "weighted avg       0.98      0.98      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.90      0.88        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.67      0.20      0.31        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.69      0.72       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.78      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.75      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.91      0.63      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.79      0.59      0.64       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.84      0.88       200\n",
      "     neutral       0.91      0.96      0.93       315\n",
      "    positive       0.88      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.90      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.85       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.69      0.41      0.51        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.83      0.73      0.77       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.85        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.96      0.94      0.95        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.38      0.54        29\n",
      "     neutral       0.97      1.00      0.99       525\n",
      "    positive       0.62      0.76      0.68        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.71      0.74       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.92        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.76      0.80       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.97      0.95        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.64      0.66      0.65       571\n",
      "weighted avg       0.98      0.99      0.99       571\n",
      "\n",
      "Total train time: 213.83717131614685 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 127\n",
      "Sampling duration: 0.00012302398681640625 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4981, Accuracy: 0.8016, F1 Micro: 0.8898, F1 Macro: 0.8854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3858, Accuracy: 0.8856, F1 Micro: 0.9325, F1 Macro: 0.9283\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2863, Accuracy: 0.9198, F1 Micro: 0.9512, F1 Macro: 0.9471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2196, Accuracy: 0.9408, F1 Micro: 0.9638, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.183, Accuracy: 0.9441, F1 Micro: 0.9658, F1 Macro: 0.9636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1507, Accuracy: 0.9481, F1 Micro: 0.9681, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1265, Accuracy: 0.9516, F1 Micro: 0.9702, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1084, Accuracy: 0.958, F1 Micro: 0.9741, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0942, Accuracy: 0.9582, F1 Micro: 0.9741, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0842, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9733\n",
      "\n",
      "Aspect detection accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.92      0.94      0.93       317\n",
      "       linen       0.93      0.95      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4017, Accuracy: 0.8516, F1 Micro: 0.8516, F1 Macro: 0.7969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2251, Accuracy: 0.8648, F1 Micro: 0.8648, F1 Macro: 0.8349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1801, Accuracy: 0.8948, F1 Micro: 0.8948, F1 Macro: 0.8627\n",
      "Epoch 4/10, Train Loss: 0.1235, Accuracy: 0.8873, F1 Micro: 0.8873, F1 Macro: 0.8546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1012, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8799\n",
      "Epoch 6/10, Train Loss: 0.0564, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8722\n",
      "Epoch 7/10, Train Loss: 0.0573, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8764\n",
      "Epoch 8/10, Train Loss: 0.0439, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8725\n",
      "Epoch 9/10, Train Loss: 0.0511, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8777\n",
      "Epoch 10/10, Train Loss: 0.0385, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8685\n",
      "\n",
      "Sentiment analysis accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       762\n",
      "    positive       0.91      0.75      0.82       303\n",
      "\n",
      "    accuracy                           0.91      1065\n",
      "   macro avg       0.91      0.86      0.88      1065\n",
      "weighted avg       0.91      0.91      0.90      1065\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9527, F1 Micro: 0.9527, F1 Macro: 0.8256\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.60      0.30      0.40        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.72      0.76       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.77      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.84      0.63      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.54      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88       200\n",
      "     neutral       0.92      0.94      0.93       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.91      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.87      0.84       162\n",
      "     neutral       0.93      0.95      0.94       387\n",
      "    positive       1.00      0.09      0.17        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.91      0.64      0.65       571\n",
      "weighted avg       0.90      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.88      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.90      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.41      0.55        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.62      0.76      0.68        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.80      0.73      0.74       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 230.25746297836304 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 114\n",
      "Sampling duration: 0.0001919269561767578 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4958, Accuracy: 0.8095, F1 Micro: 0.8902, F1 Macro: 0.8728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.37, Accuracy: 0.8979, F1 Micro: 0.9388, F1 Macro: 0.9334\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2621, Accuracy: 0.9309, F1 Micro: 0.9581, F1 Macro: 0.9556\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1952, Accuracy: 0.9444, F1 Micro: 0.9661, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1698, Accuracy: 0.9464, F1 Micro: 0.9671, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1363, Accuracy: 0.9533, F1 Micro: 0.9712, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1188, Accuracy: 0.9578, F1 Micro: 0.974, F1 Macro: 0.9718\n",
      "Epoch 8/10, Train Loss: 0.0982, Accuracy: 0.9573, F1 Micro: 0.9737, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0883, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9731\n",
      "Epoch 10/10, Train Loss: 0.0752, Accuracy: 0.9601, F1 Micro: 0.9752, F1 Macro: 0.973\n",
      "\n",
      "Aspect detection accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.94      0.95      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       0.99      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4035, Accuracy: 0.8203, F1 Micro: 0.8203, F1 Macro: 0.7309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2287, Accuracy: 0.8743, F1 Micro: 0.8743, F1 Macro: 0.836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1888, Accuracy: 0.8818, F1 Micro: 0.8818, F1 Macro: 0.8411\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1233, Accuracy: 0.8966, F1 Micro: 0.8966, F1 Macro: 0.867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1073, Accuracy: 0.9022, F1 Micro: 0.9022, F1 Macro: 0.8742\n",
      "Epoch 6/10, Train Loss: 0.09, Accuracy: 0.8948, F1 Micro: 0.8948, F1 Macro: 0.8601\n",
      "Epoch 7/10, Train Loss: 0.0692, Accuracy: 0.8966, F1 Micro: 0.8966, F1 Macro: 0.8625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0453, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.8765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.047, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.879\n",
      "Epoch 10/10, Train Loss: 0.0479, Accuracy: 0.9041, F1 Micro: 0.9041, F1 Macro: 0.8737\n",
      "\n",
      "Sentiment analysis accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94       767\n",
      "    positive       0.90      0.76      0.82       307\n",
      "\n",
      "    accuracy                           0.91      1074\n",
      "   macro avg       0.90      0.86      0.88      1074\n",
      "weighted avg       0.91      0.91      0.90      1074\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9543, F1 Micro: 0.9543, F1 Macro: 0.8441\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.80      0.40      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.90      0.76      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.20      0.14      0.17         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.88      0.63      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.67      0.59      0.62       571\n",
      "weighted avg       0.93      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.89      0.86       162\n",
      "     neutral       0.94      0.95      0.94       387\n",
      "    positive       0.75      0.27      0.40        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.84      0.70      0.74       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.89      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.48      0.61        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.82      0.74        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.77      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.89      0.93       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 246.38198065757751 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 103\n",
      "Sampling duration: 0.00012302398681640625 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4921, Accuracy: 0.8073, F1 Micro: 0.8926, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3484, Accuracy: 0.8957, F1 Micro: 0.9382, F1 Macro: 0.9342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.248, Accuracy: 0.9356, F1 Micro: 0.9608, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1951, Accuracy: 0.9458, F1 Micro: 0.9669, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1585, Accuracy: 0.9535, F1 Micro: 0.9714, F1 Macro: 0.9693\n",
      "Epoch 6/10, Train Loss: 0.1327, Accuracy: 0.9509, F1 Micro: 0.9699, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.114, Accuracy: 0.9587, F1 Micro: 0.9745, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0957, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0812, Accuracy: 0.9622, F1 Micro: 0.9766, F1 Macro: 0.9744\n",
      "Epoch 10/10, Train Loss: 0.0725, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9733\n",
      "\n",
      "Aspect detection accuracy: 0.9622, F1 Micro: 0.9766, F1 Macro: 0.9744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.99      0.97       496\n",
      "     general       0.93      0.99      0.96       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3911, Accuracy: 0.8615, F1 Micro: 0.8615, F1 Macro: 0.8102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.228, Accuracy: 0.8738, F1 Micro: 0.8738, F1 Macro: 0.8229\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1604, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8696\n",
      "Epoch 4/10, Train Loss: 0.1179, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0954, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.888\n",
      "Epoch 6/10, Train Loss: 0.0643, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8805\n",
      "Epoch 7/10, Train Loss: 0.0655, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8827\n",
      "Epoch 8/10, Train Loss: 0.0377, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8798\n",
      "Epoch 9/10, Train Loss: 0.0474, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0267, Accuracy: 0.9165, F1 Micro: 0.9165, F1 Macro: 0.8883\n",
      "\n",
      "Sentiment analysis accuracy: 0.9165, F1 Micro: 0.9165, F1 Macro: 0.8883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       764\n",
      "    positive       0.93      0.75      0.83       290\n",
      "\n",
      "    accuracy                           0.92      1054\n",
      "   macro avg       0.92      0.87      0.89      1054\n",
      "weighted avg       0.92      0.92      0.91      1054\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9559, F1 Micro: 0.9559, F1 Macro: 0.8518\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.82      0.93      0.87        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.95      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.93      0.54      0.69        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.62      0.51      0.55       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.88       200\n",
      "     neutral       0.93      0.92      0.93       315\n",
      "    positive       0.83      0.96      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.75      0.79       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 258.2450358867645 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 62\n",
      "Sampling duration: 0.01787567138671875 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4825, Accuracy: 0.803, F1 Micro: 0.8905, F1 Macro: 0.886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3407, Accuracy: 0.9031, F1 Micro: 0.9422, F1 Macro: 0.9386\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2401, Accuracy: 0.9344, F1 Micro: 0.9601, F1 Macro: 0.9577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1876, Accuracy: 0.9458, F1 Micro: 0.9669, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1535, Accuracy: 0.9535, F1 Micro: 0.9713, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1281, Accuracy: 0.9536, F1 Micro: 0.9714, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1101, Accuracy: 0.9545, F1 Micro: 0.972, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0968, Accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0802, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0689, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.90      0.97      0.93       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.399, Accuracy: 0.864, F1 Micro: 0.864, F1 Macro: 0.8242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2081, Accuracy: 0.8912, F1 Micro: 0.8912, F1 Macro: 0.8608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1601, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.115, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8883\n",
      "Epoch 5/10, Train Loss: 0.0903, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.081, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.8934\n",
      "Epoch 7/10, Train Loss: 0.0418, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0486, Accuracy: 0.9193, F1 Micro: 0.9193, F1 Macro: 0.8954\n",
      "Epoch 9/10, Train Loss: 0.0291, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.8938\n",
      "Epoch 10/10, Train Loss: 0.0258, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.8955\n",
      "\n",
      "Sentiment analysis accuracy: 0.9193, F1 Micro: 0.9193, F1 Macro: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       760\n",
      "    positive       0.94      0.77      0.85       306\n",
      "\n",
      "    accuracy                           0.92      1066\n",
      "   macro avg       0.93      0.87      0.90      1066\n",
      "weighted avg       0.92      0.92      0.92      1066\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9562, F1 Micro: 0.9562, F1 Macro: 0.8701\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.86      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.82      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.78      0.81        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.63      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.82      0.88       200\n",
      "     neutral       0.90      0.97      0.93       315\n",
      "    positive       0.86      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.91      0.90      0.90       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.83      0.86       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.56      0.41      0.47        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.79      0.73      0.76       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.87      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.48      0.61        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.77      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 274.12464213371277 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 86\n",
      "Sampling duration: 0.00012040138244628906 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4854, Accuracy: 0.8109, F1 Micro: 0.8944, F1 Macro: 0.8898\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3373, Accuracy: 0.9038, F1 Micro: 0.9427, F1 Macro: 0.939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2339, Accuracy: 0.942, F1 Micro: 0.9645, F1 Macro: 0.9616\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1811, Accuracy: 0.95, F1 Micro: 0.9694, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1522, Accuracy: 0.9533, F1 Micro: 0.9712, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1249, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1054, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0888, Accuracy: 0.9622, F1 Micro: 0.9766, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0772, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0646, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.96      0.94       317\n",
      "       linen       0.90      0.99      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.96      0.99      0.97      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.99      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4041, Accuracy: 0.8641, F1 Micro: 0.8641, F1 Macro: 0.8033\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2347, Accuracy: 0.889, F1 Micro: 0.889, F1 Macro: 0.8559\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1547, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.8815\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1309, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0748, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0578, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0499, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0442, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.8936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0404, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.899\n",
      "Epoch 10/10, Train Loss: 0.0217, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.8978\n",
      "\n",
      "Sentiment analysis accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       760\n",
      "    positive       0.94      0.78      0.85       285\n",
      "\n",
      "    accuracy                           0.92      1045\n",
      "   macro avg       0.93      0.88      0.90      1045\n",
      "weighted avg       0.93      0.92      0.92      1045\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9562, F1 Micro: 0.9562, F1 Macro: 0.8576\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.88      0.93        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.86      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.88      0.63      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.72      0.59      0.63       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.86      0.90       200\n",
      "     neutral       0.93      0.96      0.94       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.78      0.85       162\n",
      "     neutral       0.90      0.99      0.94       387\n",
      "    positive       0.60      0.27      0.37        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.81      0.68      0.72       571\n",
      "weighted avg       0.90      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.85        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.89      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.78      0.80       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 294.0525424480438 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 77\n",
      "Sampling duration: 9.584426879882812e-05 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4808, Accuracy: 0.8339, F1 Micro: 0.9048, F1 Macro: 0.8977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3234, Accuracy: 0.9149, F1 Micro: 0.9488, F1 Macro: 0.9455\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2286, Accuracy: 0.9389, F1 Micro: 0.9628, F1 Macro: 0.9606\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1811, Accuracy: 0.9453, F1 Micro: 0.9665, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1508, Accuracy: 0.9549, F1 Micro: 0.9722, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1221, Accuracy: 0.9561, F1 Micro: 0.9729, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1075, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.088, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Epoch 9/10, Train Loss: 0.0747, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.975\n",
      "Epoch 10/10, Train Loss: 0.0615, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9733\n",
      "\n",
      "Aspect detection accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.92      0.95      0.93       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.364, Accuracy: 0.8659, F1 Micro: 0.8659, F1 Macro: 0.8269\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2177, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1552, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0956, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0816, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0636, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0616, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8862\n",
      "Epoch 8/10, Train Loss: 0.0359, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8757\n",
      "Epoch 9/10, Train Loss: 0.0344, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8846\n",
      "Epoch 10/10, Train Loss: 0.0228, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8849\n",
      "\n",
      "Sentiment analysis accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8862\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       773\n",
      "    positive       0.92      0.76      0.83       301\n",
      "\n",
      "    accuracy                           0.91      1074\n",
      "   macro avg       0.92      0.87      0.89      1074\n",
      "weighted avg       0.91      0.91      0.91      1074\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9562, F1 Micro: 0.9562, F1 Macro: 0.8692\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.79      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.09      0.14      0.11         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.90      0.63      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.65      0.59      0.61       571\n",
      "weighted avg       0.94      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.67      0.45      0.54        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.84      0.76      0.79       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.85      0.82        85\n",
      "     neutral       0.97      0.96      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.91      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 293.30030274391174 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 70\n",
      "Sampling duration: 9.965896606445312e-05 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4786, Accuracy: 0.8297, F1 Micro: 0.9021, F1 Macro: 0.8946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3263, Accuracy: 0.9149, F1 Micro: 0.9488, F1 Macro: 0.9459\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2173, Accuracy: 0.9446, F1 Micro: 0.966, F1 Macro: 0.9637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1726, Accuracy: 0.9509, F1 Micro: 0.9697, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1466, Accuracy: 0.9549, F1 Micro: 0.9721, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1216, Accuracy: 0.9557, F1 Micro: 0.9727, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1018, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0898, Accuracy: 0.9609, F1 Micro: 0.9759, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0718, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0626, Accuracy: 0.9613, F1 Micro: 0.9761, F1 Macro: 0.974\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9761, F1 Macro: 0.974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.90      0.99      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.99      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3531, Accuracy: 0.8706, F1 Micro: 0.8706, F1 Macro: 0.835\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.213, Accuracy: 0.8955, F1 Micro: 0.8955, F1 Macro: 0.8609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1495, Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0978, Accuracy: 0.9214, F1 Micro: 0.9214, F1 Macro: 0.8958\n",
      "Epoch 5/10, Train Loss: 0.071, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.8913\n",
      "Epoch 6/10, Train Loss: 0.0545, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.8932\n",
      "Epoch 7/10, Train Loss: 0.0503, Accuracy: 0.9204, F1 Micro: 0.9204, F1 Macro: 0.8949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0317, Accuracy: 0.9233, F1 Micro: 0.9233, F1 Macro: 0.8991\n",
      "Epoch 9/10, Train Loss: 0.0436, Accuracy: 0.9214, F1 Micro: 0.9214, F1 Macro: 0.898\n",
      "Epoch 10/10, Train Loss: 0.0463, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.892\n",
      "\n",
      "Sentiment analysis accuracy: 0.9233, F1 Micro: 0.9233, F1 Macro: 0.8991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       754\n",
      "    positive       0.93      0.78      0.85       289\n",
      "\n",
      "    accuracy                           0.92      1043\n",
      "   macro avg       0.93      0.88      0.90      1043\n",
      "weighted avg       0.92      0.92      0.92      1043\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9539, F1 Micro: 0.9539, F1 Macro: 0.8378\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.76      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.77      0.82        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.84      0.62      0.71        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.53      0.56       571\n",
      "weighted avg       0.91      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.88       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.77      0.84       162\n",
      "     neutral       0.90      0.99      0.94       387\n",
      "    positive       0.60      0.27      0.37        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.81      0.68      0.72       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.84      0.88        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.48      0.61        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.64      0.82      0.72        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.77      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 303.0621392726898 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 52\n",
      "Sampling duration: 0.015110492706298828 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4731, Accuracy: 0.8455, F1 Micro: 0.911, F1 Macro: 0.9053\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3101, Accuracy: 0.9191, F1 Micro: 0.9513, F1 Macro: 0.9482\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.217, Accuracy: 0.9427, F1 Micro: 0.9651, F1 Macro: 0.9629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1673, Accuracy: 0.9514, F1 Micro: 0.9701, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1381, Accuracy: 0.9578, F1 Micro: 0.974, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1177, Accuracy: 0.9583, F1 Micro: 0.9743, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1007, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9736\n",
      "Epoch 8/10, Train Loss: 0.0827, Accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0685, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9749\n",
      "Epoch 10/10, Train Loss: 0.0584, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9736\n",
      "\n",
      "Aspect detection accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3624, Accuracy: 0.8663, F1 Micro: 0.8663, F1 Macro: 0.823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2108, Accuracy: 0.88, F1 Micro: 0.88, F1 Macro: 0.8467\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.143, Accuracy: 0.8956, F1 Micro: 0.8956, F1 Macro: 0.8621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0964, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0693, Accuracy: 0.9029, F1 Micro: 0.9029, F1 Macro: 0.8742\n",
      "Epoch 6/10, Train Loss: 0.0499, Accuracy: 0.9002, F1 Micro: 0.9002, F1 Macro: 0.8702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.058, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.036, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0192, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.879\n",
      "Epoch 10/10, Train Loss: 0.0302, Accuracy: 0.9002, F1 Micro: 0.9002, F1 Macro: 0.8687\n",
      "\n",
      "Sentiment analysis accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       774\n",
      "    positive       0.91      0.75      0.82       318\n",
      "\n",
      "    accuracy                           0.91      1092\n",
      "   macro avg       0.91      0.86      0.88      1092\n",
      "weighted avg       0.91      0.91      0.90      1092\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.8548\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.60      0.30      0.40        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.73      0.76       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.83      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.87      0.69      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.72      0.61      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.92      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.88      0.89      0.88        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.91      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       1.00      0.23      0.37        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.69      0.72       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        85\n",
      "     neutral       0.97      0.96      0.96       418\n",
      "    positive       0.89      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.48      0.60        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.82      0.74        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.77      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 308.6971070766449 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 58\n",
      "Sampling duration: 8.845329284667969e-05 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4714, Accuracy: 0.8552, F1 Micro: 0.915, F1 Macro: 0.9057\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3078, Accuracy: 0.924, F1 Micro: 0.9539, F1 Macro: 0.9507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2111, Accuracy: 0.9465, F1 Micro: 0.9673, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1654, Accuracy: 0.9484, F1 Micro: 0.9684, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1379, Accuracy: 0.9519, F1 Micro: 0.9705, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1184, Accuracy: 0.9576, F1 Micro: 0.9739, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0947, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0868, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0685, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0578, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3537, Accuracy: 0.8671, F1 Micro: 0.8671, F1 Macro: 0.8124\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2156, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1258, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8758\n",
      "Epoch 4/10, Train Loss: 0.1016, Accuracy: 0.8987, F1 Micro: 0.8987, F1 Macro: 0.867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.085, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0506, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.04, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8879\n",
      "Epoch 8/10, Train Loss: 0.0335, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8827\n",
      "Epoch 9/10, Train Loss: 0.0317, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8804\n",
      "Epoch 10/10, Train Loss: 0.02, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8815\n",
      "\n",
      "Sentiment analysis accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       777\n",
      "    positive       0.93      0.76      0.83       299\n",
      "\n",
      "    accuracy                           0.92      1076\n",
      "   macro avg       0.92      0.87      0.89      1076\n",
      "weighted avg       0.92      0.92      0.91      1076\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.8594\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.79      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.90      0.63      0.74        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.54      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.89      0.90       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.90      0.95      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.62      0.23      0.33        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.81      0.69      0.71       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.68      0.76      0.72        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.77      0.79       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 318.98385643959045 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 52\n",
      "Sampling duration: 8.940696716308594e-05 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4775, Accuracy: 0.8446, F1 Micro: 0.9111, F1 Macro: 0.9064\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3082, Accuracy: 0.9189, F1 Micro: 0.9513, F1 Macro: 0.9481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2122, Accuracy: 0.9429, F1 Micro: 0.9651, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1668, Accuracy: 0.9528, F1 Micro: 0.9709, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1375, Accuracy: 0.9535, F1 Micro: 0.9714, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1135, Accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9729\n",
      "Epoch 7/10, Train Loss: 0.0948, Accuracy: 0.9587, F1 Micro: 0.9743, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0821, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0648, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.976\n",
      "Epoch 10/10, Train Loss: 0.0584, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.95      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3414, Accuracy: 0.8564, F1 Micro: 0.8564, F1 Macro: 0.8204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2073, Accuracy: 0.8932, F1 Micro: 0.8932, F1 Macro: 0.8571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1347, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0929, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8858\n",
      "Epoch 5/10, Train Loss: 0.0702, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0612, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0475, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8864\n",
      "Epoch 8/10, Train Loss: 0.0246, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.87\n",
      "Epoch 9/10, Train Loss: 0.0375, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8786\n",
      "Epoch 10/10, Train Loss: 0.0312, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8878\n",
      "\n",
      "Sentiment analysis accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8864\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       772\n",
      "    positive       0.94      0.75      0.83       314\n",
      "\n",
      "    accuracy                           0.91      1086\n",
      "   macro avg       0.92      0.86      0.89      1086\n",
      "weighted avg       0.91      0.91      0.91      1086\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9573, F1 Micro: 0.9573, F1 Macro: 0.8621\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.83      0.93      0.87       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.82      0.79      0.81        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.64      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.91      0.91       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.94      0.93       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.85       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.57      0.36      0.44        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.79      0.72      0.75       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.38      0.52        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.58      0.82      0.68        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.80      0.73      0.73       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 318.28731393814087 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.0001068115234375 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4659, Accuracy: 0.8642, F1 Micro: 0.9203, F1 Macro: 0.9136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2928, Accuracy: 0.9281, F1 Micro: 0.9566, F1 Macro: 0.9542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2022, Accuracy: 0.9455, F1 Micro: 0.9665, F1 Macro: 0.9638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1631, Accuracy: 0.9507, F1 Micro: 0.9698, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1314, Accuracy: 0.9563, F1 Micro: 0.973, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1077, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9735\n",
      "Epoch 7/10, Train Loss: 0.0915, Accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0787, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Epoch 9/10, Train Loss: 0.065, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0572, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3537, Accuracy: 0.8637, F1 Micro: 0.8637, F1 Macro: 0.8232\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.225, Accuracy: 0.8932, F1 Micro: 0.8932, F1 Macro: 0.8581\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1427, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8871\n",
      "Epoch 4/10, Train Loss: 0.1027, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8735\n",
      "Epoch 5/10, Train Loss: 0.093, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8831\n",
      "Epoch 6/10, Train Loss: 0.0618, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0419, Accuracy: 0.9162, F1 Micro: 0.9162, F1 Macro: 0.8899\n",
      "Epoch 8/10, Train Loss: 0.0242, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.889\n",
      "Epoch 9/10, Train Loss: 0.0309, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8872\n",
      "Epoch 10/10, Train Loss: 0.0239, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8799\n",
      "\n",
      "Sentiment analysis accuracy: 0.9162, F1 Micro: 0.9162, F1 Macro: 0.8899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       776\n",
      "    positive       0.95      0.75      0.84       310\n",
      "\n",
      "    accuracy                           0.92      1086\n",
      "   macro avg       0.93      0.87      0.89      1086\n",
      "weighted avg       0.92      0.92      0.91      1086\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9573, F1 Micro: 0.9573, F1 Macro: 0.8488\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.60      0.30      0.40        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.73      0.77       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.82      0.94      0.87       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.89      0.89      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.90      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.67      0.27      0.39        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.83      0.70      0.74       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.82      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.52      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.74      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 324.59436774253845 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.845329284667969e-05 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4617, Accuracy: 0.8674, F1 Micro: 0.9223, F1 Macro: 0.9161\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2916, Accuracy: 0.9304, F1 Micro: 0.9577, F1 Macro: 0.9551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1963, Accuracy: 0.9484, F1 Micro: 0.9684, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1534, Accuracy: 0.9505, F1 Micro: 0.9697, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1289, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.11, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0913, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0754, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.0647, Accuracy: 0.962, F1 Micro: 0.9765, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0557, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3398, Accuracy: 0.865, F1 Micro: 0.865, F1 Macro: 0.8177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.212, Accuracy: 0.8823, F1 Micro: 0.8823, F1 Macro: 0.8493\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1405, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1038, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8799\n",
      "Epoch 5/10, Train Loss: 0.0673, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0522, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8814\n",
      "Epoch 7/10, Train Loss: 0.0365, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8736\n",
      "Epoch 8/10, Train Loss: 0.0319, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8812\n",
      "Epoch 9/10, Train Loss: 0.0291, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0243, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8873\n",
      "\n",
      "Sentiment analysis accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       782\n",
      "    positive       0.93      0.75      0.83       314\n",
      "\n",
      "    accuracy                           0.91      1096\n",
      "   macro avg       0.92      0.87      0.89      1096\n",
      "weighted avg       0.91      0.91      0.91      1096\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.875\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.92      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.82      0.93      0.87        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.95      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.85        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.87      0.66      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.60      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.94      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.76      0.80       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.90      0.97      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 340.47151494026184 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 6.318092346191406e-05 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4686, Accuracy: 0.871, F1 Micro: 0.9248, F1 Macro: 0.9203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2858, Accuracy: 0.9335, F1 Micro: 0.9596, F1 Macro: 0.9573\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1984, Accuracy: 0.9476, F1 Micro: 0.9679, F1 Macro: 0.9657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1604, Accuracy: 0.9517, F1 Micro: 0.9704, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1296, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1067, Accuracy: 0.9618, F1 Micro: 0.9764, F1 Macro: 0.9744\n",
      "Epoch 7/10, Train Loss: 0.0922, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0748, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0652, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0556, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.96      0.97      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.90      0.98      0.94       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3767, Accuracy: 0.8599, F1 Micro: 0.8599, F1 Macro: 0.8258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2149, Accuracy: 0.8846, F1 Micro: 0.8846, F1 Macro: 0.8458\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.15, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8888\n",
      "Epoch 4/10, Train Loss: 0.1062, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.079, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.8985\n",
      "Epoch 6/10, Train Loss: 0.0453, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8837\n",
      "Epoch 7/10, Train Loss: 0.0358, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8931\n",
      "Epoch 8/10, Train Loss: 0.0278, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8928\n",
      "Epoch 9/10, Train Loss: 0.0214, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8945\n",
      "Epoch 10/10, Train Loss: 0.0184, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.893\n",
      "\n",
      "Sentiment analysis accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.8985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94       770\n",
      "    positive       0.93      0.79      0.85       322\n",
      "\n",
      "    accuracy                           0.92      1092\n",
      "   macro avg       0.92      0.88      0.90      1092\n",
      "weighted avg       0.92      0.92      0.92      1092\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.8518\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.92      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.82      0.93      0.87        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.95      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.50      0.50      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.80      0.80      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.78      0.82        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.96      0.97      0.97       496\n",
      "    positive       0.79      0.81      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.58      0.59      0.59       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.80      0.86       162\n",
      "     neutral       0.90      0.98      0.94       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.91      0.73      0.79       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.87      0.97      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.95      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.82      0.74        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.77      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 338.9971454143524 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 25\n",
      "Sampling duration: 0.01675701141357422 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4675, Accuracy: 0.8799, F1 Micro: 0.9291, F1 Macro: 0.9237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2777, Accuracy: 0.9358, F1 Micro: 0.9608, F1 Macro: 0.9577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1978, Accuracy: 0.9507, F1 Micro: 0.9697, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1542, Accuracy: 0.9554, F1 Micro: 0.9725, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1296, Accuracy: 0.9564, F1 Micro: 0.9732, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1067, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.091, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "Epoch 8/10, Train Loss: 0.0736, Accuracy: 0.9608, F1 Micro: 0.9756, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0622, Accuracy: 0.9637, F1 Micro: 0.9774, F1 Macro: 0.9752\n",
      "Epoch 10/10, Train Loss: 0.0523, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9637, F1 Micro: 0.9774, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.94      0.95      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3473, Accuracy: 0.8602, F1 Micro: 0.8602, F1 Macro: 0.8183\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1968, Accuracy: 0.8772, F1 Micro: 0.8772, F1 Macro: 0.8369\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1315, Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0915, Accuracy: 0.8952, F1 Micro: 0.8952, F1 Macro: 0.8633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0856, Accuracy: 0.8987, F1 Micro: 0.8987, F1 Macro: 0.8729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0679, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8792\n",
      "Epoch 7/10, Train Loss: 0.0392, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8729\n",
      "Epoch 8/10, Train Loss: 0.0354, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8698\n",
      "Epoch 9/10, Train Loss: 0.0384, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0276, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8827\n",
      "\n",
      "Sentiment analysis accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       786\n",
      "    positive       0.90      0.77      0.83       330\n",
      "\n",
      "    accuracy                           0.91      1116\n",
      "   macro avg       0.91      0.87      0.88      1116\n",
      "weighted avg       0.91      0.91      0.90      1116\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9571, F1 Micro: 0.9571, F1 Macro: 0.8663\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.75      1.00      0.86        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.97      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.93      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.81      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.86      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.91      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.83      0.86       162\n",
      "     neutral       0.94      0.95      0.94       387\n",
      "    positive       0.50      0.59      0.54        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.77      0.79      0.78       571\n",
      "weighted avg       0.91      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.87      0.97      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 345.2807252407074 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.487701416015625e-05 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4595, Accuracy: 0.8767, F1 Micro: 0.9274, F1 Macro: 0.9216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2837, Accuracy: 0.9373, F1 Micro: 0.9619, F1 Macro: 0.9598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2038, Accuracy: 0.9439, F1 Micro: 0.9658, F1 Macro: 0.9636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1586, Accuracy: 0.9519, F1 Micro: 0.9704, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1325, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1068, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Epoch 7/10, Train Loss: 0.0878, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0752, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "Epoch 9/10, Train Loss: 0.0629, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.0556, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.94      0.95      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3633, Accuracy: 0.8721, F1 Micro: 0.8721, F1 Macro: 0.8365\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1998, Accuracy: 0.8919, F1 Micro: 0.8919, F1 Macro: 0.859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1394, Accuracy: 0.9018, F1 Micro: 0.9018, F1 Macro: 0.8777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1019, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0751, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0508, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8745\n",
      "Epoch 7/10, Train Loss: 0.0482, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0273, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8833\n",
      "Epoch 9/10, Train Loss: 0.0254, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.878\n",
      "Epoch 10/10, Train Loss: 0.0236, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8752\n",
      "\n",
      "Sentiment analysis accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8833\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       790\n",
      "    positive       0.94      0.74      0.83       320\n",
      "\n",
      "    accuracy                           0.91      1110\n",
      "   macro avg       0.92      0.86      0.88      1110\n",
      "weighted avg       0.91      0.91      0.91      1110\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.8746\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.97      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.29      0.33         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.74      0.65      0.69       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.86      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.67      0.36      0.47        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.82      0.73      0.76       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.86      0.84        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.93      0.91      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 349.020103931427 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.153915405273438e-05 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4578, Accuracy: 0.8764, F1 Micro: 0.927, F1 Macro: 0.9203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2758, Accuracy: 0.9387, F1 Micro: 0.9626, F1 Macro: 0.9601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1951, Accuracy: 0.9483, F1 Micro: 0.9682, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1525, Accuracy: 0.9543, F1 Micro: 0.9719, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1263, Accuracy: 0.959, F1 Micro: 0.9747, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.105, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0874, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0746, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0612, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0524, Accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3418, Accuracy: 0.873, F1 Micro: 0.873, F1 Macro: 0.8395\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1798, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1354, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.8944\n",
      "Epoch 4/10, Train Loss: 0.0871, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8886\n",
      "Epoch 5/10, Train Loss: 0.0684, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8819\n",
      "Epoch 6/10, Train Loss: 0.0496, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0356, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.8978\n",
      "Epoch 8/10, Train Loss: 0.0256, Accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8933\n",
      "Epoch 9/10, Train Loss: 0.0211, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.8962\n",
      "Epoch 10/10, Train Loss: 0.0332, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8902\n",
      "\n",
      "Sentiment analysis accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.8978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       776\n",
      "    positive       0.93      0.78      0.85       311\n",
      "\n",
      "    accuracy                           0.92      1087\n",
      "   macro avg       0.93      0.88      0.90      1087\n",
      "weighted avg       0.92      0.92      0.92      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9592, F1 Micro: 0.9592, F1 Macro: 0.8632\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.92      0.91        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.77      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.88      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.69      0.50      0.58        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.84      0.77      0.80       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.82      0.86        85\n",
      "     neutral       0.97      0.99      0.98       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.66      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 370.3599419593811 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.225440979003906e-05 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4613, Accuracy: 0.8795, F1 Micro: 0.9283, F1 Macro: 0.9196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2716, Accuracy: 0.9385, F1 Micro: 0.9626, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1901, Accuracy: 0.9507, F1 Micro: 0.9697, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1551, Accuracy: 0.9517, F1 Micro: 0.9704, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1219, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9751\n",
      "Epoch 6/10, Train Loss: 0.1027, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0853, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9752\n",
      "Epoch 8/10, Train Loss: 0.0738, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0606, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9764\n",
      "Epoch 10/10, Train Loss: 0.0519, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3637, Accuracy: 0.8801, F1 Micro: 0.8801, F1 Macro: 0.8435\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2013, Accuracy: 0.9022, F1 Micro: 0.9022, F1 Macro: 0.8724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1281, Accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0956, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0582, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.8996\n",
      "Epoch 6/10, Train Loss: 0.0469, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.8961\n",
      "Epoch 7/10, Train Loss: 0.0417, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.8948\n",
      "Epoch 8/10, Train Loss: 0.0238, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.8926\n",
      "Epoch 9/10, Train Loss: 0.0253, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8895\n",
      "Epoch 10/10, Train Loss: 0.0241, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8887\n",
      "\n",
      "Sentiment analysis accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.8996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       774\n",
      "    positive       0.94      0.78      0.85       310\n",
      "\n",
      "    accuracy                           0.92      1084\n",
      "   macro avg       0.93      0.88      0.90      1084\n",
      "weighted avg       0.92      0.92      0.92      1084\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9587, F1 Micro: 0.9587, F1 Macro: 0.8681\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.91      0.79      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.14      0.14      0.14         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.86      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.65      0.62      0.63       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.78      0.32      0.45        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.72      0.75       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.66      0.70        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.75      0.71      0.73        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 362.5693197250366 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.343292236328125e-05 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4457, Accuracy: 0.884, F1 Micro: 0.9313, F1 Macro: 0.9252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.263, Accuracy: 0.9354, F1 Micro: 0.9607, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1887, Accuracy: 0.9512, F1 Micro: 0.9701, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1512, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1273, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1047, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9754\n",
      "Epoch 7/10, Train Loss: 0.0857, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9748\n",
      "Epoch 8/10, Train Loss: 0.0709, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0592, Accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9769\n",
      "Epoch 10/10, Train Loss: 0.0521, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3307, Accuracy: 0.8588, F1 Micro: 0.8588, F1 Macro: 0.804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1967, Accuracy: 0.8882, F1 Micro: 0.8882, F1 Macro: 0.8626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1422, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0966, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0729, Accuracy: 0.9193, F1 Micro: 0.9193, F1 Macro: 0.8962\n",
      "Epoch 6/10, Train Loss: 0.051, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8931\n",
      "Epoch 7/10, Train Loss: 0.0386, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.882\n",
      "Epoch 8/10, Train Loss: 0.025, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8878\n",
      "Epoch 9/10, Train Loss: 0.0285, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.889\n",
      "Epoch 10/10, Train Loss: 0.0329, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8895\n",
      "\n",
      "Sentiment analysis accuracy: 0.9193, F1 Micro: 0.9193, F1 Macro: 0.8962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.95       780\n",
      "    positive       0.92      0.78      0.85       311\n",
      "\n",
      "    accuracy                           0.92      1091\n",
      "   macro avg       0.92      0.88      0.90      1091\n",
      "weighted avg       0.92      0.92      0.92      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.8687\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        78\n",
      "     neutral       0.98      0.97      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.95      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.75      0.27      0.40        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.70      0.74       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.87      0.84        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.95      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.69      0.77        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.86      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 369.0399684906006 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.00015354156494140625 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4554, Accuracy: 0.8802, F1 Micro: 0.9294, F1 Macro: 0.9249\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2653, Accuracy: 0.9335, F1 Micro: 0.9596, F1 Macro: 0.9571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.185, Accuracy: 0.949, F1 Micro: 0.9688, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1453, Accuracy: 0.9514, F1 Micro: 0.9701, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.119, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0972, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "Epoch 7/10, Train Loss: 0.084, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0677, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.0593, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0486, Accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.977\n",
      "\n",
      "Aspect detection accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.95      0.94      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3546, Accuracy: 0.8647, F1 Micro: 0.8647, F1 Macro: 0.8128\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1783, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8816\n",
      "Epoch 3/10, Train Loss: 0.1221, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0915, Accuracy: 0.9196, F1 Micro: 0.9196, F1 Macro: 0.8965\n",
      "Epoch 5/10, Train Loss: 0.0607, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8796\n",
      "Epoch 6/10, Train Loss: 0.0639, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8821\n",
      "Epoch 7/10, Train Loss: 0.0507, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8851\n",
      "Epoch 8/10, Train Loss: 0.0472, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.8888\n",
      "Epoch 9/10, Train Loss: 0.0261, Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.8891\n",
      "Epoch 10/10, Train Loss: 0.0201, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8861\n",
      "\n",
      "Sentiment analysis accuracy: 0.9196, F1 Micro: 0.9196, F1 Macro: 0.8965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.95       781\n",
      "    positive       0.92      0.78      0.85       313\n",
      "\n",
      "    accuracy                           0.92      1094\n",
      "   macro avg       0.92      0.88      0.90      1094\n",
      "weighted avg       0.92      0.92      0.92      1094\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.8669\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.86      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.89      0.71      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.90       200\n",
      "     neutral       0.95      0.94      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.86      0.76      0.80       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.90      0.97      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.71      0.83      0.77         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.88      0.92      0.90       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 379.43410181999207 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 36\n",
      "Sampling duration: 0.022786855697631836 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4405, Accuracy: 0.8889, F1 Micro: 0.9339, F1 Macro: 0.9281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2621, Accuracy: 0.9354, F1 Micro: 0.9608, F1 Macro: 0.9582\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1832, Accuracy: 0.9486, F1 Micro: 0.9684, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1432, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1197, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1008, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0852, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.069, Accuracy: 0.9641, F1 Micro: 0.9776, F1 Macro: 0.9752\n",
      "Epoch 9/10, Train Loss: 0.0558, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9753\n",
      "Epoch 10/10, Train Loss: 0.0483, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9641, F1 Micro: 0.9776, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.97      0.97       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3568, Accuracy: 0.8615, F1 Micro: 0.8615, F1 Macro: 0.8188\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2052, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.129, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.8698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.11, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0872, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8823\n",
      "Epoch 6/10, Train Loss: 0.0609, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0564, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8823\n",
      "Epoch 8/10, Train Loss: 0.0431, Accuracy: 0.9002, F1 Micro: 0.9002, F1 Macro: 0.8701\n",
      "Epoch 9/10, Train Loss: 0.0296, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8774\n",
      "Epoch 10/10, Train Loss: 0.0282, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.878\n",
      "\n",
      "Sentiment analysis accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8823\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       780\n",
      "    positive       0.93      0.75      0.83       332\n",
      "\n",
      "    accuracy                           0.91      1112\n",
      "   macro avg       0.91      0.86      0.88      1112\n",
      "weighted avg       0.91      0.91      0.90      1112\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9559, F1 Micro: 0.9559, F1 Macro: 0.8627\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.90      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.75      1.00      0.86        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.96      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.86      0.87       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.29      0.36         7\n",
      "     neutral       0.96      0.97      0.97       496\n",
      "    positive       0.81      0.81      0.81        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.69      0.71       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.86       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.52      0.50      0.51        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.79      0.77      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.87      0.96      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.82      0.74        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.78      0.79       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.85      0.89        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.50      1.00      0.67         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.81      0.95      0.85       571\n",
      "weighted avg       0.99      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 388.06227684020996 s\n",
      "Total runtime: 7518.646129608154 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1284cb9",
   "metadata": {
    "papermill": {
     "duration": 0.01119,
     "end_time": "2025-03-31T11:40:20.250875",
     "exception": false,
     "start_time": "2025-03-31T11:40:20.239685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2513a85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6341, Accuracy: 0.7974, F1 Micro: 0.8859, F1 Macro: 0.8768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5134, Accuracy: 0.8014, F1 Micro: 0.8897, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4829, Accuracy: 0.8017, F1 Micro: 0.8897, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4632, Accuracy: 0.8045, F1 Micro: 0.8906, F1 Macro: 0.8847\n",
      "Epoch 5/10, Train Loss: 0.4642, Accuracy: 0.8047, F1 Micro: 0.8903, F1 Macro: 0.8835\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4501, Accuracy: 0.8075, F1 Micro: 0.891, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.451, Accuracy: 0.8149, F1 Micro: 0.8947, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4034, Accuracy: 0.8273, F1 Micro: 0.9007, F1 Macro: 0.892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3957, Accuracy: 0.8345, F1 Micro: 0.9041, F1 Macro: 0.8954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3562, Accuracy: 0.8448, F1 Micro: 0.9097, F1 Macro: 0.9016\n",
      "\n",
      "Aspect detection accuracy: 0.8448, F1 Micro: 0.9097, F1 Macro: 0.9016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.83      1.00      0.90       462\n",
      "   air_panas       0.83      1.00      0.91       480\n",
      "         bau       0.86      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.70      0.75      0.73       317\n",
      "       linen       0.77      0.94      0.85       392\n",
      "     service       0.90      0.98      0.94       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.88      1.00      0.94       498\n",
      "\n",
      "   micro avg       0.85      0.98      0.91      4614\n",
      "   macro avg       0.85      0.97      0.90      4614\n",
      "weighted avg       0.85      0.98      0.91      4614\n",
      " samples avg       0.85      0.97      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7316, Accuracy: 0.5412, F1 Micro: 0.5412, F1 Macro: 0.3512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.612, Accuracy: 0.5412, F1 Micro: 0.5412, F1 Macro: 0.3512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5437, Accuracy: 0.5645, F1 Micro: 0.5645, F1 Macro: 0.4185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5596, Accuracy: 0.5751, F1 Micro: 0.5751, F1 Macro: 0.4522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4998, Accuracy: 0.5877, F1 Micro: 0.5877, F1 Macro: 0.5659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.478, Accuracy: 0.6025, F1 Micro: 0.6025, F1 Macro: 0.5626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3806, Accuracy: 0.666, F1 Micro: 0.666, F1 Macro: 0.6564\n",
      "Epoch 8/10, Train Loss: 0.3522, Accuracy: 0.6195, F1 Micro: 0.6195, F1 Macro: 0.5823\n",
      "Epoch 9/10, Train Loss: 0.3548, Accuracy: 0.6575, F1 Micro: 0.6575, F1 Macro: 0.6482\n",
      "Epoch 10/10, Train Loss: 0.3088, Accuracy: 0.6237, F1 Micro: 0.6237, F1 Macro: 0.6009\n",
      "\n",
      "Sentiment analysis accuracy: 0.666, F1 Micro: 0.666, F1 Macro: 0.6564\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.77      0.71       256\n",
      "    positive       0.67      0.54      0.60       217\n",
      "\n",
      "    accuracy                           0.67       473\n",
      "   macro avg       0.67      0.66      0.66       473\n",
      "weighted avg       0.67      0.67      0.66       473\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8275, F1 Micro: 0.8275, F1 Macro: 0.4031\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.16      0.28        97\n",
      "     neutral       0.83      1.00      0.91       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.61      0.39      0.40       571\n",
      "weighted avg       0.83      0.83      0.78       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.28      0.33      0.30       571\n",
      "weighted avg       0.69      0.83      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        78\n",
      "     neutral       0.86      1.00      0.92       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.74      0.86      0.80       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.55      0.45      0.49       200\n",
      "     neutral       0.70      0.75      0.73       315\n",
      "    positive       0.28      0.36      0.31        56\n",
      "\n",
      "    accuracy                           0.61       571\n",
      "   macro avg       0.51      0.52      0.51       571\n",
      "weighted avg       0.61      0.61      0.60       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.31      0.43       162\n",
      "     neutral       0.76      0.94      0.84       387\n",
      "    positive       0.21      0.18      0.20        22\n",
      "\n",
      "    accuracy                           0.73       571\n",
      "   macro avg       0.55      0.48      0.49       571\n",
      "weighted avg       0.72      0.73      0.70       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.44      0.50        85\n",
      "     neutral       0.90      0.98      0.93       418\n",
      "    positive       0.73      0.56      0.63        68\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.74      0.66      0.69       571\n",
      "weighted avg       0.83      0.85      0.83       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.24        74\n",
      "     neutral       0.88      1.00      0.94       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.63      0.38      0.39       571\n",
      "weighted avg       0.89      0.88      0.84       571\n",
      "\n",
      "Total train time: 82.01495838165283 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 215\n",
      "Sampling duration: 0.0001976490020751953 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5648, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4616, Accuracy: 0.8031, F1 Micro: 0.8901, F1 Macro: 0.8847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4413, Accuracy: 0.8095, F1 Micro: 0.8932, F1 Macro: 0.8877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4301, Accuracy: 0.8361, F1 Micro: 0.9052, F1 Macro: 0.8971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3745, Accuracy: 0.8616, F1 Micro: 0.9195, F1 Macro: 0.9149\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3251, Accuracy: 0.8828, F1 Micro: 0.9305, F1 Macro: 0.9252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.293, Accuracy: 0.8939, F1 Micro: 0.937, F1 Macro: 0.9333\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2436, Accuracy: 0.9069, F1 Micro: 0.9443, F1 Macro: 0.9411\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2187, Accuracy: 0.9144, F1 Micro: 0.9485, F1 Macro: 0.9453\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1887, Accuracy: 0.9198, F1 Micro: 0.9517, F1 Macro: 0.9487\n",
      "\n",
      "Aspect detection accuracy: 0.9198, F1 Micro: 0.9517, F1 Macro: 0.9487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.96      0.99      0.98       462\n",
      "   air_panas       0.92      0.99      0.95       480\n",
      "         bau       0.92      0.99      0.95       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.83      0.93      0.88       317\n",
      "       linen       0.84      0.98      0.91       392\n",
      "     service       0.95      0.96      0.96       423\n",
      "sunrise_meal       0.94      1.00      0.97       530\n",
      "          tv       0.96      1.00      0.98       516\n",
      "        wifi       0.98      0.99      0.99       498\n",
      "\n",
      "   micro avg       0.92      0.99      0.95      4614\n",
      "   macro avg       0.92      0.98      0.95      4614\n",
      "weighted avg       0.92      0.99      0.95      4614\n",
      " samples avg       0.92      0.99      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5312, Accuracy: 0.7407, F1 Micro: 0.7407, F1 Macro: 0.4255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4404, Accuracy: 0.7914, F1 Micro: 0.7914, F1 Macro: 0.7046\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3497, Accuracy: 0.8247, F1 Micro: 0.8247, F1 Macro: 0.7772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2653, Accuracy: 0.8481, F1 Micro: 0.8481, F1 Macro: 0.7858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2303, Accuracy: 0.8519, F1 Micro: 0.8519, F1 Macro: 0.793\n",
      "Epoch 6/10, Train Loss: 0.1797, Accuracy: 0.8506, F1 Micro: 0.8506, F1 Macro: 0.7988\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1687, Accuracy: 0.8667, F1 Micro: 0.8667, F1 Macro: 0.8048\n",
      "Epoch 8/10, Train Loss: 0.181, Accuracy: 0.8642, F1 Micro: 0.8642, F1 Macro: 0.8004\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1322, Accuracy: 0.879, F1 Micro: 0.879, F1 Macro: 0.8405\n",
      "Epoch 10/10, Train Loss: 0.122, Accuracy: 0.8704, F1 Micro: 0.8704, F1 Macro: 0.8345\n",
      "\n",
      "Sentiment analysis accuracy: 0.879, F1 Micro: 0.879, F1 Macro: 0.8405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92       600\n",
      "    positive       0.78      0.75      0.76       210\n",
      "\n",
      "    accuracy                           0.88       810\n",
      "   macro avg       0.85      0.84      0.84       810\n",
      "weighted avg       0.88      0.88      0.88       810\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.6664\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.81      0.88        97\n",
      "     neutral       0.96      0.99      0.98       459\n",
      "    positive       0.60      0.60      0.60        15\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.52      0.67        86\n",
      "     neutral       0.91      0.99      0.95       475\n",
      "    positive       0.43      0.30      0.35        10\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.75      0.60      0.66       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.46      0.60        78\n",
      "     neutral       0.92      0.99      0.95       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.58      0.48      0.51       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.64      0.75       200\n",
      "     neutral       0.83      0.93      0.88       315\n",
      "    positive       0.57      0.82      0.68        56\n",
      "\n",
      "    accuracy                           0.82       571\n",
      "   macro avg       0.77      0.80      0.77       571\n",
      "weighted avg       0.84      0.82      0.82       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.61      0.74       162\n",
      "     neutral       0.84      0.98      0.90       387\n",
      "    positive       0.31      0.18      0.23        22\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.69      0.59      0.62       571\n",
      "weighted avg       0.84      0.84      0.83       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.64      0.74        85\n",
      "     neutral       0.95      0.97      0.96       418\n",
      "    positive       0.73      0.91      0.81        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.84      0.84       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.07      0.13        29\n",
      "     neutral       0.94      1.00      0.97       525\n",
      "    positive       0.69      0.53      0.60        17\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.88      0.53      0.57       571\n",
      "weighted avg       0.94      0.94      0.91       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.65      0.76        54\n",
      "     neutral       0.96      1.00      0.98       511\n",
      "    positive       0.50      0.33      0.40         6\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.79      0.66      0.71       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.85      0.91        74\n",
      "     neutral       0.98      0.99      0.99       494\n",
      "    positive       0.50      1.00      0.67         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.82      0.95      0.85       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 124.0265257358551 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 193\n",
      "Sampling duration: 0.00014328956604003906 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5259, Accuracy: 0.8014, F1 Micro: 0.8897, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4503, Accuracy: 0.8118, F1 Micro: 0.8947, F1 Macro: 0.8901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4041, Accuracy: 0.847, F1 Micro: 0.9119, F1 Macro: 0.907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3475, Accuracy: 0.8715, F1 Micro: 0.9249, F1 Macro: 0.9209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2846, Accuracy: 0.8925, F1 Micro: 0.9364, F1 Macro: 0.9331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2512, Accuracy: 0.9175, F1 Micro: 0.9503, F1 Macro: 0.947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2087, Accuracy: 0.9264, F1 Micro: 0.9554, F1 Macro: 0.9523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1833, Accuracy: 0.9326, F1 Micro: 0.9591, F1 Macro: 0.9564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1536, Accuracy: 0.9398, F1 Micro: 0.963, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.145, Accuracy: 0.9411, F1 Micro: 0.9638, F1 Macro: 0.961\n",
      "\n",
      "Aspect detection accuracy: 0.9411, F1 Micro: 0.9638, F1 Macro: 0.961\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.96      0.98      0.97       480\n",
      "         bau       0.95      0.98      0.96       496\n",
      "     general       0.89      0.99      0.93       500\n",
      "  kebersihan       0.89      0.91      0.90       317\n",
      "       linen       0.90      0.95      0.93       392\n",
      "     service       0.96      0.96      0.96       423\n",
      "sunrise_meal       0.97      0.99      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      0.99      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      4614\n",
      "   macro avg       0.95      0.97      0.96      4614\n",
      "weighted avg       0.95      0.98      0.96      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4882, Accuracy: 0.7425, F1 Micro: 0.7425, F1 Macro: 0.5551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3728, Accuracy: 0.8022, F1 Micro: 0.8022, F1 Macro: 0.699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.271, Accuracy: 0.8191, F1 Micro: 0.8191, F1 Macro: 0.78\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.209, Accuracy: 0.838, F1 Micro: 0.838, F1 Macro: 0.7939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.182, Accuracy: 0.8509, F1 Micro: 0.8509, F1 Macro: 0.805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1714, Accuracy: 0.8559, F1 Micro: 0.8559, F1 Macro: 0.8052\n",
      "Epoch 7/10, Train Loss: 0.1284, Accuracy: 0.8439, F1 Micro: 0.8439, F1 Macro: 0.7849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1109, Accuracy: 0.8579, F1 Micro: 0.8579, F1 Macro: 0.8074\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0752, Accuracy: 0.8648, F1 Micro: 0.8648, F1 Macro: 0.82\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0715, Accuracy: 0.8688, F1 Micro: 0.8688, F1 Macro: 0.8275\n",
      "\n",
      "Sentiment analysis accuracy: 0.8688, F1 Micro: 0.8688, F1 Macro: 0.8275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91       716\n",
      "    positive       0.85      0.66      0.74       290\n",
      "\n",
      "    accuracy                           0.87      1006\n",
      "   macro avg       0.86      0.81      0.83      1006\n",
      "weighted avg       0.87      0.87      0.86      1006\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.7482\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.90      0.93        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.76      0.87      0.81        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.76      0.80        86\n",
      "     neutral       0.96      0.98      0.97       475\n",
      "    positive       0.50      0.50      0.50        10\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.74      0.76       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.68      0.76        78\n",
      "     neutral       0.95      0.98      0.96       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.55      0.57       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.89      0.99      0.93       496\n",
      "    positive       0.71      0.18      0.28        68\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.53      0.39      0.41       571\n",
      "weighted avg       0.85      0.88      0.85       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.77      0.82       200\n",
      "     neutral       0.89      0.91      0.90       315\n",
      "    positive       0.71      0.95      0.81        56\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.83      0.87      0.84       571\n",
      "weighted avg       0.87      0.86      0.86       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.81      0.82       162\n",
      "     neutral       0.90      0.95      0.93       387\n",
      "    positive       1.00      0.23      0.37        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.91      0.66      0.70       571\n",
      "weighted avg       0.89      0.88      0.87       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.76      0.81        85\n",
      "     neutral       0.96      0.97      0.96       418\n",
      "    positive       0.81      0.88      0.85        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.88      0.87      0.87       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.31      0.43        29\n",
      "     neutral       0.97      0.99      0.98       525\n",
      "    positive       0.60      0.71      0.65        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.75      0.67      0.69       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.93      0.90        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.75      0.80       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.95      0.95        74\n",
      "     neutral       0.99      0.99      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.98      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 158.00045943260193 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 174\n",
      "Sampling duration: 0.00012993812561035156 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5107, Accuracy: 0.8016, F1 Micro: 0.8898, F1 Macro: 0.8854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4425, Accuracy: 0.8165, F1 Micro: 0.897, F1 Macro: 0.8925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3731, Accuracy: 0.8759, F1 Micro: 0.9266, F1 Macro: 0.9211\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3066, Accuracy: 0.9016, F1 Micro: 0.9413, F1 Macro: 0.9375\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2529, Accuracy: 0.9253, F1 Micro: 0.9548, F1 Macro: 0.9518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2043, Accuracy: 0.9328, F1 Micro: 0.9591, F1 Macro: 0.9564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1737, Accuracy: 0.9387, F1 Micro: 0.9625, F1 Macro: 0.9595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1564, Accuracy: 0.9398, F1 Micro: 0.9632, F1 Macro: 0.9604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1292, Accuracy: 0.9439, F1 Micro: 0.9655, F1 Macro: 0.9626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1134, Accuracy: 0.9455, F1 Micro: 0.9666, F1 Macro: 0.9637\n",
      "\n",
      "Aspect detection accuracy: 0.9455, F1 Micro: 0.9666, F1 Macro: 0.9637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.96      1.00      0.98       480\n",
      "         bau       0.95      0.98      0.97       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.84      0.96      0.90       317\n",
      "       linen       0.90      0.96      0.93       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.95      1.00      0.97       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.97      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4915, Accuracy: 0.7915, F1 Micro: 0.7915, F1 Macro: 0.7091\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2874, Accuracy: 0.8537, F1 Micro: 0.8537, F1 Macro: 0.8068\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2009, Accuracy: 0.8693, F1 Micro: 0.8693, F1 Macro: 0.8217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1699, Accuracy: 0.8807, F1 Micro: 0.8807, F1 Macro: 0.8453\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1536, Accuracy: 0.8952, F1 Micro: 0.8952, F1 Macro: 0.8627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0857, Accuracy: 0.8983, F1 Micro: 0.8983, F1 Macro: 0.868\n",
      "Epoch 7/10, Train Loss: 0.0727, Accuracy: 0.8828, F1 Micro: 0.8828, F1 Macro: 0.8525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0666, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.071, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8782\n",
      "Epoch 10/10, Train Loss: 0.036, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8771\n",
      "\n",
      "Sentiment analysis accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       694\n",
      "    positive       0.89      0.76      0.82       270\n",
      "\n",
      "    accuracy                           0.91       964\n",
      "   macro avg       0.90      0.86      0.88       964\n",
      "weighted avg       0.91      0.91      0.90       964\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9378, F1 Micro: 0.9378, F1 Macro: 0.7967\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.90      0.93        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.72      0.87      0.79        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.78      0.86        86\n",
      "     neutral       0.96      1.00      0.98       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.85      0.76      0.80       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.72      0.77        78\n",
      "     neutral       0.95      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.73      0.80       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.95       496\n",
      "    positive       0.83      0.44      0.58        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.58      0.48      0.51       571\n",
      "weighted avg       0.89      0.91      0.89       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.71      0.80       200\n",
      "     neutral       0.85      0.96      0.90       315\n",
      "    positive       0.82      0.88      0.84        56\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.86      0.85      0.85       571\n",
      "weighted avg       0.87      0.86      0.86       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.77      0.82       162\n",
      "     neutral       0.90      0.96      0.93       387\n",
      "    positive       0.53      0.41      0.46        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.77      0.71      0.74       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.75      0.83        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.83      0.94      0.88        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.89      0.89       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.17      0.28        29\n",
      "     neutral       0.95      1.00      0.97       525\n",
      "    positive       0.77      0.59      0.67        17\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.81      0.59      0.64       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.86      0.91       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.98      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 175.09377694129944 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 156\n",
      "Sampling duration: 0.00012993812561035156 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4963, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4028, Accuracy: 0.8523, F1 Micro: 0.9143, F1 Macro: 0.9088\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3265, Accuracy: 0.8944, F1 Micro: 0.937, F1 Macro: 0.932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2661, Accuracy: 0.9212, F1 Micro: 0.9525, F1 Macro: 0.949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2177, Accuracy: 0.9292, F1 Micro: 0.9572, F1 Macro: 0.9551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1827, Accuracy: 0.9368, F1 Micro: 0.9616, F1 Macro: 0.9587\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1481, Accuracy: 0.9439, F1 Micro: 0.9656, F1 Macro: 0.9631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1396, Accuracy: 0.9512, F1 Micro: 0.97, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1164, Accuracy: 0.9526, F1 Micro: 0.9708, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0972, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9706\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.97      0.97       496\n",
      "     general       0.93      0.98      0.96       500\n",
      "  kebersihan       0.91      0.91      0.91       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4738, Accuracy: 0.8181, F1 Micro: 0.8181, F1 Macro: 0.7481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3107, Accuracy: 0.8507, F1 Micro: 0.8507, F1 Macro: 0.8044\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2082, Accuracy: 0.8591, F1 Micro: 0.8591, F1 Macro: 0.8105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1765, Accuracy: 0.8713, F1 Micro: 0.8713, F1 Macro: 0.83\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1474, Accuracy: 0.8722, F1 Micro: 0.8722, F1 Macro: 0.8365\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1141, Accuracy: 0.8918, F1 Micro: 0.8918, F1 Macro: 0.8601\n",
      "Epoch 7/10, Train Loss: 0.0787, Accuracy: 0.8834, F1 Micro: 0.8834, F1 Macro: 0.8443\n",
      "Epoch 8/10, Train Loss: 0.0558, Accuracy: 0.8843, F1 Micro: 0.8843, F1 Macro: 0.8494\n",
      "Epoch 9/10, Train Loss: 0.0603, Accuracy: 0.8871, F1 Micro: 0.8871, F1 Macro: 0.8536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0582, Accuracy: 0.8946, F1 Micro: 0.8946, F1 Macro: 0.8645\n",
      "\n",
      "Sentiment analysis accuracy: 0.8946, F1 Micro: 0.8946, F1 Macro: 0.8645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93       758\n",
      "    positive       0.90      0.72      0.80       314\n",
      "\n",
      "    accuracy                           0.89      1072\n",
      "   macro avg       0.90      0.84      0.86      1072\n",
      "weighted avg       0.89      0.89      0.89      1072\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.8306\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.78      0.93      0.85        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.95      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.84      0.88        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.84      0.84       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.78      0.79        78\n",
      "     neutral       0.96      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.75      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.83      0.57      0.68        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.52      0.55       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.85       200\n",
      "     neutral       0.91      0.91      0.91       315\n",
      "    positive       0.77      0.95      0.85        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.85      0.89      0.87       571\n",
      "weighted avg       0.89      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.78      0.83       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.80      0.83        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.88      0.93      0.90        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.90      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.52      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.65      0.69        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.72      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.95        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.87      0.87      0.87       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 198.09158420562744 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 141\n",
      "Sampling duration: 0.00011968612670898438 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4965, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4059, Accuracy: 0.8632, F1 Micro: 0.9203, F1 Macro: 0.9147\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3127, Accuracy: 0.9059, F1 Micro: 0.9438, F1 Macro: 0.9397\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2384, Accuracy: 0.9318, F1 Micro: 0.9586, F1 Macro: 0.9562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1957, Accuracy: 0.9382, F1 Micro: 0.9625, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1625, Accuracy: 0.9436, F1 Micro: 0.9656, F1 Macro: 0.9632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1429, Accuracy: 0.9472, F1 Micro: 0.9677, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1229, Accuracy: 0.9516, F1 Micro: 0.9701, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1016, Accuracy: 0.9557, F1 Micro: 0.9726, F1 Macro: 0.9701\n",
      "Epoch 10/10, Train Loss: 0.0943, Accuracy: 0.9545, F1 Micro: 0.9721, F1 Macro: 0.9694\n",
      "\n",
      "Aspect detection accuracy: 0.9557, F1 Micro: 0.9726, F1 Macro: 0.9701\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.89      0.94      0.92       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      0.99      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.43, Accuracy: 0.8348, F1 Micro: 0.8348, F1 Macro: 0.7692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2513, Accuracy: 0.8443, F1 Micro: 0.8443, F1 Macro: 0.774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1825, Accuracy: 0.8682, F1 Micro: 0.8682, F1 Macro: 0.8257\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1626, Accuracy: 0.8787, F1 Micro: 0.8787, F1 Macro: 0.8361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1299, Accuracy: 0.8863, F1 Micro: 0.8863, F1 Macro: 0.857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0738, Accuracy: 0.8883, F1 Micro: 0.8883, F1 Macro: 0.8473\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0702, Accuracy: 0.9007, F1 Micro: 0.9007, F1 Macro: 0.8696\n",
      "Epoch 8/10, Train Loss: 0.0428, Accuracy: 0.8949, F1 Micro: 0.8949, F1 Macro: 0.8617\n",
      "Epoch 9/10, Train Loss: 0.0289, Accuracy: 0.8997, F1 Micro: 0.8997, F1 Macro: 0.871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0276, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8763\n",
      "\n",
      "Sentiment analysis accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       749\n",
      "    positive       0.91      0.74      0.82       298\n",
      "\n",
      "    accuracy                           0.91      1047\n",
      "   macro avg       0.91      0.86      0.88      1047\n",
      "weighted avg       0.91      0.91      0.90      1047\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9489, F1 Micro: 0.9489, F1 Macro: 0.8373\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.70      0.93      0.80        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.94      0.91       571\n",
      "weighted avg       0.98      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.88        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.82      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.77      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.83      0.50      0.62        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.59      0.49      0.53       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.86       200\n",
      "     neutral       0.90      0.94      0.92       315\n",
      "    positive       0.84      0.93      0.88        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.88      0.89      0.88       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.86       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.48      0.61        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.73      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      1.00      0.98        74\n",
      "     neutral       1.00      0.99      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 215.22177839279175 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 127\n",
      "Sampling duration: 0.00017380714416503906 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4862, Accuracy: 0.8012, F1 Micro: 0.8896, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3792, Accuracy: 0.8823, F1 Micro: 0.9302, F1 Macro: 0.9239\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2818, Accuracy: 0.9177, F1 Micro: 0.9505, F1 Macro: 0.9474\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2243, Accuracy: 0.9352, F1 Micro: 0.9607, F1 Macro: 0.9587\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1794, Accuracy: 0.9457, F1 Micro: 0.9668, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.149, Accuracy: 0.9514, F1 Micro: 0.9701, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1257, Accuracy: 0.9528, F1 Micro: 0.971, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1114, Accuracy: 0.9536, F1 Micro: 0.9714, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0943, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9714\n",
      "Epoch 10/10, Train Loss: 0.0795, Accuracy: 0.9571, F1 Micro: 0.9734, F1 Macro: 0.9709\n",
      "\n",
      "Aspect detection accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.90      0.98      0.94       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.424, Accuracy: 0.8496, F1 Micro: 0.8496, F1 Macro: 0.8027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2507, Accuracy: 0.8582, F1 Micro: 0.8582, F1 Macro: 0.8259\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2025, Accuracy: 0.8822, F1 Micro: 0.8822, F1 Macro: 0.8473\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1425, Accuracy: 0.8946, F1 Micro: 0.8946, F1 Macro: 0.8619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1099, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8715\n",
      "Epoch 6/10, Train Loss: 0.0624, Accuracy: 0.8994, F1 Micro: 0.8994, F1 Macro: 0.8709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0592, Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8834\n",
      "Epoch 8/10, Train Loss: 0.053, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8723\n",
      "Epoch 9/10, Train Loss: 0.0294, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8714\n",
      "Epoch 10/10, Train Loss: 0.0217, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8733\n",
      "\n",
      "Sentiment analysis accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8834\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       744\n",
      "    positive       0.90      0.77      0.83       300\n",
      "\n",
      "    accuracy                           0.91      1044\n",
      "   macro avg       0.91      0.87      0.88      1044\n",
      "weighted avg       0.91      0.91      0.91      1044\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.822\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.89      0.92        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.68      1.00      0.81        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.96      0.91       571\n",
      "weighted avg       0.98      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.81      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.79      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.97      0.96       496\n",
      "    positive       0.84      0.62      0.71        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.53      0.56       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.88       200\n",
      "     neutral       0.93      0.92      0.93       315\n",
      "    positive       0.82      0.95      0.88        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.88      0.91      0.89       571\n",
      "weighted avg       0.91      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85       162\n",
      "     neutral       0.93      0.96      0.94       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.74      0.78       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.52      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.74      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.92        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.60      0.50      0.55         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 230.48521423339844 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 114\n",
      "Sampling duration: 0.00011277198791503906 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4863, Accuracy: 0.8035, F1 Micro: 0.8906, F1 Macro: 0.886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3714, Accuracy: 0.8946, F1 Micro: 0.9374, F1 Macro: 0.9332\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2672, Accuracy: 0.9288, F1 Micro: 0.9569, F1 Macro: 0.9545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2062, Accuracy: 0.9405, F1 Micro: 0.9636, F1 Macro: 0.9616\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1703, Accuracy: 0.9441, F1 Micro: 0.9659, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.146, Accuracy: 0.9528, F1 Micro: 0.9709, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1243, Accuracy: 0.9554, F1 Micro: 0.9725, F1 Macro: 0.9701\n",
      "Epoch 8/10, Train Loss: 0.0976, Accuracy: 0.9538, F1 Micro: 0.9717, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0903, Accuracy: 0.9597, F1 Micro: 0.975, F1 Macro: 0.9727\n",
      "Epoch 10/10, Train Loss: 0.0771, Accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.9723\n",
      "\n",
      "Aspect detection accuracy: 0.9597, F1 Micro: 0.975, F1 Macro: 0.9727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.97      0.96       500\n",
      "  kebersihan       0.91      0.95      0.93       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4316, Accuracy: 0.8438, F1 Micro: 0.8438, F1 Macro: 0.7792\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2577, Accuracy: 0.8634, F1 Micro: 0.8634, F1 Macro: 0.8125\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1792, Accuracy: 0.8868, F1 Micro: 0.8868, F1 Macro: 0.8524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1462, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8727\n",
      "Epoch 5/10, Train Loss: 0.1052, Accuracy: 0.8952, F1 Micro: 0.8952, F1 Macro: 0.8613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0771, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8803\n",
      "Epoch 7/10, Train Loss: 0.0366, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8724\n",
      "Epoch 8/10, Train Loss: 0.0351, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8741\n",
      "Epoch 9/10, Train Loss: 0.034, Accuracy: 0.8971, F1 Micro: 0.8971, F1 Macro: 0.8613\n",
      "Epoch 10/10, Train Loss: 0.033, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8772\n",
      "\n",
      "Sentiment analysis accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       760\n",
      "    positive       0.93      0.73      0.82       309\n",
      "\n",
      "    accuracy                           0.91      1069\n",
      "   macro avg       0.92      0.86      0.88      1069\n",
      "weighted avg       0.91      0.91      0.90      1069\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9517, F1 Micro: 0.9517, F1 Macro: 0.8237\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.92      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.82      0.93      0.87        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.95      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.85      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.85      0.85       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.81      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.77      0.76      0.76       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.97      0.96       496\n",
      "    positive       0.77      0.65      0.70        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.57      0.54      0.55       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.82      0.86       200\n",
      "     neutral       0.91      0.94      0.93       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.90      0.90       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.87      0.86       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       1.00      0.27      0.43        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.70      0.75       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.83      0.94      0.88        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.90      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.65      0.88      0.75        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.78      0.78       571\n",
      "weighted avg       0.97      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.86      0.99      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 245.5424084663391 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 103\n",
      "Sampling duration: 0.00018310546875 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4827, Accuracy: 0.8127, F1 Micro: 0.8942, F1 Macro: 0.8875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.359, Accuracy: 0.8967, F1 Micro: 0.9387, F1 Macro: 0.9352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2653, Accuracy: 0.9352, F1 Micro: 0.9606, F1 Macro: 0.9583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1964, Accuracy: 0.9392, F1 Micro: 0.963, F1 Macro: 0.9606\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1678, Accuracy: 0.95, F1 Micro: 0.9691, F1 Macro: 0.9664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1422, Accuracy: 0.9569, F1 Micro: 0.9735, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1107, Accuracy: 0.9587, F1 Micro: 0.9746, F1 Macro: 0.9724\n",
      "Epoch 8/10, Train Loss: 0.0983, Accuracy: 0.958, F1 Micro: 0.9741, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0831, Accuracy: 0.9611, F1 Micro: 0.9758, F1 Macro: 0.9732\n",
      "Epoch 10/10, Train Loss: 0.0733, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9729\n",
      "\n",
      "Aspect detection accuracy: 0.9611, F1 Micro: 0.9758, F1 Macro: 0.9732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.90      0.92       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4335, Accuracy: 0.8364, F1 Micro: 0.8364, F1 Macro: 0.7696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2594, Accuracy: 0.8729, F1 Micro: 0.8729, F1 Macro: 0.8382\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1935, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1331, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8775\n",
      "Epoch 5/10, Train Loss: 0.0856, Accuracy: 0.8985, F1 Micro: 0.8985, F1 Macro: 0.8685\n",
      "Epoch 6/10, Train Loss: 0.0635, Accuracy: 0.9022, F1 Micro: 0.9022, F1 Macro: 0.877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0664, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8832\n",
      "Epoch 8/10, Train Loss: 0.0423, Accuracy: 0.904, F1 Micro: 0.904, F1 Macro: 0.8791\n",
      "Epoch 9/10, Train Loss: 0.0334, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8827\n",
      "Epoch 10/10, Train Loss: 0.0283, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8748\n",
      "\n",
      "Sentiment analysis accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       769\n",
      "    positive       0.93      0.74      0.83       325\n",
      "\n",
      "    accuracy                           0.91      1094\n",
      "   macro avg       0.92      0.86      0.88      1094\n",
      "weighted avg       0.91      0.91      0.91      1094\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.8552\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.79      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.83      0.71      0.76        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.56      0.58       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.89      0.87       200\n",
      "     neutral       0.94      0.90      0.92       315\n",
      "    positive       0.86      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.88      0.90      0.89       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.89       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.86      0.55      0.67        22\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.90      0.79      0.84       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.88      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.91      0.91      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.88      0.77      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 263.11382603645325 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 62\n",
      "Sampling duration: 0.031193256378173828 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4743, Accuracy: 0.8222, F1 Micro: 0.8997, F1 Macro: 0.8951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.344, Accuracy: 0.9052, F1 Micro: 0.9432, F1 Macro: 0.9396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2517, Accuracy: 0.938, F1 Micro: 0.9622, F1 Macro: 0.9602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1954, Accuracy: 0.9443, F1 Micro: 0.9659, F1 Macro: 0.9636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1612, Accuracy: 0.9503, F1 Micro: 0.9696, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1314, Accuracy: 0.9547, F1 Micro: 0.972, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1113, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9724\n",
      "Epoch 8/10, Train Loss: 0.0902, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9724\n",
      "Epoch 9/10, Train Loss: 0.0799, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0691, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9725\n",
      "\n",
      "Aspect detection accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.97      0.96       500\n",
      "  kebersihan       0.88      0.96      0.92       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3923, Accuracy: 0.8531, F1 Micro: 0.8531, F1 Macro: 0.8162\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.242, Accuracy: 0.8719, F1 Micro: 0.8719, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1809, Accuracy: 0.8983, F1 Micro: 0.8983, F1 Macro: 0.8684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1267, Accuracy: 0.8983, F1 Micro: 0.8983, F1 Macro: 0.8652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0951, Accuracy: 0.9002, F1 Micro: 0.9002, F1 Macro: 0.87\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0673, Accuracy: 0.904, F1 Micro: 0.904, F1 Macro: 0.8763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.042, Accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8956\n",
      "Epoch 8/10, Train Loss: 0.0367, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8781\n",
      "Epoch 9/10, Train Loss: 0.0186, Accuracy: 0.8964, F1 Micro: 0.8964, F1 Macro: 0.8607\n",
      "Epoch 10/10, Train Loss: 0.0297, Accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.882\n",
      "\n",
      "Sentiment analysis accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94       754\n",
      "    positive       0.92      0.78      0.85       308\n",
      "\n",
      "    accuracy                           0.92      1062\n",
      "   macro avg       0.92      0.88      0.90      1062\n",
      "weighted avg       0.92      0.92      0.92      1062\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9525, F1 Micro: 0.9525, F1 Macro: 0.845\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.78      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.97      0.96       496\n",
      "    positive       0.76      0.71      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.57      0.56      0.56       571\n",
      "weighted avg       0.91      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.79      0.84       200\n",
      "     neutral       0.88      0.96      0.92       315\n",
      "    positive       0.83      0.86      0.84        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.87      0.87      0.87       571\n",
      "weighted avg       0.89      0.89      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.93      0.75      0.80       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.87      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.88      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.75      0.80       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 270.37142848968506 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 86\n",
      "Sampling duration: 0.00010204315185546875 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4682, Accuracy: 0.8326, F1 Micro: 0.9046, F1 Macro: 0.8996\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3426, Accuracy: 0.9111, F1 Micro: 0.9467, F1 Macro: 0.9436\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2284, Accuracy: 0.937, F1 Micro: 0.9617, F1 Macro: 0.9596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1836, Accuracy: 0.9474, F1 Micro: 0.9678, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1473, Accuracy: 0.9526, F1 Micro: 0.9708, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.123, Accuracy: 0.9531, F1 Micro: 0.9711, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1058, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0906, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9745\n",
      "Epoch 9/10, Train Loss: 0.076, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9735\n",
      "Epoch 10/10, Train Loss: 0.0663, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.91      0.96      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3886, Accuracy: 0.8481, F1 Micro: 0.8481, F1 Macro: 0.7841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2307, Accuracy: 0.8751, F1 Micro: 0.8751, F1 Macro: 0.8346\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1652, Accuracy: 0.9021, F1 Micro: 0.9021, F1 Macro: 0.8747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1206, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8859\n",
      "Epoch 5/10, Train Loss: 0.0649, Accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.8832\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0691, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8915\n",
      "Epoch 7/10, Train Loss: 0.0515, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8806\n",
      "Epoch 8/10, Train Loss: 0.0367, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8803\n",
      "Epoch 9/10, Train Loss: 0.0188, Accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.8773\n",
      "Epoch 10/10, Train Loss: 0.0348, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8827\n",
      "\n",
      "Sentiment analysis accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       762\n",
      "    positive       0.94      0.76      0.84       311\n",
      "\n",
      "    accuracy                           0.92      1073\n",
      "   macro avg       0.92      0.87      0.89      1073\n",
      "weighted avg       0.92      0.92      0.91      1073\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.8471\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.80      0.40      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.76      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.81      0.74      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.57      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.85      0.89      0.87        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.90      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.90      0.88       162\n",
      "     neutral       0.95      0.97      0.96       387\n",
      "    positive       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.94      0.76      0.81       571\n",
      "weighted avg       0.93      0.93      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.87      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.90      0.91      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.59      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.85      0.65      0.73        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.74      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.92        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.76      0.80       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 277.55267429351807 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 77\n",
      "Sampling duration: 9.989738464355469e-05 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4594, Accuracy: 0.8377, F1 Micro: 0.9069, F1 Macro: 0.9014\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3397, Accuracy: 0.9142, F1 Micro: 0.9485, F1 Macro: 0.9454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2314, Accuracy: 0.9389, F1 Micro: 0.9626, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1843, Accuracy: 0.9464, F1 Micro: 0.9673, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1482, Accuracy: 0.9533, F1 Micro: 0.9714, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1227, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9741\n",
      "Epoch 7/10, Train Loss: 0.1046, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9731\n",
      "Epoch 8/10, Train Loss: 0.085, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0739, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.063, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4134, Accuracy: 0.8607, F1 Micro: 0.8607, F1 Macro: 0.8112\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2254, Accuracy: 0.8736, F1 Micro: 0.8736, F1 Macro: 0.8292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1508, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1127, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.881\n",
      "Epoch 5/10, Train Loss: 0.0751, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8841\n",
      "Epoch 6/10, Train Loss: 0.0539, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.8764\n",
      "Epoch 7/10, Train Loss: 0.041, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.8784\n",
      "Epoch 8/10, Train Loss: 0.0394, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.8753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0247, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0234, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8828\n",
      "\n",
      "Sentiment analysis accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       773\n",
      "    positive       0.93      0.74      0.83       311\n",
      "\n",
      "    accuracy                           0.91      1084\n",
      "   macro avg       0.92      0.86      0.88      1084\n",
      "weighted avg       0.91      0.91      0.91      1084\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9564, F1 Micro: 0.9564, F1 Macro: 0.8488\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.90      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.78      0.93      0.85        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.86      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.81       571\n",
      "weighted avg       0.96      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.82      0.69      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.60      0.66       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.94      0.78      0.83       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.52      0.62        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.77      0.59      0.67        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.70      0.76       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 290.69236278533936 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 70\n",
      "Sampling duration: 8.893013000488281e-05 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4698, Accuracy: 0.838, F1 Micro: 0.9073, F1 Macro: 0.9018\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.325, Accuracy: 0.9208, F1 Micro: 0.9521, F1 Macro: 0.9496\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2293, Accuracy: 0.9398, F1 Micro: 0.9632, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1788, Accuracy: 0.9465, F1 Micro: 0.9672, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1471, Accuracy: 0.9552, F1 Micro: 0.9725, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.118, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1077, Accuracy: 0.9623, F1 Micro: 0.9765, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0902, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9743\n",
      "Epoch 9/10, Train Loss: 0.0718, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0616, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9748\n",
      "\n",
      "Aspect detection accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.92      0.98      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3833, Accuracy: 0.8605, F1 Micro: 0.8605, F1 Macro: 0.8191\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.202, Accuracy: 0.8923, F1 Micro: 0.8923, F1 Macro: 0.8573\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1342, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1062, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0707, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0579, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8903\n",
      "Epoch 7/10, Train Loss: 0.0433, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0359, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.8917\n",
      "Epoch 9/10, Train Loss: 0.0225, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8905\n",
      "Epoch 10/10, Train Loss: 0.0238, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8837\n",
      "\n",
      "Sentiment analysis accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.8917\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       766\n",
      "    positive       0.94      0.76      0.84       302\n",
      "\n",
      "    accuracy                           0.92      1068\n",
      "   macro avg       0.92      0.87      0.89      1068\n",
      "weighted avg       0.92      0.92      0.91      1068\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9557, F1 Micro: 0.9557, F1 Macro: 0.8464\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.81      0.68      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.58      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.88       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.85      0.84      0.85        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.89      0.89       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.83      0.86       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.94      0.75      0.81       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.96      0.94      0.95        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.62      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.53      0.64        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.72      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 304.7085943222046 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 52\n",
      "Sampling duration: 0.0200808048248291 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.454, Accuracy: 0.85, F1 Micro: 0.9133, F1 Macro: 0.9077\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3096, Accuracy: 0.9238, F1 Micro: 0.9538, F1 Macro: 0.9509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2228, Accuracy: 0.9432, F1 Micro: 0.9653, F1 Macro: 0.9631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1714, Accuracy: 0.95, F1 Micro: 0.9692, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1403, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.112, Accuracy: 0.9569, F1 Micro: 0.9735, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0906, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0813, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.071, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9764\n",
      "Epoch 10/10, Train Loss: 0.0581, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.95      0.97      0.96       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3848, Accuracy: 0.8647, F1 Micro: 0.8647, F1 Macro: 0.8185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2257, Accuracy: 0.8876, F1 Micro: 0.8876, F1 Macro: 0.8529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1589, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1094, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.8892\n",
      "Epoch 5/10, Train Loss: 0.0882, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0543, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.8882\n",
      "Epoch 7/10, Train Loss: 0.0316, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8848\n",
      "Epoch 8/10, Train Loss: 0.0447, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8866\n",
      "Epoch 9/10, Train Loss: 0.032, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8859\n",
      "Epoch 10/10, Train Loss: 0.026, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.877\n",
      "\n",
      "Sentiment analysis accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.8882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       780\n",
      "    positive       0.93      0.75      0.83       314\n",
      "\n",
      "    accuracy                           0.91      1094\n",
      "   macro avg       0.92      0.87      0.89      1094\n",
      "weighted avg       0.92      0.91      0.91      1094\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9571, F1 Micro: 0.9571, F1 Macro: 0.8245\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.60      0.30      0.40        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.72      0.76       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.80      0.71      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.58      0.56      0.57       571\n",
      "weighted avg       0.92      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.90      0.88       162\n",
      "     neutral       0.95      0.97      0.96       387\n",
      "    positive       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.94      0.76      0.81       571\n",
      "weighted avg       0.93      0.93      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.55      0.63        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.71      0.73        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.75      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.96      0.91        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.71      0.73       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 308.85275530815125 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 58\n",
      "Sampling duration: 8.463859558105469e-05 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4644, Accuracy: 0.845, F1 Micro: 0.9109, F1 Macro: 0.9056\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3116, Accuracy: 0.9212, F1 Micro: 0.9522, F1 Macro: 0.9483\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2155, Accuracy: 0.9422, F1 Micro: 0.9647, F1 Macro: 0.9624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1708, Accuracy: 0.9507, F1 Micro: 0.9696, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1427, Accuracy: 0.9542, F1 Micro: 0.9718, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1165, Accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0969, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9737\n",
      "Epoch 8/10, Train Loss: 0.0825, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0702, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "Epoch 10/10, Train Loss: 0.0602, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3521, Accuracy: 0.8467, F1 Micro: 0.8467, F1 Macro: 0.7842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2177, Accuracy: 0.8777, F1 Micro: 0.8777, F1 Macro: 0.8362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1652, Accuracy: 0.8987, F1 Micro: 0.8987, F1 Macro: 0.8661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1179, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.885\n",
      "Epoch 5/10, Train Loss: 0.0936, Accuracy: 0.8914, F1 Micro: 0.8914, F1 Macro: 0.8554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0564, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8817\n",
      "Epoch 7/10, Train Loss: 0.0509, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8742\n",
      "Epoch 8/10, Train Loss: 0.0331, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0324, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8867\n",
      "Epoch 10/10, Train Loss: 0.0228, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8851\n",
      "\n",
      "Sentiment analysis accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       777\n",
      "    positive       0.92      0.76      0.83       319\n",
      "\n",
      "    accuracy                           0.91      1096\n",
      "   macro avg       0.91      0.87      0.89      1096\n",
      "weighted avg       0.91      0.91      0.91      1096\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9587, F1 Micro: 0.9587, F1 Macro: 0.8649\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.85      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.81      0.93      0.86       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.87      0.76      0.81        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.58      0.59       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.90      0.89       162\n",
      "     neutral       0.95      0.96      0.96       387\n",
      "    positive       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.94      0.79      0.84       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 316.7863826751709 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 52\n",
      "Sampling duration: 8.58306884765625e-05 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4617, Accuracy: 0.85, F1 Micro: 0.9138, F1 Macro: 0.9091\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3007, Accuracy: 0.9233, F1 Micro: 0.9537, F1 Macro: 0.951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2146, Accuracy: 0.9431, F1 Micro: 0.9652, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1676, Accuracy: 0.9464, F1 Micro: 0.9672, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1417, Accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1152, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9748\n",
      "Epoch 7/10, Train Loss: 0.0967, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.973\n",
      "Epoch 8/10, Train Loss: 0.0809, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0691, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.976\n",
      "Epoch 10/10, Train Loss: 0.0577, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9754\n",
      "\n",
      "Aspect detection accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.93      0.98      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3703, Accuracy: 0.8491, F1 Micro: 0.8491, F1 Macro: 0.7786\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1994, Accuracy: 0.8838, F1 Micro: 0.8838, F1 Macro: 0.844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1419, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.8819\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0973, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.8992\n",
      "Epoch 5/10, Train Loss: 0.0911, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8892\n",
      "Epoch 6/10, Train Loss: 0.0468, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.8948\n",
      "Epoch 7/10, Train Loss: 0.0524, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.8952\n",
      "Epoch 8/10, Train Loss: 0.0321, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.8961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0231, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.8981\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.028, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.8983\n",
      "\n",
      "Sentiment analysis accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.8983\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.95       766\n",
      "    positive       0.92      0.79      0.85       301\n",
      "\n",
      "    accuracy                           0.92      1067\n",
      "   macro avg       0.92      0.88      0.90      1067\n",
      "weighted avg       0.92      0.92      0.92      1067\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9574, F1 Micro: 0.9574, F1 Macro: 0.851\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.75      1.00      0.86        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.97      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.86      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.85      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.81      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.82      0.69      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.56      0.57       571\n",
      "weighted avg       0.92      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.89       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.77      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.52      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.74      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 320.33056449890137 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.843971252441406e-05 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4571, Accuracy: 0.8627, F1 Micro: 0.9199, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2969, Accuracy: 0.9323, F1 Micro: 0.9589, F1 Macro: 0.9566\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2029, Accuracy: 0.946, F1 Micro: 0.9669, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1588, Accuracy: 0.953, F1 Micro: 0.971, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1318, Accuracy: 0.9569, F1 Micro: 0.9735, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1063, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9731\n",
      "Epoch 7/10, Train Loss: 0.0897, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0791, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9768\n",
      "Epoch 9/10, Train Loss: 0.0664, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9749\n",
      "Epoch 10/10, Train Loss: 0.0572, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.96      0.92      0.94       317\n",
      "       linen       0.94      0.97      0.96       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3705, Accuracy: 0.8528, F1 Micro: 0.8528, F1 Macro: 0.8214\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2263, Accuracy: 0.8844, F1 Micro: 0.8844, F1 Macro: 0.847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1546, Accuracy: 0.8925, F1 Micro: 0.8925, F1 Macro: 0.8593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1079, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0772, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8855\n",
      "Epoch 6/10, Train Loss: 0.0521, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.8641\n",
      "Epoch 7/10, Train Loss: 0.0597, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8748\n",
      "Epoch 8/10, Train Loss: 0.0341, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8717\n",
      "Epoch 9/10, Train Loss: 0.0179, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8827\n",
      "Epoch 10/10, Train Loss: 0.03, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8706\n",
      "\n",
      "Sentiment analysis accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8855\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       785\n",
      "    positive       0.95      0.74      0.83       322\n",
      "\n",
      "    accuracy                           0.91      1107\n",
      "   macro avg       0.93      0.86      0.89      1107\n",
      "weighted avg       0.92      0.91      0.91      1107\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9573, F1 Micro: 0.9573, F1 Macro: 0.8498\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.92      0.92        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.93      0.95      0.94       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.91      0.80      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.81      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.12      0.14      0.13         7\n",
      "     neutral       0.96      0.97      0.96       496\n",
      "    positive       0.83      0.74      0.78        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.64      0.62      0.63       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.94      0.90       200\n",
      "     neutral       0.96      0.92      0.94       315\n",
      "    positive       0.89      0.84      0.86        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.90      0.90       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.89      0.88       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       1.00      0.36      0.53        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.94      0.74      0.79       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.59      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.72      0.76      0.74        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.78      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.96      0.82      0.86       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 325.6778349876404 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.390975952148438e-05 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4586, Accuracy: 0.8639, F1 Micro: 0.9208, F1 Macro: 0.9156\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2864, Accuracy: 0.929, F1 Micro: 0.957, F1 Macro: 0.9543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2039, Accuracy: 0.9453, F1 Micro: 0.9666, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1626, Accuracy: 0.9528, F1 Micro: 0.971, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1301, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.107, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0896, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0782, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.976\n",
      "Epoch 9/10, Train Loss: 0.0663, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.055, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.977\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.94      0.94       317\n",
      "       linen       0.95      0.97      0.96       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.382, Accuracy: 0.8595, F1 Micro: 0.8595, F1 Macro: 0.8075\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2182, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8753\n",
      "Epoch 3/10, Train Loss: 0.1407, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1077, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8891\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0649, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8905\n",
      "Epoch 6/10, Train Loss: 0.0536, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.879\n",
      "Epoch 7/10, Train Loss: 0.0403, Accuracy: 0.9155, F1 Micro: 0.9155, F1 Macro: 0.8894\n",
      "Epoch 8/10, Train Loss: 0.0352, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8838\n",
      "Epoch 9/10, Train Loss: 0.0348, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8877\n",
      "Epoch 10/10, Train Loss: 0.0215, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8777\n",
      "\n",
      "Sentiment analysis accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       781\n",
      "    positive       0.93      0.76      0.84       308\n",
      "\n",
      "    accuracy                           0.92      1089\n",
      "   macro avg       0.92      0.87      0.89      1089\n",
      "weighted avg       0.92      0.92      0.91      1089\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.8388\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.90      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.74      0.93      0.82        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.94      0.91       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.81      0.88        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.54      0.70      0.61        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.84      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.81      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91       200\n",
      "     neutral       0.95      0.94      0.94       315\n",
      "    positive       0.88      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.89      0.88       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.88      0.32      0.47        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.73      0.77       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.55      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.71      0.73        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.75      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.67      0.33      0.44         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.86      0.75      0.79       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.43      1.00      0.60         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.80      0.98      0.85       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 335.4565131664276 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 6.151199340820312e-05 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4518, Accuracy: 0.8651, F1 Micro: 0.9209, F1 Macro: 0.9139\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2863, Accuracy: 0.9314, F1 Micro: 0.9583, F1 Macro: 0.9558\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2013, Accuracy: 0.9432, F1 Micro: 0.9654, F1 Macro: 0.9632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1544, Accuracy: 0.9543, F1 Micro: 0.9718, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.129, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9736\n",
      "Epoch 6/10, Train Loss: 0.1085, Accuracy: 0.9602, F1 Micro: 0.9755, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0901, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0742, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9762\n",
      "Epoch 9/10, Train Loss: 0.0669, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9756\n",
      "Epoch 10/10, Train Loss: 0.0532, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.95      0.97      0.96       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3532, Accuracy: 0.86, F1 Micro: 0.86, F1 Macro: 0.82\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2225, Accuracy: 0.8867, F1 Micro: 0.8867, F1 Macro: 0.8447\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1499, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8777\n",
      "Epoch 4/10, Train Loss: 0.0926, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8792\n",
      "Epoch 5/10, Train Loss: 0.0918, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0458, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0513, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.8906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0324, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.8947\n",
      "Epoch 9/10, Train Loss: 0.0261, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8812\n",
      "Epoch 10/10, Train Loss: 0.0282, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8821\n",
      "\n",
      "Sentiment analysis accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.8947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94       776\n",
      "    positive       0.92      0.78      0.85       310\n",
      "\n",
      "    accuracy                           0.92      1086\n",
      "   macro avg       0.92      0.88      0.89      1086\n",
      "weighted avg       0.92      0.92      0.92      1086\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9571, F1 Micro: 0.9571, F1 Macro: 0.8374\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.90      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.96      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.83      0.89        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.58      0.70      0.64        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.84      0.84       571\n",
      "weighted avg       0.97      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.83      0.74      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91       200\n",
      "     neutral       0.95      0.94      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87       162\n",
      "     neutral       0.95      0.97      0.96       387\n",
      "    positive       0.62      0.59      0.60        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.82      0.80      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.87      0.96      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.52      0.61        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.69      0.65      0.67        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.72      0.76       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.50      1.00      0.67         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.82      0.99      0.88       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 339.45446968078613 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 25\n",
      "Sampling duration: 0.016931772232055664 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4551, Accuracy: 0.8689, F1 Micro: 0.9231, F1 Macro: 0.9165\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2845, Accuracy: 0.9316, F1 Micro: 0.9586, F1 Macro: 0.9565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1956, Accuracy: 0.949, F1 Micro: 0.9687, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1535, Accuracy: 0.9557, F1 Micro: 0.9727, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1282, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1024, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "Epoch 7/10, Train Loss: 0.0874, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9744\n",
      "Epoch 8/10, Train Loss: 0.0705, Accuracy: 0.9637, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Epoch 9/10, Train Loss: 0.0618, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9747\n",
      "Epoch 10/10, Train Loss: 0.0514, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9741\n",
      "\n",
      "Aspect detection accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3649, Accuracy: 0.8607, F1 Micro: 0.8607, F1 Macro: 0.813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.239, Accuracy: 0.8964, F1 Micro: 0.8964, F1 Macro: 0.8705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1637, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1109, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8823\n",
      "Epoch 5/10, Train Loss: 0.0971, Accuracy: 0.8964, F1 Micro: 0.8964, F1 Macro: 0.8618\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0798, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8844\n",
      "Epoch 7/10, Train Loss: 0.056, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.88\n",
      "Epoch 8/10, Train Loss: 0.05, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8833\n",
      "Epoch 9/10, Train Loss: 0.0303, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.865\n",
      "Epoch 10/10, Train Loss: 0.0284, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8697\n",
      "\n",
      "Sentiment analysis accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       776\n",
      "    positive       0.93      0.75      0.83       315\n",
      "\n",
      "    accuracy                           0.91      1091\n",
      "   macro avg       0.92      0.86      0.88      1091\n",
      "weighted avg       0.91      0.91      0.91      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9543, F1 Micro: 0.9543, F1 Macro: 0.8441\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.81      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       200\n",
      "     neutral       0.96      0.91      0.94       315\n",
      "    positive       0.77      0.98      0.87        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.93      0.89       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85       162\n",
      "     neutral       0.95      0.96      0.95       387\n",
      "    positive       0.57      0.18      0.28        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.78      0.67      0.69       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.89      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.78      0.80       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.92        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.81      0.86       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 351.07054257392883 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.989738464355469e-05 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4457, Accuracy: 0.8644, F1 Micro: 0.9211, F1 Macro: 0.9163\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2761, Accuracy: 0.9276, F1 Micro: 0.9562, F1 Macro: 0.9539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1976, Accuracy: 0.9451, F1 Micro: 0.9665, F1 Macro: 0.9639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1527, Accuracy: 0.9491, F1 Micro: 0.9689, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1243, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1012, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "Epoch 7/10, Train Loss: 0.0873, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0749, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0613, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "Epoch 10/10, Train Loss: 0.0517, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.93       317\n",
      "       linen       0.93      0.98      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3633, Accuracy: 0.8654, F1 Micro: 0.8654, F1 Macro: 0.818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2083, Accuracy: 0.8956, F1 Micro: 0.8956, F1 Macro: 0.8665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1406, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0891, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0787, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0558, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0417, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0392, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8903\n",
      "Epoch 9/10, Train Loss: 0.0276, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8858\n",
      "Epoch 10/10, Train Loss: 0.0218, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8796\n",
      "\n",
      "Sentiment analysis accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8903\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       777\n",
      "    positive       0.94      0.75      0.84       315\n",
      "\n",
      "    accuracy                           0.92      1092\n",
      "   macro avg       0.93      0.87      0.89      1092\n",
      "weighted avg       0.92      0.92      0.91      1092\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.8609\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.80      0.40      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.77      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.29      0.40         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.83      0.74      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.82      0.67      0.72       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.91      0.88       200\n",
      "     neutral       0.95      0.91      0.93       315\n",
      "    positive       0.86      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88       162\n",
      "     neutral       0.93      0.98      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.92      0.77      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.83        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.95      0.87      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.90      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.69      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      1.00      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.89      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 361.4845986366272 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.200241088867188e-05 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.447, Accuracy: 0.8741, F1 Micro: 0.926, F1 Macro: 0.9206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2714, Accuracy: 0.9347, F1 Micro: 0.9603, F1 Macro: 0.9582\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1897, Accuracy: 0.949, F1 Micro: 0.9687, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1508, Accuracy: 0.954, F1 Micro: 0.9718, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1277, Accuracy: 0.9606, F1 Micro: 0.9755, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1017, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9758\n",
      "Epoch 7/10, Train Loss: 0.0868, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9746\n",
      "Epoch 8/10, Train Loss: 0.0708, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.0616, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.05, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.96      0.92      0.94       317\n",
      "       linen       0.92      0.98      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3749, Accuracy: 0.8734, F1 Micro: 0.8734, F1 Macro: 0.8267\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2081, Accuracy: 0.9009, F1 Micro: 0.9009, F1 Macro: 0.8684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.156, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8844\n",
      "Epoch 4/10, Train Loss: 0.1241, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0912, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8833\n",
      "Epoch 6/10, Train Loss: 0.0842, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8814\n",
      "Epoch 7/10, Train Loss: 0.0561, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8788\n",
      "Epoch 8/10, Train Loss: 0.0511, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0392, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.886\n",
      "Epoch 10/10, Train Loss: 0.0325, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8808\n",
      "\n",
      "Sentiment analysis accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       781\n",
      "    positive       0.94      0.74      0.83       309\n",
      "\n",
      "    accuracy                           0.91      1090\n",
      "   macro avg       0.92      0.86      0.89      1090\n",
      "weighted avg       0.92      0.91      0.91      1090\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.958, F1 Micro: 0.958, F1 Macro: 0.8495\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.83      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.77      0.77      0.77       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.63      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.54      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90       200\n",
      "     neutral       0.96      0.92      0.94       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.87      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       1.00      0.32      0.48        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.93      0.72      0.77       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.88      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.93      0.91      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 357.301726102829 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.845329284667969e-05 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4434, Accuracy: 0.8734, F1 Micro: 0.9251, F1 Macro: 0.9172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2682, Accuracy: 0.9359, F1 Micro: 0.9609, F1 Macro: 0.9586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.187, Accuracy: 0.9523, F1 Micro: 0.9706, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1488, Accuracy: 0.9556, F1 Micro: 0.9725, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.124, Accuracy: 0.9583, F1 Micro: 0.9743, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0988, Accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.087, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9753\n",
      "Epoch 8/10, Train Loss: 0.0686, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9748\n",
      "Epoch 9/10, Train Loss: 0.0589, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.048, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.97      0.96       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3621, Accuracy: 0.8651, F1 Micro: 0.8651, F1 Macro: 0.829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2041, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1461, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1042, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8839\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.082, Accuracy: 0.9165, F1 Micro: 0.9165, F1 Macro: 0.8923\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0777, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.8929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0623, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.8946\n",
      "Epoch 8/10, Train Loss: 0.0325, Accuracy: 0.9165, F1 Micro: 0.9165, F1 Macro: 0.8939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0294, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.8927\n",
      "Epoch 10/10, Train Loss: 0.0336, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8906\n",
      "\n",
      "Sentiment analysis accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.8927\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.99      0.95       775\n",
      "    positive       0.97      0.74      0.84       315\n",
      "\n",
      "    accuracy                           0.92      1090\n",
      "   macro avg       0.94      0.87      0.89      1090\n",
      "weighted avg       0.92      0.92      0.91      1090\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.8693\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.97      0.96       496\n",
      "    positive       0.77      0.71      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.57      0.56      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.86       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.75      0.55      0.63        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.78      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.91      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 392.352046251297 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.775161743164062e-05 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4426, Accuracy: 0.8738, F1 Micro: 0.9257, F1 Macro: 0.9202\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2683, Accuracy: 0.9351, F1 Micro: 0.9604, F1 Macro: 0.9582\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.183, Accuracy: 0.9477, F1 Micro: 0.968, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1492, Accuracy: 0.9589, F1 Micro: 0.9746, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1208, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.097, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Epoch 7/10, Train Loss: 0.0845, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0735, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0599, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0485, Accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3465, Accuracy: 0.8674, F1 Micro: 0.8674, F1 Macro: 0.8222\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2034, Accuracy: 0.8892, F1 Micro: 0.8892, F1 Macro: 0.8518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1424, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8819\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0875, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8889\n",
      "Epoch 5/10, Train Loss: 0.0666, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8732\n",
      "Epoch 6/10, Train Loss: 0.0626, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.055, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.8934\n",
      "Epoch 8/10, Train Loss: 0.0404, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.883\n",
      "Epoch 9/10, Train Loss: 0.027, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.883\n",
      "Epoch 10/10, Train Loss: 0.0277, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8842\n",
      "\n",
      "Sentiment analysis accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.8934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       781\n",
      "    positive       0.94      0.76      0.84       320\n",
      "\n",
      "    accuracy                           0.92      1101\n",
      "   macro avg       0.93      0.87      0.89      1101\n",
      "weighted avg       0.92      0.92      0.91      1101\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.8735\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.82      0.78      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.63      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.88       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.81      0.98      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.93      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.86       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.58      0.50      0.54        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.80      0.77      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.78      0.80       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.97      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 398.99615693092346 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.581710815429688e-05 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4421, Accuracy: 0.8802, F1 Micro: 0.9285, F1 Macro: 0.9216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2687, Accuracy: 0.9351, F1 Micro: 0.9605, F1 Macro: 0.9582\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.188, Accuracy: 0.9514, F1 Micro: 0.9701, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1456, Accuracy: 0.9559, F1 Micro: 0.9728, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1157, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0988, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "Epoch 7/10, Train Loss: 0.0807, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9742\n",
      "Epoch 8/10, Train Loss: 0.0673, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0565, Accuracy: 0.9663, F1 Micro: 0.979, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0494, Accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.977\n",
      "\n",
      "Aspect detection accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3612, Accuracy: 0.8728, F1 Micro: 0.8728, F1 Macro: 0.8308\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2013, Accuracy: 0.901, F1 Micro: 0.901, F1 Macro: 0.8711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.146, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8813\n",
      "Epoch 4/10, Train Loss: 0.0956, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0739, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8918\n",
      "Epoch 6/10, Train Loss: 0.0596, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0306, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.8966\n",
      "Epoch 8/10, Train Loss: 0.0343, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8861\n",
      "Epoch 9/10, Train Loss: 0.0202, Accuracy: 0.9155, F1 Micro: 0.9155, F1 Macro: 0.8888\n",
      "Epoch 10/10, Train Loss: 0.0382, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8914\n",
      "\n",
      "Sentiment analysis accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.8966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94       785\n",
      "    positive       0.92      0.79      0.85       316\n",
      "\n",
      "    accuracy                           0.92      1101\n",
      "   macro avg       0.92      0.88      0.90      1101\n",
      "weighted avg       0.92      0.92      0.92      1101\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8849\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.43      0.60         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.75      0.79        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.72      0.79       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.73      0.77       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.55      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.75      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 401.1827130317688 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 36\n",
      "Sampling duration: 0.022339344024658203 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4411, Accuracy: 0.8814, F1 Micro: 0.9299, F1 Macro: 0.9241\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2568, Accuracy: 0.9349, F1 Micro: 0.9604, F1 Macro: 0.9579\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1876, Accuracy: 0.9502, F1 Micro: 0.9693, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1462, Accuracy: 0.9543, F1 Micro: 0.9719, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.117, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0979, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0812, Accuracy: 0.9651, F1 Micro: 0.9784, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0665, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9767\n",
      "Epoch 9/10, Train Loss: 0.0586, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0464, Accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9771\n",
      "\n",
      "Aspect detection accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.94      0.97      0.96       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3606, Accuracy: 0.8662, F1 Micro: 0.8662, F1 Macro: 0.8151\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1984, Accuracy: 0.8899, F1 Micro: 0.8899, F1 Macro: 0.8494\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1319, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1018, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0705, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0565, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8884\n",
      "Epoch 7/10, Train Loss: 0.0358, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8853\n",
      "Epoch 8/10, Train Loss: 0.0315, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0286, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8871\n",
      "Epoch 10/10, Train Loss: 0.028, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8868\n",
      "\n",
      "Sentiment analysis accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       788\n",
      "    positive       0.94      0.75      0.83       311\n",
      "\n",
      "    accuracy                           0.91      1099\n",
      "   macro avg       0.92      0.86      0.89      1099\n",
      "weighted avg       0.92      0.91      0.91      1099\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.865\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.92      0.93        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.86      0.84      0.85       571\n",
      "weighted avg       0.97      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.83      0.66      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.88       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       1.00      0.36      0.53        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.94      0.74      0.79       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.79      0.80       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 414.5362329483032 s\n",
      "Total runtime: 7636.093672037125 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6064a4ec",
   "metadata": {
    "papermill": {
     "duration": 0.011711,
     "end_time": "2025-03-31T11:40:20.337579",
     "exception": false,
     "start_time": "2025-03-31T11:40:20.325868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f4beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6072, Accuracy: 0.7955, F1 Micro: 0.8818, F1 Macro: 0.8546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4916, Accuracy: 0.8016, F1 Micro: 0.8877, F1 Macro: 0.8774\n",
      "Epoch 3/10, Train Loss: 0.453, Accuracy: 0.8024, F1 Micro: 0.8857, F1 Macro: 0.8609\n",
      "Epoch 4/10, Train Loss: 0.4515, Accuracy: 0.8021, F1 Micro: 0.8849, F1 Macro: 0.8543\n",
      "Epoch 5/10, Train Loss: 0.417, Accuracy: 0.8047, F1 Micro: 0.8868, F1 Macro: 0.862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4402, Accuracy: 0.8092, F1 Micro: 0.8902, F1 Macro: 0.874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3799, Accuracy: 0.8141, F1 Micro: 0.8937, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3851, Accuracy: 0.8252, F1 Micro: 0.899, F1 Macro: 0.8873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3532, Accuracy: 0.8361, F1 Micro: 0.9044, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3254, Accuracy: 0.8502, F1 Micro: 0.9121, F1 Macro: 0.9018\n",
      "\n",
      "Aspect detection accuracy: 0.8502, F1 Micro: 0.9121, F1 Macro: 0.9018\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.86      1.00      0.93       462\n",
      "   air_panas       0.90      0.99      0.94       480\n",
      "         bau       0.87      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.77      0.66      0.71       317\n",
      "       linen       0.74      0.98      0.84       392\n",
      "     service       0.82      0.98      0.89       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.89      1.00      0.94       498\n",
      "\n",
      "   micro avg       0.86      0.97      0.91      4614\n",
      "   macro avg       0.85      0.96      0.90      4614\n",
      "weighted avg       0.86      0.97      0.91      4614\n",
      " samples avg       0.86      0.97      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5988, Accuracy: 0.6204, F1 Micro: 0.6204, F1 Macro: 0.3829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5281, Accuracy: 0.6204, F1 Micro: 0.6204, F1 Macro: 0.3829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4888, Accuracy: 0.6259, F1 Micro: 0.6259, F1 Macro: 0.4027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3707, Accuracy: 0.6861, F1 Micro: 0.6861, F1 Macro: 0.5752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3492, Accuracy: 0.7336, F1 Micro: 0.7336, F1 Macro: 0.6917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2739, Accuracy: 0.7372, F1 Micro: 0.7372, F1 Macro: 0.7005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3739, Accuracy: 0.7409, F1 Micro: 0.7409, F1 Macro: 0.7103\n",
      "Epoch 8/10, Train Loss: 0.2974, Accuracy: 0.7281, F1 Micro: 0.7281, F1 Macro: 0.6718\n",
      "Epoch 9/10, Train Loss: 0.18, Accuracy: 0.7372, F1 Micro: 0.7372, F1 Macro: 0.703\n",
      "Epoch 10/10, Train Loss: 0.1429, Accuracy: 0.7281, F1 Micro: 0.7281, F1 Macro: 0.6706\n",
      "\n",
      "Sentiment analysis accuracy: 0.7409, F1 Micro: 0.7409, F1 Macro: 0.7103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.86      0.80       340\n",
      "    positive       0.70      0.55      0.62       208\n",
      "\n",
      "    accuracy                           0.74       548\n",
      "   macro avg       0.73      0.70      0.71       548\n",
      "weighted avg       0.74      0.74      0.73       548\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8408, F1 Micro: 0.8408, F1 Macro: 0.4385\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.36      0.51        97\n",
      "     neutral       0.87      1.00      0.93       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.58      0.45      0.48       571\n",
      "weighted avg       0.84      0.86      0.83       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.48      0.60        86\n",
      "     neutral       0.90      0.99      0.94       475\n",
      "    positive       1.00      0.10      0.18        10\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.90      0.52      0.57       571\n",
      "weighted avg       0.89      0.89      0.88       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.12      0.20        78\n",
      "     neutral       0.87      1.00      0.93       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.59      0.37      0.38       571\n",
      "weighted avg       0.87      0.87      0.83       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.73      0.66       200\n",
      "     neutral       0.77      0.66      0.71       315\n",
      "    positive       0.32      0.36      0.34        56\n",
      "\n",
      "    accuracy                           0.65       571\n",
      "   macro avg       0.57      0.58      0.57       571\n",
      "weighted avg       0.67      0.65      0.66       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.30      0.44       162\n",
      "     neutral       0.74      0.98      0.84       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.75       571\n",
      "   macro avg       0.53      0.43      0.43       571\n",
      "weighted avg       0.74      0.75      0.70       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.20      0.32        85\n",
      "     neutral       0.81      0.98      0.89       418\n",
      "    positive       0.61      0.41      0.49        68\n",
      "\n",
      "    accuracy                           0.80       571\n",
      "   macro avg       0.74      0.53      0.57       571\n",
      "weighted avg       0.79      0.80      0.76       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.24      0.39        74\n",
      "     neutral       0.89      1.00      0.94       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.61      0.41      0.44       571\n",
      "weighted avg       0.90      0.89      0.87       571\n",
      "\n",
      "Total train time: 83.71989798545837 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 215\n",
      "Sampling duration: 0.0002040863037109375 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5336, Accuracy: 0.8031, F1 Micro: 0.887, F1 Macro: 0.8693\n",
      "Epoch 2/10, Train Loss: 0.4418, Accuracy: 0.8042, F1 Micro: 0.8868, F1 Macro: 0.8645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4333, Accuracy: 0.8144, F1 Micro: 0.8946, F1 Macro: 0.8865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3941, Accuracy: 0.8392, F1 Micro: 0.9067, F1 Macro: 0.8973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3346, Accuracy: 0.8745, F1 Micro: 0.925, F1 Macro: 0.9145\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2948, Accuracy: 0.8929, F1 Micro: 0.936, F1 Macro: 0.93\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2572, Accuracy: 0.9038, F1 Micro: 0.942, F1 Macro: 0.9368\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2127, Accuracy: 0.9122, F1 Micro: 0.9468, F1 Macro: 0.9422\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2048, Accuracy: 0.9155, F1 Micro: 0.949, F1 Macro: 0.9457\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1704, Accuracy: 0.9214, F1 Micro: 0.9523, F1 Macro: 0.9495\n",
      "\n",
      "Aspect detection accuracy: 0.9214, F1 Micro: 0.9523, F1 Macro: 0.9495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.97      0.99      0.98       462\n",
      "   air_panas       0.91      1.00      0.95       480\n",
      "         bau       0.96      0.97      0.96       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.87      0.89      0.88       317\n",
      "       linen       0.86      0.97      0.91       392\n",
      "     service       0.96      0.96      0.96       423\n",
      "sunrise_meal       0.93      1.00      0.96       530\n",
      "          tv       0.93      1.00      0.96       516\n",
      "        wifi       0.99      0.99      0.99       498\n",
      "\n",
      "   micro avg       0.93      0.98      0.95      4614\n",
      "   macro avg       0.92      0.98      0.95      4614\n",
      "weighted avg       0.93      0.98      0.95      4614\n",
      " samples avg       0.92      0.98      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4981, Accuracy: 0.7315, F1 Micro: 0.7315, F1 Macro: 0.4225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3922, Accuracy: 0.7928, F1 Micro: 0.7928, F1 Macro: 0.7225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3477, Accuracy: 0.8032, F1 Micro: 0.8032, F1 Macro: 0.7005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2849, Accuracy: 0.8322, F1 Micro: 0.8322, F1 Macro: 0.7559\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2419, Accuracy: 0.8322, F1 Micro: 0.8322, F1 Macro: 0.7386\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1514, Accuracy: 0.8519, F1 Micro: 0.8519, F1 Macro: 0.7953\n",
      "Epoch 7/10, Train Loss: 0.1552, Accuracy: 0.8356, F1 Micro: 0.8356, F1 Macro: 0.7529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1421, Accuracy: 0.8576, F1 Micro: 0.8576, F1 Macro: 0.7982\n",
      "Epoch 9/10, Train Loss: 0.0973, Accuracy: 0.8507, F1 Micro: 0.8507, F1 Macro: 0.7905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0963, Accuracy: 0.8588, F1 Micro: 0.8588, F1 Macro: 0.8062\n",
      "\n",
      "Sentiment analysis accuracy: 0.8588, F1 Micro: 0.8588, F1 Macro: 0.8062\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.94      0.91       632\n",
      "    positive       0.80      0.63      0.71       232\n",
      "\n",
      "    accuracy                           0.86       864\n",
      "   macro avg       0.84      0.79      0.81       864\n",
      "weighted avg       0.85      0.86      0.85       864\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.6598\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        97\n",
      "     neutral       0.97      0.99      0.98       459\n",
      "    positive       0.78      0.47      0.58        15\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.89      0.77      0.82       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.49      0.64        86\n",
      "     neutral       0.90      1.00      0.95       475\n",
      "    positive       0.67      0.20      0.31        10\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.83      0.56      0.63       571\n",
      "weighted avg       0.90      0.91      0.89       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.72      0.76        78\n",
      "     neutral       0.96      0.97      0.96       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.56      0.57       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.76      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82       200\n",
      "     neutral       0.88      0.89      0.88       315\n",
      "    positive       0.67      0.79      0.72        56\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.80      0.82      0.81       571\n",
      "weighted avg       0.85      0.84      0.84       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.67      0.76       162\n",
      "     neutral       0.86      0.97      0.91       387\n",
      "    positive       0.33      0.23      0.27        22\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.70      0.62      0.65       571\n",
      "weighted avg       0.85      0.85      0.85       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.73      0.76        85\n",
      "     neutral       0.96      0.96      0.96       418\n",
      "    positive       0.79      0.85      0.82        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.85      0.85      0.85       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.10      0.19        29\n",
      "     neutral       0.93      1.00      0.96       525\n",
      "    positive       0.67      0.24      0.35        17\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.87      0.45      0.50       571\n",
      "weighted avg       0.93      0.93      0.91       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.35      0.51        54\n",
      "     neutral       0.93      1.00      0.96       511\n",
      "    positive       0.50      0.17      0.25         6\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.79      0.51      0.58       571\n",
      "weighted avg       0.93      0.93      0.91       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.88      0.92        74\n",
      "     neutral       0.99      0.99      0.99       494\n",
      "    positive       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.85      0.96      0.89       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 127.18798446655273 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 193\n",
      "Sampling duration: 0.00014638900756835938 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5256, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.463, Accuracy: 0.8052, F1 Micro: 0.8913, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3997, Accuracy: 0.8627, F1 Micro: 0.9194, F1 Macro: 0.9112\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3306, Accuracy: 0.8917, F1 Micro: 0.9351, F1 Macro: 0.9287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2719, Accuracy: 0.916, F1 Micro: 0.949, F1 Macro: 0.9439\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2405, Accuracy: 0.9273, F1 Micro: 0.9559, F1 Macro: 0.9532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1949, Accuracy: 0.9351, F1 Micro: 0.9605, F1 Macro: 0.9579\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1753, Accuracy: 0.9391, F1 Micro: 0.9626, F1 Macro: 0.9596\n",
      "Epoch 9/10, Train Loss: 0.1496, Accuracy: 0.9372, F1 Micro: 0.9616, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1321, Accuracy: 0.945, F1 Micro: 0.9662, F1 Macro: 0.9636\n",
      "\n",
      "Aspect detection accuracy: 0.945, F1 Micro: 0.9662, F1 Macro: 0.9636\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.96      0.99      0.97       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.89      0.99      0.94       500\n",
      "  kebersihan       0.91      0.91      0.91       317\n",
      "       linen       0.88      0.97      0.92       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.96      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      0.99      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.97      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4845, Accuracy: 0.7651, F1 Micro: 0.7651, F1 Macro: 0.7226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3744, Accuracy: 0.8315, F1 Micro: 0.8315, F1 Macro: 0.7804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2393, Accuracy: 0.858, F1 Micro: 0.858, F1 Macro: 0.8022\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1896, Accuracy: 0.8744, F1 Micro: 0.8744, F1 Macro: 0.8281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1742, Accuracy: 0.8836, F1 Micro: 0.8836, F1 Macro: 0.8422\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1274, Accuracy: 0.8856, F1 Micro: 0.8856, F1 Macro: 0.8418\n",
      "Epoch 7/10, Train Loss: 0.0946, Accuracy: 0.8795, F1 Micro: 0.8795, F1 Macro: 0.8367\n",
      "Epoch 8/10, Train Loss: 0.0707, Accuracy: 0.8825, F1 Micro: 0.8825, F1 Macro: 0.8388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0897, Accuracy: 0.8958, F1 Micro: 0.8958, F1 Macro: 0.85\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0479, Accuracy: 0.8958, F1 Micro: 0.8958, F1 Macro: 0.8542\n",
      "\n",
      "Sentiment analysis accuracy: 0.8958, F1 Micro: 0.8958, F1 Macro: 0.8542\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       721\n",
      "    positive       0.89      0.69      0.78       258\n",
      "\n",
      "    accuracy                           0.90       979\n",
      "   macro avg       0.90      0.83      0.85       979\n",
      "weighted avg       0.90      0.90      0.89       979\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.752\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.81      0.87      0.84        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.76      0.82        86\n",
      "     neutral       0.96      0.99      0.97       475\n",
      "    positive       0.44      0.40      0.42        10\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.71      0.74       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.77      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.60      0.58      0.59       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.89      0.99      0.94       496\n",
      "    positive       0.76      0.19      0.31        68\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.55      0.39      0.41       571\n",
      "weighted avg       0.86      0.88      0.85       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.86       200\n",
      "     neutral       0.91      0.91      0.91       315\n",
      "    positive       0.87      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.88      0.90      0.89       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.75      0.81       162\n",
      "     neutral       0.88      0.97      0.92       387\n",
      "    positive       0.75      0.27      0.40        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.84      0.66      0.71       571\n",
      "weighted avg       0.88      0.88      0.87       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.79      0.84        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.89      0.87      0.88        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.88      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.38      0.51        29\n",
      "     neutral       0.96      1.00      0.98       525\n",
      "    positive       0.83      0.59      0.69        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.86      0.66      0.73       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       0.60      0.50      0.55         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.93      0.94        74\n",
      "     neutral       1.00      0.99      0.99       494\n",
      "    positive       0.40      0.67      0.50         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.78      0.86      0.81       571\n",
      "weighted avg       0.99      0.98      0.99       571\n",
      "\n",
      "Total train time: 159.20660877227783 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 174\n",
      "Sampling duration: 0.0001437664031982422 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5, Accuracy: 0.8092, F1 Micro: 0.8931, F1 Macro: 0.8877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4267, Accuracy: 0.8373, F1 Micro: 0.907, F1 Macro: 0.9015\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3592, Accuracy: 0.8946, F1 Micro: 0.937, F1 Macro: 0.9311\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2799, Accuracy: 0.9062, F1 Micro: 0.944, F1 Macro: 0.9403\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2221, Accuracy: 0.9333, F1 Micro: 0.9595, F1 Macro: 0.9573\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1878, Accuracy: 0.9349, F1 Micro: 0.9603, F1 Macro: 0.9576\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1659, Accuracy: 0.9394, F1 Micro: 0.963, F1 Macro: 0.9607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1491, Accuracy: 0.9432, F1 Micro: 0.9652, F1 Macro: 0.9626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1301, Accuracy: 0.9497, F1 Micro: 0.969, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1123, Accuracy: 0.951, F1 Micro: 0.9698, F1 Macro: 0.9677\n",
      "\n",
      "Aspect detection accuracy: 0.951, F1 Micro: 0.9698, F1 Macro: 0.9677\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.89      0.99      0.94       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.90      0.96      0.93       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4322, Accuracy: 0.7798, F1 Micro: 0.7798, F1 Macro: 0.6248\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.316, Accuracy: 0.8327, F1 Micro: 0.8327, F1 Macro: 0.7387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.209, Accuracy: 0.8796, F1 Micro: 0.8796, F1 Macro: 0.8298\n",
      "Epoch 4/10, Train Loss: 0.1926, Accuracy: 0.8777, F1 Micro: 0.8777, F1 Macro: 0.826\n",
      "Epoch 5/10, Train Loss: 0.1579, Accuracy: 0.8767, F1 Micro: 0.8767, F1 Macro: 0.8383\n",
      "Epoch 6/10, Train Loss: 0.1299, Accuracy: 0.8728, F1 Micro: 0.8728, F1 Macro: 0.813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1034, Accuracy: 0.8914, F1 Micro: 0.8914, F1 Macro: 0.8536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0709, Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8508\n",
      "Epoch 9/10, Train Loss: 0.0477, Accuracy: 0.8904, F1 Micro: 0.8904, F1 Macro: 0.8457\n",
      "Epoch 10/10, Train Loss: 0.0383, Accuracy: 0.8865, F1 Micro: 0.8865, F1 Macro: 0.8368\n",
      "\n",
      "Sentiment analysis accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       747\n",
      "    positive       0.93      0.66      0.77       275\n",
      "\n",
      "    accuracy                           0.89      1022\n",
      "   macro avg       0.91      0.82      0.85      1022\n",
      "weighted avg       0.90      0.89      0.89      1022\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9431, F1 Micro: 0.9431, F1 Macro: 0.7651\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.81      0.74      0.77       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.79      0.81        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.60      0.59      0.59       571\n",
      "weighted avg       0.94      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.89      0.99      0.94       496\n",
      "    positive       0.85      0.25      0.39        68\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.58      0.41      0.44       571\n",
      "weighted avg       0.88      0.89      0.86       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.87       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.86      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.90      0.90       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82       162\n",
      "     neutral       0.89      0.97      0.93       387\n",
      "    positive       0.50      0.05      0.08        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.75      0.60      0.61       571\n",
      "weighted avg       0.87      0.88      0.87       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.41      0.49        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.75      0.35      0.48        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.77      0.59      0.65       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 179.52199149131775 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 156\n",
      "Sampling duration: 0.00013756752014160156 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4914, Accuracy: 0.8089, F1 Micro: 0.8931, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.411, Accuracy: 0.8755, F1 Micro: 0.9266, F1 Macro: 0.9205\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3154, Accuracy: 0.905, F1 Micro: 0.9433, F1 Macro: 0.9391\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2403, Accuracy: 0.9314, F1 Micro: 0.9583, F1 Macro: 0.9556\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.197, Accuracy: 0.9401, F1 Micro: 0.9634, F1 Macro: 0.9609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1719, Accuracy: 0.9458, F1 Micro: 0.9667, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1523, Accuracy: 0.9493, F1 Micro: 0.9688, F1 Macro: 0.9669\n",
      "Epoch 8/10, Train Loss: 0.1305, Accuracy: 0.949, F1 Micro: 0.9687, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1151, Accuracy: 0.9516, F1 Micro: 0.9701, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0999, Accuracy: 0.9519, F1 Micro: 0.9703, F1 Macro: 0.9682\n",
      "\n",
      "Aspect detection accuracy: 0.9519, F1 Micro: 0.9703, F1 Macro: 0.9682\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.95      0.98      0.97       496\n",
      "     general       0.89      0.99      0.94       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.92      0.95      0.93       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4687, Accuracy: 0.8076, F1 Micro: 0.8076, F1 Macro: 0.731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2952, Accuracy: 0.8416, F1 Micro: 0.8416, F1 Macro: 0.7931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2013, Accuracy: 0.8707, F1 Micro: 0.8707, F1 Macro: 0.8185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1708, Accuracy: 0.8727, F1 Micro: 0.8727, F1 Macro: 0.8238\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1239, Accuracy: 0.8921, F1 Micro: 0.8921, F1 Macro: 0.8536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.102, Accuracy: 0.8941, F1 Micro: 0.8941, F1 Macro: 0.8517\n",
      "Epoch 7/10, Train Loss: 0.0631, Accuracy: 0.8912, F1 Micro: 0.8912, F1 Macro: 0.8517\n",
      "Epoch 8/10, Train Loss: 0.057, Accuracy: 0.8776, F1 Micro: 0.8776, F1 Macro: 0.8225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0411, Accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.8622\n",
      "Epoch 10/10, Train Loss: 0.0476, Accuracy: 0.895, F1 Micro: 0.895, F1 Macro: 0.852\n",
      "\n",
      "Sentiment analysis accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.8622\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       750\n",
      "    positive       0.90      0.71      0.79       279\n",
      "\n",
      "    accuracy                           0.90      1029\n",
      "   macro avg       0.90      0.84      0.86      1029\n",
      "weighted avg       0.90      0.90      0.89      1029\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.7946\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.75      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.71      0.77        78\n",
      "     neutral       0.95      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.89      0.99      0.94       496\n",
      "    positive       0.84      0.24      0.37        68\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.58      0.41      0.44       571\n",
      "weighted avg       0.88      0.89      0.86       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.84      0.93      0.88        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.83      0.84       162\n",
      "     neutral       0.92      0.95      0.93       387\n",
      "    positive       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.92      0.73      0.78       571\n",
      "weighted avg       0.90      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.80      0.85        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.52      0.56        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.71      0.29      0.42        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.76      0.60      0.65       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 203.7249653339386 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 141\n",
      "Sampling duration: 0.00015425682067871094 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4901, Accuracy: 0.8069, F1 Micro: 0.8922, F1 Macro: 0.8873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3831, Accuracy: 0.8825, F1 Micro: 0.9306, F1 Macro: 0.9252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2876, Accuracy: 0.9194, F1 Micro: 0.9517, F1 Macro: 0.9485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2222, Accuracy: 0.9368, F1 Micro: 0.9614, F1 Macro: 0.9586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1889, Accuracy: 0.946, F1 Micro: 0.9669, F1 Macro: 0.9647\n",
      "Epoch 6/10, Train Loss: 0.1502, Accuracy: 0.9415, F1 Micro: 0.9643, F1 Macro: 0.9624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.138, Accuracy: 0.9476, F1 Micro: 0.9679, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1188, Accuracy: 0.9536, F1 Micro: 0.9714, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1014, Accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0894, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9725\n",
      "\n",
      "Aspect detection accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.96      0.99      0.97       496\n",
      "     general       0.93      0.99      0.96       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4473, Accuracy: 0.8287, F1 Micro: 0.8287, F1 Macro: 0.7453\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2609, Accuracy: 0.8402, F1 Micro: 0.8402, F1 Macro: 0.7525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2262, Accuracy: 0.8756, F1 Micro: 0.8756, F1 Macro: 0.8247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1785, Accuracy: 0.8804, F1 Micro: 0.8804, F1 Macro: 0.8277\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1309, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8808\n",
      "Epoch 6/10, Train Loss: 0.0856, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8731\n",
      "Epoch 7/10, Train Loss: 0.0635, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8644\n",
      "Epoch 8/10, Train Loss: 0.0453, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8584\n",
      "Epoch 9/10, Train Loss: 0.063, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.861\n",
      "Epoch 10/10, Train Loss: 0.0364, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8755\n",
      "\n",
      "Sentiment analysis accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       761\n",
      "    positive       0.91      0.75      0.82       284\n",
      "\n",
      "    accuracy                           0.91      1045\n",
      "   macro avg       0.91      0.86      0.88      1045\n",
      "weighted avg       0.91      0.91      0.91      1045\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9527, F1 Micro: 0.9527, F1 Macro: 0.8306\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.76      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.73      0.81        78\n",
      "     neutral       0.96      0.99      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.74      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.99      0.96       496\n",
      "    positive       0.92      0.53      0.67        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.62      0.51      0.54       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.88       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.81      0.93      0.87        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.88      0.91      0.89       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.83      0.23      0.36        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.87      0.68      0.72       571\n",
      "weighted avg       0.90      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.82      0.87        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.62      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.99      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.88      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 220.19632196426392 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 127\n",
      "Sampling duration: 0.00012493133544921875 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.481, Accuracy: 0.8045, F1 Micro: 0.8912, F1 Macro: 0.8868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3584, Accuracy: 0.8981, F1 Micro: 0.9392, F1 Macro: 0.9343\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2523, Accuracy: 0.9318, F1 Micro: 0.9584, F1 Macro: 0.9557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2008, Accuracy: 0.9424, F1 Micro: 0.9647, F1 Macro: 0.9623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1701, Accuracy: 0.9469, F1 Micro: 0.9674, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1438, Accuracy: 0.9505, F1 Micro: 0.9696, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1231, Accuracy: 0.9516, F1 Micro: 0.9703, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1049, Accuracy: 0.9563, F1 Micro: 0.973, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0919, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.078, Accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.9741\n",
      "\n",
      "Aspect detection accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.9741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.90      0.97      0.94       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4286, Accuracy: 0.8432, F1 Micro: 0.8432, F1 Macro: 0.7809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2554, Accuracy: 0.8706, F1 Micro: 0.8706, F1 Macro: 0.8287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1842, Accuracy: 0.8924, F1 Micro: 0.8924, F1 Macro: 0.858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1185, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0787, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8748\n",
      "Epoch 6/10, Train Loss: 0.0708, Accuracy: 0.899, F1 Micro: 0.899, F1 Macro: 0.8627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0605, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8806\n",
      "Epoch 8/10, Train Loss: 0.0396, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.029, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8856\n",
      "Epoch 10/10, Train Loss: 0.0402, Accuracy: 0.9075, F1 Micro: 0.9075, F1 Macro: 0.8767\n",
      "\n",
      "Sentiment analysis accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8856\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94       761\n",
      "    positive       0.89      0.78      0.83       298\n",
      "\n",
      "    accuracy                           0.91      1059\n",
      "   macro avg       0.90      0.87      0.89      1059\n",
      "weighted avg       0.91      0.91      0.91      1059\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.955, F1 Micro: 0.955, F1 Macro: 0.8569\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.88        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.78      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.81      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.17      0.14      0.15         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.93      0.59      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.68      0.57      0.61       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.80      0.84       162\n",
      "     neutral       0.90      0.97      0.94       387\n",
      "    positive       1.00      0.27      0.43        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.93      0.68      0.73       571\n",
      "weighted avg       0.90      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.78      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 243.44713950157166 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 114\n",
      "Sampling duration: 0.0001125335693359375 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.475, Accuracy: 0.8167, F1 Micro: 0.8965, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3501, Accuracy: 0.9052, F1 Micro: 0.9432, F1 Macro: 0.9386\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2503, Accuracy: 0.9368, F1 Micro: 0.9615, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1899, Accuracy: 0.9441, F1 Micro: 0.9658, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1664, Accuracy: 0.9481, F1 Micro: 0.9682, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1375, Accuracy: 0.953, F1 Micro: 0.971, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1176, Accuracy: 0.958, F1 Micro: 0.974, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1006, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.084, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.074, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.99      0.97       500\n",
      "  kebersihan       0.93      0.94      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3799, Accuracy: 0.8443, F1 Micro: 0.8443, F1 Macro: 0.8012\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2391, Accuracy: 0.8827, F1 Micro: 0.8827, F1 Macro: 0.8412\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1631, Accuracy: 0.9034, F1 Micro: 0.9034, F1 Macro: 0.8727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1312, Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8804\n",
      "Epoch 5/10, Train Loss: 0.0962, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8776\n",
      "Epoch 6/10, Train Loss: 0.0606, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.877\n",
      "Epoch 7/10, Train Loss: 0.0506, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0335, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.038, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8817\n",
      "Epoch 10/10, Train Loss: 0.0148, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.88\n",
      "\n",
      "Sentiment analysis accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       769\n",
      "    positive       0.94      0.73      0.82       297\n",
      "\n",
      "    accuracy                           0.91      1066\n",
      "   macro avg       0.92      0.86      0.88      1066\n",
      "weighted avg       0.91      0.91      0.91      1066\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9573, F1 Micro: 0.9573, F1 Macro: 0.8547\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.82      0.93      0.87        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.95      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.60      0.30      0.40        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.72      0.76       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.94      0.99      0.97       496\n",
      "    positive       0.94      0.66      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.79      0.60      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89       200\n",
      "     neutral       0.93      0.94      0.93       315\n",
      "    positive       0.90      0.95      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.74      0.78       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.59      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.85      0.65      0.73        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.74      0.80       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.98      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 258.4711322784424 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 103\n",
      "Sampling duration: 0.00012636184692382812 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4723, Accuracy: 0.8188, F1 Micro: 0.898, F1 Macro: 0.8934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3376, Accuracy: 0.9139, F1 Micro: 0.9479, F1 Macro: 0.9433\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2427, Accuracy: 0.9398, F1 Micro: 0.9631, F1 Macro: 0.9606\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1819, Accuracy: 0.9465, F1 Micro: 0.9673, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1549, Accuracy: 0.949, F1 Micro: 0.9687, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.134, Accuracy: 0.9535, F1 Micro: 0.9714, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1108, Accuracy: 0.954, F1 Micro: 0.9717, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.093, Accuracy: 0.9587, F1 Micro: 0.9745, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.08, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9749\n",
      "Epoch 10/10, Train Loss: 0.0697, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.97      0.96       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.403, Accuracy: 0.7843, F1 Micro: 0.7843, F1 Macro: 0.6467\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2636, Accuracy: 0.8781, F1 Micro: 0.8781, F1 Macro: 0.8424\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1829, Accuracy: 0.8944, F1 Micro: 0.8944, F1 Macro: 0.8665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1335, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0855, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0679, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0774, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0508, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8772\n",
      "Epoch 9/10, Train Loss: 0.0343, Accuracy: 0.8963, F1 Micro: 0.8963, F1 Macro: 0.8644\n",
      "Epoch 10/10, Train Loss: 0.028, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8769\n",
      "\n",
      "Sentiment analysis accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       775\n",
      "    positive       0.93      0.73      0.82       324\n",
      "\n",
      "    accuracy                           0.90      1099\n",
      "   macro avg       0.91      0.86      0.88      1099\n",
      "weighted avg       0.91      0.90      0.90      1099\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9557, F1 Micro: 0.9557, F1 Macro: 0.8595\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.97      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.82      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.81      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.20      0.14      0.17         7\n",
      "     neutral       0.95      0.97      0.96       496\n",
      "    positive       0.80      0.72      0.76        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.65      0.61      0.63       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.89       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.78      0.32      0.45        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.72      0.76       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.66      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.87      0.91        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.50      1.00      0.67         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.82      0.95      0.86       571\n",
      "weighted avg       0.99      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 275.17922258377075 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 62\n",
      "Sampling duration: 0.019001245498657227 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4715, Accuracy: 0.8339, F1 Micro: 0.9055, F1 Macro: 0.9004\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.323, Accuracy: 0.9175, F1 Micro: 0.9502, F1 Macro: 0.9468\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2263, Accuracy: 0.9429, F1 Micro: 0.9651, F1 Macro: 0.9629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.183, Accuracy: 0.9444, F1 Micro: 0.9661, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1516, Accuracy: 0.95, F1 Micro: 0.9693, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.124, Accuracy: 0.9559, F1 Micro: 0.9728, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1115, Accuracy: 0.958, F1 Micro: 0.9741, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0927, Accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0798, Accuracy: 0.9615, F1 Micro: 0.976, F1 Macro: 0.9738\n",
      "Epoch 10/10, Train Loss: 0.068, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.99      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.94      0.91      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3879, Accuracy: 0.8371, F1 Micro: 0.8371, F1 Macro: 0.7692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2294, Accuracy: 0.8655, F1 Micro: 0.8655, F1 Macro: 0.8128\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1697, Accuracy: 0.893, F1 Micro: 0.893, F1 Macro: 0.8604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1173, Accuracy: 0.8966, F1 Micro: 0.8966, F1 Macro: 0.8655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1017, Accuracy: 0.9021, F1 Micro: 0.9021, F1 Macro: 0.874\n",
      "Epoch 6/10, Train Loss: 0.0762, Accuracy: 0.8994, F1 Micro: 0.8994, F1 Macro: 0.8726\n",
      "Epoch 7/10, Train Loss: 0.054, Accuracy: 0.8994, F1 Micro: 0.8994, F1 Macro: 0.8664\n",
      "Epoch 8/10, Train Loss: 0.0578, Accuracy: 0.9003, F1 Micro: 0.9003, F1 Macro: 0.8687\n",
      "Epoch 9/10, Train Loss: 0.0336, Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.8697\n",
      "Epoch 10/10, Train Loss: 0.0191, Accuracy: 0.892, F1 Micro: 0.892, F1 Macro: 0.8549\n",
      "\n",
      "Sentiment analysis accuracy: 0.9021, F1 Micro: 0.9021, F1 Macro: 0.874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       778\n",
      "    positive       0.90      0.75      0.81       315\n",
      "\n",
      "    accuracy                           0.90      1093\n",
      "   macro avg       0.90      0.86      0.87      1093\n",
      "weighted avg       0.90      0.90      0.90      1093\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9546, F1 Micro: 0.9546, F1 Macro: 0.8354\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.76      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.88      0.65      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.61      0.54      0.57       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.91      0.89       200\n",
      "     neutral       0.96      0.91      0.93       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.90      0.85       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.58      0.62      0.60       571\n",
      "weighted avg       0.87      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.89      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.94      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.66      0.70        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.99      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.88      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 275.1674041748047 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 86\n",
      "Sampling duration: 0.00011610984802246094 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4635, Accuracy: 0.8401, F1 Micro: 0.9083, F1 Macro: 0.9026\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.31, Accuracy: 0.9214, F1 Micro: 0.9524, F1 Macro: 0.9487\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2187, Accuracy: 0.9443, F1 Micro: 0.9659, F1 Macro: 0.9638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1696, Accuracy: 0.9455, F1 Micro: 0.9667, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1497, Accuracy: 0.9561, F1 Micro: 0.9729, F1 Macro: 0.971\n",
      "Epoch 6/10, Train Loss: 0.1242, Accuracy: 0.9543, F1 Micro: 0.9719, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.102, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0864, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9754\n",
      "Epoch 9/10, Train Loss: 0.0742, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9749\n",
      "Epoch 10/10, Train Loss: 0.0641, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.402, Accuracy: 0.8288, F1 Micro: 0.8288, F1 Macro: 0.7453\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2186, Accuracy: 0.8901, F1 Micro: 0.8901, F1 Macro: 0.8604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1541, Accuracy: 0.8965, F1 Micro: 0.8965, F1 Macro: 0.8719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1172, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8839\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0944, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8913\n",
      "Epoch 6/10, Train Loss: 0.079, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8768\n",
      "Epoch 7/10, Train Loss: 0.0616, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8898\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0474, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8887\n",
      "Epoch 9/10, Train Loss: 0.0354, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8829\n",
      "Epoch 10/10, Train Loss: 0.0262, Accuracy: 0.9075, F1 Micro: 0.9075, F1 Macro: 0.88\n",
      "\n",
      "Sentiment analysis accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       774\n",
      "    positive       0.94      0.75      0.84       318\n",
      "\n",
      "    accuracy                           0.91      1092\n",
      "   macro avg       0.92      0.87      0.89      1092\n",
      "weighted avg       0.92      0.91      0.91      1092\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9573, F1 Micro: 0.9573, F1 Macro: 0.8569\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.91      0.90        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.77      0.79       571\n",
      "weighted avg       0.96      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.77      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.83      0.74      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.92      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.88      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.73      0.77       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.59      0.63        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.59      0.65        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.79      0.72      0.75       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.97      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 288.914532661438 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 77\n",
      "Sampling duration: 0.00010967254638671875 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4667, Accuracy: 0.8523, F1 Micro: 0.9145, F1 Macro: 0.9086\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3106, Accuracy: 0.9273, F1 Micro: 0.9558, F1 Macro: 0.953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2189, Accuracy: 0.946, F1 Micro: 0.9668, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1721, Accuracy: 0.9491, F1 Micro: 0.9688, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1463, Accuracy: 0.9493, F1 Micro: 0.9689, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1218, Accuracy: 0.9578, F1 Micro: 0.974, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0967, Accuracy: 0.9613, F1 Micro: 0.9761, F1 Macro: 0.9738\n",
      "Epoch 8/10, Train Loss: 0.0816, Accuracy: 0.9571, F1 Micro: 0.9736, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0747, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.975\n",
      "Epoch 10/10, Train Loss: 0.0643, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.91      0.96      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3846, Accuracy: 0.8586, F1 Micro: 0.8586, F1 Macro: 0.8142\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2134, Accuracy: 0.8916, F1 Micro: 0.8916, F1 Macro: 0.8545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1293, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1089, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0869, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.054, Accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0316, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.8969\n",
      "Epoch 8/10, Train Loss: 0.0293, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8863\n",
      "Epoch 9/10, Train Loss: 0.0298, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8862\n",
      "Epoch 10/10, Train Loss: 0.0285, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8863\n",
      "\n",
      "Sentiment analysis accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.8969\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       761\n",
      "    positive       0.93      0.78      0.85       300\n",
      "\n",
      "    accuracy                           0.92      1061\n",
      "   macro avg       0.92      0.88      0.90      1061\n",
      "weighted avg       0.92      0.92      0.92      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9557, F1 Micro: 0.9557, F1 Macro: 0.8616\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.83      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.86      0.65      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.54      0.57       571\n",
      "weighted avg       0.92      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.89      0.87       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.87      0.84      0.85        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.88      0.89       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.86      0.76      0.80       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 298.33415389060974 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 70\n",
      "Sampling duration: 9.393692016601562e-05 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4631, Accuracy: 0.8677, F1 Micro: 0.9227, F1 Macro: 0.9172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2963, Accuracy: 0.9299, F1 Micro: 0.9573, F1 Macro: 0.9545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2117, Accuracy: 0.9441, F1 Micro: 0.9658, F1 Macro: 0.9636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1674, Accuracy: 0.9517, F1 Micro: 0.9703, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1433, Accuracy: 0.9523, F1 Micro: 0.9707, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1173, Accuracy: 0.9556, F1 Micro: 0.9727, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1003, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.975\n",
      "Epoch 8/10, Train Loss: 0.0835, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9728\n",
      "Epoch 9/10, Train Loss: 0.0696, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9731\n",
      "Epoch 10/10, Train Loss: 0.0612, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9729\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.93      0.99      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3772, Accuracy: 0.8558, F1 Micro: 0.8558, F1 Macro: 0.8012\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2186, Accuracy: 0.8878, F1 Micro: 0.8878, F1 Macro: 0.8466\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1446, Accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.8694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1156, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8843\n",
      "Epoch 5/10, Train Loss: 0.0978, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8752\n",
      "Epoch 6/10, Train Loss: 0.072, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0505, Accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8893\n",
      "Epoch 8/10, Train Loss: 0.048, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8855\n",
      "Epoch 9/10, Train Loss: 0.0288, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8819\n",
      "Epoch 10/10, Train Loss: 0.0218, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8866\n",
      "\n",
      "Sentiment analysis accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       767\n",
      "    positive       0.94      0.75      0.83       294\n",
      "\n",
      "    accuracy                           0.92      1061\n",
      "   macro avg       0.92      0.87      0.89      1061\n",
      "weighted avg       0.92      0.92      0.91      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9559, F1 Micro: 0.9559, F1 Macro: 0.8572\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.91        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.91      0.57      0.70        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.62      0.52      0.56       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.91      0.89       200\n",
      "     neutral       0.96      0.91      0.93       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.85       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.73      0.36      0.48        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.84      0.72      0.76       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.55      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 302.69293308258057 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 52\n",
      "Sampling duration: 0.015854597091674805 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4515, Accuracy: 0.862, F1 Micro: 0.9198, F1 Macro: 0.9143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2921, Accuracy: 0.9332, F1 Micro: 0.9592, F1 Macro: 0.9565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2026, Accuracy: 0.9469, F1 Micro: 0.9674, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1647, Accuracy: 0.9477, F1 Micro: 0.9679, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1392, Accuracy: 0.9514, F1 Micro: 0.9702, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1162, Accuracy: 0.9568, F1 Micro: 0.9734, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0951, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0822, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9754\n",
      "Epoch 9/10, Train Loss: 0.069, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "Epoch 10/10, Train Loss: 0.059, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "\n",
      "Aspect detection accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.99      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.94      0.93      0.93       317\n",
      "       linen       0.95      0.95      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3615, Accuracy: 0.8554, F1 Micro: 0.8554, F1 Macro: 0.7997\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2216, Accuracy: 0.8897, F1 Micro: 0.8897, F1 Macro: 0.8567\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1409, Accuracy: 0.8962, F1 Micro: 0.8962, F1 Macro: 0.862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1113, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8685\n",
      "Epoch 5/10, Train Loss: 0.0997, Accuracy: 0.8953, F1 Micro: 0.8953, F1 Macro: 0.857\n",
      "Epoch 6/10, Train Loss: 0.0728, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0507, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8858\n",
      "Epoch 8/10, Train Loss: 0.0332, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.873\n",
      "Epoch 9/10, Train Loss: 0.0351, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8703\n",
      "Epoch 10/10, Train Loss: 0.0214, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.884\n",
      "\n",
      "Sentiment analysis accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8858\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       771\n",
      "    positive       0.92      0.76      0.83       308\n",
      "\n",
      "    accuracy                           0.91      1079\n",
      "   macro avg       0.91      0.87      0.89      1079\n",
      "weighted avg       0.91      0.91      0.91      1079\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9571, F1 Micro: 0.9571, F1 Macro: 0.8524\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.78      0.70      0.74        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.86      0.88       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.78      0.84        78\n",
      "     neutral       0.97      0.99      0.98       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.76      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.88      0.65      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.61      0.54      0.57       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85       162\n",
      "     neutral       0.95      0.95      0.95       387\n",
      "    positive       0.57      0.55      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.79      0.78      0.79       571\n",
      "weighted avg       0.90      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.41      0.55        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.68      0.88      0.77        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.76      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 313.6651442050934 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 58\n",
      "Sampling duration: 9.298324584960938e-05 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4488, Accuracy: 0.8675, F1 Micro: 0.9219, F1 Macro: 0.9149\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2908, Accuracy: 0.9349, F1 Micro: 0.9603, F1 Macro: 0.958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2021, Accuracy: 0.9464, F1 Micro: 0.9671, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1608, Accuracy: 0.9503, F1 Micro: 0.9695, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1367, Accuracy: 0.9542, F1 Micro: 0.9718, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1126, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Epoch 7/10, Train Loss: 0.0885, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9741\n",
      "Epoch 8/10, Train Loss: 0.0768, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9746\n",
      "Epoch 9/10, Train Loss: 0.0665, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.057, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.95      0.94       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3769, Accuracy: 0.8595, F1 Micro: 0.8595, F1 Macro: 0.8057\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2178, Accuracy: 0.8949, F1 Micro: 0.8949, F1 Macro: 0.8611\n",
      "Epoch 3/10, Train Loss: 0.1364, Accuracy: 0.8912, F1 Micro: 0.8912, F1 Macro: 0.8529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1089, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0767, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0656, Accuracy: 0.9172, F1 Micro: 0.9172, F1 Macro: 0.8936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0599, Accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8952\n",
      "Epoch 8/10, Train Loss: 0.0327, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0312, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.8962\n",
      "Epoch 10/10, Train Loss: 0.0262, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8851\n",
      "\n",
      "Sentiment analysis accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.8962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       767\n",
      "    positive       0.94      0.77      0.85       308\n",
      "\n",
      "    accuracy                           0.92      1075\n",
      "   macro avg       0.93      0.87      0.90      1075\n",
      "weighted avg       0.92      0.92      0.92      1075\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9566, F1 Micro: 0.9566, F1 Macro: 0.8646\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.84      0.88        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.58      0.70      0.64        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.84      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.83      0.92      0.86       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.71      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.61      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.85      0.89       200\n",
      "     neutral       0.94      0.95      0.94       315\n",
      "    positive       0.80      0.98      0.88        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.93      0.90       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.85       162\n",
      "     neutral       0.93      0.96      0.94       387\n",
      "    positive       0.62      0.45      0.53        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.81      0.75      0.77       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.52      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.78      0.80       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 326.7404980659485 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 52\n",
      "Sampling duration: 9.703636169433594e-05 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4556, Accuracy: 0.8752, F1 Micro: 0.9263, F1 Macro: 0.9202\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2808, Accuracy: 0.9352, F1 Micro: 0.9604, F1 Macro: 0.958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1989, Accuracy: 0.9493, F1 Micro: 0.9689, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1672, Accuracy: 0.9538, F1 Micro: 0.9716, F1 Macro: 0.9699\n",
      "Epoch 5/10, Train Loss: 0.1347, Accuracy: 0.9535, F1 Micro: 0.9715, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1068, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9738\n",
      "Epoch 7/10, Train Loss: 0.0919, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0761, Accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "Epoch 9/10, Train Loss: 0.0637, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "Epoch 10/10, Train Loss: 0.0558, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3741, Accuracy: 0.87, F1 Micro: 0.87, F1 Macro: 0.8331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2153, Accuracy: 0.8873, F1 Micro: 0.8873, F1 Macro: 0.8548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1425, Accuracy: 0.8964, F1 Micro: 0.8964, F1 Macro: 0.8644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1038, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0763, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0534, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8819\n",
      "Epoch 7/10, Train Loss: 0.0413, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8795\n",
      "Epoch 8/10, Train Loss: 0.0381, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0288, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8894\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0389, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8887\n",
      "\n",
      "Sentiment analysis accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       780\n",
      "    positive       0.93      0.76      0.84       320\n",
      "\n",
      "    accuracy                           0.91      1100\n",
      "   macro avg       0.92      0.87      0.89      1100\n",
      "weighted avg       0.92      0.91      0.91      1100\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.868\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.84      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       0.40      1.00      0.57         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.74      0.94      0.80       571\n",
      "weighted avg       0.96      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.20      0.14      0.17         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.89      0.74      0.81        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.68      0.62      0.65       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.77      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.89      0.88        85\n",
      "     neutral       0.98      0.97      0.98       418\n",
      "    positive       0.96      0.94      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.69      0.77        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.86      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 330.6900599002838 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.00011110305786132812 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4484, Accuracy: 0.872, F1 Micro: 0.925, F1 Macro: 0.9194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2723, Accuracy: 0.9326, F1 Micro: 0.959, F1 Macro: 0.9562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1934, Accuracy: 0.9493, F1 Micro: 0.9689, F1 Macro: 0.9672\n",
      "Epoch 4/10, Train Loss: 0.1602, Accuracy: 0.9486, F1 Micro: 0.9686, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1328, Accuracy: 0.9578, F1 Micro: 0.974, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1056, Accuracy: 0.9622, F1 Micro: 0.9766, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0914, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "Epoch 8/10, Train Loss: 0.078, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9733\n",
      "Epoch 9/10, Train Loss: 0.0654, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9741\n",
      "Epoch 10/10, Train Loss: 0.0523, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.99      0.98       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.94      0.95      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3726, Accuracy: 0.8669, F1 Micro: 0.8669, F1 Macro: 0.8279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.216, Accuracy: 0.8907, F1 Micro: 0.8907, F1 Macro: 0.86\n",
      "Epoch 3/10, Train Loss: 0.1463, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8508\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1077, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0871, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8774\n",
      "Epoch 6/10, Train Loss: 0.0976, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8759\n",
      "Epoch 7/10, Train Loss: 0.0627, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8754\n",
      "Epoch 8/10, Train Loss: 0.0424, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8746\n",
      "Epoch 9/10, Train Loss: 0.0348, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8696\n",
      "Epoch 10/10, Train Loss: 0.0396, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8723\n",
      "\n",
      "Sentiment analysis accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       774\n",
      "    positive       0.93      0.73      0.82       315\n",
      "\n",
      "    accuracy                           0.91      1089\n",
      "   macro avg       0.92      0.85      0.88      1089\n",
      "weighted avg       0.91      0.91      0.90      1089\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9574, F1 Micro: 0.9574, F1 Macro: 0.8719\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.91      0.90        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.78      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.25      0.14      0.18         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.87      0.68      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.69      0.60      0.64       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.88      0.85       162\n",
      "     neutral       0.95      0.95      0.95       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.73      0.77       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.66      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 332.9539592266083 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.274482727050781e-05 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4436, Accuracy: 0.8821, F1 Micro: 0.9302, F1 Macro: 0.9242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2736, Accuracy: 0.9309, F1 Micro: 0.9582, F1 Macro: 0.9561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1896, Accuracy: 0.9493, F1 Micro: 0.9689, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1575, Accuracy: 0.9538, F1 Micro: 0.9715, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.129, Accuracy: 0.9575, F1 Micro: 0.9736, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1039, Accuracy: 0.9583, F1 Micro: 0.9743, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0871, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0731, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9759\n",
      "Epoch 9/10, Train Loss: 0.06, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9751\n",
      "Epoch 10/10, Train Loss: 0.0547, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9754\n",
      "\n",
      "Aspect detection accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.94      0.95      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3837, Accuracy: 0.855, F1 Micro: 0.855, F1 Macro: 0.7984\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.215, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.8663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1494, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8852\n",
      "Epoch 4/10, Train Loss: 0.1073, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0752, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0594, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8873\n",
      "Epoch 7/10, Train Loss: 0.0482, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8836\n",
      "Epoch 8/10, Train Loss: 0.0342, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8865\n",
      "Epoch 9/10, Train Loss: 0.0343, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0187, Accuracy: 0.9187, F1 Micro: 0.9187, F1 Macro: 0.8935\n",
      "\n",
      "Sentiment analysis accuracy: 0.9187, F1 Micro: 0.9187, F1 Macro: 0.8935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       774\n",
      "    positive       0.95      0.76      0.84       309\n",
      "\n",
      "    accuracy                           0.92      1083\n",
      "   macro avg       0.93      0.87      0.89      1083\n",
      "weighted avg       0.92      0.92      0.92      1083\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.958, F1 Micro: 0.958, F1 Macro: 0.8767\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.17      0.14      0.15         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.66      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.66      0.60      0.62       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89       200\n",
      "     neutral       0.95      0.92      0.93       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85       162\n",
      "     neutral       0.94      0.95      0.94       387\n",
      "    positive       0.75      0.41      0.53        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.84      0.74      0.78       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.83      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 345.2079656124115 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.702278137207031e-05 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4423, Accuracy: 0.8852, F1 Micro: 0.9318, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2681, Accuracy: 0.9401, F1 Micro: 0.9633, F1 Macro: 0.9609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1909, Accuracy: 0.9481, F1 Micro: 0.9682, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1531, Accuracy: 0.9528, F1 Micro: 0.9709, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1236, Accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1021, Accuracy: 0.9618, F1 Micro: 0.9764, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0878, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0739, Accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "Epoch 9/10, Train Loss: 0.0618, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9761\n",
      "Epoch 10/10, Train Loss: 0.0517, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.96      0.94      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.98      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3664, Accuracy: 0.866, F1 Micro: 0.866, F1 Macro: 0.823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.213, Accuracy: 0.8874, F1 Micro: 0.8874, F1 Macro: 0.855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.143, Accuracy: 0.8972, F1 Micro: 0.8972, F1 Macro: 0.8651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1136, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8793\n",
      "Epoch 5/10, Train Loss: 0.0797, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8747\n",
      "Epoch 6/10, Train Loss: 0.055, Accuracy: 0.8981, F1 Micro: 0.8981, F1 Macro: 0.8699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0528, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8836\n",
      "Epoch 8/10, Train Loss: 0.0394, Accuracy: 0.9044, F1 Micro: 0.9044, F1 Macro: 0.8775\n",
      "Epoch 9/10, Train Loss: 0.0365, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8803\n",
      "Epoch 10/10, Train Loss: 0.0333, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8743\n",
      "\n",
      "Sentiment analysis accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       790\n",
      "    positive       0.92      0.75      0.83       329\n",
      "\n",
      "    accuracy                           0.91      1119\n",
      "   macro avg       0.91      0.86      0.88      1119\n",
      "weighted avg       0.91      0.91      0.91      1119\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.8662\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.81      0.74      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.89       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.92      0.86       162\n",
      "     neutral       0.96      0.94      0.95       387\n",
      "    positive       0.86      0.27      0.41        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.71      0.74       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.69      0.78        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.84      0.94      0.89        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.88      0.89       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.96      0.82      0.86       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 350.7445876598358 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 25\n",
      "Sampling duration: 0.017178773880004883 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4355, Accuracy: 0.8818, F1 Micro: 0.9302, F1 Macro: 0.9253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2703, Accuracy: 0.9368, F1 Micro: 0.9615, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1903, Accuracy: 0.9486, F1 Micro: 0.9685, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1503, Accuracy: 0.9507, F1 Micro: 0.9697, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1219, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9729\n",
      "Epoch 6/10, Train Loss: 0.0994, Accuracy: 0.9585, F1 Micro: 0.9745, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0833, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0706, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9758\n",
      "Epoch 9/10, Train Loss: 0.0594, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9736\n",
      "Epoch 10/10, Train Loss: 0.0524, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9743\n",
      "\n",
      "Aspect detection accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.94      0.93      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.354, Accuracy: 0.8651, F1 Micro: 0.8651, F1 Macro: 0.8187\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1924, Accuracy: 0.8924, F1 Micro: 0.8924, F1 Macro: 0.8554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1297, Accuracy: 0.8997, F1 Micro: 0.8997, F1 Macro: 0.8656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0982, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.8728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.085, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.064, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.886\n",
      "Epoch 7/10, Train Loss: 0.0452, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8817\n",
      "Epoch 8/10, Train Loss: 0.0353, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.882\n",
      "Epoch 9/10, Train Loss: 0.0275, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8737\n",
      "Epoch 10/10, Train Loss: 0.0205, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8759\n",
      "\n",
      "Sentiment analysis accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       784\n",
      "    positive       0.93      0.75      0.83       313\n",
      "\n",
      "    accuracy                           0.91      1097\n",
      "   macro avg       0.92      0.86      0.89      1097\n",
      "weighted avg       0.91      0.91      0.91      1097\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9566, F1 Micro: 0.9566, F1 Macro: 0.8641\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.17      0.14      0.15         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.89      0.62      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.67      0.58      0.62       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.90      0.89       200\n",
      "     neutral       0.94      0.91      0.93       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.87      0.85       162\n",
      "     neutral       0.94      0.95      0.95       387\n",
      "    positive       0.75      0.41      0.53        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.84      0.74      0.78       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.89      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.66      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.67      1.00      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.87      0.97      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 353.43603253364563 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.00010275840759277344 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4386, Accuracy: 0.8835, F1 Micro: 0.9311, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2619, Accuracy: 0.9373, F1 Micro: 0.9619, F1 Macro: 0.9597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1938, Accuracy: 0.9484, F1 Micro: 0.9684, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1508, Accuracy: 0.9535, F1 Micro: 0.9713, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1228, Accuracy: 0.9568, F1 Micro: 0.9734, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1067, Accuracy: 0.9635, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0848, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0732, Accuracy: 0.9648, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "Epoch 9/10, Train Loss: 0.061, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9751\n",
      "Epoch 10/10, Train Loss: 0.0514, Accuracy: 0.9641, F1 Micro: 0.9776, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9648, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.94      0.93       317\n",
      "       linen       0.93      0.98      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.99      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3495, Accuracy: 0.8791, F1 Micro: 0.8791, F1 Macro: 0.8399\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2182, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8835\n",
      "Epoch 3/10, Train Loss: 0.148, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1062, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.893\n",
      "Epoch 5/10, Train Loss: 0.0715, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0735, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.8954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.05, Accuracy: 0.926, F1 Micro: 0.926, F1 Macro: 0.902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0415, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9054\n",
      "Epoch 9/10, Train Loss: 0.0236, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.8966\n",
      "Epoch 10/10, Train Loss: 0.0126, Accuracy: 0.925, F1 Micro: 0.925, F1 Macro: 0.9013\n",
      "\n",
      "Sentiment analysis accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9054\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.97      0.95       770\n",
      "    positive       0.92      0.81      0.86       297\n",
      "\n",
      "    accuracy                           0.93      1067\n",
      "   macro avg       0.92      0.89      0.91      1067\n",
      "weighted avg       0.93      0.93      0.93      1067\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.958, F1 Micro: 0.958, F1 Macro: 0.8661\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.92      0.93        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.87      0.88       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.83      0.65      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.54      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.91      0.88       200\n",
      "     neutral       0.95      0.90      0.92       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.90      0.87       162\n",
      "     neutral       0.95      0.95      0.95       387\n",
      "    positive       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.93      0.75      0.80       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 361.9581551551819 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.00010561943054199219 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4374, Accuracy: 0.8903, F1 Micro: 0.9347, F1 Macro: 0.929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.257, Accuracy: 0.9394, F1 Micro: 0.9631, F1 Macro: 0.961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1842, Accuracy: 0.9484, F1 Micro: 0.9684, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1524, Accuracy: 0.9536, F1 Micro: 0.9716, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1189, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1028, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9753\n",
      "Epoch 7/10, Train Loss: 0.082, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9749\n",
      "Epoch 8/10, Train Loss: 0.0693, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9735\n",
      "Epoch 9/10, Train Loss: 0.0591, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0511, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.93      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3728, Accuracy: 0.8586, F1 Micro: 0.8586, F1 Macro: 0.8001\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1898, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1227, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0982, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8846\n",
      "Epoch 5/10, Train Loss: 0.0766, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8844\n",
      "Epoch 6/10, Train Loss: 0.049, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0316, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8843\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0285, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.033, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8865\n",
      "Epoch 10/10, Train Loss: 0.0146, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8868\n",
      "\n",
      "Sentiment analysis accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.99      0.94       779\n",
      "    positive       0.96      0.73      0.83       310\n",
      "\n",
      "    accuracy                           0.91      1089\n",
      "   macro avg       0.93      0.86      0.89      1089\n",
      "weighted avg       0.92      0.91      0.91      1089\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8725\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.86      0.87       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.66      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.60      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.87      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.73      0.77       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.83      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 377.3724467754364 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.034706115722656e-05 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4348, Accuracy: 0.8889, F1 Micro: 0.9339, F1 Macro: 0.9285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2512, Accuracy: 0.942, F1 Micro: 0.9645, F1 Macro: 0.9619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.183, Accuracy: 0.9531, F1 Micro: 0.9712, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1487, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.12, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.099, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9751\n",
      "Epoch 7/10, Train Loss: 0.0811, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0687, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "Epoch 9/10, Train Loss: 0.0572, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "Epoch 10/10, Train Loss: 0.0475, Accuracy: 0.9649, F1 Micro: 0.9783, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3656, Accuracy: 0.8452, F1 Micro: 0.8452, F1 Macro: 0.7754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2051, Accuracy: 0.8974, F1 Micro: 0.8974, F1 Macro: 0.8664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1244, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0971, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.066, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0616, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0365, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0354, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8892\n",
      "Epoch 9/10, Train Loss: 0.0357, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0244, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8906\n",
      "\n",
      "Sentiment analysis accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8906\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       779\n",
      "    positive       0.95      0.75      0.84       313\n",
      "\n",
      "    accuracy                           0.92      1092\n",
      "   macro avg       0.93      0.87      0.89      1092\n",
      "weighted avg       0.92      0.92      0.91      1092\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.8752\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.92      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.82      0.93      0.86       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.25      0.14      0.18         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.87      0.69      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.69      0.61      0.64       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.89      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       1.00      0.36      0.53        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.93      0.74      0.79       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.84      0.87       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 388.61397671699524 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.654594421386719e-05 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.433, Accuracy: 0.8913, F1 Micro: 0.9355, F1 Macro: 0.9308\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2479, Accuracy: 0.9439, F1 Micro: 0.9656, F1 Macro: 0.9632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1763, Accuracy: 0.9505, F1 Micro: 0.9697, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1432, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1199, Accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.096, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "Epoch 7/10, Train Loss: 0.0798, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9755\n",
      "Epoch 8/10, Train Loss: 0.0662, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0544, Accuracy: 0.9661, F1 Micro: 0.9789, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0461, Accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.977\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.95      0.95      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3424, Accuracy: 0.859, F1 Micro: 0.859, F1 Macro: 0.8193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2103, Accuracy: 0.8969, F1 Micro: 0.8969, F1 Macro: 0.865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1505, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1077, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.885\n",
      "Epoch 5/10, Train Loss: 0.0792, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8819\n",
      "Epoch 6/10, Train Loss: 0.061, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0491, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.8964\n",
      "Epoch 8/10, Train Loss: 0.0344, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.88\n",
      "Epoch 9/10, Train Loss: 0.0293, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.877\n",
      "Epoch 10/10, Train Loss: 0.0198, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8845\n",
      "\n",
      "Sentiment analysis accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.8964\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94       787\n",
      "    positive       0.92      0.79      0.85       319\n",
      "\n",
      "    accuracy                           0.92      1106\n",
      "   macro avg       0.92      0.88      0.90      1106\n",
      "weighted avg       0.92      0.92      0.92      1106\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9604, F1 Micro: 0.9604, F1 Macro: 0.8749\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.29      0.40         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.83      0.66      0.72       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.89       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.90      0.87       162\n",
      "     neutral       0.95      0.95      0.95       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.78      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.99      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.88      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 387.06544303894043 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.059906005859375e-05 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4326, Accuracy: 0.8958, F1 Micro: 0.9378, F1 Macro: 0.9331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2443, Accuracy: 0.9451, F1 Micro: 0.9663, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1793, Accuracy: 0.9543, F1 Micro: 0.972, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1426, Accuracy: 0.9585, F1 Micro: 0.9743, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1179, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0945, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0786, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0684, Accuracy: 0.9668, F1 Micro: 0.9794, F1 Macro: 0.9773\n",
      "Epoch 9/10, Train Loss: 0.0567, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "Epoch 10/10, Train Loss: 0.0461, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9668, F1 Micro: 0.9794, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.98      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.345, Accuracy: 0.866, F1 Micro: 0.866, F1 Macro: 0.8253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1778, Accuracy: 0.8903, F1 Micro: 0.8903, F1 Macro: 0.8641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1212, Accuracy: 0.9002, F1 Micro: 0.9002, F1 Macro: 0.8758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0893, Accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.8764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0754, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.88\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0593, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8834\n",
      "Epoch 7/10, Train Loss: 0.0439, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8728\n",
      "Epoch 8/10, Train Loss: 0.0443, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8783\n",
      "Epoch 9/10, Train Loss: 0.0235, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0294, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8868\n",
      "\n",
      "Sentiment analysis accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.99      0.94       790\n",
      "    positive       0.96      0.74      0.83       322\n",
      "\n",
      "    accuracy                           0.91      1112\n",
      "   macro avg       0.93      0.86      0.89      1112\n",
      "weighted avg       0.92      0.91      0.91      1112\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9611, F1 Micro: 0.9611, F1 Macro: 0.8879\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.25      0.14      0.18         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.87      0.71      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.69      0.61      0.64       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.92      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.88       162\n",
      "     neutral       0.95      0.96      0.95       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.78      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.88        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.66      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 395.85768485069275 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 36\n",
      "Sampling duration: 0.020323753356933594 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4332, Accuracy: 0.8899, F1 Micro: 0.9344, F1 Macro: 0.9286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.244, Accuracy: 0.9432, F1 Micro: 0.9653, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1788, Accuracy: 0.9524, F1 Micro: 0.9708, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1399, Accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1155, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.975\n",
      "Epoch 6/10, Train Loss: 0.0963, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0791, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "Epoch 8/10, Train Loss: 0.0682, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0554, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "Epoch 10/10, Train Loss: 0.0468, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3489, Accuracy: 0.8814, F1 Micro: 0.8814, F1 Macro: 0.8411\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1971, Accuracy: 0.9018, F1 Micro: 0.9018, F1 Macro: 0.8681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.117, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0824, Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.9044\n",
      "Epoch 5/10, Train Loss: 0.0614, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8866\n",
      "Epoch 6/10, Train Loss: 0.0456, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8845\n",
      "Epoch 7/10, Train Loss: 0.0419, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9011\n",
      "Epoch 8/10, Train Loss: 0.0262, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8867\n",
      "Epoch 9/10, Train Loss: 0.0156, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0264, Accuracy: 0.9268, F1 Micro: 0.9268, F1 Macro: 0.9055\n",
      "\n",
      "Sentiment analysis accuracy: 0.9268, F1 Micro: 0.9268, F1 Macro: 0.9055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       773\n",
      "    positive       0.93      0.80      0.86       306\n",
      "\n",
      "    accuracy                           0.93      1079\n",
      "   macro avg       0.93      0.89      0.91      1079\n",
      "weighted avg       0.93      0.93      0.92      1079\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.8703\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.86      0.87       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.78      0.78      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.29      0.33         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.83      0.72      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.73      0.66      0.69       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.76      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 400.6071171760559 s\n",
      "Total runtime: 7773.6315886974335 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06450dfa",
   "metadata": {
    "papermill": {
     "duration": 0.011356,
     "end_time": "2025-03-31T11:40:20.387953",
     "exception": false,
     "start_time": "2025-03-31T11:40:20.376597",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e0ff132",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T11:40:20.411286Z",
     "iopub.status.busy": "2025-03-31T11:40:20.411088Z",
     "iopub.status.idle": "2025-03-31T13:30:00.356378Z",
     "shell.execute_reply": "2025-03-31T13:30:00.355355Z"
    },
    "papermill": {
     "duration": 6579.958675,
     "end_time": "2025-03-31T13:30:00.358024",
     "exception": false,
     "start_time": "2025-03-31T11:40:20.399349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e9281428a84bddaf7ab4fe58702b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6222, Accuracy: 0.7984, F1 Micro: 0.8875, F1 Macro: 0.8819\n",
      "Epoch 2/10, Train Loss: 0.4944, Accuracy: 0.7981, F1 Micro: 0.8873, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4566, Accuracy: 0.7997, F1 Micro: 0.8881, F1 Macro: 0.8821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4288, Accuracy: 0.8017, F1 Micro: 0.8893, F1 Macro: 0.8836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4243, Accuracy: 0.804, F1 Micro: 0.8907, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4161, Accuracy: 0.8135, F1 Micro: 0.8944, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4005, Accuracy: 0.8179, F1 Micro: 0.8965, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3794, Accuracy: 0.8247, F1 Micro: 0.9001, F1 Macro: 0.8939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3213, Accuracy: 0.8417, F1 Micro: 0.9083, F1 Macro: 0.9019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3264, Accuracy: 0.8519, F1 Micro: 0.9131, F1 Macro: 0.9062\n",
      "\n",
      "Aspect detection accuracy: 0.8519, F1 Micro: 0.9131, F1 Macro: 0.9062\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.88      1.00      0.94       462\n",
      "   air_panas       0.83      1.00      0.91       480\n",
      "         bau       0.87      0.98      0.92       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.78      0.78      0.78       317\n",
      "       linen       0.79      0.92      0.85       392\n",
      "     service       0.87      0.96      0.91       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.86      1.00      0.93       498\n",
      "\n",
      "   micro avg       0.86      0.97      0.91      4614\n",
      "   macro avg       0.86      0.96      0.91      4614\n",
      "weighted avg       0.86      0.97      0.91      4614\n",
      " samples avg       0.86      0.97      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5506, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4796, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4879, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4287, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3515, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3279, Accuracy: 0.7, F1 Micro: 0.7, F1 Macro: 0.6242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2793, Accuracy: 0.7073, F1 Micro: 0.7073, F1 Macro: 0.6432\n",
      "Epoch 8/10, Train Loss: 0.202, Accuracy: 0.6873, F1 Micro: 0.6873, F1 Macro: 0.6008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2003, Accuracy: 0.7309, F1 Micro: 0.7309, F1 Macro: 0.6829\n",
      "Epoch 10/10, Train Loss: 0.1315, Accuracy: 0.7109, F1 Micro: 0.7109, F1 Macro: 0.649\n",
      "\n",
      "Sentiment analysis accuracy: 0.7309, F1 Micro: 0.7309, F1 Macro: 0.6829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.93      0.81       332\n",
      "    positive       0.80      0.43      0.56       218\n",
      "\n",
      "    accuracy                           0.73       550\n",
      "   macro avg       0.75      0.68      0.68       550\n",
      "weighted avg       0.75      0.73      0.71       550\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8427, F1 Micro: 0.8427, F1 Macro: 0.4234\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.46      0.61        97\n",
      "     neutral       0.88      1.00      0.94       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.59      0.49      0.51       571\n",
      "weighted avg       0.86      0.88      0.86       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.28      0.33      0.30       571\n",
      "weighted avg       0.69      0.83      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.08      0.12        78\n",
      "     neutral       0.87      0.98      0.92       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.40      0.35      0.35       571\n",
      "weighted avg       0.79      0.85      0.81       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.69      0.70       200\n",
      "     neutral       0.78      0.77      0.78       315\n",
      "    positive       0.40      0.43      0.41        56\n",
      "\n",
      "    accuracy                           0.71       571\n",
      "   macro avg       0.63      0.63      0.63       571\n",
      "weighted avg       0.72      0.71      0.71       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.48      0.56       162\n",
      "     neutral       0.78      0.92      0.85       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.76       571\n",
      "   macro avg       0.48      0.47      0.47       571\n",
      "weighted avg       0.72      0.76      0.73       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.52      0.58        85\n",
      "     neutral       0.87      0.96      0.91       418\n",
      "    positive       0.90      0.53      0.67        68\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.81      0.67      0.72       571\n",
      "weighted avg       0.84      0.84      0.83       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        74\n",
      "     neutral       0.87      1.00      0.93       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.80       571\n",
      "\n",
      "Total train time: 85.02579832077026 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 215\n",
      "Sampling duration: 0.0002219676971435547 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5589, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4694, Accuracy: 0.8045, F1 Micro: 0.8905, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4394, Accuracy: 0.8161, F1 Micro: 0.8955, F1 Macro: 0.8885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3901, Accuracy: 0.8311, F1 Micro: 0.9038, F1 Macro: 0.8985\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3607, Accuracy: 0.8642, F1 Micro: 0.9203, F1 Macro: 0.9135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3011, Accuracy: 0.8747, F1 Micro: 0.9262, F1 Macro: 0.9212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2634, Accuracy: 0.8976, F1 Micro: 0.939, F1 Macro: 0.9353\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.236, Accuracy: 0.9095, F1 Micro: 0.9457, F1 Macro: 0.9425\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2042, Accuracy: 0.9184, F1 Micro: 0.9504, F1 Macro: 0.9469\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1802, Accuracy: 0.9186, F1 Micro: 0.9505, F1 Macro: 0.9468\n",
      "\n",
      "Aspect detection accuracy: 0.9186, F1 Micro: 0.9505, F1 Macro: 0.9468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.98      0.98       462\n",
      "   air_panas       0.93      1.00      0.96       480\n",
      "         bau       0.96      0.95      0.96       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.91      0.84      0.87       317\n",
      "       linen       0.85      0.97      0.91       392\n",
      "     service       0.91      0.99      0.95       423\n",
      "sunrise_meal       0.93      1.00      0.96       530\n",
      "          tv       0.94      0.99      0.97       516\n",
      "        wifi       0.98      0.99      0.99       498\n",
      "\n",
      "   micro avg       0.93      0.98      0.95      4614\n",
      "   macro avg       0.93      0.97      0.95      4614\n",
      "weighted avg       0.93      0.98      0.95      4614\n",
      " samples avg       0.93      0.97      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4826, Accuracy: 0.7101, F1 Micro: 0.7101, F1 Macro: 0.4153\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3642, Accuracy: 0.7559, F1 Micro: 0.7559, F1 Macro: 0.5885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3311, Accuracy: 0.8027, F1 Micro: 0.8027, F1 Macro: 0.7424\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2169, Accuracy: 0.8082, F1 Micro: 0.8082, F1 Macro: 0.7243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2333, Accuracy: 0.8227, F1 Micro: 0.8227, F1 Macro: 0.7419\n",
      "Epoch 6/10, Train Loss: 0.166, Accuracy: 0.8149, F1 Micro: 0.8149, F1 Macro: 0.7229\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.178, Accuracy: 0.8239, F1 Micro: 0.8239, F1 Macro: 0.7544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1521, Accuracy: 0.835, F1 Micro: 0.835, F1 Macro: 0.7636\n",
      "Epoch 9/10, Train Loss: 0.1031, Accuracy: 0.825, F1 Micro: 0.825, F1 Macro: 0.7404\n",
      "Epoch 10/10, Train Loss: 0.0822, Accuracy: 0.8305, F1 Micro: 0.8305, F1 Macro: 0.7546\n",
      "\n",
      "Sentiment analysis accuracy: 0.835, F1 Micro: 0.835, F1 Macro: 0.7636\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.97      0.89       637\n",
      "    positive       0.89      0.49      0.63       260\n",
      "\n",
      "    accuracy                           0.84       897\n",
      "   macro avg       0.86      0.73      0.76       897\n",
      "weighted avg       0.84      0.84      0.82       897\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.6386\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89        97\n",
      "     neutral       0.98      0.98      0.98       459\n",
      "    positive       0.79      0.73      0.76        15\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.88      0.87      0.87       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.63      0.74        86\n",
      "     neutral       0.93      1.00      0.96       475\n",
      "    positive       0.50      0.10      0.17        10\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.78      0.57      0.62       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.78      0.74        78\n",
      "     neutral       0.96      0.95      0.95       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.74      0.79       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       1.00      0.03      0.06        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.62      0.34      0.33       571\n",
      "weighted avg       0.88      0.87      0.82       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.85      0.81       200\n",
      "     neutral       0.91      0.83      0.87       315\n",
      "    positive       0.80      0.86      0.83        56\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.83      0.85      0.83       571\n",
      "weighted avg       0.85      0.84      0.84       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.66      0.74       162\n",
      "     neutral       0.85      0.97      0.91       387\n",
      "    positive       0.50      0.05      0.08        22\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.73      0.56      0.58       571\n",
      "weighted avg       0.83      0.85      0.83       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.61      0.71        85\n",
      "     neutral       0.91      0.99      0.95       418\n",
      "    positive       0.90      0.69      0.78        68\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.77      0.81       571\n",
      "weighted avg       0.90      0.90      0.89       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.07      0.12        29\n",
      "     neutral       0.93      1.00      0.96       525\n",
      "    positive       0.50      0.06      0.11        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.70      0.38      0.40       571\n",
      "weighted avg       0.90      0.92      0.89       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.46      0.60        54\n",
      "     neutral       0.94      0.99      0.97       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.49      0.52       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89        74\n",
      "     neutral       0.98      0.99      0.99       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.63      0.62      0.63       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Total train time: 116.88195085525513 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 193\n",
      "Sampling duration: 0.00014710426330566406 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5201, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4532, Accuracy: 0.8038, F1 Micro: 0.8908, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4001, Accuracy: 0.859, F1 Micro: 0.9176, F1 Macro: 0.9117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3281, Accuracy: 0.8858, F1 Micro: 0.9323, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2667, Accuracy: 0.913, F1 Micro: 0.9477, F1 Macro: 0.9451\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2218, Accuracy: 0.9283, F1 Micro: 0.9563, F1 Macro: 0.9536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1856, Accuracy: 0.9323, F1 Micro: 0.9587, F1 Macro: 0.9564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1751, Accuracy: 0.9356, F1 Micro: 0.9608, F1 Macro: 0.9586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1464, Accuracy: 0.9403, F1 Micro: 0.9635, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.128, Accuracy: 0.9415, F1 Micro: 0.9642, F1 Macro: 0.9616\n",
      "\n",
      "Aspect detection accuracy: 0.9415, F1 Micro: 0.9642, F1 Macro: 0.9616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.94      1.00      0.97       480\n",
      "         bau       0.95      0.98      0.96       496\n",
      "     general       0.90      1.00      0.95       500\n",
      "  kebersihan       0.91      0.91      0.91       317\n",
      "       linen       0.89      0.96      0.92       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.96      1.00      0.98       530\n",
      "          tv       0.97      1.00      0.98       516\n",
      "        wifi       0.98      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      4614\n",
      "   macro avg       0.94      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.96      4614\n",
      " samples avg       0.94      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4426, Accuracy: 0.7476, F1 Micro: 0.7476, F1 Macro: 0.5323\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.275, Accuracy: 0.8429, F1 Micro: 0.8429, F1 Macro: 0.7756\n",
      "Epoch 3/10, Train Loss: 0.2305, Accuracy: 0.8419, F1 Micro: 0.8419, F1 Macro: 0.7738\n",
      "Epoch 4/10, Train Loss: 0.1903, Accuracy: 0.8356, F1 Micro: 0.8356, F1 Macro: 0.7531\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1872, Accuracy: 0.8492, F1 Micro: 0.8492, F1 Macro: 0.8115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1305, Accuracy: 0.8775, F1 Micro: 0.8775, F1 Macro: 0.8351\n",
      "Epoch 7/10, Train Loss: 0.1425, Accuracy: 0.8723, F1 Micro: 0.8723, F1 Macro: 0.8258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1039, Accuracy: 0.8817, F1 Micro: 0.8817, F1 Macro: 0.8334\n",
      "Epoch 9/10, Train Loss: 0.0467, Accuracy: 0.8733, F1 Micro: 0.8733, F1 Macro: 0.8238\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0412, Accuracy: 0.8848, F1 Micro: 0.8848, F1 Macro: 0.8439\n",
      "\n",
      "Sentiment analysis accuracy: 0.8848, F1 Micro: 0.8848, F1 Macro: 0.8439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.97      0.92       686\n",
      "    positive       0.90      0.66      0.76       269\n",
      "\n",
      "    accuracy                           0.88       955\n",
      "   macro avg       0.89      0.82      0.84       955\n",
      "weighted avg       0.89      0.88      0.88       955\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9335, F1 Micro: 0.9335, F1 Macro: 0.7749\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.72      0.82        86\n",
      "     neutral       0.94      1.00      0.97       475\n",
      "    positive       0.75      0.30      0.43        10\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.88      0.67      0.74       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.69      0.75        78\n",
      "     neutral       0.95      0.98      0.96       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.72      0.79       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.90      1.00      0.95       496\n",
      "    positive       0.95      0.28      0.43        68\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.62      0.43      0.46       571\n",
      "weighted avg       0.89      0.90      0.87       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84       200\n",
      "     neutral       0.91      0.91      0.91       315\n",
      "    positive       0.76      0.91      0.83        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.84      0.88      0.86       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.74      0.79       162\n",
      "     neutral       0.89      0.96      0.92       387\n",
      "    positive       0.62      0.23      0.33        22\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.78      0.64      0.68       571\n",
      "weighted avg       0.86      0.87      0.86       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.80      0.82        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.94      0.85      0.89        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.88      0.89       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.28      0.39        29\n",
      "     neutral       0.96      1.00      0.98       525\n",
      "    positive       0.85      0.65      0.73        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.82      0.64      0.70       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.70      0.79        54\n",
      "     neutral       0.97      1.00      0.98       511\n",
      "    positive       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.96      0.68      0.76       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.88      0.92        74\n",
      "     neutral       0.98      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.96      0.92       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 138.09097719192505 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 174\n",
      "Sampling duration: 0.00013780593872070312 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4998, Accuracy: 0.8005, F1 Micro: 0.8892, F1 Macro: 0.8847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4137, Accuracy: 0.8253, F1 Micro: 0.9011, F1 Macro: 0.8958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3523, Accuracy: 0.879, F1 Micro: 0.9285, F1 Macro: 0.9244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2825, Accuracy: 0.9116, F1 Micro: 0.9469, F1 Macro: 0.9439\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2291, Accuracy: 0.9337, F1 Micro: 0.9597, F1 Macro: 0.9572\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1891, Accuracy: 0.9372, F1 Micro: 0.9616, F1 Macro: 0.9592\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1654, Accuracy: 0.9422, F1 Micro: 0.9646, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1415, Accuracy: 0.9425, F1 Micro: 0.9649, F1 Macro: 0.9626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1263, Accuracy: 0.9488, F1 Micro: 0.9686, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1073, Accuracy: 0.9547, F1 Micro: 0.972, F1 Macro: 0.9695\n",
      "\n",
      "Aspect detection accuracy: 0.9547, F1 Micro: 0.972, F1 Macro: 0.9695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.96      1.00      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.92      0.93      0.92       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.96      0.96       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4545, Accuracy: 0.7342, F1 Micro: 0.7342, F1 Macro: 0.5178\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2968, Accuracy: 0.8467, F1 Micro: 0.8467, F1 Macro: 0.7854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2179, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.8046\n",
      "Epoch 4/10, Train Loss: 0.1957, Accuracy: 0.8543, F1 Micro: 0.8543, F1 Macro: 0.796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1505, Accuracy: 0.8761, F1 Micro: 0.8761, F1 Macro: 0.8344\n",
      "Epoch 6/10, Train Loss: 0.1159, Accuracy: 0.8694, F1 Micro: 0.8694, F1 Macro: 0.8258\n",
      "Epoch 7/10, Train Loss: 0.0961, Accuracy: 0.8732, F1 Micro: 0.8732, F1 Macro: 0.8282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0617, Accuracy: 0.8912, F1 Micro: 0.8912, F1 Macro: 0.8572\n",
      "Epoch 9/10, Train Loss: 0.0508, Accuracy: 0.8893, F1 Micro: 0.8893, F1 Macro: 0.8518\n",
      "Epoch 10/10, Train Loss: 0.0771, Accuracy: 0.8865, F1 Micro: 0.8865, F1 Macro: 0.8493\n",
      "\n",
      "Sentiment analysis accuracy: 0.8912, F1 Micro: 0.8912, F1 Macro: 0.8572\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93       745\n",
      "    positive       0.93      0.68      0.79       312\n",
      "\n",
      "    accuracy                           0.89      1057\n",
      "   macro avg       0.91      0.83      0.86      1057\n",
      "weighted avg       0.90      0.89      0.89      1057\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9461, F1 Micro: 0.9461, F1 Macro: 0.7965\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.92      0.93        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.81      0.87      0.84        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.81      0.88        86\n",
      "     neutral       0.96      1.00      0.98       475\n",
      "    positive       0.67      0.20      0.31        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.67      0.72       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.88      0.62      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.53      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86       200\n",
      "     neutral       0.92      0.93      0.92       315\n",
      "    positive       0.81      0.91      0.86        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.87      0.89      0.88       571\n",
      "weighted avg       0.90      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.84      0.84       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.83      0.23      0.36        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.86      0.68      0.71       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.87      0.83        85\n",
      "     neutral       0.97      0.96      0.97       418\n",
      "    positive       0.91      0.90      0.90        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.45      0.55        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.83      0.59      0.69        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.68      0.74       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.92        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.76      0.80       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.86      0.91       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 157.98622465133667 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 156\n",
      "Sampling duration: 0.0001251697540283203 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4987, Accuracy: 0.8036, F1 Micro: 0.8861, F1 Macro: 0.8597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4169, Accuracy: 0.8472, F1 Micro: 0.9124, F1 Macro: 0.9078\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3282, Accuracy: 0.9082, F1 Micro: 0.9449, F1 Macro: 0.9409\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2565, Accuracy: 0.9311, F1 Micro: 0.9579, F1 Macro: 0.9549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1977, Accuracy: 0.9382, F1 Micro: 0.9625, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1733, Accuracy: 0.9465, F1 Micro: 0.9672, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1471, Accuracy: 0.9495, F1 Micro: 0.9689, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1265, Accuracy: 0.951, F1 Micro: 0.9699, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1078, Accuracy: 0.9524, F1 Micro: 0.9707, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0949, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9714\n",
      "\n",
      "Aspect detection accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.91      0.93       317\n",
      "       linen       0.91      0.98      0.94       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4437, Accuracy: 0.843, F1 Micro: 0.843, F1 Macro: 0.8028\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2675, Accuracy: 0.8553, F1 Micro: 0.8553, F1 Macro: 0.7993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2069, Accuracy: 0.8609, F1 Micro: 0.8609, F1 Macro: 0.8137\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1345, Accuracy: 0.8903, F1 Micro: 0.8903, F1 Macro: 0.8578\n",
      "Epoch 5/10, Train Loss: 0.1227, Accuracy: 0.8846, F1 Micro: 0.8846, F1 Macro: 0.8511\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0975, Accuracy: 0.8903, F1 Micro: 0.8903, F1 Macro: 0.8561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.072, Accuracy: 0.8921, F1 Micro: 0.8921, F1 Macro: 0.8634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0369, Accuracy: 0.8997, F1 Micro: 0.8997, F1 Macro: 0.8701\n",
      "Epoch 9/10, Train Loss: 0.0433, Accuracy: 0.8903, F1 Micro: 0.8903, F1 Macro: 0.8547\n",
      "Epoch 10/10, Train Loss: 0.0468, Accuracy: 0.8903, F1 Micro: 0.8903, F1 Macro: 0.8578\n",
      "\n",
      "Sentiment analysis accuracy: 0.8997, F1 Micro: 0.8997, F1 Macro: 0.8701\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93       748\n",
      "    positive       0.92      0.72      0.81       309\n",
      "\n",
      "    accuracy                           0.90      1057\n",
      "   macro avg       0.91      0.85      0.87      1057\n",
      "weighted avg       0.90      0.90      0.90      1057\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.8147\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.78      0.93      0.85        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.85      0.89        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.78      0.81       571\n",
      "weighted avg       0.96      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.84      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.87       200\n",
      "     neutral       0.94      0.91      0.92       315\n",
      "    positive       0.85      0.93      0.89        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.88      0.91      0.89       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.80      0.83       162\n",
      "     neutral       0.91      0.98      0.94       387\n",
      "    positive       1.00      0.05      0.09        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.92      0.61      0.62       571\n",
      "weighted avg       0.89      0.89      0.87       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.78      0.83        85\n",
      "     neutral       0.96      0.97      0.97       418\n",
      "    positive       0.83      0.91      0.87        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.89      0.89      0.89       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.41      0.52        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.69      0.65      0.67        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.79      0.69      0.72       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.97      0.81      0.86       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.98      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 181.3117551803589 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 141\n",
      "Sampling duration: 0.00013756752014160156 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.492, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3985, Accuracy: 0.8646, F1 Micro: 0.9204, F1 Macro: 0.9137\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2988, Accuracy: 0.9128, F1 Micro: 0.9476, F1 Macro: 0.9436\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2258, Accuracy: 0.9359, F1 Micro: 0.9609, F1 Macro: 0.9577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1813, Accuracy: 0.9443, F1 Micro: 0.9659, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1536, Accuracy: 0.9476, F1 Micro: 0.9678, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1328, Accuracy: 0.9516, F1 Micro: 0.9702, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1099, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9712\n",
      "Epoch 9/10, Train Loss: 0.1006, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0872, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9728\n",
      "\n",
      "Aspect detection accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.91      0.98      0.94       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3956, Accuracy: 0.8456, F1 Micro: 0.8456, F1 Macro: 0.795\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2433, Accuracy: 0.8636, F1 Micro: 0.8636, F1 Macro: 0.8238\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2081, Accuracy: 0.8722, F1 Micro: 0.8722, F1 Macro: 0.8298\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1306, Accuracy: 0.8873, F1 Micro: 0.8873, F1 Macro: 0.8525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1029, Accuracy: 0.8977, F1 Micro: 0.8977, F1 Macro: 0.8694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0764, Accuracy: 0.8987, F1 Micro: 0.8987, F1 Macro: 0.8704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0877, Accuracy: 0.8987, F1 Micro: 0.8987, F1 Macro: 0.8667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0616, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0347, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.8839\n",
      "Epoch 10/10, Train Loss: 0.04, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8798\n",
      "\n",
      "Sentiment analysis accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.8839\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       750\n",
      "    positive       0.92      0.75      0.83       306\n",
      "\n",
      "    accuracy                           0.91      1056\n",
      "   macro avg       0.91      0.86      0.88      1056\n",
      "weighted avg       0.91      0.91      0.91      1056\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.828\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.92      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.82      0.93      0.87        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.95      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.84      0.88        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.78      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.77      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.81      0.98      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.85       162\n",
      "     neutral       0.91      0.98      0.95       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.72      0.77       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.90      0.91      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.90      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.78      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.96      0.76      0.81       571\n",
      "weighted avg       0.99      0.99      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 193.60978436470032 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 127\n",
      "Sampling duration: 0.0001442432403564453 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4883, Accuracy: 0.8012, F1 Micro: 0.8895, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3771, Accuracy: 0.8877, F1 Micro: 0.9333, F1 Macro: 0.9282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2729, Accuracy: 0.9302, F1 Micro: 0.9576, F1 Macro: 0.9548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2102, Accuracy: 0.9361, F1 Micro: 0.961, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1675, Accuracy: 0.9458, F1 Micro: 0.9668, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1444, Accuracy: 0.9535, F1 Micro: 0.9713, F1 Macro: 0.9689\n",
      "Epoch 7/10, Train Loss: 0.1228, Accuracy: 0.9531, F1 Micro: 0.9711, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.105, Accuracy: 0.9564, F1 Micro: 0.9732, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0908, Accuracy: 0.9573, F1 Micro: 0.9736, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0816, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9732\n",
      "\n",
      "Aspect detection accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.91      0.98      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4275, Accuracy: 0.8453, F1 Micro: 0.8453, F1 Macro: 0.7964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2243, Accuracy: 0.8625, F1 Micro: 0.8625, F1 Macro: 0.8144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.179, Accuracy: 0.8797, F1 Micro: 0.8797, F1 Macro: 0.8384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1337, Accuracy: 0.894, F1 Micro: 0.894, F1 Macro: 0.8586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0971, Accuracy: 0.8997, F1 Micro: 0.8997, F1 Macro: 0.8659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0543, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8847\n",
      "Epoch 7/10, Train Loss: 0.0422, Accuracy: 0.8949, F1 Micro: 0.8949, F1 Macro: 0.8621\n",
      "Epoch 8/10, Train Loss: 0.0328, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8724\n",
      "Epoch 9/10, Train Loss: 0.0291, Accuracy: 0.9007, F1 Micro: 0.9007, F1 Macro: 0.8706\n",
      "Epoch 10/10, Train Loss: 0.0406, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8732\n",
      "\n",
      "Sentiment analysis accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8847\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       748\n",
      "    positive       0.94      0.74      0.83       299\n",
      "\n",
      "    accuracy                           0.91      1047\n",
      "   macro avg       0.92      0.86      0.88      1047\n",
      "weighted avg       0.91      0.91      0.91      1047\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9513, F1 Micro: 0.9513, F1 Macro: 0.8331\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.78      0.93      0.85        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.85      0.90        86\n",
      "     neutral       0.97      1.00      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.74      0.79        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.71      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.83      0.96      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84       162\n",
      "     neutral       0.91      0.98      0.95       387\n",
      "    positive       1.00      0.14      0.24        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.93      0.64      0.67       571\n",
      "weighted avg       0.90      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.84        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.90      0.88      0.89        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.89      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.24      0.37        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.57      0.76      0.65        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.77      0.67      0.67       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.97      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 203.21215963363647 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 114\n",
      "Sampling duration: 0.00011157989501953125 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4683, Accuracy: 0.8071, F1 Micro: 0.8921, F1 Macro: 0.8868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3638, Accuracy: 0.8986, F1 Micro: 0.9397, F1 Macro: 0.9351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2508, Accuracy: 0.9299, F1 Micro: 0.9575, F1 Macro: 0.9552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1947, Accuracy: 0.9429, F1 Micro: 0.965, F1 Macro: 0.9624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1602, Accuracy: 0.9481, F1 Micro: 0.9682, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1322, Accuracy: 0.9533, F1 Micro: 0.9712, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.114, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0985, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0831, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9735\n",
      "Epoch 10/10, Train Loss: 0.0723, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9732\n",
      "\n",
      "Aspect detection accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.91      0.98      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4121, Accuracy: 0.8501, F1 Micro: 0.8501, F1 Macro: 0.8082\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2268, Accuracy: 0.8794, F1 Micro: 0.8794, F1 Macro: 0.8402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1663, Accuracy: 0.8907, F1 Micro: 0.8907, F1 Macro: 0.8519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1247, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0813, Accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.8736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0779, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8865\n",
      "Epoch 7/10, Train Loss: 0.0481, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.883\n",
      "Epoch 8/10, Train Loss: 0.0507, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8827\n",
      "Epoch 9/10, Train Loss: 0.0501, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8816\n",
      "Epoch 10/10, Train Loss: 0.0614, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.88\n",
      "\n",
      "Sentiment analysis accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       757\n",
      "    positive       0.92      0.76      0.83       304\n",
      "\n",
      "    accuracy                           0.91      1061\n",
      "   macro avg       0.92      0.87      0.89      1061\n",
      "weighted avg       0.91      0.91      0.91      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9543, F1 Micro: 0.9543, F1 Macro: 0.8419\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.82      0.93      0.87        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.95      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.75      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.87      0.71      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.89      0.88       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.83      0.86       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.80      0.18      0.30        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.67      0.70       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.48      0.58        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.71      0.73        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.73      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.98      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 217.43471312522888 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 103\n",
      "Sampling duration: 0.00011944770812988281 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4745, Accuracy: 0.8158, F1 Micro: 0.8967, F1 Macro: 0.8922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3505, Accuracy: 0.9083, F1 Micro: 0.9453, F1 Macro: 0.9423\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2428, Accuracy: 0.9377, F1 Micro: 0.9621, F1 Macro: 0.9596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1838, Accuracy: 0.9476, F1 Micro: 0.9678, F1 Macro: 0.9655\n",
      "Epoch 5/10, Train Loss: 0.1507, Accuracy: 0.9467, F1 Micro: 0.9674, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.131, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1093, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.973\n",
      "Epoch 8/10, Train Loss: 0.0924, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9723\n",
      "Epoch 9/10, Train Loss: 0.0782, Accuracy: 0.9597, F1 Micro: 0.975, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0711, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9733\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4109, Accuracy: 0.823, F1 Micro: 0.823, F1 Macro: 0.7344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2321, Accuracy: 0.8745, F1 Micro: 0.8745, F1 Macro: 0.8335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1767, Accuracy: 0.8886, F1 Micro: 0.8886, F1 Macro: 0.8555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1039, Accuracy: 0.8923, F1 Micro: 0.8923, F1 Macro: 0.8573\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0791, Accuracy: 0.8998, F1 Micro: 0.8998, F1 Macro: 0.8676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0693, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8814\n",
      "Epoch 7/10, Train Loss: 0.0489, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0345, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0324, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8822\n",
      "Epoch 10/10, Train Loss: 0.0152, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.884\n",
      "\n",
      "Sentiment analysis accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       757\n",
      "    positive       0.93      0.74      0.83       311\n",
      "\n",
      "    accuracy                           0.91      1068\n",
      "   macro avg       0.92      0.86      0.88      1068\n",
      "weighted avg       0.91      0.91      0.91      1068\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.8293\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.90      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.75      1.00      0.86        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.96      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.86      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.79      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.81      0.74      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.78      0.85       162\n",
      "     neutral       0.91      0.98      0.94       387\n",
      "    positive       0.52      0.50      0.51        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.79      0.75      0.77       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.89        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.41      0.56        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.68      0.76      0.72        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.72      0.75       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       0.67      1.00      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.87      0.97      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.89      0.93        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.50      1.00      0.67         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.82      0.96      0.86       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 227.94895434379578 s\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 62\n",
      "Sampling duration: 0.022046327590942383 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4668, Accuracy: 0.817, F1 Micro: 0.8974, F1 Macro: 0.8928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3401, Accuracy: 0.9144, F1 Micro: 0.9487, F1 Macro: 0.945\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.23, Accuracy: 0.9385, F1 Micro: 0.9625, F1 Macro: 0.9602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1798, Accuracy: 0.9497, F1 Micro: 0.9691, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1443, Accuracy: 0.9538, F1 Micro: 0.9716, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1256, Accuracy: 0.9554, F1 Micro: 0.9725, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1038, Accuracy: 0.9604, F1 Micro: 0.9754, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0909, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0786, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9741\n",
      "Epoch 10/10, Train Loss: 0.0663, Accuracy: 0.9615, F1 Micro: 0.976, F1 Macro: 0.9736\n",
      "\n",
      "Aspect detection accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3966, Accuracy: 0.8546, F1 Micro: 0.8546, F1 Macro: 0.7967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.248, Accuracy: 0.8678, F1 Micro: 0.8678, F1 Macro: 0.8125\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1652, Accuracy: 0.8867, F1 Micro: 0.8867, F1 Macro: 0.8467\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1287, Accuracy: 0.8952, F1 Micro: 0.8952, F1 Macro: 0.866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0714, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8818\n",
      "Epoch 6/10, Train Loss: 0.0667, Accuracy: 0.899, F1 Micro: 0.899, F1 Macro: 0.8624\n",
      "Epoch 7/10, Train Loss: 0.0678, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8724\n",
      "Epoch 8/10, Train Loss: 0.0452, Accuracy: 0.9037, F1 Micro: 0.9037, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0359, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8797\n",
      "Epoch 10/10, Train Loss: 0.0226, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8805\n",
      "\n",
      "Sentiment analysis accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       764\n",
      "    positive       0.93      0.73      0.82       295\n",
      "\n",
      "    accuracy                           0.91      1059\n",
      "   macro avg       0.92      0.85      0.88      1059\n",
      "weighted avg       0.91      0.91      0.91      1059\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.8545\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.90      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.75      1.00      0.86        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.96      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.86      0.82        78\n",
      "     neutral       0.98      0.96      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.09      0.14      0.11         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.89      0.60      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.64      0.58      0.60       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89       200\n",
      "     neutral       0.95      0.92      0.93       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.93      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85       162\n",
      "     neutral       0.94      0.94      0.94       387\n",
      "    positive       0.67      0.45      0.54        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.81      0.76      0.78       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.41      0.52        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.71      0.69        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.78      0.71      0.73       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 232.4229552745819 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 86\n",
      "Sampling duration: 0.00010228157043457031 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4664, Accuracy: 0.8285, F1 Micro: 0.9019, F1 Macro: 0.8947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3285, Accuracy: 0.9217, F1 Micro: 0.9526, F1 Macro: 0.9493\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2241, Accuracy: 0.9429, F1 Micro: 0.9651, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1765, Accuracy: 0.9474, F1 Micro: 0.9677, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.142, Accuracy: 0.9573, F1 Micro: 0.9735, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1164, Accuracy: 0.9582, F1 Micro: 0.9742, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0997, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.085, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9755\n",
      "Epoch 9/10, Train Loss: 0.0745, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9749\n",
      "Epoch 10/10, Train Loss: 0.064, Accuracy: 0.9608, F1 Micro: 0.9758, F1 Macro: 0.9738\n",
      "\n",
      "Aspect detection accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.96      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3805, Accuracy: 0.859, F1 Micro: 0.859, F1 Macro: 0.8084\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2081, Accuracy: 0.8729, F1 Micro: 0.8729, F1 Macro: 0.831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.163, Accuracy: 0.8776, F1 Micro: 0.8776, F1 Macro: 0.8291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1064, Accuracy: 0.8952, F1 Micro: 0.8952, F1 Macro: 0.8602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0785, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8864\n",
      "Epoch 6/10, Train Loss: 0.0546, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8757\n",
      "Epoch 7/10, Train Loss: 0.0482, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.878\n",
      "Epoch 8/10, Train Loss: 0.0438, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.8799\n",
      "Epoch 9/10, Train Loss: 0.0324, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8802\n",
      "Epoch 10/10, Train Loss: 0.0432, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.8823\n",
      "\n",
      "Sentiment analysis accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8864\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       770\n",
      "    positive       0.93      0.75      0.83       308\n",
      "\n",
      "    accuracy                           0.91      1078\n",
      "   macro avg       0.92      0.86      0.89      1078\n",
      "weighted avg       0.91      0.91      0.91      1078\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9555, F1 Micro: 0.9555, F1 Macro: 0.8483\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.90      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.75      1.00      0.86        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.96      0.92       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.78      0.79        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.81      0.92      0.85       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.71      0.61      0.64       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.83      0.86       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.52      0.50      0.51        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.78      0.77      0.77       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.93      0.91      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.41      0.56        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.68      0.88      0.77        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.76      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.94      0.96        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.98      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.95      0.97        74\n",
      "     neutral       0.99      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.98      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 242.42967009544373 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 77\n",
      "Sampling duration: 9.250640869140625e-05 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4645, Accuracy: 0.8344, F1 Micro: 0.9057, F1 Macro: 0.9006\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3247, Accuracy: 0.9264, F1 Micro: 0.9554, F1 Macro: 0.9526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2181, Accuracy: 0.9427, F1 Micro: 0.965, F1 Macro: 0.9625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1707, Accuracy: 0.9509, F1 Micro: 0.9698, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1414, Accuracy: 0.9554, F1 Micro: 0.9725, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1209, Accuracy: 0.9604, F1 Micro: 0.9754, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0991, Accuracy: 0.962, F1 Micro: 0.9765, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0824, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0708, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9753\n",
      "Epoch 10/10, Train Loss: 0.0612, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.99      0.97       500\n",
      "  kebersihan       0.95      0.95      0.95       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3594, Accuracy: 0.8609, F1 Micro: 0.8609, F1 Macro: 0.8009\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2264, Accuracy: 0.8816, F1 Micro: 0.8816, F1 Macro: 0.8437\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1426, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8662\n",
      "Epoch 4/10, Train Loss: 0.1132, Accuracy: 0.8957, F1 Micro: 0.8957, F1 Macro: 0.8666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0861, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.053, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0466, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0303, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8861\n",
      "Epoch 9/10, Train Loss: 0.0359, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8797\n",
      "Epoch 10/10, Train Loss: 0.0178, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8828\n",
      "\n",
      "Sentiment analysis accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94       768\n",
      "    positive       0.90      0.77      0.83       296\n",
      "\n",
      "    accuracy                           0.91      1064\n",
      "   macro avg       0.91      0.87      0.89      1064\n",
      "weighted avg       0.91      0.91      0.91      1064\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.8541\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.79      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.17      0.14      0.15         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.88      0.66      0.76        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.67      0.60      0.62       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.90       200\n",
      "     neutral       0.95      0.94      0.94       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.86       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.83      0.23      0.36        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.68      0.72       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.86      0.84        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.45      0.54        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.65      0.65      0.65        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.77      0.70      0.73       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 256.4709098339081 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 70\n",
      "Sampling duration: 8.58306884765625e-05 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4625, Accuracy: 0.8411, F1 Micro: 0.9091, F1 Macro: 0.9044\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3111, Accuracy: 0.9314, F1 Micro: 0.9581, F1 Macro: 0.955\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2125, Accuracy: 0.9396, F1 Micro: 0.9632, F1 Macro: 0.9606\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1674, Accuracy: 0.9503, F1 Micro: 0.9696, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1415, Accuracy: 0.9563, F1 Micro: 0.9729, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1145, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0959, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0802, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "Epoch 9/10, Train Loss: 0.0704, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "Epoch 10/10, Train Loss: 0.0604, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3598, Accuracy: 0.8675, F1 Micro: 0.8675, F1 Macro: 0.8205\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2255, Accuracy: 0.8906, F1 Micro: 0.8906, F1 Macro: 0.8557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1591, Accuracy: 0.899, F1 Micro: 0.899, F1 Macro: 0.8662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1071, Accuracy: 0.9018, F1 Micro: 0.9018, F1 Macro: 0.8688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0884, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0668, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.065, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8869\n",
      "Epoch 8/10, Train Loss: 0.0485, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0289, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0301, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8938\n",
      "\n",
      "Sentiment analysis accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94       770\n",
      "    positive       0.92      0.78      0.84       309\n",
      "\n",
      "    accuracy                           0.92      1079\n",
      "   macro avg       0.92      0.88      0.89      1079\n",
      "weighted avg       0.92      0.92      0.92      1079\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9578, F1 Micro: 0.9578, F1 Macro: 0.8622\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.50      0.50      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.81      0.79      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.78      0.81        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.50      0.45      0.48        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.78      0.75      0.76       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.76      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 263.61661314964294 s\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 52\n",
      "Sampling duration: 0.015448331832885742 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.464, Accuracy: 0.8418, F1 Micro: 0.9097, F1 Macro: 0.905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2979, Accuracy: 0.9283, F1 Micro: 0.9566, F1 Macro: 0.9541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2069, Accuracy: 0.9446, F1 Micro: 0.9661, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1636, Accuracy: 0.9516, F1 Micro: 0.9702, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1366, Accuracy: 0.958, F1 Micro: 0.9741, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1151, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0925, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0825, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0681, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0586, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.97      0.97       496\n",
      "     general       0.94      0.99      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3508, Accuracy: 0.87, F1 Micro: 0.87, F1 Macro: 0.8244\n",
      "Epoch 2/10, Train Loss: 0.2093, Accuracy: 0.8691, F1 Micro: 0.8691, F1 Macro: 0.8146\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1512, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8763\n",
      "Epoch 4/10, Train Loss: 0.1001, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8658\n",
      "Epoch 5/10, Train Loss: 0.0969, Accuracy: 0.8904, F1 Micro: 0.8904, F1 Macro: 0.8504\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0524, Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8839\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0618, Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8812\n",
      "Epoch 8/10, Train Loss: 0.0358, Accuracy: 0.9044, F1 Micro: 0.9044, F1 Macro: 0.8759\n",
      "Epoch 9/10, Train Loss: 0.0467, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.876\n",
      "Epoch 10/10, Train Loss: 0.0305, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8627\n",
      "\n",
      "Sentiment analysis accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       773\n",
      "    positive       0.91      0.75      0.82       304\n",
      "\n",
      "    accuracy                           0.91      1077\n",
      "   macro avg       0.91      0.86      0.88      1077\n",
      "weighted avg       0.91      0.91      0.91      1077\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9555, F1 Micro: 0.9555, F1 Macro: 0.8428\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.76      0.79       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.77      0.79        78\n",
      "     neutral       0.96      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.99      0.97       496\n",
      "    positive       0.88      0.66      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.60      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.89       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.87      0.86       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.67      0.09      0.16        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.82      0.64      0.66       571\n",
      "weighted avg       0.90      0.91      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.95      0.84      0.89        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.90      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.55      0.63        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.65      0.69        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.73      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.82      0.87       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 265.5720992088318 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 58\n",
      "Sampling duration: 8.821487426757812e-05 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4641, Accuracy: 0.8514, F1 Micro: 0.9143, F1 Macro: 0.9097\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2964, Accuracy: 0.9306, F1 Micro: 0.9579, F1 Macro: 0.9552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2044, Accuracy: 0.9438, F1 Micro: 0.9656, F1 Macro: 0.9632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.157, Accuracy: 0.951, F1 Micro: 0.9699, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1301, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1104, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Epoch 7/10, Train Loss: 0.0946, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9745\n",
      "Epoch 8/10, Train Loss: 0.0775, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9736\n",
      "Epoch 9/10, Train Loss: 0.0659, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.056, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.94      0.95      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3421, Accuracy: 0.8539, F1 Micro: 0.8539, F1 Macro: 0.7972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1973, Accuracy: 0.864, F1 Micro: 0.864, F1 Macro: 0.8105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1342, Accuracy: 0.8934, F1 Micro: 0.8934, F1 Macro: 0.8589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1092, Accuracy: 0.8971, F1 Micro: 0.8971, F1 Macro: 0.8724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0833, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0589, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0589, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.8787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.044, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8835\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0272, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8877\n",
      "Epoch 10/10, Train Loss: 0.0215, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8789\n",
      "\n",
      "Sentiment analysis accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       774\n",
      "    positive       0.92      0.76      0.83       314\n",
      "\n",
      "    accuracy                           0.91      1088\n",
      "   macro avg       0.92      0.87      0.89      1088\n",
      "weighted avg       0.91      0.91      0.91      1088\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.958, F1 Micro: 0.958, F1 Macro: 0.872\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.80      0.40      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.76      0.81       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.81      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.67      0.74       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.89       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.86      0.85       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.75      0.27      0.40        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.84      0.70      0.73       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.89        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.62      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.77      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 279.7212052345276 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 52\n",
      "Sampling duration: 8.869171142578125e-05 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4587, Accuracy: 0.8594, F1 Micro: 0.9182, F1 Macro: 0.9131\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2923, Accuracy: 0.9304, F1 Micro: 0.9577, F1 Macro: 0.955\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1953, Accuracy: 0.9467, F1 Micro: 0.9674, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1588, Accuracy: 0.9526, F1 Micro: 0.9708, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1274, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9737\n",
      "Epoch 6/10, Train Loss: 0.1075, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0923, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0768, Accuracy: 0.9649, F1 Micro: 0.9783, F1 Macro: 0.9765\n",
      "Epoch 9/10, Train Loss: 0.0672, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "Epoch 10/10, Train Loss: 0.0566, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9783, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.99      0.97       500\n",
      "  kebersihan       0.94      0.95      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3453, Accuracy: 0.8594, F1 Micro: 0.8594, F1 Macro: 0.8024\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2012, Accuracy: 0.8883, F1 Micro: 0.8883, F1 Macro: 0.8489\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.154, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8781\n",
      "Epoch 4/10, Train Loss: 0.1057, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0725, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0672, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8829\n",
      "Epoch 7/10, Train Loss: 0.0486, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0355, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.8879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0373, Accuracy: 0.9162, F1 Micro: 0.9162, F1 Macro: 0.8903\n",
      "Epoch 10/10, Train Loss: 0.0256, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8796\n",
      "\n",
      "Sentiment analysis accuracy: 0.9162, F1 Micro: 0.9162, F1 Macro: 0.8903\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94       774\n",
      "    positive       0.92      0.77      0.84       300\n",
      "\n",
      "    accuracy                           0.92      1074\n",
      "   macro avg       0.92      0.87      0.89      1074\n",
      "weighted avg       0.92      0.92      0.91      1074\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.8541\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.75      0.30      0.43        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.73      0.77       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.17      0.14      0.15         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.90      0.66      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.67      0.60      0.63       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.89      0.86       162\n",
      "     neutral       0.95      0.95      0.95       387\n",
      "    positive       0.70      0.32      0.44        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.83      0.72      0.75       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.88      0.86        85\n",
      "     neutral       0.98      0.97      0.98       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.96      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.48      0.60        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.71      0.69        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.73      0.76       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.88      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 278.54726004600525 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.82012939453125e-05 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4545, Accuracy: 0.8625, F1 Micro: 0.9198, F1 Macro: 0.9146\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2835, Accuracy: 0.9373, F1 Micro: 0.9618, F1 Macro: 0.9596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2001, Accuracy: 0.9469, F1 Micro: 0.9674, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1578, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1277, Accuracy: 0.9604, F1 Micro: 0.9754, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1039, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Epoch 7/10, Train Loss: 0.0915, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9753\n",
      "Epoch 8/10, Train Loss: 0.0746, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0631, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.054, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.94      0.95      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3488, Accuracy: 0.8476, F1 Micro: 0.8476, F1 Macro: 0.8163\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2059, Accuracy: 0.8944, F1 Micro: 0.8944, F1 Macro: 0.8656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1442, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8815\n",
      "Epoch 4/10, Train Loss: 0.0993, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.065, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0489, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.8817\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.05, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8878\n",
      "Epoch 8/10, Train Loss: 0.0415, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8804\n",
      "Epoch 9/10, Train Loss: 0.0358, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.883\n",
      "Epoch 10/10, Train Loss: 0.0282, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8781\n",
      "\n",
      "Sentiment analysis accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       778\n",
      "    positive       0.93      0.76      0.83       311\n",
      "\n",
      "    accuracy                           0.91      1089\n",
      "   macro avg       0.92      0.87      0.89      1089\n",
      "weighted avg       0.91      0.91      0.91      1089\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.958, F1 Micro: 0.958, F1 Macro: 0.8652\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.86      0.89       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.90      0.86       162\n",
      "     neutral       0.94      0.95      0.95       387\n",
      "    positive       1.00      0.23      0.37        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.92      0.69      0.73       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.89        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.96      0.94      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.62      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.77      0.59      0.67        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.74      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 287.42833185195923 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.58306884765625e-05 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4517, Accuracy: 0.8628, F1 Micro: 0.9204, F1 Macro: 0.9162\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2759, Accuracy: 0.9389, F1 Micro: 0.9626, F1 Macro: 0.9601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1852, Accuracy: 0.9486, F1 Micro: 0.9685, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1502, Accuracy: 0.9561, F1 Micro: 0.9728, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1221, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9742\n",
      "Epoch 6/10, Train Loss: 0.1022, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0867, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9756\n",
      "Epoch 8/10, Train Loss: 0.0732, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0603, Accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.977\n",
      "Epoch 10/10, Train Loss: 0.0529, Accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.96      0.95       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3408, Accuracy: 0.8707, F1 Micro: 0.8707, F1 Macro: 0.8322\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2049, Accuracy: 0.8781, F1 Micro: 0.8781, F1 Macro: 0.8298\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1285, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8795\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0756, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0645, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0644, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8849\n",
      "Epoch 7/10, Train Loss: 0.0447, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8751\n",
      "Epoch 8/10, Train Loss: 0.0366, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0248, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8874\n",
      "Epoch 10/10, Train Loss: 0.0379, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8841\n",
      "\n",
      "Sentiment analysis accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       778\n",
      "    positive       0.94      0.74      0.83       305\n",
      "\n",
      "    accuracy                           0.92      1083\n",
      "   macro avg       0.92      0.86      0.89      1083\n",
      "weighted avg       0.92      0.92      0.91      1083\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8564\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85        78\n",
      "     neutral       0.98      0.97      0.98       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.94      0.88       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.89      0.71      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.78      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87       162\n",
      "     neutral       0.95      0.96      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.77      0.80       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.55      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.72      0.76      0.74        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.77      0.79       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.89      0.91        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.60      1.00      0.75         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.85      0.96      0.89       571\n",
      "weighted avg       0.99      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 291.3169710636139 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 6.341934204101562e-05 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4564, Accuracy: 0.8618, F1 Micro: 0.9183, F1 Macro: 0.9124\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.287, Accuracy: 0.9351, F1 Micro: 0.9603, F1 Macro: 0.9569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1985, Accuracy: 0.9457, F1 Micro: 0.9666, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1547, Accuracy: 0.9517, F1 Micro: 0.9702, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1216, Accuracy: 0.9573, F1 Micro: 0.9735, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1002, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0846, Accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9765\n",
      "Epoch 8/10, Train Loss: 0.0735, Accuracy: 0.9642, F1 Micro: 0.9777, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0639, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0501, Accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.96      0.92      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3581, Accuracy: 0.8685, F1 Micro: 0.8685, F1 Macro: 0.8217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2093, Accuracy: 0.8858, F1 Micro: 0.8858, F1 Macro: 0.8462\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1341, Accuracy: 0.8959, F1 Micro: 0.8959, F1 Macro: 0.8629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1058, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0909, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8792\n",
      "Epoch 6/10, Train Loss: 0.0631, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0463, Accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.883\n",
      "Epoch 8/10, Train Loss: 0.0332, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8809\n",
      "Epoch 9/10, Train Loss: 0.0253, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8811\n",
      "Epoch 10/10, Train Loss: 0.0286, Accuracy: 0.9014, F1 Micro: 0.9014, F1 Macro: 0.8753\n",
      "\n",
      "Sentiment analysis accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       781\n",
      "    positive       0.92      0.75      0.83       314\n",
      "\n",
      "    accuracy                           0.91      1095\n",
      "   macro avg       0.91      0.86      0.88      1095\n",
      "weighted avg       0.91      0.91      0.91      1095\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.8486\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.85      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.78      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.71      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.61      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89       200\n",
      "     neutral       0.96      0.92      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.81      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.46      0.55      0.50        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.77      0.78      0.77       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        85\n",
      "     neutral       0.98      0.97      0.98       418\n",
      "    positive       0.90      0.93      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.38      0.52        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.94      0.78        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.77      0.76       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.60      1.00      0.75         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.85      0.97      0.89       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.95      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.43      1.00      0.60         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.80      0.98      0.85       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 299.49466609954834 s\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 25\n",
      "Sampling duration: 0.017493724822998047 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.454, Accuracy: 0.8686, F1 Micro: 0.9229, F1 Macro: 0.9173\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2743, Accuracy: 0.9299, F1 Micro: 0.9573, F1 Macro: 0.9538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1907, Accuracy: 0.9479, F1 Micro: 0.9681, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.15, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1187, Accuracy: 0.9616, F1 Micro: 0.9761, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0997, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0854, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9752\n",
      "Epoch 8/10, Train Loss: 0.0717, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0603, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "Epoch 10/10, Train Loss: 0.051, Accuracy: 0.9644, F1 Micro: 0.9778, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.95      0.92      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3698, Accuracy: 0.8575, F1 Micro: 0.8575, F1 Macro: 0.8129\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2069, Accuracy: 0.8986, F1 Micro: 0.8986, F1 Macro: 0.8664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1362, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8785\n",
      "Epoch 4/10, Train Loss: 0.1073, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0814, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.046, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8783\n",
      "Epoch 7/10, Train Loss: 0.043, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0416, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.883\n",
      "Epoch 9/10, Train Loss: 0.0193, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8799\n",
      "Epoch 10/10, Train Loss: 0.0345, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8749\n",
      "\n",
      "Sentiment analysis accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       781\n",
      "    positive       0.93      0.74      0.83       314\n",
      "\n",
      "    accuracy                           0.91      1095\n",
      "   macro avg       0.92      0.86      0.88      1095\n",
      "weighted avg       0.91      0.91      0.91      1095\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9555, F1 Micro: 0.9555, F1 Macro: 0.8596\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.82      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.83      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.25      0.14      0.18         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.68      0.60      0.64       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.90      0.87       200\n",
      "     neutral       0.95      0.88      0.92       315\n",
      "    positive       0.82      0.96      0.89        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.87      0.91      0.89       571\n",
      "weighted avg       0.90      0.89      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87       162\n",
      "     neutral       0.95      0.96      0.95       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.86      0.76      0.80       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.45      0.58        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.62      0.88      0.73        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.78      0.77       571\n",
      "weighted avg       0.97      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 298.40840220451355 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.00012612342834472656 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4487, Accuracy: 0.87, F1 Micro: 0.924, F1 Macro: 0.9202\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2693, Accuracy: 0.9406, F1 Micro: 0.9636, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1842, Accuracy: 0.9491, F1 Micro: 0.9688, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1476, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1222, Accuracy: 0.9611, F1 Micro: 0.976, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1038, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0847, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "Epoch 8/10, Train Loss: 0.0709, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.976\n",
      "Epoch 9/10, Train Loss: 0.0625, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "Epoch 10/10, Train Loss: 0.0538, Accuracy: 0.9644, F1 Micro: 0.978, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.93      0.94      0.93       317\n",
      "       linen       0.95      0.95      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3561, Accuracy: 0.8561, F1 Micro: 0.8561, F1 Macro: 0.808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2033, Accuracy: 0.8891, F1 Micro: 0.8891, F1 Macro: 0.8506\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1597, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1024, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0804, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0592, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0435, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8852\n",
      "Epoch 8/10, Train Loss: 0.0385, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8842\n",
      "Epoch 9/10, Train Loss: 0.036, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0321, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8874\n",
      "\n",
      "Sentiment analysis accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       780\n",
      "    positive       0.93      0.75      0.83       311\n",
      "\n",
      "    accuracy                           0.91      1091\n",
      "   macro avg       0.92      0.87      0.89      1091\n",
      "weighted avg       0.92      0.91      0.91      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9594, F1 Micro: 0.9594, F1 Macro: 0.877\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.17      0.14      0.15         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.87      0.66      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.66      0.60      0.62       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.90      0.88       162\n",
      "     neutral       0.95      0.95      0.95       387\n",
      "    positive       0.80      0.55      0.65        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 307.5288701057434 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.176399230957031e-05 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4528, Accuracy: 0.8726, F1 Micro: 0.9255, F1 Macro: 0.9213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2739, Accuracy: 0.9354, F1 Micro: 0.9607, F1 Macro: 0.9582\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1936, Accuracy: 0.9486, F1 Micro: 0.9685, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1526, Accuracy: 0.9533, F1 Micro: 0.9713, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1236, Accuracy: 0.9613, F1 Micro: 0.9761, F1 Macro: 0.9738\n",
      "Epoch 6/10, Train Loss: 0.0989, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0835, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "Epoch 8/10, Train Loss: 0.0733, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9746\n",
      "Epoch 9/10, Train Loss: 0.0603, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0519, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.95      0.95      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3557, Accuracy: 0.8601, F1 Micro: 0.8601, F1 Macro: 0.8219\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2019, Accuracy: 0.8702, F1 Micro: 0.8702, F1 Macro: 0.8185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1307, Accuracy: 0.9022, F1 Micro: 0.9022, F1 Macro: 0.8711\n",
      "Epoch 4/10, Train Loss: 0.1015, Accuracy: 0.8949, F1 Micro: 0.8949, F1 Macro: 0.864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0773, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8817\n",
      "Epoch 6/10, Train Loss: 0.0415, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.874\n",
      "Epoch 7/10, Train Loss: 0.0483, Accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.874\n",
      "Epoch 8/10, Train Loss: 0.0422, Accuracy: 0.9022, F1 Micro: 0.9022, F1 Macro: 0.8754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0356, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8816\n",
      "Epoch 10/10, Train Loss: 0.0338, Accuracy: 0.8967, F1 Micro: 0.8967, F1 Macro: 0.8704\n",
      "\n",
      "Sentiment analysis accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       779\n",
      "    positive       0.94      0.74      0.82       315\n",
      "\n",
      "    accuracy                           0.91      1094\n",
      "   macro avg       0.92      0.86      0.88      1094\n",
      "weighted avg       0.91      0.91      0.91      1094\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.8461\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.97      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.87      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.86      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.77      0.82        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.55      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85       162\n",
      "     neutral       0.95      0.95      0.95       387\n",
      "    positive       0.54      0.59      0.57        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.78      0.79      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.80      0.85        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.84      0.96      0.90        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.34      0.49        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.58      0.88      0.70        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.80      0.74      0.72       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 306.88897228240967 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.630752563476562e-05 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4399, Accuracy: 0.8745, F1 Micro: 0.9266, F1 Macro: 0.9224\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2539, Accuracy: 0.9406, F1 Micro: 0.9637, F1 Macro: 0.9616\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1814, Accuracy: 0.9523, F1 Micro: 0.9705, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1433, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1188, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0999, Accuracy: 0.9618, F1 Micro: 0.9764, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0828, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "Epoch 8/10, Train Loss: 0.068, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9762\n",
      "Epoch 9/10, Train Loss: 0.0589, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "Epoch 10/10, Train Loss: 0.0491, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3378, Accuracy: 0.8772, F1 Micro: 0.8772, F1 Macro: 0.8347\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1943, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.132, Accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.8953\n",
      "Epoch 4/10, Train Loss: 0.1081, Accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.894\n",
      "Epoch 5/10, Train Loss: 0.0805, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0617, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.8963\n",
      "Epoch 7/10, Train Loss: 0.0451, Accuracy: 0.9172, F1 Micro: 0.9172, F1 Macro: 0.8932\n",
      "Epoch 8/10, Train Loss: 0.0261, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8873\n",
      "Epoch 9/10, Train Loss: 0.0398, Accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.894\n",
      "Epoch 10/10, Train Loss: 0.0188, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.8884\n",
      "\n",
      "Sentiment analysis accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.8963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       772\n",
      "    positive       0.94      0.77      0.85       303\n",
      "\n",
      "    accuracy                           0.92      1075\n",
      "   macro avg       0.93      0.87      0.90      1075\n",
      "weighted avg       0.92      0.92      0.92      1075\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.8661\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.81      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.25      0.14      0.18         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.88      0.68      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.69      0.60      0.64       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.78      0.32      0.45        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.71      0.75       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.89      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      1.00      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.89      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 307.0959680080414 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.319450378417969e-05 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4417, Accuracy: 0.8724, F1 Micro: 0.9254, F1 Macro: 0.9205\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2623, Accuracy: 0.9382, F1 Micro: 0.9624, F1 Macro: 0.9602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1862, Accuracy: 0.9486, F1 Micro: 0.9684, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1462, Accuracy: 0.9573, F1 Micro: 0.9736, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.12, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0966, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0852, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0688, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.0617, Accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9752\n",
      "Epoch 10/10, Train Loss: 0.0504, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9754\n",
      "\n",
      "Aspect detection accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.331, Accuracy: 0.8625, F1 Micro: 0.8625, F1 Macro: 0.8093\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1912, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1253, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0935, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8868\n",
      "Epoch 5/10, Train Loss: 0.0723, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0604, Accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.8925\n",
      "Epoch 7/10, Train Loss: 0.0421, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8896\n",
      "Epoch 8/10, Train Loss: 0.0175, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0196, Accuracy: 0.9201, F1 Micro: 0.9201, F1 Macro: 0.8964\n",
      "Epoch 10/10, Train Loss: 0.0283, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8886\n",
      "\n",
      "Sentiment analysis accuracy: 0.9201, F1 Micro: 0.9201, F1 Macro: 0.8964\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.95       772\n",
      "    positive       0.92      0.78      0.85       304\n",
      "\n",
      "    accuracy                           0.92      1076\n",
      "   macro avg       0.92      0.88      0.90      1076\n",
      "weighted avg       0.92      0.92      0.92      1076\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.8571\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.86      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.79      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.87      0.68      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.60      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.63      0.55      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.82      0.78      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.89      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.94      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.79       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.89      0.91        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.56      0.83      0.67         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.82      0.91      0.86       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 320.0829482078552 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 0.00010156631469726562 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4424, Accuracy: 0.8811, F1 Micro: 0.9295, F1 Macro: 0.9232\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2575, Accuracy: 0.9436, F1 Micro: 0.9654, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.183, Accuracy: 0.9519, F1 Micro: 0.9704, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1458, Accuracy: 0.9573, F1 Micro: 0.9737, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1153, Accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0961, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.079, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0663, Accuracy: 0.967, F1 Micro: 0.9795, F1 Macro: 0.9774\n",
      "Epoch 9/10, Train Loss: 0.0573, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "Epoch 10/10, Train Loss: 0.0481, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.967, F1 Micro: 0.9795, F1 Macro: 0.9774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3441, Accuracy: 0.8735, F1 Micro: 0.8735, F1 Macro: 0.8365\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1974, Accuracy: 0.8979, F1 Micro: 0.8979, F1 Macro: 0.8654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.143, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.102, Accuracy: 0.9178, F1 Micro: 0.9178, F1 Macro: 0.8948\n",
      "Epoch 5/10, Train Loss: 0.075, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8863\n",
      "Epoch 6/10, Train Loss: 0.0622, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8871\n",
      "Epoch 7/10, Train Loss: 0.0468, Accuracy: 0.8961, F1 Micro: 0.8961, F1 Macro: 0.8617\n",
      "Epoch 8/10, Train Loss: 0.044, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.89\n",
      "Epoch 9/10, Train Loss: 0.0326, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8882\n",
      "Epoch 10/10, Train Loss: 0.0242, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8894\n",
      "\n",
      "Sentiment analysis accuracy: 0.9178, F1 Micro: 0.9178, F1 Macro: 0.8948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       786\n",
      "    positive       0.93      0.78      0.85       321\n",
      "\n",
      "    accuracy                           0.92      1107\n",
      "   macro avg       0.92      0.88      0.89      1107\n",
      "weighted avg       0.92      0.92      0.92      1107\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.8768\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.80      0.84       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.83      0.82        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.81      0.93      0.86       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.78      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.68      0.74       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.91      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.94      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.75      0.79       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.88        85\n",
      "     neutral       0.98      0.97      0.98       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 323.1802728176117 s\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 36\n",
      "Sampling duration: 0.02087092399597168 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4415, Accuracy: 0.8858, F1 Micro: 0.9322, F1 Macro: 0.9268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2533, Accuracy: 0.9443, F1 Micro: 0.9658, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1789, Accuracy: 0.9524, F1 Micro: 0.9706, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1368, Accuracy: 0.9571, F1 Micro: 0.9736, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.115, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0951, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0803, Accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.9771\n",
      "Epoch 8/10, Train Loss: 0.0694, Accuracy: 0.9641, F1 Micro: 0.9776, F1 Macro: 0.9752\n",
      "Epoch 9/10, Train Loss: 0.0574, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.0484, Accuracy: 0.9649, F1 Micro: 0.9783, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3384, Accuracy: 0.8605, F1 Micro: 0.8605, F1 Macro: 0.8195\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2039, Accuracy: 0.8922, F1 Micro: 0.8922, F1 Macro: 0.8558\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1416, Accuracy: 0.904, F1 Micro: 0.904, F1 Macro: 0.8732\n",
      "Epoch 4/10, Train Loss: 0.1217, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.089, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0672, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0696, Accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.8891\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.043, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8915\n",
      "Epoch 9/10, Train Loss: 0.0353, Accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.8899\n",
      "Epoch 10/10, Train Loss: 0.0388, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.878\n",
      "\n",
      "Sentiment analysis accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       785\n",
      "    positive       0.95      0.75      0.84       319\n",
      "\n",
      "    accuracy                           0.92      1104\n",
      "   macro avg       0.93      0.87      0.89      1104\n",
      "weighted avg       0.92      0.92      0.91      1104\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.8818\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.94        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.81      0.84       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.43      0.43         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.86      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.75      0.72      0.73       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.86      0.88      0.87        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.90      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.74      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.89      0.87        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.93       571\n",
      "weighted avg       0.96      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.62      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.65      0.71        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.75      0.79       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 329.78635931015015 s\n",
      "Total runtime: 6579.017170190811 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6765120,
     "sourceId": 10886992,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6611.477976,
   "end_time": "2025-03-31T13:30:03.339136",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-31T11:39:51.861160",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0e8c4b7c7a904ed4bfc3d45b13c46257": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2043b1121ff346d7a29ba65ecce9c3ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c14b6eb0185944ea9813eae1c7372261",
        "IPY_MODEL_68a92254b5cb429188bf58d2defde7fd",
        "IPY_MODEL_9de68f6eabd04c6297ddfb59e7039644"
       ],
       "layout": "IPY_MODEL_742c8bc2450c46d59563b540096f1502",
       "tabbable": null,
       "tooltip": null
      }
     },
     "245e721c92694d208cff2928f13793f7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2d7428200a604845820bf8fc146aea20": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_245e721c92694d208cff2928f13793f7",
       "placeholder": "",
       "style": "IPY_MODEL_52bd4ebf6c0f48d88b2960ec78348546",
       "tabbable": null,
       "tooltip": null,
       "value": "498M/498M[00:02&lt;00:00,171MB/s]"
      }
     },
     "326d92cf906041cf8410a33b79f16288": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_57e66b7cff2548b08df1d1accb37203c",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0e8c4b7c7a904ed4bfc3d45b13c46257",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "37f71df31b2f469eaae9f1a092d47329": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3c544e2345834d9e9759fb9d55808b82": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4489c4b199194f72b7d359d4d7c31773": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4989ccad4ca44141a355ef3591fafcf1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "51c0aefb5e3442f3918e14bc6e63f983": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "52bd4ebf6c0f48d88b2960ec78348546": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5500f595609745849cefc83ed025e2a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d7595d98e2d6421bad393e68c87bc342",
       "placeholder": "",
       "style": "IPY_MODEL_8028d25f41154839a6649c155ac10f80",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json:100%"
      }
     },
     "57e66b7cff2548b08df1d1accb37203c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "58b67335a28d4e3e8943fe6d3de8d269": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6d97ac1fe06844028ef060bc2746ab28",
       "placeholder": "",
       "style": "IPY_MODEL_51c0aefb5e3442f3918e14bc6e63f983",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors:100%"
      }
     },
     "68a92254b5cb429188bf58d2defde7fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b37a23c780354c17b61609f6f2f3fc4d",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b61b92d6679245a19f6580fed09f1bcc",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "6d97ac1fe06844028ef060bc2746ab28": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "70b89a448ca0426490deaa2b2986c6da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "742c8bc2450c46d59563b540096f1502": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "753540820ec64c17a3f2386df00459e2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "759117da1de74ad09dcd1b533f580756": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_aba693c123694de9bf22bcb605e2f037",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4489c4b199194f72b7d359d4d7c31773",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     },
     "75994b658bfc46b88f22c18106b321d6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "75b030e9e3d3415180ae51aa3183dd06": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b33961d815dd44c88cb69ab1ff410015",
       "max": 497787752,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_37f71df31b2f469eaae9f1a092d47329",
       "tabbable": null,
       "tooltip": null,
       "value": 497787752
      }
     },
     "7b0a1759f5de40f89fac870a5ed9ae50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d9c1ca161de546e08e5dc43983d46e5c",
       "placeholder": "",
       "style": "IPY_MODEL_8163cc04d57a43ec8d66dafae169169d",
       "tabbable": null,
       "tooltip": null,
       "value": "2.00/2.00[00:00&lt;00:00,159B/s]"
      }
     },
     "8028d25f41154839a6649c155ac10f80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8107c6437a8b4014b9c5247dd0734c64": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_815a2d0c0ad74e7e9e2f8fe2decd899d",
        "IPY_MODEL_326d92cf906041cf8410a33b79f16288",
        "IPY_MODEL_7b0a1759f5de40f89fac870a5ed9ae50"
       ],
       "layout": "IPY_MODEL_4989ccad4ca44141a355ef3591fafcf1",
       "tabbable": null,
       "tooltip": null
      }
     },
     "815a2d0c0ad74e7e9e2f8fe2decd899d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f277d32cbc40433eb3f5bf8198b36e7b",
       "placeholder": "",
       "style": "IPY_MODEL_cc54e9d846914d4cb6608dd3f9471883",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:100%"
      }
     },
     "8163cc04d57a43ec8d66dafae169169d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8420a90a810748af87b6322a04e1ebb7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f75c738019eb4227b5f17c5aab9ae22d",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c94d484259254a9a962959f3585a4a6d",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "89a9f80d81b6433b845519e95a5b32f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9866c5b7310f4a10863f285cb4ee0d23",
       "placeholder": "",
       "style": "IPY_MODEL_a6dfe3868af14d9490b2a673e112e182",
       "tabbable": null,
       "tooltip": null,
       "value": "1.53k/1.53k[00:00&lt;00:00,151kB/s]"
      }
     },
     "95a99e53d0e54426ae382523c0b9e0d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b2987c8be0c640efbc4c69eb3da8344e",
        "IPY_MODEL_759117da1de74ad09dcd1b533f580756",
        "IPY_MODEL_89a9f80d81b6433b845519e95a5b32f9"
       ],
       "layout": "IPY_MODEL_75994b658bfc46b88f22c18106b321d6",
       "tabbable": null,
       "tooltip": null
      }
     },
     "96e9281428a84bddaf7ab4fe58702b24": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_58b67335a28d4e3e8943fe6d3de8d269",
        "IPY_MODEL_75b030e9e3d3415180ae51aa3183dd06",
        "IPY_MODEL_2d7428200a604845820bf8fc146aea20"
       ],
       "layout": "IPY_MODEL_3c544e2345834d9e9759fb9d55808b82",
       "tabbable": null,
       "tooltip": null
      }
     },
     "9866c5b7310f4a10863f285cb4ee0d23": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9de68f6eabd04c6297ddfb59e7039644": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_753540820ec64c17a3f2386df00459e2",
       "placeholder": "",
       "style": "IPY_MODEL_70b89a448ca0426490deaa2b2986c6da",
       "tabbable": null,
       "tooltip": null,
       "value": "229k/229k[00:00&lt;00:00,6.71MB/s]"
      }
     },
     "a6dfe3868af14d9490b2a673e112e182": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a6e323f0b6964b5eb65cba4485815829": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f5eb9ab9828e4584a182e939db85eb30",
       "placeholder": "",
       "style": "IPY_MODEL_f92be566492f486fa3d41366eae0b41e",
       "tabbable": null,
       "tooltip": null,
       "value": "112/112[00:00&lt;00:00,12.1kB/s]"
      }
     },
     "aba693c123694de9bf22bcb605e2f037": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ad6b2cd13cef43cf998e7f0d1d3dcda8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5500f595609745849cefc83ed025e2a8",
        "IPY_MODEL_8420a90a810748af87b6322a04e1ebb7",
        "IPY_MODEL_a6e323f0b6964b5eb65cba4485815829"
       ],
       "layout": "IPY_MODEL_afaeadad72f54b7e842d8efec048c63c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "afaeadad72f54b7e842d8efec048c63c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b25cc51fa0224f6b9cc770c75b825a2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b2987c8be0c640efbc4c69eb3da8344e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_be276b61ffeb4074b078ecb9baa6ef0c",
       "placeholder": "",
       "style": "IPY_MODEL_f40afc8fc5d54976b66c4d95f1e9496e",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:100%"
      }
     },
     "b33961d815dd44c88cb69ab1ff410015": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b37a23c780354c17b61609f6f2f3fc4d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b61b92d6679245a19f6580fed09f1bcc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b68faeb9d2c8438e825b6c7980f23e17": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "be276b61ffeb4074b078ecb9baa6ef0c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c14b6eb0185944ea9813eae1c7372261": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b68faeb9d2c8438e825b6c7980f23e17",
       "placeholder": "",
       "style": "IPY_MODEL_b25cc51fa0224f6b9cc770c75b825a2b",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt:100%"
      }
     },
     "c94d484259254a9a962959f3585a4a6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "cc54e9d846914d4cb6608dd3f9471883": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d7595d98e2d6421bad393e68c87bc342": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d9c1ca161de546e08e5dc43983d46e5c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f277d32cbc40433eb3f5bf8198b36e7b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f40afc8fc5d54976b66c4d95f1e9496e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f5eb9ab9828e4584a182e939db85eb30": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f75c738019eb4227b5f17c5aab9ae22d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f92be566492f486fa3d41366eae0b41e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
