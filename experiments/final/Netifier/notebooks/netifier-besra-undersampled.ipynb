{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30ef38dd",
   "metadata": {
    "papermill": {
     "duration": 0.004781,
     "end_time": "2025-05-11T04:25:50.445846",
     "exception": false,
     "start_time": "2025-05-11T04:25:50.441065",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4fd7a59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T04:25:50.455208Z",
     "iopub.status.busy": "2025-05-11T04:25:50.454890Z",
     "iopub.status.idle": "2025-05-11T04:26:24.548440Z",
     "shell.execute_reply": "2025-05-11T04:26:24.547728Z"
    },
    "papermill": {
     "duration": 34.099944,
     "end_time": "2025-05-11T04:26:24.550144",
     "exception": false,
     "start_time": "2025-05-11T04:25:50.450200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "from scipy.stats import beta\n",
    "from scipy.special import betaln\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24688d2f",
   "metadata": {
    "papermill": {
     "duration": 0.003795,
     "end_time": "2025-05-11T04:26:24.558202",
     "exception": false,
     "start_time": "2025-05-11T04:26:24.554407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "583ac313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T04:26:24.567301Z",
     "iopub.status.busy": "2025-05-11T04:26:24.566853Z",
     "iopub.status.idle": "2025-05-11T04:26:24.570281Z",
     "shell.execute_reply": "2025-05-11T04:26:24.569654Z"
    },
    "papermill": {
     "duration": 0.00905,
     "end_time": "2025-05-11T04:26:24.571362",
     "exception": false,
     "start_time": "2025-05-11T04:26:24.562312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4641a045",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T04:26:24.579719Z",
     "iopub.status.busy": "2025-05-11T04:26:24.579510Z",
     "iopub.status.idle": "2025-05-11T04:26:24.582862Z",
     "shell.execute_reply": "2025-05-11T04:26:24.582269Z"
    },
    "papermill": {
     "duration": 0.008866,
     "end_time": "2025-05-11T04:26:24.584017",
     "exception": false,
     "start_time": "2025-05-11T04:26:24.575151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8978cecb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T04:26:24.592643Z",
     "iopub.status.busy": "2025-05-11T04:26:24.592400Z",
     "iopub.status.idle": "2025-05-11T04:26:24.604853Z",
     "shell.execute_reply": "2025-05-11T04:26:24.604274Z"
    },
    "papermill": {
     "duration": 0.018112,
     "end_time": "2025-05-11T04:26:24.606042",
     "exception": false,
     "start_time": "2025-05-11T04:26:24.587930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f01127b",
   "metadata": {
    "papermill": {
     "duration": 0.003758,
     "end_time": "2025-05-11T04:26:24.613850",
     "exception": false,
     "start_time": "2025-05-11T04:26:24.610092",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1447513d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T04:26:24.622526Z",
     "iopub.status.busy": "2025-05-11T04:26:24.622309Z",
     "iopub.status.idle": "2025-05-11T04:26:24.681554Z",
     "shell.execute_reply": "2025-05-11T04:26:24.680058Z"
    },
    "papermill": {
     "duration": 0.065674,
     "end_time": "2025-05-11T04:26:24.683409",
     "exception": false,
     "start_time": "2025-05-11T04:26:24.617735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "data_used = manager.list()\n",
    "sampling_dur = manager.list()\n",
    "new_samples = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'netifier-undersampled-besra'\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "sequence_length = 96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78d0a62",
   "metadata": {
    "papermill": {
     "duration": 0.003888,
     "end_time": "2025-05-11T04:26:24.691311",
     "exception": false,
     "start_time": "2025-05-11T04:26:24.687423",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aa3b9c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T04:26:24.700593Z",
     "iopub.status.busy": "2025-05-11T04:26:24.700285Z",
     "iopub.status.idle": "2025-05-11T04:26:24.780419Z",
     "shell.execute_reply": "2025-05-11T04:26:24.779549Z"
    },
    "papermill": {
     "duration": 0.086595,
     "end_time": "2025-05-11T04:26:24.781882",
     "exception": false,
     "start_time": "2025-05-11T04:26:24.695287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5798, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/kaggle/input/netifier/undersampled.csv', encoding='latin-1')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84607feb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T04:26:24.791614Z",
     "iopub.status.busy": "2025-05-11T04:26:24.791337Z",
     "iopub.status.idle": "2025-05-11T04:26:24.819004Z",
     "shell.execute_reply": "2025-05-11T04:26:24.818229Z"
    },
    "papermill": {
     "duration": 0.033931,
     "end_time": "2025-05-11T04:26:24.820309",
     "exception": false,
     "start_time": "2025-05-11T04:26:24.786378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_text</th>\n",
       "      <th>pornografi</th>\n",
       "      <th>sara</th>\n",
       "      <th>radikalisme</th>\n",
       "      <th>pencemaran_nama_baik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sidangahok semoga sipenista agama dan ateknya ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>itu membuktikan bahwa rakyat malaysia anti cin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eh memek diam kamu kepala kamu kaya kontol muk...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>font fira sans some pakistanis dan indian musl...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pngusiran syiah kok jadi mirip sama di usir ny...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      processed_text  pornografi  sara  \\\n",
       "0  sidangahok semoga sipenista agama dan ateknya ...           0     1   \n",
       "1  itu membuktikan bahwa rakyat malaysia anti cin...           0     1   \n",
       "2  eh memek diam kamu kepala kamu kaya kontol muk...           1     0   \n",
       "3  font fira sans some pakistanis dan indian musl...           0     1   \n",
       "4  pngusiran syiah kok jadi mirip sama di usir ny...           0     0   \n",
       "\n",
       "   radikalisme  pencemaran_nama_baik  \n",
       "0            1                     1  \n",
       "1            0                     1  \n",
       "2            0                     0  \n",
       "3            1                     0  \n",
       "4            1                     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88e6b79f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T04:26:24.830062Z",
     "iopub.status.busy": "2025-05-11T04:26:24.829855Z",
     "iopub.status.idle": "2025-05-11T04:26:24.852072Z",
     "shell.execute_reply": "2025-05-11T04:26:24.851342Z"
    },
    "papermill": {
     "duration": 0.028529,
     "end_time": "2025-05-11T04:26:24.853359",
     "exception": false,
     "start_time": "2025-05-11T04:26:24.824830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4638,) (4638, 4)\n",
      "(1160,) (1160, 4)\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "train_labels = train_data.columns[1:]\n",
    "val_labels = val_data.columns[1:]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['processed_text'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['processed_text'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c84c9f5",
   "metadata": {
    "papermill": {
     "duration": 0.004302,
     "end_time": "2025-05-11T04:26:24.862077",
     "exception": false,
     "start_time": "2025-05-11T04:26:24.857775",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82c1690b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T04:26:24.871546Z",
     "iopub.status.busy": "2025-05-11T04:26:24.871256Z",
     "iopub.status.idle": "2025-05-11T04:26:25.821650Z",
     "shell.execute_reply": "2025-05-11T04:26:25.820790Z"
    },
    "papermill": {
     "duration": 0.956682,
     "end_time": "2025-05-11T04:26:25.823025",
     "exception": false,
     "start_time": "2025-05-11T04:26:24.866343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9677001535cc40dea8461f7492598b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a146cc457e04d5f81906f23e3583bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857ab4870bc04d17b2cf0f6b9513944a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6118a4b0d4d44ce0b9eeefb224a9b66f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NetifierDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=96, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(labels, dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def get_per_class_probs(self):\n",
    "        \"\"\"\n",
    "        Calculate the spread of labels (0 and 1) for each class in the dataset.\n",
    "        Returns:\n",
    "            dict: A dictionary where keys are class indices and values are [count_0, count_1].\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize a dictionary to store counts for each class\n",
    "        label_counts = defaultdict(lambda: [0, 0])  # [count_0, count_1] for each class\n",
    "\n",
    "        for i in range(len(self)):\n",
    "            # Get the labels for the i-th sample\n",
    "            labels = self[i]['labels']\n",
    "\n",
    "            # Update counts for each class\n",
    "            for class_idx, label in enumerate(labels):\n",
    "                label_counts[class_idx][int(label)] += 1\n",
    "\n",
    "        for key in label_counts.keys():\n",
    "            total = sum(label_counts[key])\n",
    "            label_counts[key] = [x / total for x in label_counts[key]]\n",
    "\n",
    "        return label_counts\n",
    "\n",
    "    def get_global_probs(self):\n",
    "        \"\"\"\n",
    "        Calculate the global count of 0s and 1s across all classes in the dataset.\n",
    "        Returns:\n",
    "            dict: A dictionary with keys '0' and '1' representing their global counts.\n",
    "        \"\"\"\n",
    "        global_counts = {'0': 0, '1': 0}\n",
    "\n",
    "        for i in range(len(self)):\n",
    "            # Get the labels for the i-th sample\n",
    "            labels = self[i]['labels']\n",
    "\n",
    "            # Update global counts\n",
    "            for label in labels:\n",
    "                global_counts[str(int(label))] += 1\n",
    "\n",
    "        total = global_counts['0'] + global_counts['1']\n",
    "        for key in global_counts.keys():\n",
    "            global_counts[key] /= total\n",
    "\n",
    "        return global_counts\n",
    "\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b548a282",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T04:26:25.834209Z",
     "iopub.status.busy": "2025-05-11T04:26:25.833967Z",
     "iopub.status.idle": "2025-05-11T04:26:25.838259Z",
     "shell.execute_reply": "2025-05-11T04:26:25.837490Z"
    },
    "papermill": {
     "duration": 0.011256,
     "end_time": "2025-05-11T04:26:25.839548",
     "exception": false,
     "start_time": "2025-05-11T04:26:25.828292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(X_train, y_train, X_val, y_val, sequence_length=96, num_workers=4):\n",
    "    train_dataset = NetifierDataset(X_train, y_train, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = NetifierDataset(X_val, y_val, tokenizer, max_length=sequence_length)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f62535c",
   "metadata": {
    "papermill": {
     "duration": 0.004531,
     "end_time": "2025-05-11T04:26:25.848859",
     "exception": false,
     "start_time": "2025-05-11T04:26:25.844328",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5833c3c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T04:26:25.859401Z",
     "iopub.status.busy": "2025-05-11T04:26:25.859130Z",
     "iopub.status.idle": "2025-05-11T04:26:25.862603Z",
     "shell.execute_reply": "2025-05-11T04:26:25.862033Z"
    },
    "papermill": {
     "duration": 0.010088,
     "end_time": "2025-05-11T04:26:25.863854",
     "exception": false,
     "start_time": "2025-05-11T04:26:25.853766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4059eb3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T04:26:25.874505Z",
     "iopub.status.busy": "2025-05-11T04:26:25.874265Z",
     "iopub.status.idle": "2025-05-11T04:26:25.878543Z",
     "shell.execute_reply": "2025-05-11T04:26:25.877950Z"
    },
    "papermill": {
     "duration": 0.010905,
     "end_time": "2025-05-11T04:26:25.879815",
     "exception": false,
     "start_time": "2025-05-11T04:26:25.868910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        target_names=['pornografi', 'sara', 'radikalisme', 'pencemaran_nama_baik'],\n",
    "        zero_division=0\n",
    "    )  \n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "095abc2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T04:26:25.890693Z",
     "iopub.status.busy": "2025-05-11T04:26:25.890428Z",
     "iopub.status.idle": "2025-05-11T04:26:25.902943Z",
     "shell.execute_reply": "2025-05-11T04:26:25.902365Z"
    },
    "papermill": {
     "duration": 0.019251,
     "end_time": "2025-05-11T04:26:25.904121",
     "exception": false,
     "start_time": "2025-05-11T04:26:25.884870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, metrics, trials, i):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    train_loader, val_loader = get_dataloaders(current_X_train, current_y_train, X_val, y_val)\n",
    "\n",
    "    with accelerator.main_process_first():\n",
    "        model = BertForSequenceClassification.from_pretrained(\n",
    "            'indobenchmark/indobert-base-p1',\n",
    "            num_labels=len(train_labels),\n",
    "            problem_type=\"multi_label_classification\"\n",
    "        )\n",
    "        \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    model, optimizer, train_loader, val_loader = accelerator.prepare(\n",
    "        model, optimizer, train_loader, val_loader\n",
    "    )\n",
    "\n",
    "    best_result = None\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "            labels = batch['labels']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}))\n",
    "\n",
    "        if best_result is None or result['f1_micro'] >= best_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "\n",
    "            nearest_cp = current_train_size\n",
    "            if nearest_cp not in checkpoints:\n",
    "                for cp in checkpoints:\n",
    "                    if cp > current_train_size:\n",
    "                        nearest_cp = cp\n",
    "                        break\n",
    "            percentage = math.ceil(nearest_cp / total_data * 100)\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-{trials+1}-model-{i+1}-{percentage}',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            best_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"Model {i+1} - Iteration {current_train_size}: Accuracy: {round(best_result['accuracy'], 4)}, F1 Micro: {round(best_result['f1_micro'], 4)}, F1 Macro: {round(best_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(best_result['report'])\n",
    "        \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    accelerator.print(f\"Training completed in {duration} s\")\n",
    "    \n",
    "    # Update the shared lists\n",
    "    if accelerator.is_local_main_process:\n",
    "        metrics[0].append(best_result['accuracy'])\n",
    "        metrics[1].append(best_result['f1_micro'])\n",
    "        metrics[2].append(best_result['f1_macro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a161f32c",
   "metadata": {
    "papermill": {
     "duration": 0.00476,
     "end_time": "2025-05-11T04:26:25.913868",
     "exception": false,
     "start_time": "2025-05-11T04:26:25.909108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eea77de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T04:26:25.924486Z",
     "iopub.status.busy": "2025-05-11T04:26:25.924251Z",
     "iopub.status.idle": "2025-05-11T04:26:25.929800Z",
     "shell.execute_reply": "2025-05-11T04:26:25.928934Z"
    },
    "papermill": {
     "duration": 0.012345,
     "end_time": "2025-05-11T04:26:25.931112",
     "exception": false,
     "start_time": "2025-05-11T04:26:25.918767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3601b1",
   "metadata": {
    "papermill": {
     "duration": 0.004851,
     "end_time": "2025-05-11T04:26:25.940865",
     "exception": false,
     "start_time": "2025-05-11T04:26:25.936014",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bcb082a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T04:26:25.951649Z",
     "iopub.status.busy": "2025-05-11T04:26:25.951384Z",
     "iopub.status.idle": "2025-05-11T04:26:25.972177Z",
     "shell.execute_reply": "2025-05-11T04:26:25.971352Z"
    },
    "papermill": {
     "duration": 0.027866,
     "end_time": "2025-05-11T04:26:25.973656",
     "exception": false,
     "start_time": "2025-05-11T04:26:25.945790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def beta_score(p, y, alpha=0.1, beta=3):\n",
    "    \"\"\"Calculates Beta score for a given probability p and label y.\"\"\"\n",
    "    \n",
    "    if y == 1:\n",
    "        return -betaln(alpha, beta + 1) + betaln(alpha + p, beta + 1 - p)\n",
    "    elif y == 0:\n",
    "        return -betaln(alpha + 1, beta) + betaln(alpha + 1 - p, beta + p)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid label: y must be 0 or 1.\")\n",
    "\n",
    "def bayesian_update(prior, likelihood, evidence, alpha=0.1, beta_param=3):\n",
    "    \"\"\" \n",
    "    Bayes' Theorem: P(y'|x') = P(x'|y') * P(y') / P(x')\n",
    "    P(y'|x') or likelihood = model probs\n",
    "    p(y') or prior = class probabilities\n",
    "    p(x') or evidence = 1 / number of data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Using the Beta score to simulate the posterior\n",
    "    posterior = (likelihood * prior) / evidence\n",
    "    \n",
    "    # We calculate the posterior using the Beta distribution\n",
    "    return posterior\n",
    "\n",
    "def compute_expected_score_change(predicted_prob, class_probs, label_probs, class_idx):\n",
    "    scores_before = []\n",
    "    scores_after = []\n",
    "\n",
    "    # Before data addition: calculate Beta score for predicted prob\n",
    "    scores_before.append(beta_score(predicted_prob, int(1 if predicted_prob >= 0.5 else 0)))\n",
    "    scores_before.append(beta_score(1-predicted_prob, int(1 if predicted_prob >= 0.5 else 0)))\n",
    "    \n",
    "    # After data addition: use Bayesian update (posterior probability)\n",
    "    for k in range(2):\n",
    "        prior = predicted_prob\n",
    "        likelihood = class_probs[class_idx][k]  # Likelihood is the true label (0 or 1)\n",
    "        posterior = bayesian_update(prior, likelihood, 1)\n",
    "        scores_after.append(beta_score(posterior, int(1 if posterior >= 0.5 else 0)))\n",
    "\n",
    "    score_diff_0 = scores_after[0] - scores_before[0]\n",
    "    score_diff_1 = scores_after[1] - scores_before[1]\n",
    "    return label_probs['0'] * score_diff_0 + label_probs['1'] * score_diff_1\n",
    "\n",
    "# Function to compute Expected Score Change (âˆ†Q)\n",
    "def besra_sampling(models, X_pool, train_indices, remaining_indices, tokenizer, sampling_dur, new_samples, trials, n_clusters=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "    \n",
    "    dataset = NetifierDataset(X_pool, np.zeros((len(X_pool), 4)), tokenizer, max_length=sequence_length)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    labeled_dataset = NetifierDataset(current_X_train, current_y_train, tokenizer, max_length=sequence_length)\n",
    "    label_probs = labeled_dataset.get_global_probs()\n",
    "    class_probs = labeled_dataset.get_per_class_probs()\n",
    "\n",
    "    for model in models:\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "    start_time = time.time()\n",
    "    score_changes = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(model.device)\n",
    "        attention_mask = batch['attention_mask'].to(model.device)\n",
    "        labels = batch['labels'].to(model.device)\n",
    "\n",
    "        model_probs = []\n",
    "\n",
    "        for model in models:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                probs = torch.sigmoid(logits)  # Multi-label classification uses sigmoid\n",
    "                model_probs.append(probs.unsqueeze(0))  # Add batch dimension for averaging\n",
    "        \n",
    "        # Stack all model predictions and compute the mean across models\n",
    "        model_probs = torch.cat(model_probs, dim=0)  # Concatenate predictions across models\n",
    "        probs = model_probs.mean(dim=0)  # Take the mean along the model axis\n",
    "\n",
    "        # Calculate Beta scores before and after data addition\n",
    "        for i in range(len(probs)):\n",
    "            score_diff = []\n",
    "            for class_idx in range(probs.shape[1]):\n",
    "                predicted_prob = probs[i, class_idx].item()\n",
    "                score_diff.append(compute_expected_score_change(predicted_prob, class_probs, label_probs, class_idx))\n",
    "            \n",
    "            score_changes.append(np.mean(score_diff))\n",
    "    \n",
    "    accelerator.wait_for_everyone()    \n",
    "    if accelerator.is_local_main_process:\n",
    "        score_changes = np.array(score_changes)\n",
    "        score_changes = score_changes.reshape(-1, 1)\n",
    "\n",
    "        target_samples = math.ceil(0.1 * len(X_pool))\n",
    "        collected_indices = set()\n",
    "        thresholds = []\n",
    "    \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        arrived_at_cp = False\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "\n",
    "        # Determine number of maximum samples to be acquired\n",
    "        if target_samples <= n_clusters and n_clusters < nearest_cp - current_train_size:\n",
    "            target_samples = n_clusters\n",
    "        elif target_samples > n_clusters and target_samples < nearest_cp - current_train_size:\n",
    "            target_samples = target_samples\n",
    "        else:\n",
    "            arrived_at_cp = True\n",
    "            target_samples = nearest_cp - current_train_size\n",
    "\n",
    "        # No clustering needed when there's little data left\n",
    "        # No clustering needed when there's little data left\n",
    "        if current_train_size >= checkpoints[len(checkpoints)-1] - min_increment:\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend(remaining_indices)\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                'pornografi': [y_train[i][0] for i in temp],\n",
    "                'sara': [y_train[i][1] for i in temp],\n",
    "                'radikalisme': [y_train[i][2] for i in temp],\n",
    "                'pencemaran_nama_baik': [y_train[i][3] for i in temp],\n",
    "            })\n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Acquired samples:\", len(remaining_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "            \n",
    "            sampling_dur.append(duration)\n",
    "            for i in remaining_indices:\n",
    "                new_samples.append(i)\n",
    "        else:\n",
    "            # Cluster the data based on its embeddings\n",
    "            kmeans=KMeans(n_clusters=n_clusters, n_init=1)\n",
    "            kmeans.fit(score_changes)\n",
    "            \n",
    "            for cluster_id in range(n_clusters):\n",
    "                # Cluster center and indices of samples in the current cluster\n",
    "                cluster_center = kmeans.cluster_centers_[cluster_id]\n",
    "                cluster_indices = np.where(kmeans.labels_ == cluster_id)[0]\n",
    "            \n",
    "                if cluster_indices.size == 0:\n",
    "                    # Skip clusters with no members\n",
    "                    print(f\"Cluster {cluster_id} has no members, skipping.\")\n",
    "                    continue\n",
    "            \n",
    "                # Calculate distances of each point in the cluster from the cluster center\n",
    "                cluster_distances = np.linalg.norm(score_changes[cluster_indices] - cluster_center, axis=1)\n",
    "            \n",
    "                # Determine the local threshold (10th percentile of closest distances to cluster center)\n",
    "                local_threshold = np.percentile(cluster_distances, 90)\n",
    "                thresholds.append(local_threshold)\n",
    "            \n",
    "                below_threshold_indices = cluster_indices[cluster_distances >= local_threshold]\n",
    "                collected_indices.update(below_threshold_indices)\n",
    "    \n",
    "            # To handle multiple points with same distance\n",
    "            if len(collected_indices) > target_samples:\n",
    "                collected_indices = np.array(list(collected_indices))\n",
    "                np.random.shuffle(collected_indices)\n",
    "                collected_indices = collected_indices[:target_samples]\n",
    "                \n",
    "            end_time = time.time() \n",
    "            duration = end_time - start_time \n",
    "    \n",
    "            if arrived_at_cp:\n",
    "                temp = train_indices.copy()\n",
    "                temp.extend(collected_indices)\n",
    "                \n",
    "                # Save acquired data up to checkpoint\n",
    "                acquired_data = pd.DataFrame({\n",
    "                    'processed_text': [X_train[i] for i in temp],\n",
    "                    'pornografi': [y_train[i][0] for i in temp],\n",
    "                    'sara': [y_train[i][1] for i in temp],\n",
    "                    'radikalisme': [y_train[i][2] for i in temp],\n",
    "                    'pencemaran_nama_baik': [y_train[i][3] for i in temp],\n",
    "                })\n",
    "        \n",
    "                acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "            \n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            # print(f\"Thresholds: {thresholds}\")\n",
    "            print(\"Acquired samples:\", len(collected_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "        \n",
    "            sampling_dur.append(duration)\n",
    "            for i in collected_indices:\n",
    "                new_samples.append(remaining_indices[i])\n",
    "\n",
    "        threshold_data = pd.DataFrame({\n",
    "            'Threshold': thresholds\n",
    "        })\n",
    "        threshold_data.to_csv(f\"results/{filename}-thresholds-{trials+1}-{current_train_size}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166411b7",
   "metadata": {
    "papermill": {
     "duration": 0.004892,
     "end_time": "2025-05-11T04:26:25.983713",
     "exception": false,
     "start_time": "2025-05-11T04:26:25.978821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3586a2c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T04:26:25.994539Z",
     "iopub.status.busy": "2025-05-11T04:26:25.994277Z",
     "iopub.status.idle": "2025-05-11T04:26:26.004882Z",
     "shell.execute_reply": "2025-05-11T04:26:26.004098Z"
    },
    "papermill": {
     "duration": 0.017471,
     "end_time": "2025-05-11T04:26:26.006153",
     "exception": false,
     "start_time": "2025-05-11T04:26:25.988682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "    \n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        model_accuracies = manager.list()\n",
    "        model_f1_micros = manager.list()\n",
    "        model_f1_macros = manager.list()\n",
    "        \n",
    "        # Train the model\n",
    "        for j in range(3):\n",
    "            set_seed(seed[j])\n",
    "            args = (current_train_size, train_indices, (model_accuracies, model_f1_micros, model_f1_macros), i, j)\n",
    "            notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        data_used.append(current_train_size)\n",
    "        accuracies.append(np.mean(model_accuracies))\n",
    "        f1_micros.append(np.mean(model_f1_micros))\n",
    "        f1_macros.append(np.mean(model_f1_macros))\n",
    "        print(f\"Averaged - Iteration {current_train_size}: Accuracy: {round(np.mean(accuracies), 4)}, F1 Micro: {round(np.mean(f1_micros), 4)}, F1 Macro: {round(np.mean(f1_macros), 4)}\")\n",
    "\n",
    "        nearest_cp = current_train_size\n",
    "        if nearest_cp not in checkpoints:\n",
    "            for cp in checkpoints:\n",
    "                if cp > current_train_size:\n",
    "                    nearest_cp = cp\n",
    "                    break\n",
    "        percentage = math.ceil(nearest_cp / total_data * 100)\n",
    "        \n",
    "        models = []\n",
    "        for j in range(3):\n",
    "            model = BertForSequenceClassification.from_pretrained(f'{filename}-{i+1}-model-{j+1}-{percentage}')\n",
    "            models.append(model)\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (models, [X_train[i] for i in remaining_indices], train_indices, remaining_indices, tokenizer, sampling_dur, new_samples, i)\n",
    "        notebook_launcher(besra_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    model_accuracies = manager.list()\n",
    "    model_f1_micros = manager.list()\n",
    "    model_f1_macros = manager.list()\n",
    "    \n",
    "    for j in range(3):\n",
    "        set_seed(seed[j])\n",
    "        args = (current_train_size, train_indices, (model_accuracies, model_f1_micros, model_f1_macros), i, j)\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "        \n",
    "    data_used.append(current_train_size)\n",
    "    accuracies.append(np.mean(model_accuracies))\n",
    "    f1_micros.append(np.mean(model_f1_micros))\n",
    "    f1_macros.append(np.mean(model_f1_macros))\n",
    "    print(f\"Averaged - Iteration {current_train_size}: Accuracy: {round(np.mean(accuracies), 4)}, F1 Micro: {round(np.mean(f1_micros), 4)}, F1 Macro: {round(np.mean(f1_macros), 4)}\")\n",
    "        \n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1229c8e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T04:26:26.016849Z",
     "iopub.status.busy": "2025-05-11T04:26:26.016535Z",
     "iopub.status.idle": "2025-05-11T06:24:01.065892Z",
     "shell.execute_reply": "2025-05-11T06:24:01.064913Z"
    },
    "papermill": {
     "duration": 7055.174084,
     "end_time": "2025-05-11T06:24:01.185289",
     "exception": false,
     "start_time": "2025-05-11T04:26:26.011205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 1\n",
      "Random seed: [50, 67, 42]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6444, Accuracy: 0.728, F1 Micro: 0.0279, F1 Macro: 0.0291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5528, Accuracy: 0.7313, F1 Micro: 0.0508, F1 Macro: 0.051\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5179, Accuracy: 0.7516, F1 Micro: 0.1816, F1 Macro: 0.1523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4528, Accuracy: 0.7802, F1 Micro: 0.3626, F1 Macro: 0.2911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.424, Accuracy: 0.7987, F1 Micro: 0.5296, F1 Macro: 0.4727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3869, Accuracy: 0.8055, F1 Micro: 0.5968, F1 Macro: 0.5733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3361, Accuracy: 0.8092, F1 Micro: 0.6031, F1 Macro: 0.5816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3031, Accuracy: 0.8183, F1 Micro: 0.6273, F1 Macro: 0.6169\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.279, Accuracy: 0.8205, F1 Micro: 0.6507, F1 Macro: 0.6479\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.238, Accuracy: 0.8283, F1 Micro: 0.6643, F1 Macro: 0.661\n",
      "Model 1 - Iteration 289: Accuracy: 0.8283, F1 Micro: 0.6643, F1 Macro: 0.661\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.85      0.87      0.86       308\n",
      "                sara       0.61      0.46      0.53       367\n",
      "         radikalisme       0.75      0.72      0.73       337\n",
      "pencemaran_nama_baik       0.64      0.45      0.53       330\n",
      "\n",
      "           micro avg       0.72      0.62      0.66      1342\n",
      "           macro avg       0.71      0.62      0.66      1342\n",
      "        weighted avg       0.71      0.62      0.65      1342\n",
      "         samples avg       0.45      0.46      0.44      1342\n",
      "\n",
      "Training completed in 50.491870641708374 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.602, Accuracy: 0.7241, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5405, Accuracy: 0.7387, F1 Micro: 0.1005, F1 Macro: 0.0937\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4942, Accuracy: 0.7603, F1 Micro: 0.2438, F1 Macro: 0.1859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4231, Accuracy: 0.7917, F1 Micro: 0.4654, F1 Macro: 0.379\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3903, Accuracy: 0.8061, F1 Micro: 0.5766, F1 Macro: 0.5377\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3508, Accuracy: 0.8119, F1 Micro: 0.5985, F1 Macro: 0.574\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2999, Accuracy: 0.8183, F1 Micro: 0.6323, F1 Macro: 0.62\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2692, Accuracy: 0.8259, F1 Micro: 0.6561, F1 Macro: 0.6499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2425, Accuracy: 0.8337, F1 Micro: 0.6744, F1 Macro: 0.6709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2018, Accuracy: 0.8366, F1 Micro: 0.6746, F1 Macro: 0.6667\n",
      "Model 2 - Iteration 289: Accuracy: 0.8366, F1 Micro: 0.6746, F1 Macro: 0.6667\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.86      0.87      0.87       308\n",
      "                sara       0.68      0.46      0.55       367\n",
      "         radikalisme       0.77      0.76      0.76       337\n",
      "pencemaran_nama_baik       0.64      0.40      0.49       330\n",
      "\n",
      "           micro avg       0.75      0.61      0.67      1342\n",
      "           macro avg       0.74      0.62      0.67      1342\n",
      "        weighted avg       0.73      0.61      0.66      1342\n",
      "         samples avg       0.48      0.47      0.46      1342\n",
      "\n",
      "Training completed in 48.19691586494446 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6211, Accuracy: 0.7241, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5592, Accuracy: 0.7268, F1 Micro: 0.0192, F1 Macro: 0.0202\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5179, Accuracy: 0.7553, F1 Micro: 0.2098, F1 Macro: 0.1721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4469, Accuracy: 0.7868, F1 Micro: 0.4416, F1 Macro: 0.3902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.413, Accuracy: 0.803, F1 Micro: 0.5838, F1 Macro: 0.5641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3666, Accuracy: 0.8047, F1 Micro: 0.6154, F1 Macro: 0.597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3182, Accuracy: 0.815, F1 Micro: 0.642, F1 Macro: 0.635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2846, Accuracy: 0.8226, F1 Micro: 0.6453, F1 Macro: 0.6389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2637, Accuracy: 0.8232, F1 Micro: 0.6708, F1 Macro: 0.6715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2173, Accuracy: 0.8347, F1 Micro: 0.6745, F1 Macro: 0.6714\n",
      "Model 3 - Iteration 289: Accuracy: 0.8347, F1 Micro: 0.6745, F1 Macro: 0.6714\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.85      0.84      0.85       308\n",
      "                sara       0.67      0.50      0.57       367\n",
      "         radikalisme       0.76      0.72      0.74       337\n",
      "pencemaran_nama_baik       0.65      0.45      0.53       330\n",
      "\n",
      "           micro avg       0.74      0.62      0.67      1342\n",
      "           macro avg       0.73      0.63      0.67      1342\n",
      "        weighted avg       0.73      0.62      0.67      1342\n",
      "         samples avg       0.47      0.47      0.45      1342\n",
      "\n",
      "Training completed in 49.70271015167236 s\n",
      "Averaged - Iteration 289: Accuracy: 0.8332, F1 Micro: 0.6711, F1 Macro: 0.6664\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2899\n",
      "Acquired samples: 435\n",
      "Sampling duration: 72.99512338638306 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5932, Accuracy: 0.7309, F1 Micro: 0.048, F1 Macro: 0.0484\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4897, Accuracy: 0.7998, F1 Micro: 0.512, F1 Macro: 0.4478\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4082, Accuracy: 0.8236, F1 Micro: 0.6364, F1 Macro: 0.6045\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3366, Accuracy: 0.8421, F1 Micro: 0.7108, F1 Macro: 0.7125\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2936, Accuracy: 0.8592, F1 Micro: 0.7296, F1 Macro: 0.7296\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2542, Accuracy: 0.8657, F1 Micro: 0.7418, F1 Macro: 0.7383\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1949, Accuracy: 0.8711, F1 Micro: 0.7653, F1 Macro: 0.7695\n",
      "Epoch 8/10, Train Loss: 0.1695, Accuracy: 0.868, F1 Micro: 0.7377, F1 Macro: 0.7352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1442, Accuracy: 0.876, F1 Micro: 0.781, F1 Macro: 0.7867\n",
      "Epoch 10/10, Train Loss: 0.1153, Accuracy: 0.8674, F1 Micro: 0.736, F1 Macro: 0.7322\n",
      "Model 1 - Iteration 724: Accuracy: 0.876, F1 Micro: 0.781, F1 Macro: 0.7867\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.97      0.85      0.91       308\n",
      "                sara       0.69      0.80      0.74       367\n",
      "         radikalisme       0.76      0.85      0.80       337\n",
      "pencemaran_nama_baik       0.69      0.70      0.69       330\n",
      "\n",
      "           micro avg       0.76      0.80      0.78      1342\n",
      "           macro avg       0.78      0.80      0.79      1342\n",
      "        weighted avg       0.77      0.80      0.78      1342\n",
      "         samples avg       0.60      0.60      0.59      1342\n",
      "\n",
      "Training completed in 58.00226426124573 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5767, Accuracy: 0.7428, F1 Micro: 0.127, F1 Macro: 0.114\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4668, Accuracy: 0.8104, F1 Micro: 0.5832, F1 Macro: 0.5373\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3807, Accuracy: 0.8345, F1 Micro: 0.6729, F1 Macro: 0.6606\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3041, Accuracy: 0.8448, F1 Micro: 0.7178, F1 Macro: 0.7172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2704, Accuracy: 0.8627, F1 Micro: 0.7431, F1 Macro: 0.7463\n",
      "Epoch 6/10, Train Loss: 0.2381, Accuracy: 0.8635, F1 Micro: 0.738, F1 Macro: 0.7352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1727, Accuracy: 0.8719, F1 Micro: 0.765, F1 Macro: 0.769\n",
      "Epoch 8/10, Train Loss: 0.1449, Accuracy: 0.8643, F1 Micro: 0.7293, F1 Macro: 0.7277\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1274, Accuracy: 0.8723, F1 Micro: 0.7704, F1 Macro: 0.7755\n",
      "Epoch 10/10, Train Loss: 0.0948, Accuracy: 0.8701, F1 Micro: 0.7556, F1 Macro: 0.7583\n",
      "Model 2 - Iteration 724: Accuracy: 0.8723, F1 Micro: 0.7704, F1 Macro: 0.7755\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.86      0.90       308\n",
      "                sara       0.70      0.78      0.74       367\n",
      "         radikalisme       0.79      0.80      0.79       337\n",
      "pencemaran_nama_baik       0.66      0.67      0.66       330\n",
      "\n",
      "           micro avg       0.76      0.78      0.77      1342\n",
      "           macro avg       0.78      0.78      0.78      1342\n",
      "        weighted avg       0.77      0.78      0.77      1342\n",
      "         samples avg       0.59      0.59      0.57      1342\n",
      "\n",
      "Training completed in 56.42461323738098 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5994, Accuracy: 0.7255, F1 Micro: 0.0104, F1 Macro: 0.0111\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5022, Accuracy: 0.801, F1 Micro: 0.5576, F1 Macro: 0.5202\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4103, Accuracy: 0.8215, F1 Micro: 0.641, F1 Macro: 0.6063\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3304, Accuracy: 0.8433, F1 Micro: 0.7188, F1 Macro: 0.7179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.287, Accuracy: 0.8614, F1 Micro: 0.7431, F1 Macro: 0.7427\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2512, Accuracy: 0.8686, F1 Micro: 0.7471, F1 Macro: 0.7436\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1834, Accuracy: 0.8705, F1 Micro: 0.7621, F1 Macro: 0.763\n",
      "Epoch 8/10, Train Loss: 0.1611, Accuracy: 0.8711, F1 Micro: 0.7544, F1 Macro: 0.7534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.137, Accuracy: 0.8734, F1 Micro: 0.7763, F1 Macro: 0.7811\n",
      "Epoch 10/10, Train Loss: 0.1074, Accuracy: 0.8631, F1 Micro: 0.7286, F1 Macro: 0.723\n",
      "Model 3 - Iteration 724: Accuracy: 0.8734, F1 Micro: 0.7763, F1 Macro: 0.7811\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.84      0.89       308\n",
      "                sara       0.72      0.81      0.76       367\n",
      "         radikalisme       0.75      0.84      0.79       337\n",
      "pencemaran_nama_baik       0.66      0.70      0.68       330\n",
      "\n",
      "           micro avg       0.76      0.80      0.78      1342\n",
      "           macro avg       0.77      0.80      0.78      1342\n",
      "        weighted avg       0.77      0.80      0.78      1342\n",
      "         samples avg       0.58      0.60      0.58      1342\n",
      "\n",
      "Training completed in 57.998061180114746 s\n",
      "Averaged - Iteration 724: Accuracy: 0.8535, F1 Micro: 0.7235, F1 Macro: 0.7237\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2899\n",
      "Acquired samples: 392\n",
      "Sampling duration: 65.45853734016418 seconds\n",
      "New train size: 1116\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5859, Accuracy: 0.7701, F1 Micro: 0.296, F1 Macro: 0.2403\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4353, Accuracy: 0.8252, F1 Micro: 0.6386, F1 Macro: 0.6221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3475, Accuracy: 0.8577, F1 Micro: 0.7431, F1 Macro: 0.7495\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2807, Accuracy: 0.8694, F1 Micro: 0.7682, F1 Macro: 0.7741\n",
      "Epoch 5/10, Train Loss: 0.2301, Accuracy: 0.8756, F1 Micro: 0.7558, F1 Macro: 0.7552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1953, Accuracy: 0.8816, F1 Micro: 0.7773, F1 Macro: 0.7788\n",
      "Epoch 7/10, Train Loss: 0.1572, Accuracy: 0.8775, F1 Micro: 0.7639, F1 Macro: 0.7655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1174, Accuracy: 0.8781, F1 Micro: 0.78, F1 Macro: 0.785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1067, Accuracy: 0.8781, F1 Micro: 0.7852, F1 Macro: 0.7917\n",
      "Epoch 10/10, Train Loss: 0.0748, Accuracy: 0.8766, F1 Micro: 0.7698, F1 Macro: 0.7736\n",
      "Model 1 - Iteration 1116: Accuracy: 0.8781, F1 Micro: 0.7852, F1 Macro: 0.7917\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.96      0.86      0.91       308\n",
      "                sara       0.70      0.79      0.75       367\n",
      "         radikalisme       0.79      0.84      0.81       337\n",
      "pencemaran_nama_baik       0.66      0.74      0.70       330\n",
      "\n",
      "           micro avg       0.76      0.81      0.79      1342\n",
      "           macro avg       0.78      0.81      0.79      1342\n",
      "        weighted avg       0.77      0.81      0.79      1342\n",
      "         samples avg       0.59      0.60      0.59      1342\n",
      "\n",
      "Training completed in 65.4902195930481 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5568, Accuracy: 0.7889, F1 Micro: 0.4181, F1 Macro: 0.3627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4116, Accuracy: 0.8403, F1 Micro: 0.6737, F1 Macro: 0.6689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3228, Accuracy: 0.8643, F1 Micro: 0.7621, F1 Macro: 0.7681\n",
      "Epoch 4/10, Train Loss: 0.2638, Accuracy: 0.8697, F1 Micro: 0.762, F1 Macro: 0.7652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2156, Accuracy: 0.8847, F1 Micro: 0.783, F1 Macro: 0.7869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1797, Accuracy: 0.884, F1 Micro: 0.7839, F1 Macro: 0.7864\n",
      "Epoch 7/10, Train Loss: 0.1399, Accuracy: 0.8754, F1 Micro: 0.7603, F1 Macro: 0.7616\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.107, Accuracy: 0.8791, F1 Micro: 0.7889, F1 Macro: 0.7946\n",
      "Epoch 9/10, Train Loss: 0.0853, Accuracy: 0.8836, F1 Micro: 0.785, F1 Macro: 0.7878\n",
      "Epoch 10/10, Train Loss: 0.0671, Accuracy: 0.8791, F1 Micro: 0.7749, F1 Macro: 0.7774\n",
      "Model 2 - Iteration 1116: Accuracy: 0.8791, F1 Micro: 0.7889, F1 Macro: 0.7946\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.88      0.91       308\n",
      "                sara       0.71      0.81      0.76       367\n",
      "         radikalisme       0.79      0.84      0.81       337\n",
      "pencemaran_nama_baik       0.65      0.75      0.70       330\n",
      "\n",
      "           micro avg       0.76      0.82      0.79      1342\n",
      "           macro avg       0.77      0.82      0.79      1342\n",
      "        weighted avg       0.77      0.82      0.79      1342\n",
      "         samples avg       0.60      0.62      0.59      1342\n",
      "\n",
      "Training completed in 63.4554181098938 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5857, Accuracy: 0.7712, F1 Micro: 0.341, F1 Macro: 0.2936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4386, Accuracy: 0.8218, F1 Micro: 0.6371, F1 Macro: 0.6179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3444, Accuracy: 0.8555, F1 Micro: 0.749, F1 Macro: 0.755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.278, Accuracy: 0.8703, F1 Micro: 0.7691, F1 Macro: 0.7717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2298, Accuracy: 0.8779, F1 Micro: 0.7694, F1 Macro: 0.7696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1935, Accuracy: 0.8816, F1 Micro: 0.7841, F1 Macro: 0.7876\n",
      "Epoch 7/10, Train Loss: 0.1475, Accuracy: 0.8758, F1 Micro: 0.7702, F1 Macro: 0.7733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1166, Accuracy: 0.8787, F1 Micro: 0.7868, F1 Macro: 0.7932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.095, Accuracy: 0.8777, F1 Micro: 0.7874, F1 Macro: 0.7924\n",
      "Epoch 10/10, Train Loss: 0.0725, Accuracy: 0.8793, F1 Micro: 0.7833, F1 Macro: 0.7885\n",
      "Model 3 - Iteration 1116: Accuracy: 0.8777, F1 Micro: 0.7874, F1 Macro: 0.7924\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.87      0.90       308\n",
      "                sara       0.71      0.83      0.77       367\n",
      "         radikalisme       0.77      0.85      0.81       337\n",
      "pencemaran_nama_baik       0.65      0.73      0.69       330\n",
      "\n",
      "           micro avg       0.76      0.82      0.79      1342\n",
      "           macro avg       0.77      0.82      0.79      1342\n",
      "        weighted avg       0.76      0.82      0.79      1342\n",
      "         samples avg       0.60      0.61      0.59      1342\n",
      "\n",
      "Training completed in 66.79790616035461 s\n",
      "Averaged - Iteration 1116: Accuracy: 0.8618, F1 Micro: 0.7447, F1 Macro: 0.7468\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2899\n",
      "Acquired samples: 353\n",
      "Sampling duration: 59.05182337760925 seconds\n",
      "New train size: 1469\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.548, Accuracy: 0.8065, F1 Micro: 0.55, F1 Macro: 0.5106\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3823, Accuracy: 0.8454, F1 Micro: 0.6803, F1 Macro: 0.6711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3058, Accuracy: 0.8657, F1 Micro: 0.7381, F1 Macro: 0.7382\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2569, Accuracy: 0.8828, F1 Micro: 0.7791, F1 Macro: 0.7804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2108, Accuracy: 0.8865, F1 Micro: 0.7906, F1 Macro: 0.7934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1564, Accuracy: 0.8865, F1 Micro: 0.7914, F1 Macro: 0.7942\n",
      "Epoch 7/10, Train Loss: 0.1264, Accuracy: 0.8845, F1 Micro: 0.7825, F1 Macro: 0.7843\n",
      "Epoch 8/10, Train Loss: 0.0987, Accuracy: 0.882, F1 Micro: 0.7899, F1 Macro: 0.7941\n",
      "Epoch 9/10, Train Loss: 0.0748, Accuracy: 0.8838, F1 Micro: 0.7857, F1 Macro: 0.7891\n",
      "Epoch 10/10, Train Loss: 0.071, Accuracy: 0.8859, F1 Micro: 0.7911, F1 Macro: 0.794\n",
      "Model 1 - Iteration 1469: Accuracy: 0.8865, F1 Micro: 0.7914, F1 Macro: 0.7942\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.87      0.91       308\n",
      "                sara       0.75      0.75      0.75       367\n",
      "         radikalisme       0.79      0.85      0.82       337\n",
      "pencemaran_nama_baik       0.74      0.67      0.70       330\n",
      "\n",
      "           micro avg       0.80      0.78      0.79      1342\n",
      "           macro avg       0.81      0.78      0.79      1342\n",
      "        weighted avg       0.80      0.78      0.79      1342\n",
      "         samples avg       0.60      0.59      0.58      1342\n",
      "\n",
      "Training completed in 71.33086347579956 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5259, Accuracy: 0.8098, F1 Micro: 0.5643, F1 Macro: 0.5173\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3649, Accuracy: 0.8567, F1 Micro: 0.722, F1 Macro: 0.7227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2937, Accuracy: 0.8713, F1 Micro: 0.7568, F1 Macro: 0.7601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2421, Accuracy: 0.8849, F1 Micro: 0.779, F1 Macro: 0.7801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1944, Accuracy: 0.882, F1 Micro: 0.7812, F1 Macro: 0.7825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1449, Accuracy: 0.8836, F1 Micro: 0.788, F1 Macro: 0.791\n",
      "Epoch 7/10, Train Loss: 0.1145, Accuracy: 0.8824, F1 Micro: 0.7755, F1 Macro: 0.7776\n",
      "Epoch 8/10, Train Loss: 0.0913, Accuracy: 0.8803, F1 Micro: 0.7865, F1 Macro: 0.79\n",
      "Epoch 9/10, Train Loss: 0.0652, Accuracy: 0.8849, F1 Micro: 0.7853, F1 Macro: 0.7872\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.882, F1 Micro: 0.784, F1 Macro: 0.7886\n",
      "Model 2 - Iteration 1469: Accuracy: 0.8836, F1 Micro: 0.788, F1 Macro: 0.791\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.87      0.90       308\n",
      "                sara       0.75      0.75      0.75       367\n",
      "         radikalisme       0.80      0.85      0.82       337\n",
      "pencemaran_nama_baik       0.70      0.67      0.68       330\n",
      "\n",
      "           micro avg       0.79      0.78      0.79      1342\n",
      "           macro avg       0.80      0.79      0.79      1342\n",
      "        weighted avg       0.79      0.78      0.79      1342\n",
      "         samples avg       0.60      0.59      0.58      1342\n",
      "\n",
      "Training completed in 71.76454663276672 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5585, Accuracy: 0.7917, F1 Micro: 0.5547, F1 Macro: 0.5249\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3947, Accuracy: 0.8433, F1 Micro: 0.6882, F1 Macro: 0.6796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3076, Accuracy: 0.8662, F1 Micro: 0.7493, F1 Macro: 0.7531\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2507, Accuracy: 0.8843, F1 Micro: 0.7875, F1 Macro: 0.7913\n",
      "Epoch 5/10, Train Loss: 0.2054, Accuracy: 0.8843, F1 Micro: 0.787, F1 Macro: 0.7878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1553, Accuracy: 0.8834, F1 Micro: 0.7921, F1 Macro: 0.7969\n",
      "Epoch 7/10, Train Loss: 0.1271, Accuracy: 0.8843, F1 Micro: 0.7796, F1 Macro: 0.7813\n",
      "Epoch 8/10, Train Loss: 0.1051, Accuracy: 0.881, F1 Micro: 0.7894, F1 Macro: 0.7944\n",
      "Epoch 9/10, Train Loss: 0.0742, Accuracy: 0.8824, F1 Micro: 0.788, F1 Macro: 0.7922\n",
      "Epoch 10/10, Train Loss: 0.0626, Accuracy: 0.8849, F1 Micro: 0.7876, F1 Macro: 0.7911\n",
      "Model 3 - Iteration 1469: Accuracy: 0.8834, F1 Micro: 0.7921, F1 Macro: 0.7969\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.87      0.90       308\n",
      "                sara       0.73      0.80      0.76       367\n",
      "         radikalisme       0.82      0.82      0.82       337\n",
      "pencemaran_nama_baik       0.67      0.73      0.70       330\n",
      "\n",
      "           micro avg       0.78      0.80      0.79      1342\n",
      "           macro avg       0.79      0.81      0.80      1342\n",
      "        weighted avg       0.79      0.80      0.79      1342\n",
      "         samples avg       0.60      0.60      0.59      1342\n",
      "\n",
      "Training completed in 69.78538870811462 s\n",
      "Averaged - Iteration 1469: Accuracy: 0.8675, F1 Micro: 0.7562, F1 Macro: 0.7586\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2899\n",
      "Acquired samples: 317\n",
      "Sampling duration: 53.262290954589844 seconds\n",
      "New train size: 1786\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5402, Accuracy: 0.8102, F1 Micro: 0.5806, F1 Macro: 0.5371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.369, Accuracy: 0.8674, F1 Micro: 0.7539, F1 Macro: 0.7574\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2793, Accuracy: 0.8795, F1 Micro: 0.7855, F1 Macro: 0.7907\n",
      "Epoch 4/10, Train Loss: 0.2342, Accuracy: 0.8828, F1 Micro: 0.7804, F1 Macro: 0.779\n",
      "Epoch 5/10, Train Loss: 0.1831, Accuracy: 0.8843, F1 Micro: 0.7844, F1 Macro: 0.7857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1491, Accuracy: 0.883, F1 Micro: 0.795, F1 Macro: 0.7994\n",
      "Epoch 7/10, Train Loss: 0.1177, Accuracy: 0.8834, F1 Micro: 0.7937, F1 Macro: 0.7989\n",
      "Epoch 8/10, Train Loss: 0.0786, Accuracy: 0.8832, F1 Micro: 0.7819, F1 Macro: 0.782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0659, Accuracy: 0.8867, F1 Micro: 0.7987, F1 Macro: 0.8029\n",
      "Epoch 10/10, Train Loss: 0.053, Accuracy: 0.8847, F1 Micro: 0.7931, F1 Macro: 0.7962\n",
      "Model 1 - Iteration 1786: Accuracy: 0.8867, F1 Micro: 0.7987, F1 Macro: 0.8029\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       308\n",
      "                sara       0.74      0.78      0.76       367\n",
      "         radikalisme       0.80      0.86      0.83       337\n",
      "pencemaran_nama_baik       0.68      0.72      0.70       330\n",
      "\n",
      "           micro avg       0.78      0.81      0.80      1342\n",
      "           macro avg       0.79      0.82      0.80      1342\n",
      "        weighted avg       0.79      0.81      0.80      1342\n",
      "         samples avg       0.62      0.62      0.60      1342\n",
      "\n",
      "Training completed in 78.29703044891357 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5181, Accuracy: 0.8137, F1 Micro: 0.5774, F1 Macro: 0.5229\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3564, Accuracy: 0.868, F1 Micro: 0.7622, F1 Macro: 0.7672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2729, Accuracy: 0.882, F1 Micro: 0.7941, F1 Macro: 0.7994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2238, Accuracy: 0.889, F1 Micro: 0.7947, F1 Macro: 0.797\n",
      "Epoch 5/10, Train Loss: 0.1751, Accuracy: 0.8838, F1 Micro: 0.7839, F1 Macro: 0.786\n",
      "Epoch 6/10, Train Loss: 0.1427, Accuracy: 0.8877, F1 Micro: 0.7908, F1 Macro: 0.7917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1066, Accuracy: 0.8892, F1 Micro: 0.8, F1 Macro: 0.804\n",
      "Epoch 8/10, Train Loss: 0.0734, Accuracy: 0.8869, F1 Micro: 0.791, F1 Macro: 0.7916\n",
      "Epoch 9/10, Train Loss: 0.0578, Accuracy: 0.8884, F1 Micro: 0.7981, F1 Macro: 0.8011\n",
      "Epoch 10/10, Train Loss: 0.0457, Accuracy: 0.889, F1 Micro: 0.7879, F1 Macro: 0.7883\n",
      "Model 2 - Iteration 1786: Accuracy: 0.8892, F1 Micro: 0.8, F1 Macro: 0.804\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.96      0.88      0.92       308\n",
      "                sara       0.77      0.76      0.76       367\n",
      "         radikalisme       0.80      0.87      0.83       337\n",
      "pencemaran_nama_baik       0.69      0.71      0.70       330\n",
      "\n",
      "           micro avg       0.80      0.80      0.80      1342\n",
      "           macro avg       0.80      0.81      0.80      1342\n",
      "        weighted avg       0.80      0.80      0.80      1342\n",
      "         samples avg       0.60      0.60      0.59      1342\n",
      "\n",
      "Training completed in 78.97877740859985 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5426, Accuracy: 0.8111, F1 Micro: 0.6068, F1 Macro: 0.5822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3653, Accuracy: 0.8627, F1 Micro: 0.7526, F1 Macro: 0.7557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2789, Accuracy: 0.8764, F1 Micro: 0.7854, F1 Macro: 0.7907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2337, Accuracy: 0.8863, F1 Micro: 0.7884, F1 Macro: 0.7889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1785, Accuracy: 0.8863, F1 Micro: 0.79, F1 Macro: 0.7917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1445, Accuracy: 0.8855, F1 Micro: 0.7999, F1 Macro: 0.8047\n",
      "Epoch 7/10, Train Loss: 0.1131, Accuracy: 0.8863, F1 Micro: 0.7922, F1 Macro: 0.796\n",
      "Epoch 8/10, Train Loss: 0.0779, Accuracy: 0.8845, F1 Micro: 0.7986, F1 Macro: 0.8033\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0618, Accuracy: 0.8845, F1 Micro: 0.8, F1 Macro: 0.805\n",
      "Epoch 10/10, Train Loss: 0.0497, Accuracy: 0.8847, F1 Micro: 0.7861, F1 Macro: 0.789\n",
      "Model 3 - Iteration 1786: Accuracy: 0.8845, F1 Micro: 0.8, F1 Macro: 0.805\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       308\n",
      "                sara       0.72      0.85      0.78       367\n",
      "         radikalisme       0.80      0.84      0.82       337\n",
      "pencemaran_nama_baik       0.66      0.77      0.71       330\n",
      "\n",
      "           micro avg       0.77      0.84      0.80      1342\n",
      "           macro avg       0.78      0.84      0.81      1342\n",
      "        weighted avg       0.77      0.84      0.80      1342\n",
      "         samples avg       0.62      0.63      0.61      1342\n",
      "\n",
      "Training completed in 82.61778473854065 s\n",
      "Averaged - Iteration 1786: Accuracy: 0.8713, F1 Micro: 0.7649, F1 Macro: 0.7677\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2899\n",
      "Acquired samples: 286\n",
      "Sampling duration: 48.775174140930176 seconds\n",
      "New train size: 2072\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5159, Accuracy: 0.8185, F1 Micro: 0.6182, F1 Macro: 0.5885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3439, Accuracy: 0.8678, F1 Micro: 0.7767, F1 Macro: 0.7842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2794, Accuracy: 0.8853, F1 Micro: 0.7944, F1 Macro: 0.7989\n",
      "Epoch 4/10, Train Loss: 0.2186, Accuracy: 0.8826, F1 Micro: 0.7938, F1 Macro: 0.7978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1821, Accuracy: 0.8888, F1 Micro: 0.8052, F1 Macro: 0.8099\n",
      "Epoch 6/10, Train Loss: 0.1425, Accuracy: 0.8824, F1 Micro: 0.8025, F1 Macro: 0.8088\n",
      "Epoch 7/10, Train Loss: 0.0957, Accuracy: 0.8873, F1 Micro: 0.8003, F1 Macro: 0.8022\n",
      "Epoch 8/10, Train Loss: 0.078, Accuracy: 0.8888, F1 Micro: 0.8049, F1 Macro: 0.8096\n",
      "Epoch 9/10, Train Loss: 0.06, Accuracy: 0.8869, F1 Micro: 0.7914, F1 Macro: 0.7941\n",
      "Epoch 10/10, Train Loss: 0.0515, Accuracy: 0.89, F1 Micro: 0.7996, F1 Macro: 0.8022\n",
      "Model 1 - Iteration 2072: Accuracy: 0.8888, F1 Micro: 0.8052, F1 Macro: 0.8099\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.96      0.88      0.92       308\n",
      "                sara       0.72      0.84      0.77       367\n",
      "         radikalisme       0.78      0.87      0.83       337\n",
      "pencemaran_nama_baik       0.70      0.75      0.72       330\n",
      "\n",
      "           micro avg       0.78      0.83      0.81      1342\n",
      "           macro avg       0.79      0.83      0.81      1342\n",
      "        weighted avg       0.79      0.83      0.81      1342\n",
      "         samples avg       0.61      0.62      0.60      1342\n",
      "\n",
      "Training completed in 85.20864987373352 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4979, Accuracy: 0.824, F1 Micro: 0.6294, F1 Macro: 0.6091\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3313, Accuracy: 0.8756, F1 Micro: 0.7857, F1 Macro: 0.7928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2646, Accuracy: 0.8888, F1 Micro: 0.7967, F1 Macro: 0.8002\n",
      "Epoch 4/10, Train Loss: 0.2078, Accuracy: 0.8867, F1 Micro: 0.7948, F1 Macro: 0.7961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1744, Accuracy: 0.8832, F1 Micro: 0.7983, F1 Macro: 0.8031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1281, Accuracy: 0.8867, F1 Micro: 0.8065, F1 Macro: 0.8123\n",
      "Epoch 7/10, Train Loss: 0.09, Accuracy: 0.8898, F1 Micro: 0.8042, F1 Macro: 0.8083\n",
      "Epoch 8/10, Train Loss: 0.0705, Accuracy: 0.8886, F1 Micro: 0.8033, F1 Macro: 0.8083\n",
      "Epoch 9/10, Train Loss: 0.0525, Accuracy: 0.8912, F1 Micro: 0.8022, F1 Macro: 0.805\n",
      "Epoch 10/10, Train Loss: 0.0464, Accuracy: 0.8892, F1 Micro: 0.8003, F1 Macro: 0.8037\n",
      "Model 2 - Iteration 2072: Accuracy: 0.8867, F1 Micro: 0.8065, F1 Macro: 0.8123\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.88      0.92       308\n",
      "                sara       0.70      0.87      0.77       367\n",
      "         radikalisme       0.79      0.89      0.84       337\n",
      "pencemaran_nama_baik       0.67      0.78      0.72       330\n",
      "\n",
      "           micro avg       0.76      0.86      0.81      1342\n",
      "           macro avg       0.78      0.86      0.81      1342\n",
      "        weighted avg       0.77      0.86      0.81      1342\n",
      "         samples avg       0.61      0.64      0.61      1342\n",
      "\n",
      "Training completed in 86.93058609962463 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5174, Accuracy: 0.8203, F1 Micro: 0.6193, F1 Macro: 0.597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.341, Accuracy: 0.8692, F1 Micro: 0.7733, F1 Macro: 0.7799\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2734, Accuracy: 0.8834, F1 Micro: 0.7882, F1 Macro: 0.7919\n",
      "Epoch 4/10, Train Loss: 0.2143, Accuracy: 0.8849, F1 Micro: 0.7856, F1 Macro: 0.7859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1745, Accuracy: 0.8836, F1 Micro: 0.7965, F1 Macro: 0.801\n",
      "Epoch 6/10, Train Loss: 0.1318, Accuracy: 0.8783, F1 Micro: 0.7953, F1 Macro: 0.8014\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0881, Accuracy: 0.8921, F1 Micro: 0.813, F1 Macro: 0.8183\n",
      "Epoch 8/10, Train Loss: 0.0718, Accuracy: 0.8869, F1 Micro: 0.7907, F1 Macro: 0.7937\n",
      "Epoch 9/10, Train Loss: 0.0548, Accuracy: 0.8884, F1 Micro: 0.7912, F1 Macro: 0.7925\n",
      "Epoch 10/10, Train Loss: 0.0452, Accuracy: 0.8882, F1 Micro: 0.7914, F1 Macro: 0.7914\n",
      "Model 3 - Iteration 2072: Accuracy: 0.8921, F1 Micro: 0.813, F1 Macro: 0.8183\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.91      0.92       308\n",
      "                sara       0.75      0.81      0.78       367\n",
      "         radikalisme       0.81      0.88      0.84       337\n",
      "pencemaran_nama_baik       0.66      0.80      0.73       330\n",
      "\n",
      "           micro avg       0.78      0.85      0.81      1342\n",
      "           macro avg       0.79      0.85      0.82      1342\n",
      "        weighted avg       0.79      0.85      0.82      1342\n",
      "         samples avg       0.62      0.64      0.62      1342\n",
      "\n",
      "Training completed in 86.63585591316223 s\n",
      "Averaged - Iteration 2072: Accuracy: 0.8743, F1 Micro: 0.7721, F1 Macro: 0.7753\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2899\n",
      "Acquired samples: 257\n",
      "Sampling duration: 43.857653856277466 seconds\n",
      "New train size: 2329\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5147, Accuracy: 0.8316, F1 Micro: 0.6563, F1 Macro: 0.6378\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3444, Accuracy: 0.8713, F1 Micro: 0.7645, F1 Macro: 0.7664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2517, Accuracy: 0.8769, F1 Micro: 0.7909, F1 Macro: 0.7971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2127, Accuracy: 0.8894, F1 Micro: 0.792, F1 Macro: 0.7932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1718, Accuracy: 0.8912, F1 Micro: 0.8063, F1 Macro: 0.8093\n",
      "Epoch 6/10, Train Loss: 0.1291, Accuracy: 0.8906, F1 Micro: 0.7977, F1 Macro: 0.8\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0941, Accuracy: 0.8869, F1 Micro: 0.8081, F1 Macro: 0.8139\n",
      "Epoch 8/10, Train Loss: 0.0719, Accuracy: 0.89, F1 Micro: 0.8071, F1 Macro: 0.8098\n",
      "Epoch 9/10, Train Loss: 0.0553, Accuracy: 0.8886, F1 Micro: 0.7909, F1 Macro: 0.7918\n",
      "Epoch 10/10, Train Loss: 0.041, Accuracy: 0.891, F1 Micro: 0.8059, F1 Macro: 0.8081\n",
      "Model 1 - Iteration 2329: Accuracy: 0.8869, F1 Micro: 0.8081, F1 Macro: 0.8139\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.89      0.92       308\n",
      "                sara       0.71      0.87      0.78       367\n",
      "         radikalisme       0.77      0.89      0.82       337\n",
      "pencemaran_nama_baik       0.67      0.80      0.73       330\n",
      "\n",
      "           micro avg       0.76      0.86      0.81      1342\n",
      "           macro avg       0.77      0.86      0.81      1342\n",
      "        weighted avg       0.77      0.86      0.81      1342\n",
      "         samples avg       0.62      0.64      0.61      1342\n",
      "\n",
      "Training completed in 95.22675895690918 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4959, Accuracy: 0.839, F1 Micro: 0.6752, F1 Macro: 0.6632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3291, Accuracy: 0.876, F1 Micro: 0.7751, F1 Macro: 0.7778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2419, Accuracy: 0.8855, F1 Micro: 0.8021, F1 Macro: 0.8076\n",
      "Epoch 4/10, Train Loss: 0.1964, Accuracy: 0.8884, F1 Micro: 0.7895, F1 Macro: 0.7907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.158, Accuracy: 0.889, F1 Micro: 0.8076, F1 Macro: 0.8114\n",
      "Epoch 6/10, Train Loss: 0.1168, Accuracy: 0.8935, F1 Micro: 0.8021, F1 Macro: 0.8046\n",
      "Epoch 7/10, Train Loss: 0.0845, Accuracy: 0.8828, F1 Micro: 0.8047, F1 Macro: 0.8113\n",
      "Epoch 8/10, Train Loss: 0.0659, Accuracy: 0.8884, F1 Micro: 0.8033, F1 Macro: 0.8058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0516, Accuracy: 0.8921, F1 Micro: 0.8085, F1 Macro: 0.8121\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0374, Accuracy: 0.8882, F1 Micro: 0.8089, F1 Macro: 0.814\n",
      "Model 2 - Iteration 2329: Accuracy: 0.8882, F1 Micro: 0.8089, F1 Macro: 0.814\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       308\n",
      "                sara       0.72      0.87      0.79       367\n",
      "         radikalisme       0.78      0.89      0.83       337\n",
      "pencemaran_nama_baik       0.66      0.78      0.72       330\n",
      "\n",
      "           micro avg       0.77      0.86      0.81      1342\n",
      "           macro avg       0.78      0.86      0.81      1342\n",
      "        weighted avg       0.77      0.86      0.81      1342\n",
      "         samples avg       0.62      0.64      0.61      1342\n",
      "\n",
      "Training completed in 94.60717988014221 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5222, Accuracy: 0.8287, F1 Micro: 0.6525, F1 Macro: 0.6312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.343, Accuracy: 0.8773, F1 Micro: 0.7781, F1 Macro: 0.7805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2481, Accuracy: 0.8808, F1 Micro: 0.7963, F1 Macro: 0.8026\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2088, Accuracy: 0.8912, F1 Micro: 0.8006, F1 Macro: 0.8007\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1761, Accuracy: 0.8931, F1 Micro: 0.8052, F1 Macro: 0.8061\n",
      "Epoch 6/10, Train Loss: 0.1292, Accuracy: 0.8888, F1 Micro: 0.7931, F1 Macro: 0.7947\n",
      "Epoch 7/10, Train Loss: 0.0897, Accuracy: 0.8851, F1 Micro: 0.8043, F1 Macro: 0.8107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0706, Accuracy: 0.8902, F1 Micro: 0.8068, F1 Macro: 0.8099\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.053, Accuracy: 0.8949, F1 Micro: 0.8085, F1 Macro: 0.8109\n",
      "Epoch 10/10, Train Loss: 0.0418, Accuracy: 0.8882, F1 Micro: 0.804, F1 Macro: 0.8081\n",
      "Model 3 - Iteration 2329: Accuracy: 0.8949, F1 Micro: 0.8085, F1 Macro: 0.8109\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.89      0.92       308\n",
      "                sara       0.77      0.78      0.78       367\n",
      "         radikalisme       0.81      0.87      0.84       337\n",
      "pencemaran_nama_baik       0.73      0.68      0.71       330\n",
      "\n",
      "           micro avg       0.81      0.80      0.81      1342\n",
      "           macro avg       0.82      0.81      0.81      1342\n",
      "        weighted avg       0.81      0.80      0.81      1342\n",
      "         samples avg       0.62      0.61      0.60      1342\n",
      "\n",
      "Training completed in 96.42257356643677 s\n",
      "Averaged - Iteration 2329: Accuracy: 0.8766, F1 Micro: 0.7773, F1 Macro: 0.7807\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2899\n",
      "Acquired samples: 231\n",
      "Sampling duration: 40.05952477455139 seconds\n",
      "New train size: 2560\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4912, Accuracy: 0.8308, F1 Micro: 0.6796, F1 Macro: 0.6609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3203, Accuracy: 0.874, F1 Micro: 0.7555, F1 Macro: 0.7538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2574, Accuracy: 0.8865, F1 Micro: 0.8049, F1 Macro: 0.8106\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2206, Accuracy: 0.8919, F1 Micro: 0.8068, F1 Macro: 0.8097\n",
      "Epoch 5/10, Train Loss: 0.1701, Accuracy: 0.8904, F1 Micro: 0.8045, F1 Macro: 0.8087\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1325, Accuracy: 0.8937, F1 Micro: 0.8082, F1 Macro: 0.8123\n",
      "Epoch 7/10, Train Loss: 0.0949, Accuracy: 0.8929, F1 Micro: 0.8077, F1 Macro: 0.8081\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0681, Accuracy: 0.8888, F1 Micro: 0.8089, F1 Macro: 0.8137\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0564, Accuracy: 0.8914, F1 Micro: 0.8109, F1 Macro: 0.8158\n",
      "Epoch 10/10, Train Loss: 0.0419, Accuracy: 0.8933, F1 Micro: 0.8087, F1 Macro: 0.811\n",
      "Model 1 - Iteration 2560: Accuracy: 0.8914, F1 Micro: 0.8109, F1 Macro: 0.8158\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.90      0.92       308\n",
      "                sara       0.76      0.82      0.79       367\n",
      "         radikalisme       0.78      0.88      0.83       337\n",
      "pencemaran_nama_baik       0.67      0.79      0.73       330\n",
      "\n",
      "           micro avg       0.78      0.84      0.81      1342\n",
      "           macro avg       0.79      0.84      0.82      1342\n",
      "        weighted avg       0.79      0.84      0.81      1342\n",
      "         samples avg       0.62      0.63      0.61      1342\n",
      "\n",
      "Training completed in 101.29005575180054 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.467, Accuracy: 0.845, F1 Micro: 0.7029, F1 Macro: 0.6927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3084, Accuracy: 0.8785, F1 Micro: 0.7757, F1 Macro: 0.7783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2498, Accuracy: 0.8855, F1 Micro: 0.795, F1 Macro: 0.7997\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2069, Accuracy: 0.8912, F1 Micro: 0.811, F1 Macro: 0.8152\n",
      "Epoch 5/10, Train Loss: 0.1564, Accuracy: 0.8931, F1 Micro: 0.8058, F1 Macro: 0.8097\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1187, Accuracy: 0.8951, F1 Micro: 0.8122, F1 Macro: 0.817\n",
      "Epoch 7/10, Train Loss: 0.0861, Accuracy: 0.89, F1 Micro: 0.8071, F1 Macro: 0.8091\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0621, Accuracy: 0.8933, F1 Micro: 0.8164, F1 Macro: 0.8213\n",
      "Epoch 9/10, Train Loss: 0.0557, Accuracy: 0.8917, F1 Micro: 0.8066, F1 Macro: 0.8106\n",
      "Epoch 10/10, Train Loss: 0.0388, Accuracy: 0.8925, F1 Micro: 0.8086, F1 Macro: 0.8128\n",
      "Model 2 - Iteration 2560: Accuracy: 0.8933, F1 Micro: 0.8164, F1 Macro: 0.8213\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.96      0.90      0.93       308\n",
      "                sara       0.75      0.88      0.81       367\n",
      "         radikalisme       0.79      0.87      0.83       337\n",
      "pencemaran_nama_baik       0.67      0.79      0.72       330\n",
      "\n",
      "           micro avg       0.78      0.86      0.82      1342\n",
      "           macro avg       0.79      0.86      0.82      1342\n",
      "        weighted avg       0.79      0.86      0.82      1342\n",
      "         samples avg       0.63      0.64      0.62      1342\n",
      "\n",
      "Training completed in 100.03529620170593 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4894, Accuracy: 0.845, F1 Micro: 0.7107, F1 Macro: 0.7112\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3174, Accuracy: 0.8752, F1 Micro: 0.7588, F1 Macro: 0.758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2548, Accuracy: 0.8845, F1 Micro: 0.7999, F1 Macro: 0.8053\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.213, Accuracy: 0.8902, F1 Micro: 0.8078, F1 Macro: 0.8128\n",
      "Epoch 5/10, Train Loss: 0.1683, Accuracy: 0.8941, F1 Micro: 0.8054, F1 Macro: 0.8079\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.124, Accuracy: 0.8919, F1 Micro: 0.8129, F1 Macro: 0.8168\n",
      "Epoch 7/10, Train Loss: 0.0935, Accuracy: 0.8933, F1 Micro: 0.8084, F1 Macro: 0.8094\n",
      "Epoch 8/10, Train Loss: 0.0632, Accuracy: 0.8917, F1 Micro: 0.8101, F1 Macro: 0.8134\n",
      "Epoch 9/10, Train Loss: 0.0504, Accuracy: 0.8912, F1 Micro: 0.8047, F1 Macro: 0.806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0392, Accuracy: 0.8945, F1 Micro: 0.8147, F1 Macro: 0.8187\n",
      "Model 3 - Iteration 2560: Accuracy: 0.8945, F1 Micro: 0.8147, F1 Macro: 0.8187\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.92      0.93       308\n",
      "                sara       0.77      0.82      0.79       367\n",
      "         radikalisme       0.79      0.88      0.83       337\n",
      "pencemaran_nama_baik       0.69      0.75      0.72       330\n",
      "\n",
      "           micro avg       0.79      0.84      0.81      1342\n",
      "           macro avg       0.80      0.84      0.82      1342\n",
      "        weighted avg       0.79      0.84      0.82      1342\n",
      "         samples avg       0.63      0.63      0.62      1342\n",
      "\n",
      "Training completed in 99.58327269554138 s\n",
      "Averaged - Iteration 2560: Accuracy: 0.8786, F1 Micro: 0.7819, F1 Macro: 0.7854\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2899\n",
      "Acquired samples: 208\n",
      "Sampling duration: 35.84345984458923 seconds\n",
      "New train size: 2768\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4834, Accuracy: 0.8483, F1 Micro: 0.6938, F1 Macro: 0.6861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3216, Accuracy: 0.8795, F1 Micro: 0.7857, F1 Macro: 0.7909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2486, Accuracy: 0.889, F1 Micro: 0.7996, F1 Macro: 0.802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.204, Accuracy: 0.8951, F1 Micro: 0.8065, F1 Macro: 0.8085\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1566, Accuracy: 0.8964, F1 Micro: 0.8121, F1 Macro: 0.8148\n",
      "Epoch 6/10, Train Loss: 0.1178, Accuracy: 0.8949, F1 Micro: 0.8087, F1 Macro: 0.812\n",
      "Epoch 7/10, Train Loss: 0.0865, Accuracy: 0.8927, F1 Micro: 0.8051, F1 Macro: 0.8084\n",
      "Epoch 8/10, Train Loss: 0.0674, Accuracy: 0.891, F1 Micro: 0.8037, F1 Macro: 0.8064\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0514, Accuracy: 0.8964, F1 Micro: 0.8144, F1 Macro: 0.8177\n",
      "Epoch 10/10, Train Loss: 0.0378, Accuracy: 0.8968, F1 Micro: 0.8109, F1 Macro: 0.8137\n",
      "Model 1 - Iteration 2768: Accuracy: 0.8964, F1 Micro: 0.8144, F1 Macro: 0.8177\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.90      0.92       308\n",
      "                sara       0.79      0.78      0.79       367\n",
      "         radikalisme       0.80      0.88      0.84       337\n",
      "pencemaran_nama_baik       0.70      0.75      0.72       330\n",
      "\n",
      "           micro avg       0.80      0.82      0.81      1342\n",
      "           macro avg       0.81      0.83      0.82      1342\n",
      "        weighted avg       0.81      0.82      0.82      1342\n",
      "         samples avg       0.61      0.61      0.60      1342\n",
      "\n",
      "Training completed in 106.2536940574646 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4701, Accuracy: 0.8501, F1 Micro: 0.7142, F1 Macro: 0.7133\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3128, Accuracy: 0.8865, F1 Micro: 0.798, F1 Macro: 0.8038\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2387, Accuracy: 0.8921, F1 Micro: 0.8062, F1 Macro: 0.808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.196, Accuracy: 0.8943, F1 Micro: 0.8113, F1 Macro: 0.8143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1503, Accuracy: 0.8974, F1 Micro: 0.8161, F1 Macro: 0.8199\n",
      "Epoch 6/10, Train Loss: 0.1091, Accuracy: 0.8935, F1 Micro: 0.8112, F1 Macro: 0.8148\n",
      "Epoch 7/10, Train Loss: 0.0804, Accuracy: 0.8933, F1 Micro: 0.8066, F1 Macro: 0.8095\n",
      "Epoch 8/10, Train Loss: 0.0593, Accuracy: 0.8954, F1 Micro: 0.8133, F1 Macro: 0.8159\n",
      "Epoch 9/10, Train Loss: 0.0485, Accuracy: 0.896, F1 Micro: 0.8133, F1 Macro: 0.8166\n",
      "Epoch 10/10, Train Loss: 0.0334, Accuracy: 0.8919, F1 Micro: 0.8018, F1 Macro: 0.8044\n",
      "Model 2 - Iteration 2768: Accuracy: 0.8974, F1 Micro: 0.8161, F1 Macro: 0.8199\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.96      0.89      0.92       308\n",
      "                sara       0.79      0.79      0.79       367\n",
      "         radikalisme       0.81      0.88      0.84       337\n",
      "pencemaran_nama_baik       0.70      0.75      0.73       330\n",
      "\n",
      "           micro avg       0.81      0.82      0.82      1342\n",
      "           macro avg       0.82      0.83      0.82      1342\n",
      "        weighted avg       0.81      0.82      0.82      1342\n",
      "         samples avg       0.62      0.62      0.61      1342\n",
      "\n",
      "Training completed in 105.53050589561462 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4916, Accuracy: 0.8493, F1 Micro: 0.7067, F1 Macro: 0.7043\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3214, Accuracy: 0.8803, F1 Micro: 0.7854, F1 Macro: 0.7893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2461, Accuracy: 0.8892, F1 Micro: 0.8049, F1 Macro: 0.808\n",
      "Epoch 4/10, Train Loss: 0.1967, Accuracy: 0.8927, F1 Micro: 0.8045, F1 Macro: 0.8067\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1541, Accuracy: 0.8923, F1 Micro: 0.8093, F1 Macro: 0.8138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1142, Accuracy: 0.8947, F1 Micro: 0.8127, F1 Macro: 0.8158\n",
      "Epoch 7/10, Train Loss: 0.0822, Accuracy: 0.8939, F1 Micro: 0.8082, F1 Macro: 0.811\n",
      "Epoch 8/10, Train Loss: 0.068, Accuracy: 0.8886, F1 Micro: 0.8086, F1 Macro: 0.8118\n",
      "Epoch 9/10, Train Loss: 0.0495, Accuracy: 0.8947, F1 Micro: 0.8064, F1 Macro: 0.808\n",
      "Epoch 10/10, Train Loss: 0.0364, Accuracy: 0.8962, F1 Micro: 0.8106, F1 Macro: 0.8137\n",
      "Model 3 - Iteration 2768: Accuracy: 0.8947, F1 Micro: 0.8127, F1 Macro: 0.8158\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.90      0.92       308\n",
      "                sara       0.76      0.82      0.79       367\n",
      "         radikalisme       0.81      0.88      0.84       337\n",
      "pencemaran_nama_baik       0.71      0.72      0.71       330\n",
      "\n",
      "           micro avg       0.80      0.83      0.81      1342\n",
      "           macro avg       0.80      0.83      0.82      1342\n",
      "        weighted avg       0.80      0.83      0.81      1342\n",
      "         samples avg       0.62      0.62      0.60      1342\n",
      "\n",
      "Training completed in 104.8983998298645 s\n",
      "Averaged - Iteration 2768: Accuracy: 0.8806, F1 Micro: 0.7855, F1 Macro: 0.789\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2899\n",
      "Acquired samples: 131\n",
      "Sampling duration: 36.680651903152466 seconds\n",
      "New train size: 2899\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4851, Accuracy: 0.8538, F1 Micro: 0.7381, F1 Macro: 0.746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3039, Accuracy: 0.8861, F1 Micro: 0.7941, F1 Macro: 0.7983\n",
      "Epoch 3/10, Train Loss: 0.2307, Accuracy: 0.889, F1 Micro: 0.7897, F1 Macro: 0.7874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1935, Accuracy: 0.8917, F1 Micro: 0.805, F1 Macro: 0.8089\n",
      "Epoch 5/10, Train Loss: 0.143, Accuracy: 0.8958, F1 Micro: 0.8043, F1 Macro: 0.8053\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1127, Accuracy: 0.8917, F1 Micro: 0.8093, F1 Macro: 0.8131\n",
      "Epoch 7/10, Train Loss: 0.0828, Accuracy: 0.8943, F1 Micro: 0.8053, F1 Macro: 0.8061\n",
      "Epoch 8/10, Train Loss: 0.0647, Accuracy: 0.8923, F1 Micro: 0.8032, F1 Macro: 0.8069\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0498, Accuracy: 0.8966, F1 Micro: 0.8136, F1 Macro: 0.8169\n",
      "Epoch 10/10, Train Loss: 0.0389, Accuracy: 0.8958, F1 Micro: 0.8109, F1 Macro: 0.8143\n",
      "Model 1 - Iteration 2899: Accuracy: 0.8966, F1 Micro: 0.8136, F1 Macro: 0.8169\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.89      0.91       308\n",
      "                sara       0.77      0.81      0.79       367\n",
      "         radikalisme       0.83      0.82      0.83       337\n",
      "pencemaran_nama_baik       0.73      0.75      0.74       330\n",
      "\n",
      "           micro avg       0.81      0.82      0.81      1342\n",
      "           macro avg       0.81      0.82      0.82      1342\n",
      "        weighted avg       0.81      0.82      0.81      1342\n",
      "         samples avg       0.62      0.61      0.60      1342\n",
      "\n",
      "Training completed in 108.33710861206055 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4749, Accuracy: 0.8637, F1 Micro: 0.7497, F1 Macro: 0.7552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2982, Accuracy: 0.8863, F1 Micro: 0.7972, F1 Macro: 0.8019\n",
      "Epoch 3/10, Train Loss: 0.2238, Accuracy: 0.8902, F1 Micro: 0.7932, F1 Macro: 0.7918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1838, Accuracy: 0.8949, F1 Micro: 0.8065, F1 Macro: 0.8099\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1352, Accuracy: 0.8986, F1 Micro: 0.8204, F1 Macro: 0.8226\n",
      "Epoch 6/10, Train Loss: 0.1029, Accuracy: 0.898, F1 Micro: 0.8141, F1 Macro: 0.816\n",
      "Epoch 7/10, Train Loss: 0.0754, Accuracy: 0.8968, F1 Micro: 0.8149, F1 Macro: 0.8172\n",
      "Epoch 8/10, Train Loss: 0.0531, Accuracy: 0.8935, F1 Micro: 0.8094, F1 Macro: 0.8137\n",
      "Epoch 9/10, Train Loss: 0.0438, Accuracy: 0.8949, F1 Micro: 0.8163, F1 Macro: 0.8199\n",
      "Epoch 10/10, Train Loss: 0.0348, Accuracy: 0.8902, F1 Micro: 0.8076, F1 Macro: 0.8129\n",
      "Model 2 - Iteration 2899: Accuracy: 0.8986, F1 Micro: 0.8204, F1 Macro: 0.8226\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       308\n",
      "                sara       0.76      0.84      0.80       367\n",
      "         radikalisme       0.81      0.89      0.85       337\n",
      "pencemaran_nama_baik       0.73      0.73      0.73       330\n",
      "\n",
      "           micro avg       0.80      0.84      0.82      1342\n",
      "           macro avg       0.81      0.84      0.82      1342\n",
      "        weighted avg       0.80      0.84      0.82      1342\n",
      "         samples avg       0.62      0.63      0.61      1342\n",
      "\n",
      "Training completed in 107.77772951126099 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4943, Accuracy: 0.8528, F1 Micro: 0.7354, F1 Macro: 0.7409\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3041, Accuracy: 0.8865, F1 Micro: 0.7972, F1 Macro: 0.8013\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2308, Accuracy: 0.8914, F1 Micro: 0.7989, F1 Macro: 0.7993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1902, Accuracy: 0.8933, F1 Micro: 0.809, F1 Macro: 0.8128\n",
      "Epoch 5/10, Train Loss: 0.1448, Accuracy: 0.8935, F1 Micro: 0.8021, F1 Macro: 0.8029\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.108, Accuracy: 0.8956, F1 Micro: 0.8135, F1 Macro: 0.8162\n",
      "Epoch 7/10, Train Loss: 0.0801, Accuracy: 0.89, F1 Micro: 0.7988, F1 Macro: 0.8005\n",
      "Epoch 8/10, Train Loss: 0.0618, Accuracy: 0.8937, F1 Micro: 0.8089, F1 Macro: 0.8116\n",
      "Epoch 9/10, Train Loss: 0.0461, Accuracy: 0.8949, F1 Micro: 0.8064, F1 Macro: 0.809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0377, Accuracy: 0.8951, F1 Micro: 0.8197, F1 Macro: 0.8253\n",
      "Model 3 - Iteration 2899: Accuracy: 0.8951, F1 Micro: 0.8197, F1 Macro: 0.8253\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.91      0.93       308\n",
      "                sara       0.76      0.86      0.81       367\n",
      "         radikalisme       0.82      0.87      0.84       337\n",
      "pencemaran_nama_baik       0.65      0.82      0.73       330\n",
      "\n",
      "           micro avg       0.78      0.86      0.82      1342\n",
      "           macro avg       0.79      0.86      0.83      1342\n",
      "        weighted avg       0.79      0.86      0.82      1342\n",
      "         samples avg       0.63      0.64      0.62      1342\n",
      "\n",
      "Training completed in 111.05909442901611 s\n",
      "Averaged - Iteration 2899: Accuracy: 0.8822, F1 Micro: 0.7887, F1 Macro: 0.7923\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 3478\n",
      "Acquired samples: 200\n",
      "Sampling duration: 30.391098976135254 seconds\n",
      "New train size: 3099\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4753, Accuracy: 0.8551, F1 Micro: 0.7223, F1 Macro: 0.7244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3132, Accuracy: 0.883, F1 Micro: 0.7954, F1 Macro: 0.8008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2408, Accuracy: 0.889, F1 Micro: 0.8041, F1 Macro: 0.8087\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1938, Accuracy: 0.8943, F1 Micro: 0.8092, F1 Macro: 0.8129\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1483, Accuracy: 0.8949, F1 Micro: 0.8115, F1 Macro: 0.815\n",
      "Epoch 6/10, Train Loss: 0.1081, Accuracy: 0.8964, F1 Micro: 0.8111, F1 Macro: 0.8139\n",
      "Epoch 7/10, Train Loss: 0.0762, Accuracy: 0.8966, F1 Micro: 0.8104, F1 Macro: 0.8132\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0637, Accuracy: 0.8968, F1 Micro: 0.8171, F1 Macro: 0.8192\n",
      "Epoch 9/10, Train Loss: 0.049, Accuracy: 0.8968, F1 Micro: 0.8106, F1 Macro: 0.8144\n",
      "Epoch 10/10, Train Loss: 0.0332, Accuracy: 0.8951, F1 Micro: 0.8128, F1 Macro: 0.8159\n",
      "Model 1 - Iteration 3099: Accuracy: 0.8968, F1 Micro: 0.8171, F1 Macro: 0.8192\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.96      0.89      0.92       308\n",
      "                sara       0.74      0.85      0.79       367\n",
      "         radikalisme       0.79      0.91      0.85       337\n",
      "pencemaran_nama_baik       0.74      0.69      0.71       330\n",
      "\n",
      "           micro avg       0.80      0.84      0.82      1342\n",
      "           macro avg       0.81      0.84      0.82      1342\n",
      "        weighted avg       0.80      0.84      0.82      1342\n",
      "         samples avg       0.63      0.62      0.61      1342\n",
      "\n",
      "Training completed in 114.8670654296875 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4691, Accuracy: 0.8583, F1 Micro: 0.7293, F1 Macro: 0.7308\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3058, Accuracy: 0.8838, F1 Micro: 0.7939, F1 Macro: 0.7985\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2318, Accuracy: 0.8933, F1 Micro: 0.8071, F1 Macro: 0.8114\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1826, Accuracy: 0.8947, F1 Micro: 0.8099, F1 Macro: 0.8126\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1427, Accuracy: 0.8945, F1 Micro: 0.8139, F1 Macro: 0.8188\n",
      "Epoch 6/10, Train Loss: 0.1031, Accuracy: 0.8954, F1 Micro: 0.8091, F1 Macro: 0.8113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0753, Accuracy: 0.9007, F1 Micro: 0.8166, F1 Macro: 0.8193\n",
      "Epoch 8/10, Train Loss: 0.06, Accuracy: 0.8949, F1 Micro: 0.8155, F1 Macro: 0.8192\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.043, Accuracy: 0.8995, F1 Micro: 0.8169, F1 Macro: 0.8203\n",
      "Epoch 10/10, Train Loss: 0.03, Accuracy: 0.8966, F1 Micro: 0.8091, F1 Macro: 0.8127\n",
      "Model 2 - Iteration 3099: Accuracy: 0.8995, F1 Micro: 0.8169, F1 Macro: 0.8203\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.97      0.88      0.93       308\n",
      "                sara       0.78      0.81      0.80       367\n",
      "         radikalisme       0.84      0.84      0.84       337\n",
      "pencemaran_nama_baik       0.72      0.72      0.72       330\n",
      "\n",
      "           micro avg       0.82      0.81      0.82      1342\n",
      "           macro avg       0.83      0.81      0.82      1342\n",
      "        weighted avg       0.82      0.81      0.82      1342\n",
      "         samples avg       0.62      0.61      0.60      1342\n",
      "\n",
      "Training completed in 117.25940108299255 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4849, Accuracy: 0.8538, F1 Micro: 0.7243, F1 Macro: 0.7254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3123, Accuracy: 0.8832, F1 Micro: 0.7948, F1 Macro: 0.7996\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2382, Accuracy: 0.8933, F1 Micro: 0.8118, F1 Macro: 0.8162\n",
      "Epoch 4/10, Train Loss: 0.184, Accuracy: 0.8931, F1 Micro: 0.8071, F1 Macro: 0.8104\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1471, Accuracy: 0.8939, F1 Micro: 0.8134, F1 Macro: 0.8166\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1066, Accuracy: 0.8988, F1 Micro: 0.8159, F1 Macro: 0.8171\n",
      "Epoch 7/10, Train Loss: 0.0778, Accuracy: 0.8968, F1 Micro: 0.8138, F1 Macro: 0.8161\n",
      "Epoch 8/10, Train Loss: 0.0622, Accuracy: 0.8958, F1 Micro: 0.8157, F1 Macro: 0.819\n",
      "Epoch 9/10, Train Loss: 0.0484, Accuracy: 0.8986, F1 Micro: 0.8146, F1 Macro: 0.8171\n",
      "Epoch 10/10, Train Loss: 0.0348, Accuracy: 0.8937, F1 Micro: 0.813, F1 Macro: 0.8174\n",
      "Model 3 - Iteration 3099: Accuracy: 0.8988, F1 Micro: 0.8159, F1 Macro: 0.8171\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       308\n",
      "                sara       0.78      0.80      0.79       367\n",
      "         radikalisme       0.82      0.88      0.85       337\n",
      "pencemaran_nama_baik       0.75      0.68      0.71       330\n",
      "\n",
      "           micro avg       0.82      0.81      0.82      1342\n",
      "           macro avg       0.82      0.81      0.82      1342\n",
      "        weighted avg       0.82      0.81      0.81      1342\n",
      "         samples avg       0.61      0.61      0.59      1342\n",
      "\n",
      "Training completed in 113.8384964466095 s\n",
      "Averaged - Iteration 3099: Accuracy: 0.8837, F1 Micro: 0.7913, F1 Macro: 0.7947\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 3478\n",
      "Acquired samples: 200\n",
      "Sampling duration: 26.561655521392822 seconds\n",
      "New train size: 3299\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4686, Accuracy: 0.8633, F1 Micro: 0.7445, F1 Macro: 0.7482\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2958, Accuracy: 0.8789, F1 Micro: 0.7569, F1 Macro: 0.7517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.242, Accuracy: 0.891, F1 Micro: 0.803, F1 Macro: 0.8057\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1916, Accuracy: 0.8921, F1 Micro: 0.8033, F1 Macro: 0.8048\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1419, Accuracy: 0.8964, F1 Micro: 0.8081, F1 Macro: 0.8103\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1115, Accuracy: 0.8964, F1 Micro: 0.8197, F1 Macro: 0.8252\n",
      "Epoch 7/10, Train Loss: 0.0813, Accuracy: 0.8984, F1 Micro: 0.8188, F1 Macro: 0.8218\n",
      "Epoch 8/10, Train Loss: 0.0587, Accuracy: 0.8978, F1 Micro: 0.815, F1 Macro: 0.8178\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0466, Accuracy: 0.8993, F1 Micro: 0.8225, F1 Macro: 0.8268\n",
      "Epoch 10/10, Train Loss: 0.0359, Accuracy: 0.8966, F1 Micro: 0.8189, F1 Macro: 0.8232\n",
      "Model 1 - Iteration 3299: Accuracy: 0.8993, F1 Micro: 0.8225, F1 Macro: 0.8268\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.91      0.93       308\n",
      "                sara       0.78      0.82      0.80       367\n",
      "         radikalisme       0.82      0.87      0.84       337\n",
      "pencemaran_nama_baik       0.69      0.79      0.74       330\n",
      "\n",
      "           micro avg       0.80      0.85      0.82      1342\n",
      "           macro avg       0.81      0.85      0.83      1342\n",
      "        weighted avg       0.81      0.85      0.82      1342\n",
      "         samples avg       0.62      0.63      0.61      1342\n",
      "\n",
      "Training completed in 121.74457216262817 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4556, Accuracy: 0.867, F1 Micro: 0.7535, F1 Macro: 0.7579\n",
      "Epoch 2/10, Train Loss: 0.2867, Accuracy: 0.8756, F1 Micro: 0.7433, F1 Macro: 0.7346\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2339, Accuracy: 0.8954, F1 Micro: 0.8096, F1 Macro: 0.8133\n",
      "Epoch 4/10, Train Loss: 0.186, Accuracy: 0.8925, F1 Micro: 0.8029, F1 Macro: 0.8037\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1371, Accuracy: 0.8984, F1 Micro: 0.8116, F1 Macro: 0.8129\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1027, Accuracy: 0.9017, F1 Micro: 0.8279, F1 Macro: 0.8319\n",
      "Epoch 7/10, Train Loss: 0.0734, Accuracy: 0.8966, F1 Micro: 0.8221, F1 Macro: 0.8264\n",
      "Epoch 8/10, Train Loss: 0.0586, Accuracy: 0.8982, F1 Micro: 0.8205, F1 Macro: 0.8235\n",
      "Epoch 9/10, Train Loss: 0.0462, Accuracy: 0.898, F1 Micro: 0.8215, F1 Macro: 0.8252\n",
      "Epoch 10/10, Train Loss: 0.0351, Accuracy: 0.897, F1 Micro: 0.8185, F1 Macro: 0.8221\n",
      "Model 2 - Iteration 3299: Accuracy: 0.9017, F1 Micro: 0.8279, F1 Macro: 0.8319\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.96      0.89      0.92       308\n",
      "                sara       0.76      0.86      0.81       367\n",
      "         radikalisme       0.81      0.88      0.84       337\n",
      "pencemaran_nama_baik       0.72      0.79      0.75       330\n",
      "\n",
      "           micro avg       0.80      0.86      0.83      1342\n",
      "           macro avg       0.81      0.86      0.83      1342\n",
      "        weighted avg       0.81      0.86      0.83      1342\n",
      "         samples avg       0.63      0.64      0.62      1342\n",
      "\n",
      "Training completed in 116.43981146812439 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4773, Accuracy: 0.8573, F1 Micro: 0.7343, F1 Macro: 0.7357\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2934, Accuracy: 0.8769, F1 Micro: 0.7495, F1 Macro: 0.7452\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2395, Accuracy: 0.8947, F1 Micro: 0.8087, F1 Macro: 0.8114\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1896, Accuracy: 0.8958, F1 Micro: 0.812, F1 Macro: 0.814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1402, Accuracy: 0.8991, F1 Micro: 0.8166, F1 Macro: 0.8183\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1074, Accuracy: 0.8945, F1 Micro: 0.8214, F1 Macro: 0.8268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0781, Accuracy: 0.9007, F1 Micro: 0.8218, F1 Macro: 0.8249\n",
      "Epoch 8/10, Train Loss: 0.0589, Accuracy: 0.8993, F1 Micro: 0.8173, F1 Macro: 0.82\n",
      "Epoch 9/10, Train Loss: 0.0445, Accuracy: 0.8988, F1 Micro: 0.8191, F1 Macro: 0.8224\n",
      "Epoch 10/10, Train Loss: 0.0347, Accuracy: 0.8956, F1 Micro: 0.819, F1 Macro: 0.8233\n",
      "Model 3 - Iteration 3299: Accuracy: 0.9007, F1 Micro: 0.8218, F1 Macro: 0.8249\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.96      0.89      0.92       308\n",
      "                sara       0.76      0.86      0.81       367\n",
      "         radikalisme       0.82      0.85      0.83       337\n",
      "pencemaran_nama_baik       0.74      0.73      0.74       330\n",
      "\n",
      "           micro avg       0.81      0.83      0.82      1342\n",
      "           macro avg       0.82      0.83      0.82      1342\n",
      "        weighted avg       0.82      0.83      0.82      1342\n",
      "         samples avg       0.63      0.62      0.61      1342\n",
      "\n",
      "Training completed in 122.05372667312622 s\n",
      "Averaged - Iteration 3299: Accuracy: 0.8851, F1 Micro: 0.794, F1 Macro: 0.7975\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 3478\n",
      "Acquired samples: 179\n",
      "Sampling duration: 23.911150217056274 seconds\n",
      "New train size: 3478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4559, Accuracy: 0.8546, F1 Micro: 0.7077, F1 Macro: 0.7016\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2978, Accuracy: 0.8859, F1 Micro: 0.7966, F1 Macro: 0.8012\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2314, Accuracy: 0.8919, F1 Micro: 0.7968, F1 Macro: 0.7982\n",
      "Epoch 4/10, Train Loss: 0.1851, Accuracy: 0.8919, F1 Micro: 0.7904, F1 Macro: 0.789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1498, Accuracy: 0.9001, F1 Micro: 0.8151, F1 Macro: 0.8169\n",
      "Epoch 6/10, Train Loss: 0.1142, Accuracy: 0.8993, F1 Micro: 0.8099, F1 Macro: 0.8105\n",
      "Epoch 7/10, Train Loss: 0.086, Accuracy: 0.8991, F1 Micro: 0.8119, F1 Macro: 0.8138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0629, Accuracy: 0.8984, F1 Micro: 0.8204, F1 Macro: 0.8225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0447, Accuracy: 0.9036, F1 Micro: 0.8279, F1 Macro: 0.8312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0347, Accuracy: 0.9052, F1 Micro: 0.8335, F1 Macro: 0.8367\n",
      "Model 1 - Iteration 3478: Accuracy: 0.9052, F1 Micro: 0.8335, F1 Macro: 0.8367\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.91      0.93       308\n",
      "                sara       0.77      0.89      0.82       367\n",
      "         radikalisme       0.83      0.86      0.85       337\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       330\n",
      "\n",
      "           micro avg       0.81      0.86      0.83      1342\n",
      "           macro avg       0.82      0.86      0.84      1342\n",
      "        weighted avg       0.81      0.86      0.83      1342\n",
      "         samples avg       0.63      0.64      0.62      1342\n",
      "\n",
      "Training completed in 128.43549036979675 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4424, Accuracy: 0.8602, F1 Micro: 0.728, F1 Macro: 0.7269\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.288, Accuracy: 0.8867, F1 Micro: 0.7943, F1 Macro: 0.7991\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2242, Accuracy: 0.8919, F1 Micro: 0.7972, F1 Macro: 0.7987\n",
      "Epoch 4/10, Train Loss: 0.179, Accuracy: 0.8931, F1 Micro: 0.7915, F1 Macro: 0.79\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1437, Accuracy: 0.8978, F1 Micro: 0.8079, F1 Macro: 0.8091\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1088, Accuracy: 0.9034, F1 Micro: 0.8229, F1 Macro: 0.8249\n",
      "Epoch 7/10, Train Loss: 0.076, Accuracy: 0.8999, F1 Micro: 0.8163, F1 Macro: 0.8188\n",
      "Epoch 8/10, Train Loss: 0.0596, Accuracy: 0.8943, F1 Micro: 0.8102, F1 Macro: 0.8113\n",
      "Epoch 9/10, Train Loss: 0.0452, Accuracy: 0.9001, F1 Micro: 0.8167, F1 Macro: 0.8193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0346, Accuracy: 0.9032, F1 Micro: 0.8282, F1 Macro: 0.8315\n",
      "Model 2 - Iteration 3478: Accuracy: 0.9032, F1 Micro: 0.8282, F1 Macro: 0.8315\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.91      0.93       308\n",
      "                sara       0.78      0.85      0.81       367\n",
      "         radikalisme       0.83      0.87      0.85       337\n",
      "pencemaran_nama_baik       0.71      0.76      0.74       330\n",
      "\n",
      "           micro avg       0.81      0.85      0.83      1342\n",
      "           macro avg       0.82      0.85      0.83      1342\n",
      "        weighted avg       0.82      0.85      0.83      1342\n",
      "         samples avg       0.63      0.63      0.62      1342\n",
      "\n",
      "Training completed in 125.57839059829712 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4627, Accuracy: 0.8485, F1 Micro: 0.6971, F1 Macro: 0.6948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2961, Accuracy: 0.8849, F1 Micro: 0.7903, F1 Macro: 0.7941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.231, Accuracy: 0.8892, F1 Micro: 0.7967, F1 Macro: 0.7982\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1868, Accuracy: 0.8945, F1 Micro: 0.8011, F1 Macro: 0.8011\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1499, Accuracy: 0.9001, F1 Micro: 0.8125, F1 Macro: 0.8136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1148, Accuracy: 0.8976, F1 Micro: 0.8173, F1 Macro: 0.8206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0797, Accuracy: 0.9009, F1 Micro: 0.8193, F1 Macro: 0.8217\n",
      "Epoch 8/10, Train Loss: 0.0619, Accuracy: 0.8972, F1 Micro: 0.818, F1 Macro: 0.8204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0437, Accuracy: 0.8997, F1 Micro: 0.8195, F1 Macro: 0.8224\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0341, Accuracy: 0.903, F1 Micro: 0.8271, F1 Macro: 0.8305\n",
      "Model 3 - Iteration 3478: Accuracy: 0.903, F1 Micro: 0.8271, F1 Macro: 0.8305\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.96      0.91      0.93       308\n",
      "                sara       0.76      0.87      0.81       367\n",
      "         radikalisme       0.83      0.85      0.84       337\n",
      "pencemaran_nama_baik       0.73      0.75      0.74       330\n",
      "\n",
      "           micro avg       0.81      0.84      0.83      1342\n",
      "           macro avg       0.82      0.84      0.83      1342\n",
      "        weighted avg       0.82      0.84      0.83      1342\n",
      "         samples avg       0.63      0.63      0.62      1342\n",
      "\n",
      "Training completed in 132.43856620788574 s\n",
      "Averaged - Iteration 3478: Accuracy: 0.8865, F1 Micro: 0.7967, F1 Macro: 0.8002\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 4058\n",
      "Acquired samples: 200\n",
      "Sampling duration: 20.704350233078003 seconds\n",
      "New train size: 3678\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4609, Accuracy: 0.8657, F1 Micro: 0.7555, F1 Macro: 0.7592\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2913, Accuracy: 0.89, F1 Micro: 0.797, F1 Macro: 0.7992\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2357, Accuracy: 0.8863, F1 Micro: 0.8052, F1 Macro: 0.8122\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1847, Accuracy: 0.8988, F1 Micro: 0.8203, F1 Macro: 0.8249\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.152, Accuracy: 0.8995, F1 Micro: 0.8225, F1 Macro: 0.8251\n",
      "Epoch 6/10, Train Loss: 0.1086, Accuracy: 0.9009, F1 Micro: 0.8133, F1 Macro: 0.8135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0777, Accuracy: 0.9042, F1 Micro: 0.8275, F1 Macro: 0.8306\n",
      "Epoch 8/10, Train Loss: 0.0569, Accuracy: 0.9001, F1 Micro: 0.8254, F1 Macro: 0.828\n",
      "Epoch 9/10, Train Loss: 0.0477, Accuracy: 0.9007, F1 Micro: 0.8249, F1 Macro: 0.8287\n",
      "Epoch 10/10, Train Loss: 0.0355, Accuracy: 0.8997, F1 Micro: 0.8202, F1 Macro: 0.8228\n",
      "Model 1 - Iteration 3678: Accuracy: 0.9042, F1 Micro: 0.8275, F1 Macro: 0.8306\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.89      0.92       308\n",
      "                sara       0.79      0.83      0.81       367\n",
      "         radikalisme       0.84      0.86      0.85       337\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       330\n",
      "\n",
      "           micro avg       0.82      0.83      0.83      1342\n",
      "           macro avg       0.83      0.83      0.83      1342\n",
      "        weighted avg       0.82      0.83      0.83      1342\n",
      "         samples avg       0.62      0.62      0.61      1342\n",
      "\n",
      "Training completed in 131.17245769500732 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4435, Accuracy: 0.867, F1 Micro: 0.7667, F1 Macro: 0.7726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2833, Accuracy: 0.8927, F1 Micro: 0.803, F1 Macro: 0.806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.222, Accuracy: 0.8923, F1 Micro: 0.8143, F1 Macro: 0.8214\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1755, Accuracy: 0.9005, F1 Micro: 0.8186, F1 Macro: 0.8215\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1364, Accuracy: 0.8976, F1 Micro: 0.8205, F1 Macro: 0.8224\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0996, Accuracy: 0.9009, F1 Micro: 0.821, F1 Macro: 0.8241\n",
      "Epoch 7/10, Train Loss: 0.0718, Accuracy: 0.8974, F1 Micro: 0.8176, F1 Macro: 0.8222\n",
      "Epoch 8/10, Train Loss: 0.0563, Accuracy: 0.8984, F1 Micro: 0.8188, F1 Macro: 0.8209\n",
      "Epoch 9/10, Train Loss: 0.0435, Accuracy: 0.8982, F1 Micro: 0.8114, F1 Macro: 0.8139\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0334, Accuracy: 0.8978, F1 Micro: 0.8246, F1 Macro: 0.8301\n",
      "Model 2 - Iteration 3678: Accuracy: 0.8978, F1 Micro: 0.8246, F1 Macro: 0.8301\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       308\n",
      "                sara       0.76      0.85      0.80       367\n",
      "         radikalisme       0.83      0.89      0.86       337\n",
      "pencemaran_nama_baik       0.65      0.84      0.74       330\n",
      "\n",
      "           micro avg       0.78      0.87      0.82      1342\n",
      "           macro avg       0.80      0.87      0.83      1342\n",
      "        weighted avg       0.79      0.87      0.83      1342\n",
      "         samples avg       0.63      0.65      0.63      1342\n",
      "\n",
      "Training completed in 132.57487678527832 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4668, Accuracy: 0.8612, F1 Micro: 0.7516, F1 Macro: 0.7553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2915, Accuracy: 0.89, F1 Micro: 0.7977, F1 Macro: 0.8004\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2324, Accuracy: 0.8937, F1 Micro: 0.8166, F1 Macro: 0.8227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1803, Accuracy: 0.8999, F1 Micro: 0.8193, F1 Macro: 0.8231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1406, Accuracy: 0.8984, F1 Micro: 0.8204, F1 Macro: 0.8229\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1034, Accuracy: 0.8997, F1 Micro: 0.8207, F1 Macro: 0.8244\n",
      "Epoch 7/10, Train Loss: 0.0733, Accuracy: 0.8984, F1 Micro: 0.82, F1 Macro: 0.8244\n",
      "Epoch 8/10, Train Loss: 0.0525, Accuracy: 0.8978, F1 Micro: 0.8191, F1 Macro: 0.821\n",
      "Epoch 9/10, Train Loss: 0.0487, Accuracy: 0.8986, F1 Micro: 0.8125, F1 Macro: 0.8158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0334, Accuracy: 0.8986, F1 Micro: 0.8212, F1 Macro: 0.824\n",
      "Model 3 - Iteration 3678: Accuracy: 0.8986, F1 Micro: 0.8212, F1 Macro: 0.824\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.92      0.91       308\n",
      "                sara       0.79      0.80      0.80       367\n",
      "         radikalisme       0.82      0.88      0.85       337\n",
      "pencemaran_nama_baik       0.71      0.78      0.74       330\n",
      "\n",
      "           micro avg       0.80      0.84      0.82      1342\n",
      "           macro avg       0.80      0.85      0.82      1342\n",
      "        weighted avg       0.80      0.84      0.82      1342\n",
      "         samples avg       0.63      0.63      0.62      1342\n",
      "\n",
      "Training completed in 132.81248879432678 s\n",
      "Averaged - Iteration 3678: Accuracy: 0.8875, F1 Micro: 0.7987, F1 Macro: 0.8022\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 4058\n",
      "Acquired samples: 200\n",
      "Sampling duration: 16.960635662078857 seconds\n",
      "New train size: 3878\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.447, Accuracy: 0.8641, F1 Micro: 0.7657, F1 Macro: 0.7728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2787, Accuracy: 0.8863, F1 Micro: 0.7874, F1 Macro: 0.7904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2286, Accuracy: 0.8923, F1 Micro: 0.8104, F1 Macro: 0.8138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.182, Accuracy: 0.8939, F1 Micro: 0.8162, F1 Macro: 0.821\n",
      "Epoch 5/10, Train Loss: 0.1515, Accuracy: 0.8962, F1 Micro: 0.8147, F1 Macro: 0.8193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1108, Accuracy: 0.8982, F1 Micro: 0.8182, F1 Macro: 0.822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0757, Accuracy: 0.9017, F1 Micro: 0.8219, F1 Macro: 0.8241\n",
      "Epoch 8/10, Train Loss: 0.0572, Accuracy: 0.8974, F1 Micro: 0.8176, F1 Macro: 0.8216\n",
      "Epoch 9/10, Train Loss: 0.0437, Accuracy: 0.8978, F1 Micro: 0.8176, F1 Macro: 0.8194\n",
      "Epoch 10/10, Train Loss: 0.0341, Accuracy: 0.8976, F1 Micro: 0.819, F1 Macro: 0.8209\n",
      "Model 1 - Iteration 3878: Accuracy: 0.9017, F1 Micro: 0.8219, F1 Macro: 0.8241\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.96      0.90      0.93       308\n",
      "                sara       0.80      0.81      0.81       367\n",
      "         radikalisme       0.81      0.88      0.85       337\n",
      "pencemaran_nama_baik       0.73      0.70      0.71       330\n",
      "\n",
      "           micro avg       0.82      0.82      0.82      1342\n",
      "           macro avg       0.83      0.82      0.82      1342\n",
      "        weighted avg       0.82      0.82      0.82      1342\n",
      "         samples avg       0.63      0.62      0.61      1342\n",
      "\n",
      "Training completed in 135.673819065094 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4389, Accuracy: 0.869, F1 Micro: 0.7747, F1 Macro: 0.7809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2738, Accuracy: 0.8914, F1 Micro: 0.8006, F1 Macro: 0.8053\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2194, Accuracy: 0.8993, F1 Micro: 0.8199, F1 Macro: 0.8235\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1715, Accuracy: 0.9009, F1 Micro: 0.8232, F1 Macro: 0.8267\n",
      "Epoch 5/10, Train Loss: 0.1412, Accuracy: 0.8997, F1 Micro: 0.8214, F1 Macro: 0.8256\n",
      "Epoch 6/10, Train Loss: 0.0996, Accuracy: 0.9003, F1 Micro: 0.8179, F1 Macro: 0.8205\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0725, Accuracy: 0.9011, F1 Micro: 0.8254, F1 Macro: 0.8282\n",
      "Epoch 8/10, Train Loss: 0.0491, Accuracy: 0.8999, F1 Micro: 0.8214, F1 Macro: 0.8252\n",
      "Epoch 9/10, Train Loss: 0.0406, Accuracy: 0.8999, F1 Micro: 0.8246, F1 Macro: 0.8288\n",
      "Epoch 10/10, Train Loss: 0.034, Accuracy: 0.8982, F1 Micro: 0.8199, F1 Macro: 0.8243\n",
      "Model 2 - Iteration 3878: Accuracy: 0.9011, F1 Micro: 0.8254, F1 Macro: 0.8282\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.91      0.92       308\n",
      "                sara       0.77      0.85      0.81       367\n",
      "         radikalisme       0.80      0.88      0.84       337\n",
      "pencemaran_nama_baik       0.73      0.75      0.74       330\n",
      "\n",
      "           micro avg       0.80      0.85      0.83      1342\n",
      "           macro avg       0.81      0.85      0.83      1342\n",
      "        weighted avg       0.81      0.85      0.83      1342\n",
      "         samples avg       0.63      0.63      0.62      1342\n",
      "\n",
      "Training completed in 133.63592219352722 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4525, Accuracy: 0.862, F1 Micro: 0.7623, F1 Macro: 0.7679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2784, Accuracy: 0.8865, F1 Micro: 0.7922, F1 Macro: 0.7962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2254, Accuracy: 0.8931, F1 Micro: 0.8087, F1 Macro: 0.8117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1777, Accuracy: 0.9017, F1 Micro: 0.8253, F1 Macro: 0.8286\n",
      "Epoch 5/10, Train Loss: 0.1481, Accuracy: 0.8999, F1 Micro: 0.8205, F1 Macro: 0.8248\n",
      "Epoch 6/10, Train Loss: 0.1047, Accuracy: 0.9007, F1 Micro: 0.8213, F1 Macro: 0.8248\n",
      "Epoch 7/10, Train Loss: 0.0754, Accuracy: 0.9019, F1 Micro: 0.8239, F1 Macro: 0.8264\n",
      "Epoch 8/10, Train Loss: 0.0582, Accuracy: 0.9007, F1 Micro: 0.8237, F1 Macro: 0.8266\n",
      "Epoch 9/10, Train Loss: 0.041, Accuracy: 0.8974, F1 Micro: 0.8178, F1 Macro: 0.8207\n",
      "Epoch 10/10, Train Loss: 0.0342, Accuracy: 0.8995, F1 Micro: 0.8187, F1 Macro: 0.8215\n",
      "Model 3 - Iteration 3878: Accuracy: 0.9017, F1 Micro: 0.8253, F1 Macro: 0.8286\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       308\n",
      "                sara       0.80      0.80      0.80       367\n",
      "         radikalisme       0.83      0.86      0.85       337\n",
      "pencemaran_nama_baik       0.71      0.79      0.75       330\n",
      "\n",
      "           micro avg       0.81      0.84      0.83      1342\n",
      "           macro avg       0.81      0.84      0.83      1342\n",
      "        weighted avg       0.81      0.84      0.83      1342\n",
      "         samples avg       0.62      0.63      0.61      1342\n",
      "\n",
      "Training completed in 132.02046585083008 s\n",
      "Averaged - Iteration 3878: Accuracy: 0.8884, F1 Micro: 0.8004, F1 Macro: 0.8038\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 4058\n",
      "Acquired samples: 180\n",
      "Sampling duration: 13.398937702178955 seconds\n",
      "New train size: 4058\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4431, Accuracy: 0.8684, F1 Micro: 0.7519, F1 Macro: 0.7548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2721, Accuracy: 0.8949, F1 Micro: 0.8025, F1 Macro: 0.8045\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2253, Accuracy: 0.8898, F1 Micro: 0.8102, F1 Macro: 0.8153\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1718, Accuracy: 0.9007, F1 Micro: 0.8182, F1 Macro: 0.8221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1394, Accuracy: 0.8988, F1 Micro: 0.8215, F1 Macro: 0.8239\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.097, Accuracy: 0.9009, F1 Micro: 0.8227, F1 Macro: 0.8276\n",
      "Epoch 7/10, Train Loss: 0.0714, Accuracy: 0.8966, F1 Micro: 0.8214, F1 Macro: 0.8275\n",
      "Epoch 8/10, Train Loss: 0.0523, Accuracy: 0.8995, F1 Micro: 0.8222, F1 Macro: 0.8253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0403, Accuracy: 0.9032, F1 Micro: 0.8242, F1 Macro: 0.8261\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0361, Accuracy: 0.9044, F1 Micro: 0.8302, F1 Macro: 0.8337\n",
      "Model 1 - Iteration 4058: Accuracy: 0.9044, F1 Micro: 0.8302, F1 Macro: 0.8337\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.91      0.93       308\n",
      "                sara       0.78      0.84      0.81       367\n",
      "         radikalisme       0.84      0.86      0.85       337\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       330\n",
      "\n",
      "           micro avg       0.81      0.85      0.83      1342\n",
      "           macro avg       0.82      0.85      0.83      1342\n",
      "        weighted avg       0.82      0.85      0.83      1342\n",
      "         samples avg       0.63      0.63      0.62      1342\n",
      "\n",
      "Training completed in 144.6223509311676 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4261, Accuracy: 0.8746, F1 Micro: 0.7702, F1 Macro: 0.7748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2665, Accuracy: 0.8927, F1 Micro: 0.7975, F1 Macro: 0.8002\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2195, Accuracy: 0.8921, F1 Micro: 0.8127, F1 Macro: 0.8172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1684, Accuracy: 0.9021, F1 Micro: 0.8251, F1 Macro: 0.8283\n",
      "Epoch 5/10, Train Loss: 0.1348, Accuracy: 0.8974, F1 Micro: 0.8193, F1 Macro: 0.822\n",
      "Epoch 6/10, Train Loss: 0.0907, Accuracy: 0.8999, F1 Micro: 0.8148, F1 Macro: 0.8185\n",
      "Epoch 7/10, Train Loss: 0.0656, Accuracy: 0.8984, F1 Micro: 0.8249, F1 Macro: 0.8301\n",
      "Epoch 8/10, Train Loss: 0.0518, Accuracy: 0.9011, F1 Micro: 0.8194, F1 Macro: 0.8215\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.038, Accuracy: 0.9025, F1 Micro: 0.8256, F1 Macro: 0.8287\n",
      "Epoch 10/10, Train Loss: 0.0344, Accuracy: 0.9007, F1 Micro: 0.8239, F1 Macro: 0.828\n",
      "Model 2 - Iteration 4058: Accuracy: 0.9025, F1 Micro: 0.8256, F1 Macro: 0.8287\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.91      0.92       308\n",
      "                sara       0.81      0.80      0.80       367\n",
      "         radikalisme       0.82      0.88      0.85       337\n",
      "pencemaran_nama_baik       0.71      0.77      0.74       330\n",
      "\n",
      "           micro avg       0.82      0.84      0.83      1342\n",
      "           macro avg       0.82      0.84      0.83      1342\n",
      "        weighted avg       0.82      0.84      0.83      1342\n",
      "         samples avg       0.63      0.63      0.62      1342\n",
      "\n",
      "Training completed in 140.4100785255432 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.444, Accuracy: 0.8694, F1 Micro: 0.7624, F1 Macro: 0.7669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2721, Accuracy: 0.8939, F1 Micro: 0.8041, F1 Macro: 0.8068\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2222, Accuracy: 0.8914, F1 Micro: 0.8121, F1 Macro: 0.8164\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1679, Accuracy: 0.9015, F1 Micro: 0.8237, F1 Macro: 0.8278\n",
      "Epoch 5/10, Train Loss: 0.132, Accuracy: 0.8991, F1 Micro: 0.822, F1 Macro: 0.8246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0926, Accuracy: 0.906, F1 Micro: 0.8279, F1 Macro: 0.8308\n",
      "Epoch 7/10, Train Loss: 0.0679, Accuracy: 0.9005, F1 Micro: 0.8226, F1 Macro: 0.826\n",
      "Epoch 8/10, Train Loss: 0.0513, Accuracy: 0.8988, F1 Micro: 0.8214, F1 Macro: 0.825\n",
      "Epoch 9/10, Train Loss: 0.0371, Accuracy: 0.8995, F1 Micro: 0.8202, F1 Macro: 0.8233\n",
      "Epoch 10/10, Train Loss: 0.0321, Accuracy: 0.9034, F1 Micro: 0.8267, F1 Macro: 0.8294\n",
      "Model 3 - Iteration 4058: Accuracy: 0.906, F1 Micro: 0.8279, F1 Macro: 0.8308\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.96      0.90      0.93       308\n",
      "                sara       0.81      0.80      0.80       367\n",
      "         radikalisme       0.85      0.84      0.85       337\n",
      "pencemaran_nama_baik       0.75      0.74      0.74       330\n",
      "\n",
      "           micro avg       0.84      0.82      0.83      1342\n",
      "           macro avg       0.84      0.82      0.83      1342\n",
      "        weighted avg       0.84      0.82      0.83      1342\n",
      "         samples avg       0.61      0.61      0.60      1342\n",
      "\n",
      "Training completed in 138.81656074523926 s\n",
      "Averaged - Iteration 4058: Accuracy: 0.8894, F1 Micro: 0.8021, F1 Macro: 0.8055\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 4638\n",
      "Acquired samples: 200\n",
      "Sampling duration: 10.464521408081055 seconds\n",
      "New train size: 4258\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4312, Accuracy: 0.869, F1 Micro: 0.7495, F1 Macro: 0.7528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2809, Accuracy: 0.8882, F1 Micro: 0.799, F1 Macro: 0.8029\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2193, Accuracy: 0.8914, F1 Micro: 0.8088, F1 Macro: 0.8126\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1799, Accuracy: 0.8978, F1 Micro: 0.8168, F1 Macro: 0.8191\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.138, Accuracy: 0.9005, F1 Micro: 0.8219, F1 Macro: 0.8256\n",
      "Epoch 6/10, Train Loss: 0.1025, Accuracy: 0.8991, F1 Micro: 0.8174, F1 Macro: 0.8209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0739, Accuracy: 0.8982, F1 Micro: 0.8237, F1 Macro: 0.8278\n",
      "Epoch 8/10, Train Loss: 0.0535, Accuracy: 0.903, F1 Micro: 0.8234, F1 Macro: 0.8269\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0388, Accuracy: 0.9023, F1 Micro: 0.8253, F1 Macro: 0.8284\n",
      "Epoch 10/10, Train Loss: 0.0325, Accuracy: 0.8982, F1 Micro: 0.8201, F1 Macro: 0.8235\n",
      "Model 1 - Iteration 4258: Accuracy: 0.9023, F1 Micro: 0.8253, F1 Macro: 0.8284\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.91      0.93       308\n",
      "                sara       0.80      0.79      0.80       367\n",
      "         radikalisme       0.80      0.88      0.84       337\n",
      "pencemaran_nama_baik       0.73      0.77      0.75       330\n",
      "\n",
      "           micro avg       0.81      0.84      0.83      1342\n",
      "           macro avg       0.82      0.84      0.83      1342\n",
      "        weighted avg       0.82      0.84      0.83      1342\n",
      "         samples avg       0.62      0.63      0.61      1342\n",
      "\n",
      "Training completed in 147.08922266960144 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4125, Accuracy: 0.8771, F1 Micro: 0.7726, F1 Macro: 0.776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2704, Accuracy: 0.8925, F1 Micro: 0.8043, F1 Macro: 0.809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2111, Accuracy: 0.8956, F1 Micro: 0.8143, F1 Macro: 0.8184\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1774, Accuracy: 0.9003, F1 Micro: 0.8234, F1 Macro: 0.8267\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.133, Accuracy: 0.9005, F1 Micro: 0.828, F1 Macro: 0.833\n",
      "Epoch 6/10, Train Loss: 0.0927, Accuracy: 0.8995, F1 Micro: 0.8221, F1 Macro: 0.8256\n",
      "Epoch 7/10, Train Loss: 0.0685, Accuracy: 0.9011, F1 Micro: 0.8246, F1 Macro: 0.8274\n",
      "Epoch 8/10, Train Loss: 0.0482, Accuracy: 0.8986, F1 Micro: 0.8254, F1 Macro: 0.8296\n",
      "Epoch 9/10, Train Loss: 0.0376, Accuracy: 0.9005, F1 Micro: 0.8237, F1 Macro: 0.8271\n",
      "Epoch 10/10, Train Loss: 0.0283, Accuracy: 0.896, F1 Micro: 0.8173, F1 Macro: 0.8215\n",
      "Model 2 - Iteration 4258: Accuracy: 0.9005, F1 Micro: 0.828, F1 Macro: 0.833\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.97      0.89      0.93       308\n",
      "                sara       0.73      0.88      0.80       367\n",
      "         radikalisme       0.81      0.90      0.85       337\n",
      "pencemaran_nama_baik       0.70      0.80      0.75       330\n",
      "\n",
      "           micro avg       0.79      0.87      0.83      1342\n",
      "           macro avg       0.80      0.87      0.83      1342\n",
      "        weighted avg       0.80      0.87      0.83      1342\n",
      "         samples avg       0.63      0.65      0.63      1342\n",
      "\n",
      "Training completed in 144.34506034851074 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4273, Accuracy: 0.8676, F1 Micro: 0.7471, F1 Macro: 0.7491\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2806, Accuracy: 0.8902, F1 Micro: 0.8032, F1 Macro: 0.8071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2167, Accuracy: 0.8935, F1 Micro: 0.812, F1 Macro: 0.8171\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1791, Accuracy: 0.898, F1 Micro: 0.8141, F1 Macro: 0.8161\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1331, Accuracy: 0.9023, F1 Micro: 0.8285, F1 Macro: 0.8326\n",
      "Epoch 6/10, Train Loss: 0.0986, Accuracy: 0.8984, F1 Micro: 0.8226, F1 Macro: 0.8272\n",
      "Epoch 7/10, Train Loss: 0.0663, Accuracy: 0.8995, F1 Micro: 0.8188, F1 Macro: 0.8203\n",
      "Epoch 8/10, Train Loss: 0.0492, Accuracy: 0.8984, F1 Micro: 0.8148, F1 Macro: 0.8178\n",
      "Epoch 9/10, Train Loss: 0.0361, Accuracy: 0.9003, F1 Micro: 0.8204, F1 Macro: 0.8231\n",
      "Epoch 10/10, Train Loss: 0.0324, Accuracy: 0.8991, F1 Micro: 0.8183, F1 Macro: 0.8203\n",
      "Model 3 - Iteration 4258: Accuracy: 0.9023, F1 Micro: 0.8285, F1 Macro: 0.8326\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.96      0.91      0.93       308\n",
      "                sara       0.75      0.86      0.80       367\n",
      "         radikalisme       0.82      0.88      0.85       337\n",
      "pencemaran_nama_baik       0.72      0.77      0.75       330\n",
      "\n",
      "           micro avg       0.80      0.85      0.83      1342\n",
      "           macro avg       0.81      0.86      0.83      1342\n",
      "        weighted avg       0.81      0.85      0.83      1342\n",
      "         samples avg       0.63      0.64      0.62      1342\n",
      "\n",
      "Training completed in 145.0322334766388 s\n",
      "Averaged - Iteration 4258: Accuracy: 0.8901, F1 Micro: 0.8036, F1 Macro: 0.8071\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 4638\n",
      "Acquired samples: 200\n",
      "Sampling duration: 7.178351402282715 seconds\n",
      "New train size: 4458\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4214, Accuracy: 0.8721, F1 Micro: 0.7578, F1 Macro: 0.7594\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2672, Accuracy: 0.8898, F1 Micro: 0.8035, F1 Macro: 0.808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2123, Accuracy: 0.8974, F1 Micro: 0.8128, F1 Macro: 0.8153\n",
      "Epoch 4/10, Train Loss: 0.1696, Accuracy: 0.8972, F1 Micro: 0.8107, F1 Macro: 0.8124\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1223, Accuracy: 0.9001, F1 Micro: 0.8192, F1 Macro: 0.8221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0912, Accuracy: 0.8986, F1 Micro: 0.8249, F1 Macro: 0.829\n",
      "Epoch 7/10, Train Loss: 0.0658, Accuracy: 0.8974, F1 Micro: 0.8093, F1 Macro: 0.812\n",
      "Epoch 8/10, Train Loss: 0.0534, Accuracy: 0.9003, F1 Micro: 0.8243, F1 Macro: 0.8297\n",
      "Epoch 9/10, Train Loss: 0.0383, Accuracy: 0.8978, F1 Micro: 0.8214, F1 Macro: 0.8241\n",
      "Epoch 10/10, Train Loss: 0.0328, Accuracy: 0.9011, F1 Micro: 0.8245, F1 Macro: 0.829\n",
      "Model 1 - Iteration 4458: Accuracy: 0.8986, F1 Micro: 0.8249, F1 Macro: 0.829\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.91       308\n",
      "                sara       0.79      0.83      0.81       367\n",
      "         radikalisme       0.82      0.88      0.85       337\n",
      "pencemaran_nama_baik       0.67      0.84      0.75       330\n",
      "\n",
      "           micro avg       0.79      0.87      0.82      1342\n",
      "           macro avg       0.80      0.87      0.83      1342\n",
      "        weighted avg       0.79      0.87      0.83      1342\n",
      "         samples avg       0.62      0.64      0.62      1342\n",
      "\n",
      "Training completed in 149.38358354568481 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.405, Accuracy: 0.874, F1 Micro: 0.7649, F1 Macro: 0.7677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2597, Accuracy: 0.89, F1 Micro: 0.8021, F1 Macro: 0.8066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2063, Accuracy: 0.8991, F1 Micro: 0.8112, F1 Macro: 0.8127\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1628, Accuracy: 0.898, F1 Micro: 0.8145, F1 Macro: 0.8182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1115, Accuracy: 0.8995, F1 Micro: 0.8204, F1 Macro: 0.8246\n",
      "Epoch 6/10, Train Loss: 0.0871, Accuracy: 0.8904, F1 Micro: 0.8159, F1 Macro: 0.8225\n",
      "Epoch 7/10, Train Loss: 0.0631, Accuracy: 0.8999, F1 Micro: 0.8189, F1 Macro: 0.8201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0521, Accuracy: 0.9005, F1 Micro: 0.8236, F1 Macro: 0.8282\n",
      "Epoch 9/10, Train Loss: 0.0365, Accuracy: 0.9013, F1 Micro: 0.8225, F1 Macro: 0.8251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0264, Accuracy: 0.8999, F1 Micro: 0.8253, F1 Macro: 0.8295\n",
      "Model 2 - Iteration 4458: Accuracy: 0.8999, F1 Micro: 0.8253, F1 Macro: 0.8295\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.92      0.93       308\n",
      "                sara       0.75      0.86      0.80       367\n",
      "         radikalisme       0.83      0.88      0.85       337\n",
      "pencemaran_nama_baik       0.70      0.78      0.74       330\n",
      "\n",
      "           micro avg       0.80      0.86      0.83      1342\n",
      "           macro avg       0.80      0.86      0.83      1342\n",
      "        weighted avg       0.80      0.86      0.83      1342\n",
      "         samples avg       0.63      0.64      0.62      1342\n",
      "\n",
      "Training completed in 152.51763200759888 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4235, Accuracy: 0.867, F1 Micro: 0.7456, F1 Macro: 0.7474\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2654, Accuracy: 0.8921, F1 Micro: 0.7983, F1 Macro: 0.8013\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2085, Accuracy: 0.8964, F1 Micro: 0.805, F1 Macro: 0.8059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1669, Accuracy: 0.8929, F1 Micro: 0.8067, F1 Macro: 0.8095\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1177, Accuracy: 0.9003, F1 Micro: 0.8186, F1 Macro: 0.8218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0886, Accuracy: 0.8995, F1 Micro: 0.8238, F1 Macro: 0.8281\n",
      "Epoch 7/10, Train Loss: 0.0635, Accuracy: 0.8966, F1 Micro: 0.8108, F1 Macro: 0.8125\n",
      "Epoch 8/10, Train Loss: 0.0469, Accuracy: 0.898, F1 Micro: 0.8217, F1 Macro: 0.826\n",
      "Epoch 9/10, Train Loss: 0.0368, Accuracy: 0.9036, F1 Micro: 0.8221, F1 Macro: 0.8234\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0304, Accuracy: 0.9001, F1 Micro: 0.8256, F1 Macro: 0.8298\n",
      "Model 3 - Iteration 4458: Accuracy: 0.9001, F1 Micro: 0.8256, F1 Macro: 0.8298\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.92      0.93       308\n",
      "                sara       0.77      0.84      0.81       367\n",
      "         radikalisme       0.80      0.87      0.84       337\n",
      "pencemaran_nama_baik       0.70      0.81      0.75       330\n",
      "\n",
      "           micro avg       0.80      0.86      0.83      1342\n",
      "           macro avg       0.80      0.86      0.83      1342\n",
      "        weighted avg       0.80      0.86      0.83      1342\n",
      "         samples avg       0.62      0.64      0.62      1342\n",
      "\n",
      "Training completed in 152.95259261131287 s\n",
      "Averaged - Iteration 4458: Accuracy: 0.8907, F1 Micro: 0.8048, F1 Macro: 0.8083\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 4638\n",
      "Acquired samples: 180\n",
      "Sampling duration: 3.737186908721924 seconds\n",
      "New train size: 4638\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4162, Accuracy: 0.874, F1 Micro: 0.7557, F1 Macro: 0.7567\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.255, Accuracy: 0.8931, F1 Micro: 0.8015, F1 Macro: 0.8053\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2041, Accuracy: 0.9003, F1 Micro: 0.815, F1 Macro: 0.8183\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1644, Accuracy: 0.898, F1 Micro: 0.8211, F1 Macro: 0.8249\n",
      "Epoch 5/10, Train Loss: 0.1277, Accuracy: 0.8949, F1 Micro: 0.8174, F1 Macro: 0.8237\n",
      "Epoch 6/10, Train Loss: 0.0886, Accuracy: 0.8974, F1 Micro: 0.8193, F1 Macro: 0.8245\n",
      "Epoch 7/10, Train Loss: 0.0644, Accuracy: 0.8978, F1 Micro: 0.8209, F1 Macro: 0.8241\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.051, Accuracy: 0.8966, F1 Micro: 0.8221, F1 Macro: 0.8264\n",
      "Epoch 9/10, Train Loss: 0.0366, Accuracy: 0.8986, F1 Micro: 0.8088, F1 Macro: 0.809\n",
      "Epoch 10/10, Train Loss: 0.0276, Accuracy: 0.9003, F1 Micro: 0.8216, F1 Macro: 0.8248\n",
      "Model 1 - Iteration 4638: Accuracy: 0.8966, F1 Micro: 0.8221, F1 Macro: 0.8264\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       308\n",
      "                sara       0.74      0.87      0.80       367\n",
      "         radikalisme       0.82      0.89      0.86       337\n",
      "pencemaran_nama_baik       0.67      0.79      0.73       330\n",
      "\n",
      "           micro avg       0.78      0.87      0.82      1342\n",
      "           macro avg       0.79      0.87      0.83      1342\n",
      "        weighted avg       0.79      0.87      0.82      1342\n",
      "         samples avg       0.63      0.64      0.62      1342\n",
      "\n",
      "Training completed in 153.9765875339508 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4025, Accuracy: 0.8801, F1 Micro: 0.7801, F1 Macro: 0.7855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2471, Accuracy: 0.8912, F1 Micro: 0.8021, F1 Macro: 0.8058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1939, Accuracy: 0.8984, F1 Micro: 0.8081, F1 Macro: 0.8105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1559, Accuracy: 0.8982, F1 Micro: 0.8171, F1 Macro: 0.8201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1203, Accuracy: 0.9003, F1 Micro: 0.8179, F1 Macro: 0.8216\n",
      "Epoch 6/10, Train Loss: 0.0835, Accuracy: 0.8986, F1 Micro: 0.8105, F1 Macro: 0.8127\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0613, Accuracy: 0.8972, F1 Micro: 0.8183, F1 Macro: 0.8217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0461, Accuracy: 0.9038, F1 Micro: 0.8287, F1 Macro: 0.8321\n",
      "Epoch 9/10, Train Loss: 0.035, Accuracy: 0.9034, F1 Micro: 0.8276, F1 Macro: 0.8306\n",
      "Epoch 10/10, Train Loss: 0.0267, Accuracy: 0.8993, F1 Micro: 0.8226, F1 Macro: 0.8271\n",
      "Model 2 - Iteration 4638: Accuracy: 0.9038, F1 Micro: 0.8287, F1 Macro: 0.8321\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.96      0.91      0.93       308\n",
      "                sara       0.78      0.84      0.81       367\n",
      "         radikalisme       0.83      0.87      0.85       337\n",
      "pencemaran_nama_baik       0.72      0.76      0.74       330\n",
      "\n",
      "           micro avg       0.81      0.84      0.83      1342\n",
      "           macro avg       0.82      0.84      0.83      1342\n",
      "        weighted avg       0.82      0.84      0.83      1342\n",
      "         samples avg       0.63      0.63      0.62      1342\n",
      "\n",
      "Training completed in 158.33569288253784 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4108, Accuracy: 0.875, F1 Micro: 0.7674, F1 Macro: 0.7711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2483, Accuracy: 0.8892, F1 Micro: 0.7928, F1 Macro: 0.7935\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1989, Accuracy: 0.9003, F1 Micro: 0.8137, F1 Macro: 0.8158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1587, Accuracy: 0.8997, F1 Micro: 0.8191, F1 Macro: 0.8221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1215, Accuracy: 0.9003, F1 Micro: 0.822, F1 Macro: 0.8265\n",
      "Epoch 6/10, Train Loss: 0.0801, Accuracy: 0.8978, F1 Micro: 0.8197, F1 Macro: 0.8231\n",
      "Epoch 7/10, Train Loss: 0.0603, Accuracy: 0.8991, F1 Micro: 0.8194, F1 Macro: 0.8213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0445, Accuracy: 0.9017, F1 Micro: 0.8262, F1 Macro: 0.8294\n",
      "Epoch 9/10, Train Loss: 0.0335, Accuracy: 0.9017, F1 Micro: 0.8234, F1 Macro: 0.8256\n",
      "Epoch 10/10, Train Loss: 0.027, Accuracy: 0.8964, F1 Micro: 0.8095, F1 Macro: 0.8109\n",
      "Model 3 - Iteration 4638: Accuracy: 0.9017, F1 Micro: 0.8262, F1 Macro: 0.8294\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.91      0.93       308\n",
      "                sara       0.79      0.82      0.81       367\n",
      "         radikalisme       0.80      0.89      0.84       337\n",
      "pencemaran_nama_baik       0.71      0.77      0.74       330\n",
      "\n",
      "           micro avg       0.81      0.85      0.83      1342\n",
      "           macro avg       0.81      0.85      0.83      1342\n",
      "        weighted avg       0.81      0.85      0.83      1342\n",
      "         samples avg       0.62      0.63      0.62      1342\n",
      "\n",
      "Training completed in 156.4598090648651 s\n",
      "Averaged - Iteration 4638: Accuracy: 0.8912, F1 Micro: 0.8059, F1 Macro: 0.8094\n",
      "Total sampling time: 609.29 seconds\n",
      "Total runtime: 7053.945607423782 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning([50, 67, 42], 0)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6739372,
     "sourceId": 11761127,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7097.097635,
   "end_time": "2025-05-11T06:24:04.044803",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-11T04:25:46.947168",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0d0d06363c9649368d8c981fb6ca4654": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6ab9a4fbb39b473bbf4ecc6e6861493b",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_99b63c12b0a64b228ef326dcd39e780e",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡2.00/2.00â€‡[00:00&lt;00:00,â€‡160B/s]"
      }
     },
     "1d26f7d4c8554e3694e1a27452883b6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_95bac47cd7d0409182a15202ec48f1fd",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_aedd9679f6f54310b09320432ac9dced",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json:â€‡100%"
      }
     },
     "25dd7f43d25c417a87d928d45001d53e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "27a51725ff0347d2a5143cc4ac1d093f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2a146cc457e04d5f81906f23e3583bb4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5f100bf047074a93a375b0558da71e2c",
        "IPY_MODEL_9c5990a47f8f466a827ce2665b0e67ab",
        "IPY_MODEL_c16b5689e3824764836bdacaf944a768"
       ],
       "layout": "IPY_MODEL_d49f1a0f2aa04215ad2975973982a22e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2fd94b83f0314f21be8b07d480e899e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3a20e9b8c82d4191808eff65a43a7b56": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3bf9778c335e479d81f6bd603c01d66d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "412a766872764a28aeb9df9caa071e36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "498997d2f50a485f9c146b1ce1a5e224": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d1e0ddbd6626467bb893c8fb97503b42",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_2fd94b83f0314f21be8b07d480e899e6",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡1.53k/1.53kâ€‡[00:00&lt;00:00,â€‡177kB/s]"
      }
     },
     "598f4c544e014b2aa5bb823aa2b96faf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5f100bf047074a93a375b0558da71e2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_25dd7f43d25c417a87d928d45001d53e",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_ddaa57b71c2944fba34e01bd682e9146",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt:â€‡100%"
      }
     },
     "6118a4b0d4d44ce0b9eeefb224a9b66f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f3ceaf17773e49d48e40ffa31f99fb72",
        "IPY_MODEL_7cf4326236ca4bf288000aa2ab238bb7",
        "IPY_MODEL_498997d2f50a485f9c146b1ce1a5e224"
       ],
       "layout": "IPY_MODEL_623ff85fd8774fc595720b363e5feccb",
       "tabbable": null,
       "tooltip": null
      }
     },
     "623ff85fd8774fc595720b363e5feccb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "665b0025dbe04d8f9a8b9e2ee1e00753": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6ab9a4fbb39b473bbf4ecc6e6861493b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6c688fcd20d84a1e845b41479dca273a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "717e9a1312f64d399311291969bb4ece": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "78156ab1c5bc4c29a1bf5fe54c2906b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "78dad3dd43cd4b7c861ff1473c307d1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "78df373b937044cbadb2ee1cd7d22cf4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7cf4326236ca4bf288000aa2ab238bb7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_95526c34cacb4415acebeeb51e4b6e9d",
       "max": 1534.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_665b0025dbe04d8f9a8b9e2ee1e00753",
       "tabbable": null,
       "tooltip": null,
       "value": 1534.0
      }
     },
     "81afb713ba7e404fa3dd87256aa4cc05": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "81e75720850d4bf5a57b8f86c449145b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3a20e9b8c82d4191808eff65a43a7b56",
       "max": 112.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f0df905ffb714b759839876bdeb76e05",
       "tabbable": null,
       "tooltip": null,
       "value": 112.0
      }
     },
     "84294557777146b988c14bd6880636d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "857ab4870bc04d17b2cf0f6b9513944a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1d26f7d4c8554e3694e1a27452883b6d",
        "IPY_MODEL_81e75720850d4bf5a57b8f86c449145b",
        "IPY_MODEL_e35d47d6c3ca4141bf9f913301eccecd"
       ],
       "layout": "IPY_MODEL_78df373b937044cbadb2ee1cd7d22cf4",
       "tabbable": null,
       "tooltip": null
      }
     },
     "95526c34cacb4415acebeeb51e4b6e9d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "95bac47cd7d0409182a15202ec48f1fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9677001535cc40dea8461f7492598b43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b856c0939cd84a118be26bce791f1860",
        "IPY_MODEL_9fa662bc8196433aa7c397d795fcebf4",
        "IPY_MODEL_0d0d06363c9649368d8c981fb6ca4654"
       ],
       "layout": "IPY_MODEL_6c688fcd20d84a1e845b41479dca273a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "99b63c12b0a64b228ef326dcd39e780e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9c5990a47f8f466a827ce2665b0e67ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d51a34821f9e4ee6a0b7d53ffab95fa6",
       "max": 229167.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_412a766872764a28aeb9df9caa071e36",
       "tabbable": null,
       "tooltip": null,
       "value": 229167.0
      }
     },
     "9fa662bc8196433aa7c397d795fcebf4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_81afb713ba7e404fa3dd87256aa4cc05",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_78dad3dd43cd4b7c861ff1473c307d1e",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "aedd9679f6f54310b09320432ac9dced": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b856c0939cd84a118be26bce791f1860": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cb2fc870034f4eba8b51b1539827503b",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_84294557777146b988c14bd6880636d2",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:â€‡100%"
      }
     },
     "c16b5689e3824764836bdacaf944a768": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3bf9778c335e479d81f6bd603c01d66d",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_598f4c544e014b2aa5bb823aa2b96faf",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡229k/229kâ€‡[00:00&lt;00:00,â€‡6.63MB/s]"
      }
     },
     "c558ccaf2a554cec843f6323ea8cec8c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cb2fc870034f4eba8b51b1539827503b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d1e0ddbd6626467bb893c8fb97503b42": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d49f1a0f2aa04215ad2975973982a22e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d51a34821f9e4ee6a0b7d53ffab95fa6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ddaa57b71c2944fba34e01bd682e9146": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e35d47d6c3ca4141bf9f913301eccecd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_27a51725ff0347d2a5143cc4ac1d093f",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_78156ab1c5bc4c29a1bf5fe54c2906b6",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡112/112â€‡[00:00&lt;00:00,â€‡11.6kB/s]"
      }
     },
     "f0df905ffb714b759839876bdeb76e05": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f3ceaf17773e49d48e40ffa31f99fb72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c558ccaf2a554cec843f6323ea8cec8c",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_717e9a1312f64d399311291969bb4ece",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:â€‡100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
