{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c72dc1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:09.217206Z",
     "iopub.status.busy": "2024-12-18T15:35:09.216847Z",
     "iopub.status.idle": "2024-12-18T15:35:28.878686Z",
     "shell.execute_reply": "2024-12-18T15:35:28.877985Z"
    },
    "papermill": {
     "duration": 19.67006,
     "end_time": "2024-12-18T15:35:28.880605",
     "exception": false,
     "start_time": "2024-12-18T15:35:09.210545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import wandb\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cacf86e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:28.890378Z",
     "iopub.status.busy": "2024-12-18T15:35:28.889593Z",
     "iopub.status.idle": "2024-12-18T15:35:29.878496Z",
     "shell.execute_reply": "2024-12-18T15:35:29.877729Z"
    },
    "papermill": {
     "duration": 0.995325,
     "end_time": "2024-12-18T15:35:29.880244",
     "exception": false,
     "start_time": "2024-12-18T15:35:28.884919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "secret_value_0 = user_secrets.get_secret(\"wandb_key\")\n",
    "\n",
    "wandb.login(key=secret_value_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "699920b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:29.890040Z",
     "iopub.status.busy": "2024-12-18T15:35:29.889469Z",
     "iopub.status.idle": "2024-12-18T15:35:29.893295Z",
     "shell.execute_reply": "2024-12-18T15:35:29.892573Z"
    },
    "papermill": {
     "duration": 0.010285,
     "end_time": "2024-12-18T15:35:29.894815",
     "exception": false,
     "start_time": "2024-12-18T15:35:29.884530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5607d27b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:29.905120Z",
     "iopub.status.busy": "2024-12-18T15:35:29.904655Z",
     "iopub.status.idle": "2024-12-18T15:35:30.048768Z",
     "shell.execute_reply": "2024-12-18T15:35:30.047847Z"
    },
    "papermill": {
     "duration": 0.150657,
     "end_time": "2024-12-18T15:35:30.050603",
     "exception": false,
     "start_time": "2024-12-18T15:35:29.899946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7773, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/netifier/processed_train.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/netifier/processed_test.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data], ignore_index=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9e52461",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:30.060411Z",
     "iopub.status.busy": "2024-12-18T15:35:30.060115Z",
     "iopub.status.idle": "2024-12-18T15:35:30.074631Z",
     "shell.execute_reply": "2024-12-18T15:35:30.073779Z"
    },
    "papermill": {
     "duration": 0.021036,
     "end_time": "2024-12-18T15:35:30.076198",
     "exception": false,
     "start_time": "2024-12-18T15:35:30.055162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>source</th>\n",
       "      <th>pornografi</th>\n",
       "      <th>sara</th>\n",
       "      <th>radikalisme</th>\n",
       "      <th>pencemaran_nama_baik</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[QUOTE=jessepinkman16;5a50ac34d89b093f368b456e...</td>\n",
       "      <td>kaskus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>jabar memang provinsi barokah boleh juga dan n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@verosvante kita2 aja nitizen yang pada kepo,t...</td>\n",
       "      <td>instagram</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kita saja nitizen yang pada penasaran toh kelu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"#SidangAhok smg sipenista agama n ateknya mat...</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sidangahok semoga sipenista agama dan ateknya ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@bolususulembang.jkt barusan baca undang2 ini....</td>\n",
       "      <td>instagram</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jakarta barusan baca undang ini tetap dibedaka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bikin anak mulu lu nof \\nkaga mikir apa kasian...</td>\n",
       "      <td>kaskus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>buat anak melulu kamu nof nkaga mikir apa kasi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text     source  pornografi  \\\n",
       "0  [QUOTE=jessepinkman16;5a50ac34d89b093f368b456e...     kaskus           0   \n",
       "1  @verosvante kita2 aja nitizen yang pada kepo,t...  instagram           0   \n",
       "2  \"#SidangAhok smg sipenista agama n ateknya mat...    twitter           0   \n",
       "3  @bolususulembang.jkt barusan baca undang2 ini....  instagram           0   \n",
       "4  bikin anak mulu lu nof \\nkaga mikir apa kasian...     kaskus           0   \n",
       "\n",
       "   sara  radikalisme  pencemaran_nama_baik  \\\n",
       "0     0            0                     1   \n",
       "1     0            0                     0   \n",
       "2     1            1                     1   \n",
       "3     0            0                     0   \n",
       "4     0            0                     0   \n",
       "\n",
       "                                      processed_text  \n",
       "0  jabar memang provinsi barokah boleh juga dan n...  \n",
       "1  kita saja nitizen yang pada penasaran toh kelu...  \n",
       "2  sidangahok semoga sipenista agama dan ateknya ...  \n",
       "3  jakarta barusan baca undang ini tetap dibedaka...  \n",
       "4  buat anak melulu kamu nof nkaga mikir apa kasi...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13aa34cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:30.086303Z",
     "iopub.status.busy": "2024-12-18T15:35:30.085725Z",
     "iopub.status.idle": "2024-12-18T15:35:30.095381Z",
     "shell.execute_reply": "2024-12-18T15:35:30.094569Z"
    },
    "papermill": {
     "duration": 0.016569,
     "end_time": "2024-12-18T15:35:30.097122",
     "exception": false,
     "start_time": "2024-12-18T15:35:30.080553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ac978b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:30.107637Z",
     "iopub.status.busy": "2024-12-18T15:35:30.106832Z",
     "iopub.status.idle": "2024-12-18T15:35:30.115719Z",
     "shell.execute_reply": "2024-12-18T15:35:30.114775Z"
    },
    "papermill": {
     "duration": 0.015553,
     "end_time": "2024-12-18T15:35:30.117343",
     "exception": false,
     "start_time": "2024-12-18T15:35:30.101790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6218,) (6218, 4)\n",
      "(1555,) (1555, 4)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[2:6]\n",
    "val_labels = val_data.columns[2:6]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['processed_text'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['processed_text'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfaa5da4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:30.127088Z",
     "iopub.status.busy": "2024-12-18T15:35:30.126807Z",
     "iopub.status.idle": "2024-12-18T15:35:31.684491Z",
     "shell.execute_reply": "2024-12-18T15:35:31.683532Z"
    },
    "papermill": {
     "duration": 1.564927,
     "end_time": "2024-12-18T15:35:31.686611",
     "exception": false,
     "start_time": "2024-12-18T15:35:30.121684",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc9d04fc6b64b8bb96a1be2726d99c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dee5648268c4098b9c92ea1e694dc50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6648ea4abe4a0eb4d2302086bb7d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5d1ee199d74961a4aa93c827c7eaa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Define custom Dataset class\n",
    "class NetifierDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(labels, dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "797123d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:31.698211Z",
     "iopub.status.busy": "2024-12-18T15:35:31.697638Z",
     "iopub.status.idle": "2024-12-18T15:35:31.702760Z",
     "shell.execute_reply": "2024-12-18T15:35:31.702070Z"
    },
    "papermill": {
     "duration": 0.012532,
     "end_time": "2024-12-18T15:35:31.704377",
     "exception": false,
     "start_time": "2024-12-18T15:35:31.691845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define compute metrics for evaluation\n",
    "def compute_metrics(p):\n",
    "    preds = torch.sigmoid(torch.tensor(p.predictions)).round()  # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    a, b, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7db70319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:31.715084Z",
     "iopub.status.busy": "2024-12-18T15:35:31.714792Z",
     "iopub.status.idle": "2024-12-18T15:35:31.719729Z",
     "shell.execute_reply": "2024-12-18T15:35:31.718964Z"
    },
    "papermill": {
     "duration": 0.012109,
     "end_time": "2024-12-18T15:35:31.721357",
     "exception": false,
     "start_time": "2024-12-18T15:35:31.709248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define compute metrics for evaluation\n",
    "def compute_metrics_eval(p):\n",
    "    result = compute_metrics(p)\n",
    "    \n",
    "    preds = torch.sigmoid(torch.tensor(p.predictions)).round()  # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "    \n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        target_names=['pornografi', 'sara', 'radikalisme', 'pencemaran_nama_baik'],\n",
    "        zero_division=0\n",
    "    )    \n",
    "    return {\n",
    "        'accuracy': result['accuracy'],\n",
    "        'precision': result['precision'],\n",
    "        'recall': result['recall'],\n",
    "        'f1_micro': result['f1_micro'],\n",
    "        'f1_macro': result['f1_macro'],\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59260d66",
   "metadata": {
    "papermill": {
     "duration": 0.004492,
     "end_time": "2024-12-18T15:35:31.730620",
     "exception": false,
     "start_time": "2024-12-18T15:35:31.726128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ACTIVE LEARNING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a5fb689",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:31.741563Z",
     "iopub.status.busy": "2024-12-18T15:35:31.740856Z",
     "iopub.status.idle": "2024-12-18T15:35:31.744661Z",
     "shell.execute_reply": "2024-12-18T15:35:31.743949Z"
    },
    "papermill": {
     "duration": 0.010998,
     "end_time": "2024-12-18T15:35:31.746244",
     "exception": false,
     "start_time": "2024-12-18T15:35:31.735246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "f1_micros = []\n",
    "f1_macros = []\n",
    "sampling_dur = []\n",
    "data_used = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "717122cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:31.757034Z",
     "iopub.status.busy": "2024-12-18T15:35:31.756397Z",
     "iopub.status.idle": "2024-12-18T15:35:31.760663Z",
     "shell.execute_reply": "2024-12-18T15:35:31.760002Z"
    },
    "papermill": {
     "duration": 0.011179,
     "end_time": "2024-12-18T15:35:31.762184",
     "exception": false,
     "start_time": "2024-12-18T15:35:31.751005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = 'netifier-coreset'\n",
    "epochs = 10\n",
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c802b6ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:31.772713Z",
     "iopub.status.busy": "2024-12-18T15:35:31.772453Z",
     "iopub.status.idle": "2024-12-18T15:35:31.785185Z",
     "shell.execute_reply": "2024-12-18T15:35:31.784360Z"
    },
    "papermill": {
     "duration": 0.019914,
     "end_time": "2024-12-18T15:35:31.786752",
     "exception": false,
     "start_time": "2024-12-18T15:35:31.766838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def coreset_sampling(model, X_pool, train_indices, remaining_indices, trials, n_samples=min_increment):\n",
    "    start_time = time.time()\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    embeddings = []\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "\n",
    "    dataset = NetifierDataset(X_pool, np.zeros((len(X_pool), 4)), tokenizer, max_length=128)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=16,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            input_ids = data['input_ids'].to(device)\n",
    "            attention_mask = data['attention_mask'].to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            hidden_states = outputs.last_hidden_state.mean(dim=1)  # Mean of hidden states for vector representation\n",
    "            embeddings.append(hidden_states.cpu().numpy())\n",
    "\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    embeddings = np.array(embeddings)\n",
    "\n",
    "    # Use pairwise distances to compute a distance matrix for Coreset selection\n",
    "    distance_matrix = pairwise_distances(embeddings)    \n",
    "    selected_indices = [0]  # Start with an arbitrary first sample (e.g., index 0)\n",
    "    \n",
    "    # Calculate the minimum distance from selected points to all other points\n",
    "    min_distances = distance_matrix[selected_indices].min(axis=0)\n",
    "    sorted = np.argsort(min_distances)\n",
    "    sorted = sorted[::-1]\n",
    "    \n",
    "    threshold = np.percentile(min_distances, 90)\n",
    "    candidates = np.where(min_distances >= threshold)[0]  # Select the point farthest from the current set\n",
    "    num_of_candidates = len(candidates)\n",
    "\n",
    "    nearest_cp = 0\n",
    "    for cp in checkpoints:\n",
    "        if cp > current_train_size:\n",
    "            nearest_cp = cp\n",
    "            break\n",
    "\n",
    "    if num_of_candidates <= n_samples and n_samples < nearest_cp - current_train_size:\n",
    "        selected_indices = sorted[:n_samples]\n",
    "    elif num_of_candidates > n_samples and num_of_candidates < nearest_cp - current_train_size:\n",
    "        selected_indices = sorted[:num_of_candidates]\n",
    "    else:\n",
    "        selected_indices = sorted[:nearest_cp - current_train_size]\n",
    "\n",
    "        temp = train_indices.copy()\n",
    "        temp.extend(selected_indices)\n",
    "        \n",
    "        # Save acquired data up to checkpoint\n",
    "        acquired_data = pd.DataFrame({\n",
    "            'processed_text': [X_train[i] for i in temp],\n",
    "            'pornografi': [y_train[i][0] for i in temp],\n",
    "            'sara': [y_train[i][1] for i in temp],\n",
    "            'radikalisme': [y_train[i][2] for i in temp],\n",
    "            'pencemaran_nama_baik': [y_train[i][3] for i in temp],\n",
    "        })\n",
    "\n",
    "        acquired_data.to_csv(f'{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "    \n",
    "    end_time = time.time()  # Record the end time\n",
    "    duration = end_time - start_time  # Calculate the duration in seconds\n",
    "\n",
    "    print(\"Nearest checkpoint:\", nearest_cp)\n",
    "    print(\"Threshold:\", threshold)\n",
    "    print(\"Samples above threshold:\", num_of_candidates)\n",
    "    print(\"Acquired samples:\", len(selected_indices))\n",
    "    print(f\"Sampling duration: {duration} seconds\")  # Print or return the runtime if needed\n",
    "\n",
    "    sampling_dur.append(duration)\n",
    "    \n",
    "    return [remaining_indices[i] for i in selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c9c61e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:31.797595Z",
     "iopub.status.busy": "2024-12-18T15:35:31.797264Z",
     "iopub.status.idle": "2024-12-18T15:35:31.806112Z",
     "shell.execute_reply": "2024-12-18T15:35:31.805304Z"
    },
    "papermill": {
     "duration": 0.016103,
     "end_time": "2024-12-18T15:35:31.807680",
     "exception": false,
     "start_time": "2024-12-18T15:35:31.791577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, trials, seed):\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in model.named_parameters():\n",
    "        # Specify the layers you want to freeze (e.g., first 6 layers)\n",
    "        if \"encoder.layer\" in name:\n",
    "            # Extract the layer number safely\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                # Freeze only the first 6 layers\n",
    "                if int(layer_num) < 9:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                # Skip any parameter names that don’t follow the expected format\n",
    "                continue\n",
    "    \n",
    "    # Create Dataset with current training data\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    train_dataset = NetifierDataset(current_X_train, current_y_train, tokenizer, max_length=128)\n",
    "    val_dataset = NetifierDataset(X_val, y_val, tokenizer, max_length=128)\n",
    "    \n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'./results/{filename}-{trials+1}',\n",
    "        eval_strategy=\"epoch\",                    # Evaluate after every epoch\n",
    "        save_strategy=\"epoch\",                    # Save model after every epoch\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=epochs,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='f1_micro',\n",
    "        save_total_limit=1,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate after training\n",
    "    trainer.compute_metrics = compute_metrics_eval\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"Iteration {current_train_size}: Accuracy: {eval_results['eval_accuracy']}, F1 Micro: {eval_results['eval_f1_micro']}, F1 Macro: {eval_results['eval_f1_macro']}\")\n",
    "    print(eval_results['eval_report'])\n",
    "\n",
    "    torch.save(model.state_dict(), f'{filename}-{trials+1}-model.pth')\n",
    "    model.config.to_json_file(f'{filename}-{trials+1}-config.json')\n",
    "\n",
    "    data_used.append(current_train_size)\n",
    "    accuracies.append(eval_results['eval_accuracy'])\n",
    "    f1_micros.append(eval_results['eval_f1_micro'])\n",
    "    f1_macros.append(eval_results['eval_f1_macro'])\n",
    "    \n",
    "    return model, trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "361e4290",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:31.818775Z",
     "iopub.status.busy": "2024-12-18T15:35:31.818227Z",
     "iopub.status.idle": "2024-12-18T15:35:31.824209Z",
     "shell.execute_reply": "2024-12-18T15:35:31.823412Z"
    },
    "papermill": {
     "duration": 0.013071,
     "end_time": "2024-12-18T15:35:31.825816",
     "exception": false,
     "start_time": "2024-12-18T15:35:31.812745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bac0a57a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:31.836440Z",
     "iopub.status.busy": "2024-12-18T15:35:31.836171Z",
     "iopub.status.idle": "2024-12-18T15:35:31.843859Z",
     "shell.execute_reply": "2024-12-18T15:35:31.843178Z"
    },
    "papermill": {
     "duration": 0.014829,
     "end_time": "2024-12-18T15:35:31.845420",
     "exception": false,
     "start_time": "2024-12-18T15:35:31.830591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    accuracies.clear()\n",
    "    f1_micros.clear()\n",
    "    f1_macros.clear()\n",
    "    sampling_dur.clear()\n",
    "    data_used.clear()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        model, trainer = train_model(current_train_size, train_indices, i, seed)\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = coreset_sampling(\n",
    "            model, \n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices,\n",
    "            remaining_indices,\n",
    "            trials=i, \n",
    "        )\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    model, trainer = train_model(current_train_size, train_indices, i, seed)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time  # Calculate the duration in seconds\n",
    "    \n",
    "    print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    sampling_dur.insert(0, 0)\n",
    "    \n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    \n",
    "    results.to_csv(f'{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d736050",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:31.855856Z",
     "iopub.status.busy": "2024-12-18T15:35:31.855594Z",
     "iopub.status.idle": "2024-12-18T15:35:31.859208Z",
     "shell.execute_reply": "2024-12-18T15:35:31.858520Z"
    },
    "papermill": {
     "duration": 0.01057,
     "end_time": "2024-12-18T15:35:31.860704",
     "exception": false,
     "start_time": "2024-12-18T15:35:31.850134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec34813",
   "metadata": {
    "papermill": {
     "duration": 0.004489,
     "end_time": "2024-12-18T15:35:31.869923",
     "exception": false,
     "start_time": "2024-12-18T15:35:31.865434",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "697a9021",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T15:35:31.880247Z",
     "iopub.status.busy": "2024-12-18T15:35:31.879974Z",
     "iopub.status.idle": "2024-12-18T18:42:47.724115Z",
     "shell.execute_reply": "2024-12-18T18:42:47.723165Z"
    },
    "papermill": {
     "duration": 11235.851531,
     "end_time": "2024-12-18T18:42:47.726039",
     "exception": false,
     "start_time": "2024-12-18T15:35:31.874508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6def1b1c674a78af751f858f085706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnicost918\u001b[0m (\u001b[33mnicost918-petra-christian-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241218_153537-m6slk8k4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m./results/netifier-coreset-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/nicost918-petra-christian-university/huggingface\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/nicost918-petra-christian-university/huggingface/runs/m6slk8k4\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 02:11, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.471070</td>\n",
       "      <td>0.441801</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.019345</td>\n",
       "      <td>0.016121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.408955</td>\n",
       "      <td>0.549839</td>\n",
       "      <td>0.937743</td>\n",
       "      <td>0.181750</td>\n",
       "      <td>0.304485</td>\n",
       "      <td>0.212706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.356134</td>\n",
       "      <td>0.570418</td>\n",
       "      <td>0.760807</td>\n",
       "      <td>0.398190</td>\n",
       "      <td>0.522772</td>\n",
       "      <td>0.458811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.333005</td>\n",
       "      <td>0.578135</td>\n",
       "      <td>0.745169</td>\n",
       "      <td>0.465309</td>\n",
       "      <td>0.572888</td>\n",
       "      <td>0.519570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.328695</td>\n",
       "      <td>0.599357</td>\n",
       "      <td>0.754325</td>\n",
       "      <td>0.493213</td>\n",
       "      <td>0.596443</td>\n",
       "      <td>0.562729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.316878</td>\n",
       "      <td>0.602572</td>\n",
       "      <td>0.734064</td>\n",
       "      <td>0.555807</td>\n",
       "      <td>0.632618</td>\n",
       "      <td>0.600391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.322708</td>\n",
       "      <td>0.605788</td>\n",
       "      <td>0.756849</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.602180</td>\n",
       "      <td>0.576849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.310757</td>\n",
       "      <td>0.618006</td>\n",
       "      <td>0.728030</td>\n",
       "      <td>0.593514</td>\n",
       "      <td>0.653926</td>\n",
       "      <td>0.632917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.310798</td>\n",
       "      <td>0.616720</td>\n",
       "      <td>0.731638</td>\n",
       "      <td>0.585973</td>\n",
       "      <td>0.650754</td>\n",
       "      <td>0.631457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.310642</td>\n",
       "      <td>0.616077</td>\n",
       "      <td>0.733840</td>\n",
       "      <td>0.582202</td>\n",
       "      <td>0.649285</td>\n",
       "      <td>0.630442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.80      0.85       362\n",
      "                sara       0.62      0.32      0.42       237\n",
      "         radikalisme       0.69      0.66      0.68       235\n",
      "pencemaran_nama_baik       0.64      0.54      0.59       492\n",
      "\n",
      "           micro avg       0.73      0.59      0.65      1326\n",
      "           macro avg       0.71      0.58      0.63      1326\n",
      "        weighted avg       0.72      0.59      0.64      1326\n",
      "         samples avg       0.35      0.33      0.33      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 388: Accuracy: 0.6180064308681672, F1 Micro: 0.653926049023681, F1 Macro: 0.6329171582051338\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.80      0.85       362\n",
      "                sara       0.62      0.32      0.42       237\n",
      "         radikalisme       0.69      0.66      0.68       235\n",
      "pencemaran_nama_baik       0.64      0.54      0.59       492\n",
      "\n",
      "           micro avg       0.73      0.59      0.65      1326\n",
      "           macro avg       0.71      0.58      0.63      1326\n",
      "        weighted avg       0.72      0.59      0.64      1326\n",
      "         samples avg       0.35      0.33      0.33      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 24.41180419921875\n",
      "Samples above threshold: 586\n",
      "Acquired samples: 586\n",
      "Sampling duration: 20.872732162475586 seconds\n",
      "New train size: 974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [610/610 03:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.378640</td>\n",
       "      <td>0.549839</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.229261</td>\n",
       "      <td>0.358068</td>\n",
       "      <td>0.233581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.351685</td>\n",
       "      <td>0.553698</td>\n",
       "      <td>0.774545</td>\n",
       "      <td>0.321267</td>\n",
       "      <td>0.454158</td>\n",
       "      <td>0.367716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.319885</td>\n",
       "      <td>0.598071</td>\n",
       "      <td>0.739819</td>\n",
       "      <td>0.493213</td>\n",
       "      <td>0.591855</td>\n",
       "      <td>0.555624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.313941</td>\n",
       "      <td>0.619936</td>\n",
       "      <td>0.693910</td>\n",
       "      <td>0.653092</td>\n",
       "      <td>0.672883</td>\n",
       "      <td>0.662754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.307595</td>\n",
       "      <td>0.632797</td>\n",
       "      <td>0.699067</td>\n",
       "      <td>0.677979</td>\n",
       "      <td>0.688361</td>\n",
       "      <td>0.681140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.318404</td>\n",
       "      <td>0.633441</td>\n",
       "      <td>0.729148</td>\n",
       "      <td>0.613122</td>\n",
       "      <td>0.666120</td>\n",
       "      <td>0.649499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.329720</td>\n",
       "      <td>0.645016</td>\n",
       "      <td>0.705329</td>\n",
       "      <td>0.678733</td>\n",
       "      <td>0.691776</td>\n",
       "      <td>0.682861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.329551</td>\n",
       "      <td>0.641158</td>\n",
       "      <td>0.713259</td>\n",
       "      <td>0.673454</td>\n",
       "      <td>0.692785</td>\n",
       "      <td>0.681225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.124600</td>\n",
       "      <td>0.328354</td>\n",
       "      <td>0.648232</td>\n",
       "      <td>0.720968</td>\n",
       "      <td>0.674208</td>\n",
       "      <td>0.696804</td>\n",
       "      <td>0.685067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.124600</td>\n",
       "      <td>0.329444</td>\n",
       "      <td>0.648232</td>\n",
       "      <td>0.718650</td>\n",
       "      <td>0.674208</td>\n",
       "      <td>0.695720</td>\n",
       "      <td>0.685428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.85      0.86      0.86       362\n",
      "                sara       0.65      0.46      0.54       237\n",
      "         radikalisme       0.69      0.73      0.71       235\n",
      "pencemaran_nama_baik       0.66      0.61      0.63       492\n",
      "\n",
      "           micro avg       0.72      0.67      0.70      1326\n",
      "           macro avg       0.71      0.67      0.69      1326\n",
      "        weighted avg       0.72      0.67      0.69      1326\n",
      "         samples avg       0.38      0.38      0.37      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 974: Accuracy: 0.6482315112540193, F1 Micro: 0.6968043647700701, F1 Macro: 0.6850668023660791\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.85      0.86      0.86       362\n",
      "                sara       0.65      0.46      0.54       237\n",
      "         radikalisme       0.69      0.73      0.71       235\n",
      "pencemaran_nama_baik       0.66      0.61      0.63       492\n",
      "\n",
      "           micro avg       0.72      0.67      0.70      1326\n",
      "           macro avg       0.71      0.67      0.69      1326\n",
      "        weighted avg       0.72      0.67      0.69      1326\n",
      "         samples avg       0.38      0.38      0.37      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 23.55172481536865\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 18.46069598197937 seconds\n",
      "New train size: 1499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [940/940 04:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.376782</td>\n",
       "      <td>0.570418</td>\n",
       "      <td>0.848684</td>\n",
       "      <td>0.291855</td>\n",
       "      <td>0.434343</td>\n",
       "      <td>0.337575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.352304</td>\n",
       "      <td>0.610289</td>\n",
       "      <td>0.810321</td>\n",
       "      <td>0.438160</td>\n",
       "      <td>0.568771</td>\n",
       "      <td>0.490601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.299895</td>\n",
       "      <td>0.635370</td>\n",
       "      <td>0.752607</td>\n",
       "      <td>0.598793</td>\n",
       "      <td>0.666947</td>\n",
       "      <td>0.628067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.304544</td>\n",
       "      <td>0.636656</td>\n",
       "      <td>0.735573</td>\n",
       "      <td>0.644042</td>\n",
       "      <td>0.686771</td>\n",
       "      <td>0.650683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.318894</td>\n",
       "      <td>0.655305</td>\n",
       "      <td>0.736088</td>\n",
       "      <td>0.658371</td>\n",
       "      <td>0.695064</td>\n",
       "      <td>0.673255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.333350</td>\n",
       "      <td>0.648875</td>\n",
       "      <td>0.751144</td>\n",
       "      <td>0.619155</td>\n",
       "      <td>0.678793</td>\n",
       "      <td>0.653712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.338843</td>\n",
       "      <td>0.649518</td>\n",
       "      <td>0.732069</td>\n",
       "      <td>0.669683</td>\n",
       "      <td>0.699488</td>\n",
       "      <td>0.679486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.355337</td>\n",
       "      <td>0.645016</td>\n",
       "      <td>0.725103</td>\n",
       "      <td>0.664404</td>\n",
       "      <td>0.693428</td>\n",
       "      <td>0.675763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.353807</td>\n",
       "      <td>0.648232</td>\n",
       "      <td>0.714509</td>\n",
       "      <td>0.690799</td>\n",
       "      <td>0.702454</td>\n",
       "      <td>0.687873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.351412</td>\n",
       "      <td>0.644373</td>\n",
       "      <td>0.716680</td>\n",
       "      <td>0.677225</td>\n",
       "      <td>0.696394</td>\n",
       "      <td>0.678413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.83      0.88      0.86       362\n",
      "                sara       0.64      0.44      0.52       237\n",
      "         radikalisme       0.68      0.77      0.73       235\n",
      "pencemaran_nama_baik       0.66      0.63      0.65       492\n",
      "\n",
      "           micro avg       0.71      0.69      0.70      1326\n",
      "           macro avg       0.70      0.68      0.69      1326\n",
      "        weighted avg       0.71      0.69      0.70      1326\n",
      "         samples avg       0.40      0.40      0.39      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1499: Accuracy: 0.6482315112540193, F1 Micro: 0.7024539877300614, F1 Macro: 0.6878734613246507\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.83      0.88      0.86       362\n",
      "                sara       0.64      0.44      0.52       237\n",
      "         radikalisme       0.68      0.77      0.73       235\n",
      "pencemaran_nama_baik       0.66      0.63      0.65       492\n",
      "\n",
      "           micro avg       0.71      0.69      0.70      1326\n",
      "           macro avg       0.70      0.68      0.69      1326\n",
      "        weighted avg       0.71      0.69      0.70      1326\n",
      "         samples avg       0.40      0.40      0.39      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 23.170793533325195\n",
      "Samples above threshold: 472\n",
      "Acquired samples: 472\n",
      "Sampling duration: 16.610580444335938 seconds\n",
      "New train size: 1971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1240' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1240/1240 04:51, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.354153</td>\n",
       "      <td>0.581350</td>\n",
       "      <td>0.787682</td>\n",
       "      <td>0.366516</td>\n",
       "      <td>0.500257</td>\n",
       "      <td>0.399925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.297597</td>\n",
       "      <td>0.621865</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.665158</td>\n",
       "      <td>0.687719</td>\n",
       "      <td>0.656271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.301218</td>\n",
       "      <td>0.643087</td>\n",
       "      <td>0.814159</td>\n",
       "      <td>0.555053</td>\n",
       "      <td>0.660090</td>\n",
       "      <td>0.582405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.296579</td>\n",
       "      <td>0.658521</td>\n",
       "      <td>0.761739</td>\n",
       "      <td>0.660633</td>\n",
       "      <td>0.707593</td>\n",
       "      <td>0.672763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.139600</td>\n",
       "      <td>0.296239</td>\n",
       "      <td>0.663666</td>\n",
       "      <td>0.742089</td>\n",
       "      <td>0.707391</td>\n",
       "      <td>0.724324</td>\n",
       "      <td>0.702777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.139600</td>\n",
       "      <td>0.313729</td>\n",
       "      <td>0.664309</td>\n",
       "      <td>0.740157</td>\n",
       "      <td>0.708899</td>\n",
       "      <td>0.724191</td>\n",
       "      <td>0.706729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.139600</td>\n",
       "      <td>0.321348</td>\n",
       "      <td>0.668810</td>\n",
       "      <td>0.726379</td>\n",
       "      <td>0.724736</td>\n",
       "      <td>0.725557</td>\n",
       "      <td>0.713854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.139600</td>\n",
       "      <td>0.338739</td>\n",
       "      <td>0.663666</td>\n",
       "      <td>0.742994</td>\n",
       "      <td>0.699849</td>\n",
       "      <td>0.720777</td>\n",
       "      <td>0.699600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>0.343032</td>\n",
       "      <td>0.663023</td>\n",
       "      <td>0.731878</td>\n",
       "      <td>0.708145</td>\n",
       "      <td>0.719816</td>\n",
       "      <td>0.702492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>0.344609</td>\n",
       "      <td>0.662379</td>\n",
       "      <td>0.729457</td>\n",
       "      <td>0.709653</td>\n",
       "      <td>0.719419</td>\n",
       "      <td>0.701761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.86      0.88       362\n",
      "                sara       0.63      0.49      0.55       237\n",
      "         radikalisme       0.68      0.81      0.74       235\n",
      "pencemaran_nama_baik       0.67      0.69      0.68       492\n",
      "\n",
      "           micro avg       0.73      0.72      0.73      1326\n",
      "           macro avg       0.72      0.72      0.71      1326\n",
      "        weighted avg       0.73      0.72      0.72      1326\n",
      "         samples avg       0.41      0.41      0.40      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1971: Accuracy: 0.6688102893890675, F1 Micro: 0.7255568138920347, F1 Macro: 0.7138540517118874\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.86      0.88       362\n",
      "                sara       0.63      0.49      0.55       237\n",
      "         radikalisme       0.68      0.81      0.74       235\n",
      "pencemaran_nama_baik       0.67      0.69      0.68       492\n",
      "\n",
      "           micro avg       0.73      0.72      0.73      1326\n",
      "           macro avg       0.72      0.72      0.71      1326\n",
      "        weighted avg       0.73      0.72      0.72      1326\n",
      "         samples avg       0.41      0.41      0.40      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 22.105390548706055\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 425\n",
      "Sampling duration: 14.921244144439697 seconds\n",
      "New train size: 2396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:35, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.341568</td>\n",
       "      <td>0.591640</td>\n",
       "      <td>0.848987</td>\n",
       "      <td>0.347662</td>\n",
       "      <td>0.493312</td>\n",
       "      <td>0.400112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.281256</td>\n",
       "      <td>0.656592</td>\n",
       "      <td>0.807609</td>\n",
       "      <td>0.560332</td>\n",
       "      <td>0.661621</td>\n",
       "      <td>0.604685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.269314</td>\n",
       "      <td>0.670740</td>\n",
       "      <td>0.760033</td>\n",
       "      <td>0.699849</td>\n",
       "      <td>0.728700</td>\n",
       "      <td>0.700744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.153000</td>\n",
       "      <td>0.286633</td>\n",
       "      <td>0.679743</td>\n",
       "      <td>0.782798</td>\n",
       "      <td>0.679487</td>\n",
       "      <td>0.727493</td>\n",
       "      <td>0.690239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.153000</td>\n",
       "      <td>0.291462</td>\n",
       "      <td>0.677814</td>\n",
       "      <td>0.756735</td>\n",
       "      <td>0.720211</td>\n",
       "      <td>0.738022</td>\n",
       "      <td>0.716215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.153000</td>\n",
       "      <td>0.304747</td>\n",
       "      <td>0.676527</td>\n",
       "      <td>0.768333</td>\n",
       "      <td>0.695324</td>\n",
       "      <td>0.730008</td>\n",
       "      <td>0.700119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.321292</td>\n",
       "      <td>0.680386</td>\n",
       "      <td>0.744240</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.737443</td>\n",
       "      <td>0.720736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.327829</td>\n",
       "      <td>0.681672</td>\n",
       "      <td>0.732456</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.743875</td>\n",
       "      <td>0.732479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.336917</td>\n",
       "      <td>0.684244</td>\n",
       "      <td>0.727666</td>\n",
       "      <td>0.761689</td>\n",
       "      <td>0.744289</td>\n",
       "      <td>0.735290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>0.339169</td>\n",
       "      <td>0.678457</td>\n",
       "      <td>0.730205</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.740520</td>\n",
       "      <td>0.727993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.88      0.90       362\n",
      "                sara       0.65      0.54      0.59       237\n",
      "         radikalisme       0.69      0.83      0.75       235\n",
      "pencemaran_nama_baik       0.66      0.75      0.70       492\n",
      "\n",
      "           micro avg       0.73      0.76      0.74      1326\n",
      "           macro avg       0.73      0.75      0.74      1326\n",
      "        weighted avg       0.73      0.76      0.74      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2396: Accuracy: 0.6842443729903537, F1 Micro: 0.7442888725128961, F1 Macro: 0.7352903153543142\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.88      0.90       362\n",
      "                sara       0.65      0.54      0.59       237\n",
      "         radikalisme       0.69      0.83      0.75       235\n",
      "pencemaran_nama_baik       0.66      0.75      0.70       492\n",
      "\n",
      "           micro avg       0.73      0.76      0.74      1326\n",
      "           macro avg       0.73      0.75      0.74      1326\n",
      "        weighted avg       0.73      0.76      0.74      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 21.992998313903808\n",
      "Samples above threshold: 383\n",
      "Acquired samples: 383\n",
      "Sampling duration: 13.380363941192627 seconds\n",
      "New train size: 2779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1740' max='1740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1740/1740 06:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.338139</td>\n",
       "      <td>0.592283</td>\n",
       "      <td>0.826758</td>\n",
       "      <td>0.363499</td>\n",
       "      <td>0.504976</td>\n",
       "      <td>0.400632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.263704</td>\n",
       "      <td>0.654662</td>\n",
       "      <td>0.784259</td>\n",
       "      <td>0.638763</td>\n",
       "      <td>0.704073</td>\n",
       "      <td>0.639076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.264631</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.803704</td>\n",
       "      <td>0.654600</td>\n",
       "      <td>0.721530</td>\n",
       "      <td>0.681743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.276430</td>\n",
       "      <td>0.679743</td>\n",
       "      <td>0.773950</td>\n",
       "      <td>0.694570</td>\n",
       "      <td>0.732114</td>\n",
       "      <td>0.702400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.308147</td>\n",
       "      <td>0.654662</td>\n",
       "      <td>0.703830</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.738164</td>\n",
       "      <td>0.717420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.301405</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.723944</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.748725</td>\n",
       "      <td>0.738934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.307719</td>\n",
       "      <td>0.684887</td>\n",
       "      <td>0.736881</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.744308</td>\n",
       "      <td>0.733473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.321447</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.728959</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.749267</td>\n",
       "      <td>0.737489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.332130</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.722772</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.733886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.330192</td>\n",
       "      <td>0.682958</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.753394</td>\n",
       "      <td>0.744134</td>\n",
       "      <td>0.728145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.87      0.90       362\n",
      "                sara       0.66      0.52      0.58       237\n",
      "         radikalisme       0.68      0.83      0.75       235\n",
      "pencemaran_nama_baik       0.66      0.78      0.72       492\n",
      "\n",
      "           micro avg       0.73      0.77      0.75      1326\n",
      "           macro avg       0.73      0.75      0.74      1326\n",
      "        weighted avg       0.74      0.77      0.75      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2779: Accuracy: 0.6855305466237942, F1 Micro: 0.749266862170088, F1 Macro: 0.7374888628664577\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.87      0.90       362\n",
      "                sara       0.66      0.52      0.58       237\n",
      "         radikalisme       0.68      0.83      0.75       235\n",
      "pencemaran_nama_baik       0.66      0.78      0.72       492\n",
      "\n",
      "           micro avg       0.73      0.77      0.75      1326\n",
      "           macro avg       0.73      0.75      0.74      1326\n",
      "        weighted avg       0.74      0.77      0.75      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 20.774326705932616\n",
      "Samples above threshold: 344\n",
      "Acquired samples: 344\n",
      "Sampling duration: 12.045804023742676 seconds\n",
      "New train size: 3123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='1960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/1960 06:46, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.340380</td>\n",
       "      <td>0.591640</td>\n",
       "      <td>0.862782</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.494080</td>\n",
       "      <td>0.399829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.258342</td>\n",
       "      <td>0.683601</td>\n",
       "      <td>0.765574</td>\n",
       "      <td>0.704374</td>\n",
       "      <td>0.733700</td>\n",
       "      <td>0.702160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.183200</td>\n",
       "      <td>0.267155</td>\n",
       "      <td>0.681029</td>\n",
       "      <td>0.783595</td>\n",
       "      <td>0.677225</td>\n",
       "      <td>0.726537</td>\n",
       "      <td>0.705283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.183200</td>\n",
       "      <td>0.266957</td>\n",
       "      <td>0.686817</td>\n",
       "      <td>0.762579</td>\n",
       "      <td>0.731523</td>\n",
       "      <td>0.746728</td>\n",
       "      <td>0.726454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.183200</td>\n",
       "      <td>0.291780</td>\n",
       "      <td>0.679100</td>\n",
       "      <td>0.754137</td>\n",
       "      <td>0.721719</td>\n",
       "      <td>0.737572</td>\n",
       "      <td>0.711745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.083700</td>\n",
       "      <td>0.300816</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.743436</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.745393</td>\n",
       "      <td>0.736068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.083700</td>\n",
       "      <td>0.331441</td>\n",
       "      <td>0.677814</td>\n",
       "      <td>0.732695</td>\n",
       "      <td>0.750377</td>\n",
       "      <td>0.741431</td>\n",
       "      <td>0.730274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>0.332409</td>\n",
       "      <td>0.674598</td>\n",
       "      <td>0.724163</td>\n",
       "      <td>0.750377</td>\n",
       "      <td>0.737037</td>\n",
       "      <td>0.725892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>0.340375</td>\n",
       "      <td>0.672669</td>\n",
       "      <td>0.720029</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.737771</td>\n",
       "      <td>0.730856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>0.347310</td>\n",
       "      <td>0.673312</td>\n",
       "      <td>0.718460</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.738732</td>\n",
       "      <td>0.730951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.88      0.90       362\n",
      "                sara       0.71      0.44      0.55       237\n",
      "         radikalisme       0.72      0.77      0.74       235\n",
      "pencemaran_nama_baik       0.70      0.74      0.72       492\n",
      "\n",
      "           micro avg       0.76      0.73      0.75      1326\n",
      "           macro avg       0.76      0.71      0.73      1326\n",
      "        weighted avg       0.76      0.73      0.74      1326\n",
      "         samples avg       0.43      0.42      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3123: Accuracy: 0.6868167202572347, F1 Micro: 0.7467282525019244, F1 Macro: 0.7264539960342551\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.88      0.90       362\n",
      "                sara       0.71      0.44      0.55       237\n",
      "         radikalisme       0.72      0.77      0.74       235\n",
      "pencemaran_nama_baik       0.70      0.74      0.72       492\n",
      "\n",
      "           micro avg       0.76      0.73      0.75      1326\n",
      "           macro avg       0.76      0.71      0.73      1326\n",
      "        weighted avg       0.76      0.73      0.74      1326\n",
      "         samples avg       0.43      0.42      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 21.031661987304688\n",
      "Samples above threshold: 355\n",
      "Acquired samples: 355\n",
      "Sampling duration: 10.866553783416748 seconds\n",
      "New train size: 3478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2180' max='2180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2180/2180 07:22, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.323371</td>\n",
       "      <td>0.625080</td>\n",
       "      <td>0.879397</td>\n",
       "      <td>0.395928</td>\n",
       "      <td>0.546022</td>\n",
       "      <td>0.456980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.254917</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.796931</td>\n",
       "      <td>0.665913</td>\n",
       "      <td>0.725555</td>\n",
       "      <td>0.696203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.255598</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.767701</td>\n",
       "      <td>0.727753</td>\n",
       "      <td>0.747193</td>\n",
       "      <td>0.720292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.269783</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.781046</td>\n",
       "      <td>0.720965</td>\n",
       "      <td>0.749804</td>\n",
       "      <td>0.735722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.091500</td>\n",
       "      <td>0.288355</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.739065</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.739381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.091500</td>\n",
       "      <td>0.326252</td>\n",
       "      <td>0.662379</td>\n",
       "      <td>0.711724</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.743516</td>\n",
       "      <td>0.732967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.053400</td>\n",
       "      <td>0.314092</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.759358</td>\n",
       "      <td>0.749623</td>\n",
       "      <td>0.754459</td>\n",
       "      <td>0.741661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.053400</td>\n",
       "      <td>0.331735</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.749441</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.753656</td>\n",
       "      <td>0.739254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.053400</td>\n",
       "      <td>0.343027</td>\n",
       "      <td>0.679100</td>\n",
       "      <td>0.728754</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.751644</td>\n",
       "      <td>0.741888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.341391</td>\n",
       "      <td>0.682958</td>\n",
       "      <td>0.732666</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.752294</td>\n",
       "      <td>0.743979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.90       362\n",
      "                sara       0.68      0.53      0.60       237\n",
      "         radikalisme       0.71      0.80      0.76       235\n",
      "pencemaran_nama_baik       0.71      0.72      0.71       492\n",
      "\n",
      "           micro avg       0.76      0.75      0.75      1326\n",
      "           macro avg       0.75      0.74      0.74      1326\n",
      "        weighted avg       0.76      0.75      0.75      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3478: Accuracy: 0.6964630225080386, F1 Micro: 0.7544592030360532, F1 Macro: 0.7416608180293991\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.90       362\n",
      "                sara       0.68      0.53      0.60       237\n",
      "         radikalisme       0.71      0.80      0.76       235\n",
      "pencemaran_nama_baik       0.71      0.72      0.71       492\n",
      "\n",
      "           micro avg       0.76      0.75      0.75      1326\n",
      "           macro avg       0.75      0.74      0.74      1326\n",
      "        weighted avg       0.76      0.75      0.75      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 20.25936164855957\n",
      "Samples above threshold: 274\n",
      "Acquired samples: 274\n",
      "Sampling duration: 9.554830312728882 seconds\n",
      "New train size: 3752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2350' max='2350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2350/2350 07:49, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.322521</td>\n",
       "      <td>0.621222</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.402715</td>\n",
       "      <td>0.551938</td>\n",
       "      <td>0.465562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.247010</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.813197</td>\n",
       "      <td>0.659879</td>\n",
       "      <td>0.728560</td>\n",
       "      <td>0.693842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.199900</td>\n",
       "      <td>0.253242</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.750185</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.756636</td>\n",
       "      <td>0.738730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.199900</td>\n",
       "      <td>0.267115</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.763718</td>\n",
       "      <td>0.755394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.104600</td>\n",
       "      <td>0.285504</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.756594</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>0.756879</td>\n",
       "      <td>0.747974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.104600</td>\n",
       "      <td>0.306054</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.739478</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.753698</td>\n",
       "      <td>0.744925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.330904</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.725530</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.760675</td>\n",
       "      <td>0.757990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.350852</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.710700</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.757746</td>\n",
       "      <td>0.754367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>0.357340</td>\n",
       "      <td>0.677814</td>\n",
       "      <td>0.709441</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.754064</td>\n",
       "      <td>0.749041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>0.350748</td>\n",
       "      <td>0.684887</td>\n",
       "      <td>0.722683</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.753968</td>\n",
       "      <td>0.748767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.90       362\n",
      "                sara       0.68      0.59      0.63       237\n",
      "         radikalisme       0.72      0.82      0.76       235\n",
      "pencemaran_nama_baik       0.70      0.75      0.72       492\n",
      "\n",
      "           micro avg       0.76      0.77      0.76      1326\n",
      "           macro avg       0.75      0.76      0.76      1326\n",
      "        weighted avg       0.76      0.77      0.76      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3752: Accuracy: 0.6996784565916399, F1 Micro: 0.7637178051511757, F1 Macro: 0.7553942778248396\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.90       362\n",
      "                sara       0.68      0.59      0.63       237\n",
      "         radikalisme       0.72      0.82      0.76       235\n",
      "pencemaran_nama_baik       0.70      0.75      0.72       492\n",
      "\n",
      "           micro avg       0.76      0.77      0.76      1326\n",
      "           macro avg       0.75      0.76      0.76      1326\n",
      "        weighted avg       0.76      0.77      0.76      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 19.90263080596924\n",
      "Samples above threshold: 247\n",
      "Acquired samples: 134\n",
      "Sampling duration: 8.79787802696228 seconds\n",
      "New train size: 3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2430' max='2430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2430/2430 08:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.289579</td>\n",
       "      <td>0.629582</td>\n",
       "      <td>0.844384</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.604358</td>\n",
       "      <td>0.523087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.245495</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.763359</td>\n",
       "      <td>0.754121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.260208</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.723376</td>\n",
       "      <td>0.814480</td>\n",
       "      <td>0.766229</td>\n",
       "      <td>0.763164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.750183</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.762152</td>\n",
       "      <td>0.753582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.110200</td>\n",
       "      <td>0.287371</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.740113</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.764406</td>\n",
       "      <td>0.758835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.110200</td>\n",
       "      <td>0.309398</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.728149</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.761425</td>\n",
       "      <td>0.754772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.315701</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.739313</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.766437</td>\n",
       "      <td>0.760231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.327316</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.731063</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.760940</td>\n",
       "      <td>0.753660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>0.341402</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.728344</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.759119</td>\n",
       "      <td>0.751387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>0.342833</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.730345</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.762968</td>\n",
       "      <td>0.758117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.67      0.62      0.64       237\n",
      "         radikalisme       0.71      0.83      0.76       235\n",
      "pencemaran_nama_baik       0.67      0.79      0.73       492\n",
      "\n",
      "           micro avg       0.74      0.80      0.77      1326\n",
      "           macro avg       0.74      0.78      0.76      1326\n",
      "        weighted avg       0.75      0.80      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3886: Accuracy: 0.7003215434083602, F1 Micro: 0.7664366146022521, F1 Macro: 0.7602310738850628\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.67      0.62      0.64       237\n",
      "         radikalisme       0.71      0.83      0.76       235\n",
      "pencemaran_nama_baik       0.67      0.79      0.73       492\n",
      "\n",
      "           micro avg       0.74      0.80      0.77      1326\n",
      "           macro avg       0.74      0.78      0.76      1326\n",
      "        weighted avg       0.75      0.80      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 19.653493118286132\n",
      "Samples above threshold: 234\n",
      "Acquired samples: 234\n",
      "Sampling duration: 8.245853662490845 seconds\n",
      "New train size: 4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 08:29, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.279991</td>\n",
       "      <td>0.654019</td>\n",
       "      <td>0.814433</td>\n",
       "      <td>0.536199</td>\n",
       "      <td>0.646658</td>\n",
       "      <td>0.606643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.222400</td>\n",
       "      <td>0.238325</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.772182</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.749709</td>\n",
       "      <td>0.728603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.222400</td>\n",
       "      <td>0.250158</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.820728</td>\n",
       "      <td>0.662896</td>\n",
       "      <td>0.733417</td>\n",
       "      <td>0.700383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.125500</td>\n",
       "      <td>0.251743</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.784202</td>\n",
       "      <td>0.726244</td>\n",
       "      <td>0.754111</td>\n",
       "      <td>0.730988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.125500</td>\n",
       "      <td>0.268216</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.753813</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.768036</td>\n",
       "      <td>0.758013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.083800</td>\n",
       "      <td>0.296683</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.732278</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.765743</td>\n",
       "      <td>0.760668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.083800</td>\n",
       "      <td>0.305695</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.745965</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.772810</td>\n",
       "      <td>0.767617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.055500</td>\n",
       "      <td>0.321061</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.737395</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.757722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.055500</td>\n",
       "      <td>0.319923</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.748014</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.764294</td>\n",
       "      <td>0.757752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.040200</td>\n",
       "      <td>0.323461</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.765224</td>\n",
       "      <td>0.758745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.91       362\n",
      "                sara       0.65      0.68      0.66       237\n",
      "         radikalisme       0.72      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.70      0.77      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.77      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.80      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4120: Accuracy: 0.7080385852090032, F1 Micro: 0.772809887313704, F1 Macro: 0.7676165058333231\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.91       362\n",
      "                sara       0.65      0.68      0.66       237\n",
      "         radikalisme       0.72      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.70      0.77      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.77      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.80      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 19.414354705810545\n",
      "Samples above threshold: 210\n",
      "Acquired samples: 210\n",
      "Sampling duration: 7.409613132476807 seconds\n",
      "New train size: 4330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2710' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2710/2710 08:52, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.273988</td>\n",
       "      <td>0.668810</td>\n",
       "      <td>0.745951</td>\n",
       "      <td>0.659879</td>\n",
       "      <td>0.700280</td>\n",
       "      <td>0.696673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.254383</td>\n",
       "      <td>0.681029</td>\n",
       "      <td>0.704689</td>\n",
       "      <td>0.838612</td>\n",
       "      <td>0.765840</td>\n",
       "      <td>0.762242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.242981</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.763001</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.768713</td>\n",
       "      <td>0.758498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.137400</td>\n",
       "      <td>0.256496</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.740766</td>\n",
       "      <td>0.816742</td>\n",
       "      <td>0.776901</td>\n",
       "      <td>0.775237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.137400</td>\n",
       "      <td>0.292353</td>\n",
       "      <td>0.683601</td>\n",
       "      <td>0.714005</td>\n",
       "      <td>0.822775</td>\n",
       "      <td>0.764541</td>\n",
       "      <td>0.758676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.092400</td>\n",
       "      <td>0.291782</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.748747</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.768270</td>\n",
       "      <td>0.761644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.092400</td>\n",
       "      <td>0.304270</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.734483</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.767291</td>\n",
       "      <td>0.762888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>0.312133</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.755589</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.760120</td>\n",
       "      <td>0.754430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>0.327973</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.736620</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.761835</td>\n",
       "      <td>0.756078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>0.320982</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.748542</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.761305</td>\n",
       "      <td>0.755946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.88      0.91       362\n",
      "                sara       0.63      0.74      0.68       237\n",
      "         radikalisme       0.71      0.85      0.77       235\n",
      "pencemaran_nama_baik       0.69      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.82      0.78      1326\n",
      "           macro avg       0.74      0.81      0.78      1326\n",
      "        weighted avg       0.75      0.82      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4330: Accuracy: 0.7067524115755627, F1 Micro: 0.7769010043041606, F1 Macro: 0.7752368754164619\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.88      0.91       362\n",
      "                sara       0.63      0.74      0.68       237\n",
      "         radikalisme       0.71      0.85      0.77       235\n",
      "pencemaran_nama_baik       0.69      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.82      0.78      1326\n",
      "           macro avg       0.74      0.81      0.78      1326\n",
      "        weighted avg       0.75      0.82      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 18.727344703674316\n",
      "Samples above threshold: 189\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.647526264190674 seconds\n",
      "New train size: 4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2840' max='2840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2840/2840 09:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.262757</td>\n",
       "      <td>0.663666</td>\n",
       "      <td>0.806256</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>0.689685</td>\n",
       "      <td>0.669360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.245572</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.786575</td>\n",
       "      <td>0.689291</td>\n",
       "      <td>0.734727</td>\n",
       "      <td>0.723016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.237951</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.758982</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.761833</td>\n",
       "      <td>0.750967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.144400</td>\n",
       "      <td>0.252923</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.738112</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.771336</td>\n",
       "      <td>0.764569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.144400</td>\n",
       "      <td>0.269744</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.739160</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.772940</td>\n",
       "      <td>0.768620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.281173</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.749286</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.769626</td>\n",
       "      <td>0.765624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.314993</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.724161</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.766335</td>\n",
       "      <td>0.762336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>0.316721</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.748368</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.763031</td>\n",
       "      <td>0.755000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.049800</td>\n",
       "      <td>0.331275</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.741152</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.771955</td>\n",
       "      <td>0.766217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.049800</td>\n",
       "      <td>0.323274</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.750181</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.766507</td>\n",
       "      <td>0.760492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.63      0.68      0.65       237\n",
      "         radikalisme       0.73      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.81      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.81      0.77      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4530: Accuracy: 0.7028938906752411, F1 Micro: 0.7729399064411658, F1 Macro: 0.7686195450817634\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.63      0.68      0.65       237\n",
      "         radikalisme       0.73      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.81      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.81      0.77      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 18.82966194152832\n",
      "Samples above threshold: 169\n",
      "Acquired samples: 133\n",
      "Sampling duration: 6.135111093521118 seconds\n",
      "New train size: 4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2920' max='2920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2920/2920 09:28, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.271935</td>\n",
       "      <td>0.658521</td>\n",
       "      <td>0.808102</td>\n",
       "      <td>0.571644</td>\n",
       "      <td>0.669611</td>\n",
       "      <td>0.636810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>0.239276</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.743697</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.771242</td>\n",
       "      <td>0.760429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>0.234586</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.763353</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.769634</td>\n",
       "      <td>0.760516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.146600</td>\n",
       "      <td>0.248019</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.761421</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.776340</td>\n",
       "      <td>0.769065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.146600</td>\n",
       "      <td>0.284166</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.717067</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.770841</td>\n",
       "      <td>0.765811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.287718</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.743094</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.775775</td>\n",
       "      <td>0.771043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072900</td>\n",
       "      <td>0.311334</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.730487</td>\n",
       "      <td>0.825792</td>\n",
       "      <td>0.775221</td>\n",
       "      <td>0.767208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.072900</td>\n",
       "      <td>0.306462</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.751401</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.779230</td>\n",
       "      <td>0.774372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>0.309316</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.765832</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.774963</td>\n",
       "      <td>0.769296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>0.315398</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.756272</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.775450</td>\n",
       "      <td>0.769616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.64      0.67      0.65       237\n",
      "         radikalisme       0.74      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.70      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4663: Accuracy: 0.7118971061093248, F1 Micro: 0.7792302106027597, F1 Macro: 0.7743721042654346\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.64      0.67      0.65       237\n",
      "         radikalisme       0.74      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.70      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 19.09109573364258\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.550132751464844 seconds\n",
      "New train size: 4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3040' max='3040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3040/3040 09:51, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256302</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.785072</td>\n",
       "      <td>0.658371</td>\n",
       "      <td>0.716161</td>\n",
       "      <td>0.710833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.252300</td>\n",
       "      <td>0.239447</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.746606</td>\n",
       "      <td>0.760369</td>\n",
       "      <td>0.754596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.252300</td>\n",
       "      <td>0.234200</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.801160</td>\n",
       "      <td>0.729261</td>\n",
       "      <td>0.763522</td>\n",
       "      <td>0.745809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.157400</td>\n",
       "      <td>0.253487</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.742361</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.772957</td>\n",
       "      <td>0.767559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.114200</td>\n",
       "      <td>0.271283</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.742477</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.770236</td>\n",
       "      <td>0.762290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.114200</td>\n",
       "      <td>0.289607</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.735875</td>\n",
       "      <td>0.815234</td>\n",
       "      <td>0.773524</td>\n",
       "      <td>0.765931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.077700</td>\n",
       "      <td>0.300097</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.748933</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.770864</td>\n",
       "      <td>0.764032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.077700</td>\n",
       "      <td>0.315603</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.742138</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.770403</td>\n",
       "      <td>0.763120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.060300</td>\n",
       "      <td>0.322561</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.750353</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.767858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>0.324251</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.749474</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.776445</td>\n",
       "      <td>0.770180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.90      0.93       362\n",
      "                sara       0.63      0.65      0.64       237\n",
      "         radikalisme       0.73      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.69      0.80      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4863: Accuracy: 0.7099678456591639, F1 Micro: 0.7764449291166847, F1 Macro: 0.7701799739232943\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.90      0.93       362\n",
      "                sara       0.63      0.65      0.64       237\n",
      "         radikalisme       0.73      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.69      0.80      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 19.344175338745117\n",
      "Samples above threshold: 136\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.892844200134277 seconds\n",
      "New train size: 5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3170' max='3170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3170/3170 10:08, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.252536</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.785464</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.726904</td>\n",
       "      <td>0.714398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.256600</td>\n",
       "      <td>0.234101</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.795282</td>\n",
       "      <td>0.711916</td>\n",
       "      <td>0.751293</td>\n",
       "      <td>0.731685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.256600</td>\n",
       "      <td>0.229473</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.786719</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.772832</td>\n",
       "      <td>0.763613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.165500</td>\n",
       "      <td>0.240586</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.775019</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.775895</td>\n",
       "      <td>0.767573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.121600</td>\n",
       "      <td>0.263122</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.755175</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.775944</td>\n",
       "      <td>0.769542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.121600</td>\n",
       "      <td>0.293045</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.731132</td>\n",
       "      <td>0.818250</td>\n",
       "      <td>0.772242</td>\n",
       "      <td>0.765527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.283933</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.780195</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.782249</td>\n",
       "      <td>0.773809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.063900</td>\n",
       "      <td>0.298411</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.781583</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.778030</td>\n",
       "      <td>0.770809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.063900</td>\n",
       "      <td>0.309077</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.759913</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.777000</td>\n",
       "      <td>0.771967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>0.317313</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.747710</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.773042</td>\n",
       "      <td>0.767786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.89      0.92       362\n",
      "                sara       0.66      0.65      0.65       237\n",
      "         radikalisme       0.75      0.80      0.77       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.78      0.78      1326\n",
      "           macro avg       0.77      0.78      0.77      1326\n",
      "        weighted avg       0.78      0.78      0.78      1326\n",
      "         samples avg       0.46      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5063: Accuracy: 0.7228295819935692, F1 Micro: 0.7822489657766077, F1 Macro: 0.773808744113816\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.89      0.92       362\n",
      "                sara       0.66      0.65      0.65       237\n",
      "         radikalisme       0.75      0.80      0.77       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.78      0.78      1326\n",
      "           macro avg       0.77      0.78      0.77      1326\n",
      "        weighted avg       0.78      0.78      0.78      1326\n",
      "         samples avg       0.46      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 18.381642150878907\n",
      "Samples above threshold: 116\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.18235182762146 seconds\n",
      "New train size: 5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3290' max='3290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3290/3290 10:31, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.249562</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.764107</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.749424</td>\n",
       "      <td>0.736629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.264900</td>\n",
       "      <td>0.236059</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.798291</td>\n",
       "      <td>0.704374</td>\n",
       "      <td>0.748397</td>\n",
       "      <td>0.734654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.264900</td>\n",
       "      <td>0.236907</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.753338</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.779920</td>\n",
       "      <td>0.774721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.178800</td>\n",
       "      <td>0.258683</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.726740</td>\n",
       "      <td>0.842383</td>\n",
       "      <td>0.780300</td>\n",
       "      <td>0.778089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.127100</td>\n",
       "      <td>0.270272</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.766989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.127100</td>\n",
       "      <td>0.274767</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.761248</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.775888</td>\n",
       "      <td>0.769362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.092900</td>\n",
       "      <td>0.295714</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.738621</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.771614</td>\n",
       "      <td>0.765663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.306019</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.747346</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.771084</td>\n",
       "      <td>0.765586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.309801</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.758671</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.774908</td>\n",
       "      <td>0.769810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.054500</td>\n",
       "      <td>0.314067</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.756602</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.777411</td>\n",
       "      <td>0.772761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.60      0.76      0.67       237\n",
      "         radikalisme       0.72      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.68      0.84      0.75       492\n",
      "\n",
      "           micro avg       0.73      0.84      0.78      1326\n",
      "           macro avg       0.73      0.84      0.78      1326\n",
      "        weighted avg       0.74      0.84      0.79      1326\n",
      "         samples avg       0.46      0.48      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5263: Accuracy: 0.7112540192926045, F1 Micro: 0.7803003842123647, F1 Macro: 0.7780892165289606\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.60      0.76      0.67       237\n",
      "         radikalisme       0.72      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.68      0.84      0.75       492\n",
      "\n",
      "           micro avg       0.73      0.84      0.78      1326\n",
      "           macro avg       0.73      0.84      0.78      1326\n",
      "        weighted avg       0.74      0.84      0.79      1326\n",
      "         samples avg       0.46      0.48      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 17.609204483032226\n",
      "Samples above threshold: 96\n",
      "Acquired samples: 178\n",
      "Sampling duration: 3.7035036087036133 seconds\n",
      "New train size: 5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3410' max='3410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3410/3410 10:52, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250522</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.796580</td>\n",
       "      <td>0.667421</td>\n",
       "      <td>0.726303</td>\n",
       "      <td>0.717765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.265600</td>\n",
       "      <td>0.228089</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.752320</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.773011</td>\n",
       "      <td>0.762351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.180400</td>\n",
       "      <td>0.228425</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.761172</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.772204</td>\n",
       "      <td>0.763238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.180400</td>\n",
       "      <td>0.261979</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.720989</td>\n",
       "      <td>0.857466</td>\n",
       "      <td>0.783328</td>\n",
       "      <td>0.779818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.130500</td>\n",
       "      <td>0.251794</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.809801</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.770751</td>\n",
       "      <td>0.759221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.094600</td>\n",
       "      <td>0.287773</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.729801</td>\n",
       "      <td>0.831071</td>\n",
       "      <td>0.777151</td>\n",
       "      <td>0.773163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.094600</td>\n",
       "      <td>0.288931</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.765557</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.781388</td>\n",
       "      <td>0.771044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.074300</td>\n",
       "      <td>0.302028</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.747398</td>\n",
       "      <td>0.812217</td>\n",
       "      <td>0.778460</td>\n",
       "      <td>0.772999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.302637</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.782209</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.775665</td>\n",
       "      <td>0.767310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.308158</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.766300</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.777406</td>\n",
       "      <td>0.772514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.59      0.78      0.67       237\n",
      "         radikalisme       0.71      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.68      0.85      0.76       492\n",
      "\n",
      "           micro avg       0.72      0.86      0.78      1326\n",
      "           macro avg       0.72      0.85      0.78      1326\n",
      "        weighted avg       0.73      0.86      0.79      1326\n",
      "         samples avg       0.47      0.49      0.47      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5441: Accuracy: 0.7054662379421222, F1 Micro: 0.7833275921460557, F1 Macro: 0.7798175442366313\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.59      0.78      0.67       237\n",
      "         radikalisme       0.71      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.68      0.85      0.76       492\n",
      "\n",
      "           micro avg       0.72      0.86      0.78      1326\n",
      "           macro avg       0.72      0.85      0.78      1326\n",
      "        weighted avg       0.73      0.86      0.79      1326\n",
      "         samples avg       0.47      0.49      0.47      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 16.9408935546875\n",
      "Samples above threshold: 78\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.8961565494537354 seconds\n",
      "New train size: 5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3530' max='3530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3530/3530 11:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.257136</td>\n",
       "      <td>0.674598</td>\n",
       "      <td>0.847778</td>\n",
       "      <td>0.575415</td>\n",
       "      <td>0.685535</td>\n",
       "      <td>0.660217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.274600</td>\n",
       "      <td>0.229881</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.791426</td>\n",
       "      <td>0.723982</td>\n",
       "      <td>0.756203</td>\n",
       "      <td>0.735899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.180800</td>\n",
       "      <td>0.221247</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.768437</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.777032</td>\n",
       "      <td>0.770795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.180800</td>\n",
       "      <td>0.232188</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.771513</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.777861</td>\n",
       "      <td>0.765820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.137900</td>\n",
       "      <td>0.245131</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.765502</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.787102</td>\n",
       "      <td>0.781368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.104800</td>\n",
       "      <td>0.280173</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.751206</td>\n",
       "      <td>0.822021</td>\n",
       "      <td>0.785020</td>\n",
       "      <td>0.778737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.104800</td>\n",
       "      <td>0.271932</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.776355</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.776940</td>\n",
       "      <td>0.769637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.078200</td>\n",
       "      <td>0.287660</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.781346</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.776006</td>\n",
       "      <td>0.769972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.057900</td>\n",
       "      <td>0.303884</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.760313</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.782577</td>\n",
       "      <td>0.776913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.051200</td>\n",
       "      <td>0.305581</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.761396</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.783150</td>\n",
       "      <td>0.777624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.92       362\n",
      "                sara       0.62      0.70      0.66       237\n",
      "         radikalisme       0.76      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5641: Accuracy: 0.7215434083601286, F1 Micro: 0.787101502381825, F1 Macro: 0.7813679120268355\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.92       362\n",
      "                sara       0.62      0.70      0.66       237\n",
      "         radikalisme       0.76      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 16.63647346496582\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.2317278385162354 seconds\n",
      "New train size: 5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3660' max='3660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3660/3660 11:34, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.245839</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.802703</td>\n",
       "      <td>0.671946</td>\n",
       "      <td>0.731527</td>\n",
       "      <td>0.725644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.282900</td>\n",
       "      <td>0.224906</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.768651</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.768941</td>\n",
       "      <td>0.749931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.191400</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.777358</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.777065</td>\n",
       "      <td>0.762234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.191400</td>\n",
       "      <td>0.237475</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.773810</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.779026</td>\n",
       "      <td>0.767994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.145600</td>\n",
       "      <td>0.249944</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.805464</td>\n",
       "      <td>0.733786</td>\n",
       "      <td>0.767956</td>\n",
       "      <td>0.752011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.106700</td>\n",
       "      <td>0.282870</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.747626</td>\n",
       "      <td>0.831071</td>\n",
       "      <td>0.787143</td>\n",
       "      <td>0.781303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.283714</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.765091</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.778971</td>\n",
       "      <td>0.770212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.305786</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.754853</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.772911</td>\n",
       "      <td>0.764794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.063600</td>\n",
       "      <td>0.303527</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.766129</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.776952</td>\n",
       "      <td>0.769511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>0.314902</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.775495</td>\n",
       "      <td>0.768340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.92      0.92       362\n",
      "                sara       0.62      0.72      0.66       237\n",
      "         radikalisme       0.70      0.88      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.75      0.83      0.79      1326\n",
      "           macro avg       0.74      0.83      0.78      1326\n",
      "        weighted avg       0.76      0.83      0.79      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5841: Accuracy: 0.7209003215434083, F1 Micro: 0.7871428571428571, F1 Macro: 0.7813032679846413\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.92      0.92       362\n",
      "                sara       0.62      0.72      0.66       237\n",
      "         radikalisme       0.70      0.88      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.75      0.83      0.79      1326\n",
      "           macro avg       0.74      0.83      0.78      1326\n",
      "        weighted avg       0.76      0.83      0.79      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 15.627617073059081\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 200\n",
      "Sampling duration: 1.552551031112671 seconds\n",
      "New train size: 6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3780' max='3780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3780/3780 11:51, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.236571</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.783806</td>\n",
       "      <td>0.730015</td>\n",
       "      <td>0.755955</td>\n",
       "      <td>0.739522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.226273</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.788274</td>\n",
       "      <td>0.730015</td>\n",
       "      <td>0.758027</td>\n",
       "      <td>0.739863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.195400</td>\n",
       "      <td>0.228965</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.770987</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.780179</td>\n",
       "      <td>0.771055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.153000</td>\n",
       "      <td>0.245774</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.752770</td>\n",
       "      <td>0.819759</td>\n",
       "      <td>0.784838</td>\n",
       "      <td>0.776204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.153000</td>\n",
       "      <td>0.259948</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.754558</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.781977</td>\n",
       "      <td>0.773937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.267390</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.773282</td>\n",
       "      <td>0.763952</td>\n",
       "      <td>0.768589</td>\n",
       "      <td>0.756367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.085200</td>\n",
       "      <td>0.284224</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.773313</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.771267</td>\n",
       "      <td>0.762423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.295803</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.763808</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.777942</td>\n",
       "      <td>0.770130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.310626</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.757706</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.776920</td>\n",
       "      <td>0.770803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.055600</td>\n",
       "      <td>0.310933</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.762564</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.775843</td>\n",
       "      <td>0.767854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.92      0.91       362\n",
      "                sara       0.64      0.68      0.66       237\n",
      "         radikalisme       0.69      0.90      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.78      0.76       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.74      0.82      0.78      1326\n",
      "        weighted avg       0.76      0.82      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6041: Accuracy: 0.7209003215434083, F1 Micro: 0.7848375451263537, F1 Macro: 0.7762040426246134\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.92      0.91       362\n",
      "                sara       0.64      0.68      0.66       237\n",
      "         radikalisme       0.69      0.90      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.78      0.76       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.74      0.82      0.78      1326\n",
      "        weighted avg       0.76      0.82      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 14.797327995300293\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 177\n",
      "Sampling duration: 1.0684618949890137 seconds\n",
      "New train size: 6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3890/3890 12:13, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.234776</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.772025</td>\n",
       "      <td>0.753394</td>\n",
       "      <td>0.762595</td>\n",
       "      <td>0.756984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.292700</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.786782</td>\n",
       "      <td>0.754148</td>\n",
       "      <td>0.770119</td>\n",
       "      <td>0.755035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.204200</td>\n",
       "      <td>0.220923</td>\n",
       "      <td>0.727974</td>\n",
       "      <td>0.792702</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.781178</td>\n",
       "      <td>0.770567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.160200</td>\n",
       "      <td>0.237698</td>\n",
       "      <td>0.732476</td>\n",
       "      <td>0.808632</td>\n",
       "      <td>0.748869</td>\n",
       "      <td>0.777604</td>\n",
       "      <td>0.763040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.160200</td>\n",
       "      <td>0.255140</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.762651</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.784170</td>\n",
       "      <td>0.777199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>0.269182</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.796148</td>\n",
       "      <td>0.748115</td>\n",
       "      <td>0.771384</td>\n",
       "      <td>0.762516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.094600</td>\n",
       "      <td>0.285930</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.770540</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.777736</td>\n",
       "      <td>0.772910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>0.296722</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.762554</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.781618</td>\n",
       "      <td>0.775392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.060900</td>\n",
       "      <td>0.302468</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.767223</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.782255</td>\n",
       "      <td>0.779337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.060900</td>\n",
       "      <td>0.309054</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.767054</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.781805</td>\n",
       "      <td>0.776181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.91       362\n",
      "                sara       0.63      0.67      0.65       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.78      1326\n",
      "           macro avg       0.75      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6218: Accuracy: 0.7176848874598071, F1 Micro: 0.7841700256504214, F1 Macro: 0.7771985899129635\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.91       362\n",
      "                sara       0.63      0.67      0.65       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.78      1326\n",
      "           macro avg       0.75      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n",
      "Total sampling time: 180.03 seconds\n",
      "Total runtime: 11235.143072366714 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ecc2b7",
   "metadata": {
    "papermill": {
     "duration": 0.017993,
     "end_time": "2024-12-18T18:42:47.762993",
     "exception": false,
     "start_time": "2024-12-18T18:42:47.745000",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44cd6ec7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T18:42:47.801224Z",
     "iopub.status.busy": "2024-12-18T18:42:47.800554Z",
     "iopub.status.idle": "2024-12-18T21:48:19.428798Z",
     "shell.execute_reply": "2024-12-18T21:48:19.428094Z"
    },
    "papermill": {
     "duration": 11131.649909,
     "end_time": "2024-12-18T21:48:19.430918",
     "exception": false,
     "start_time": "2024-12-18T18:42:47.781009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 02:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.460827</td>\n",
       "      <td>0.440514</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.033937</td>\n",
       "      <td>0.065550</td>\n",
       "      <td>0.044738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.398824</td>\n",
       "      <td>0.576849</td>\n",
       "      <td>0.872222</td>\n",
       "      <td>0.236802</td>\n",
       "      <td>0.372479</td>\n",
       "      <td>0.261927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.353225</td>\n",
       "      <td>0.591640</td>\n",
       "      <td>0.830054</td>\n",
       "      <td>0.349925</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.420032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.330393</td>\n",
       "      <td>0.585852</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.429864</td>\n",
       "      <td>0.553130</td>\n",
       "      <td>0.459224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.593569</td>\n",
       "      <td>0.761511</td>\n",
       "      <td>0.486425</td>\n",
       "      <td>0.593649</td>\n",
       "      <td>0.525215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.306425</td>\n",
       "      <td>0.605145</td>\n",
       "      <td>0.788366</td>\n",
       "      <td>0.480392</td>\n",
       "      <td>0.597001</td>\n",
       "      <td>0.545943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.299625</td>\n",
       "      <td>0.612862</td>\n",
       "      <td>0.739634</td>\n",
       "      <td>0.578431</td>\n",
       "      <td>0.649175</td>\n",
       "      <td>0.610205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.297249</td>\n",
       "      <td>0.616720</td>\n",
       "      <td>0.771834</td>\n",
       "      <td>0.533183</td>\n",
       "      <td>0.630687</td>\n",
       "      <td>0.596109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.294833</td>\n",
       "      <td>0.624437</td>\n",
       "      <td>0.772004</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.641692</td>\n",
       "      <td>0.603582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.295964</td>\n",
       "      <td>0.617363</td>\n",
       "      <td>0.774123</td>\n",
       "      <td>0.532428</td>\n",
       "      <td>0.630920</td>\n",
       "      <td>0.592582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.79      0.84       362\n",
      "                sara       0.74      0.23      0.35       237\n",
      "         radikalisme       0.68      0.60      0.64       235\n",
      "pencemaran_nama_baik       0.65      0.58      0.62       492\n",
      "\n",
      "           micro avg       0.74      0.58      0.65      1326\n",
      "           macro avg       0.74      0.55      0.61      1326\n",
      "        weighted avg       0.74      0.58      0.63      1326\n",
      "         samples avg       0.38      0.34      0.35      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 388: Accuracy: 0.6128617363344051, F1 Micro: 0.649174777824799, F1 Macro: 0.6102054118583491\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.79      0.84       362\n",
      "                sara       0.74      0.23      0.35       237\n",
      "         radikalisme       0.68      0.60      0.64       235\n",
      "pencemaran_nama_baik       0.65      0.58      0.62       492\n",
      "\n",
      "           micro avg       0.74      0.58      0.65      1326\n",
      "           macro avg       0.74      0.55      0.61      1326\n",
      "        weighted avg       0.74      0.58      0.63      1326\n",
      "         samples avg       0.38      0.34      0.35      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 23.818601608276367\n",
      "Samples above threshold: 583\n",
      "Acquired samples: 583\n",
      "Sampling duration: 20.859224557876587 seconds\n",
      "New train size: 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [610/610 03:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.391608</td>\n",
       "      <td>0.568489</td>\n",
       "      <td>0.918567</td>\n",
       "      <td>0.212670</td>\n",
       "      <td>0.345377</td>\n",
       "      <td>0.216756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.346334</td>\n",
       "      <td>0.568489</td>\n",
       "      <td>0.900285</td>\n",
       "      <td>0.238311</td>\n",
       "      <td>0.376863</td>\n",
       "      <td>0.278184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.309935</td>\n",
       "      <td>0.597428</td>\n",
       "      <td>0.745251</td>\n",
       "      <td>0.503017</td>\n",
       "      <td>0.600630</td>\n",
       "      <td>0.569863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.298179</td>\n",
       "      <td>0.605145</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.601810</td>\n",
       "      <td>0.652227</td>\n",
       "      <td>0.627850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.297356</td>\n",
       "      <td>0.621865</td>\n",
       "      <td>0.758368</td>\n",
       "      <td>0.546757</td>\n",
       "      <td>0.635408</td>\n",
       "      <td>0.597555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.324648</td>\n",
       "      <td>0.615434</td>\n",
       "      <td>0.794416</td>\n",
       "      <td>0.472097</td>\n",
       "      <td>0.592242</td>\n",
       "      <td>0.540061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.299302</td>\n",
       "      <td>0.621865</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.648567</td>\n",
       "      <td>0.679842</td>\n",
       "      <td>0.663419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.307765</td>\n",
       "      <td>0.621865</td>\n",
       "      <td>0.729849</td>\n",
       "      <td>0.621418</td>\n",
       "      <td>0.671283</td>\n",
       "      <td>0.651521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.135700</td>\n",
       "      <td>0.307668</td>\n",
       "      <td>0.630225</td>\n",
       "      <td>0.743119</td>\n",
       "      <td>0.610860</td>\n",
       "      <td>0.670530</td>\n",
       "      <td>0.647768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.135700</td>\n",
       "      <td>0.309351</td>\n",
       "      <td>0.627010</td>\n",
       "      <td>0.733871</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.670762</td>\n",
       "      <td>0.648270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.87      0.88       362\n",
      "                sara       0.62      0.43      0.50       237\n",
      "         radikalisme       0.67      0.63      0.65       235\n",
      "pencemaran_nama_baik       0.63      0.60      0.62       492\n",
      "\n",
      "           micro avg       0.71      0.65      0.68      1326\n",
      "           macro avg       0.70      0.63      0.66      1326\n",
      "        weighted avg       0.71      0.65      0.68      1326\n",
      "         samples avg       0.40      0.38      0.38      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 971: Accuracy: 0.6218649517684888, F1 Micro: 0.6798418972332015, F1 Macro: 0.6634189925322678\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.87      0.88       362\n",
      "                sara       0.62      0.43      0.50       237\n",
      "         radikalisme       0.67      0.63      0.65       235\n",
      "pencemaran_nama_baik       0.63      0.60      0.62       492\n",
      "\n",
      "           micro avg       0.71      0.65      0.68      1326\n",
      "           macro avg       0.70      0.63      0.66      1326\n",
      "        weighted avg       0.71      0.65      0.68      1326\n",
      "         samples avg       0.40      0.38      0.38      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 22.461806869506844\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 18.41736888885498 seconds\n",
      "New train size: 1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [940/940 04:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.351425</td>\n",
       "      <td>0.576849</td>\n",
       "      <td>0.817805</td>\n",
       "      <td>0.297888</td>\n",
       "      <td>0.436705</td>\n",
       "      <td>0.304050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.318509</td>\n",
       "      <td>0.600643</td>\n",
       "      <td>0.785420</td>\n",
       "      <td>0.430618</td>\n",
       "      <td>0.556259</td>\n",
       "      <td>0.422041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.294906</td>\n",
       "      <td>0.605788</td>\n",
       "      <td>0.733075</td>\n",
       "      <td>0.571644</td>\n",
       "      <td>0.642373</td>\n",
       "      <td>0.576802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.290022</td>\n",
       "      <td>0.627653</td>\n",
       "      <td>0.728534</td>\n",
       "      <td>0.633484</td>\n",
       "      <td>0.677693</td>\n",
       "      <td>0.636938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.303255</td>\n",
       "      <td>0.630868</td>\n",
       "      <td>0.764113</td>\n",
       "      <td>0.571644</td>\n",
       "      <td>0.654012</td>\n",
       "      <td>0.610851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.136400</td>\n",
       "      <td>0.296028</td>\n",
       "      <td>0.635370</td>\n",
       "      <td>0.722313</td>\n",
       "      <td>0.668929</td>\n",
       "      <td>0.694597</td>\n",
       "      <td>0.676383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.136400</td>\n",
       "      <td>0.299554</td>\n",
       "      <td>0.646302</td>\n",
       "      <td>0.730737</td>\n",
       "      <td>0.665158</td>\n",
       "      <td>0.696407</td>\n",
       "      <td>0.679282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.136400</td>\n",
       "      <td>0.320263</td>\n",
       "      <td>0.637942</td>\n",
       "      <td>0.756447</td>\n",
       "      <td>0.597285</td>\n",
       "      <td>0.667509</td>\n",
       "      <td>0.641130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.136400</td>\n",
       "      <td>0.317313</td>\n",
       "      <td>0.639871</td>\n",
       "      <td>0.739092</td>\n",
       "      <td>0.638763</td>\n",
       "      <td>0.685275</td>\n",
       "      <td>0.662646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.136400</td>\n",
       "      <td>0.319192</td>\n",
       "      <td>0.639871</td>\n",
       "      <td>0.743386</td>\n",
       "      <td>0.635747</td>\n",
       "      <td>0.685366</td>\n",
       "      <td>0.661766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.86      0.89       362\n",
      "                sara       0.60      0.44      0.51       237\n",
      "         radikalisme       0.68      0.67      0.67       235\n",
      "pencemaran_nama_baik       0.67      0.62      0.65       492\n",
      "\n",
      "           micro avg       0.73      0.67      0.70      1326\n",
      "           macro avg       0.71      0.65      0.68      1326\n",
      "        weighted avg       0.73      0.67      0.69      1326\n",
      "         samples avg       0.40      0.39      0.38      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1496: Accuracy: 0.6463022508038585, F1 Micro: 0.6964074220292144, F1 Macro: 0.6792815716943266\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.86      0.89       362\n",
      "                sara       0.60      0.44      0.51       237\n",
      "         radikalisme       0.68      0.67      0.67       235\n",
      "pencemaran_nama_baik       0.67      0.62      0.65       492\n",
      "\n",
      "           micro avg       0.73      0.67      0.70      1326\n",
      "           macro avg       0.71      0.65      0.68      1326\n",
      "        weighted avg       0.73      0.67      0.69      1326\n",
      "         samples avg       0.40      0.39      0.38      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 22.361486625671386\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 16.547898769378662 seconds\n",
      "New train size: 1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1240' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1240/1240 04:49, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.317878</td>\n",
       "      <td>0.600643</td>\n",
       "      <td>0.770596</td>\n",
       "      <td>0.458522</td>\n",
       "      <td>0.574941</td>\n",
       "      <td>0.488968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.280756</td>\n",
       "      <td>0.636656</td>\n",
       "      <td>0.738837</td>\n",
       "      <td>0.661388</td>\n",
       "      <td>0.697971</td>\n",
       "      <td>0.646290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.285537</td>\n",
       "      <td>0.656592</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.601524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.278428</td>\n",
       "      <td>0.650161</td>\n",
       "      <td>0.733071</td>\n",
       "      <td>0.702112</td>\n",
       "      <td>0.717257</td>\n",
       "      <td>0.702419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.147700</td>\n",
       "      <td>0.299029</td>\n",
       "      <td>0.660450</td>\n",
       "      <td>0.775746</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.681607</td>\n",
       "      <td>0.647760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.147700</td>\n",
       "      <td>0.300136</td>\n",
       "      <td>0.655305</td>\n",
       "      <td>0.733175</td>\n",
       "      <td>0.698341</td>\n",
       "      <td>0.715334</td>\n",
       "      <td>0.689976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.147700</td>\n",
       "      <td>0.317394</td>\n",
       "      <td>0.661736</td>\n",
       "      <td>0.745164</td>\n",
       "      <td>0.668175</td>\n",
       "      <td>0.704573</td>\n",
       "      <td>0.694170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.147700</td>\n",
       "      <td>0.314433</td>\n",
       "      <td>0.666238</td>\n",
       "      <td>0.729584</td>\n",
       "      <td>0.714178</td>\n",
       "      <td>0.721799</td>\n",
       "      <td>0.708856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.051900</td>\n",
       "      <td>0.321538</td>\n",
       "      <td>0.666881</td>\n",
       "      <td>0.760309</td>\n",
       "      <td>0.667421</td>\n",
       "      <td>0.710843</td>\n",
       "      <td>0.693288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.051900</td>\n",
       "      <td>0.323824</td>\n",
       "      <td>0.671383</td>\n",
       "      <td>0.750825</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.717100</td>\n",
       "      <td>0.702617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.88      0.89       362\n",
      "                sara       0.58      0.52      0.55       237\n",
      "         radikalisme       0.72      0.71      0.72       235\n",
      "pencemaran_nama_baik       0.68      0.69      0.68       492\n",
      "\n",
      "           micro avg       0.73      0.71      0.72      1326\n",
      "           macro avg       0.72      0.70      0.71      1326\n",
      "        weighted avg       0.73      0.71      0.72      1326\n",
      "         samples avg       0.42      0.41      0.41      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1969: Accuracy: 0.6662379421221865, F1 Micro: 0.7217987804878048, F1 Macro: 0.7088562070959576\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.88      0.89       362\n",
      "                sara       0.58      0.52      0.55       237\n",
      "         radikalisme       0.72      0.71      0.72       235\n",
      "pencemaran_nama_baik       0.68      0.69      0.68       492\n",
      "\n",
      "           micro avg       0.73      0.71      0.72      1326\n",
      "           macro avg       0.72      0.70      0.71      1326\n",
      "        weighted avg       0.73      0.71      0.72      1326\n",
      "         samples avg       0.42      0.41      0.41      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 22.308552551269532\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 425\n",
      "Sampling duration: 14.917022228240967 seconds\n",
      "New train size: 2394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:30, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.360553</td>\n",
       "      <td>0.605788</td>\n",
       "      <td>0.854991</td>\n",
       "      <td>0.342383</td>\n",
       "      <td>0.488961</td>\n",
       "      <td>0.389920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266159</td>\n",
       "      <td>0.645659</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.670437</td>\n",
       "      <td>0.704717</td>\n",
       "      <td>0.671246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.272191</td>\n",
       "      <td>0.647588</td>\n",
       "      <td>0.715134</td>\n",
       "      <td>0.726998</td>\n",
       "      <td>0.721017</td>\n",
       "      <td>0.709329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.160800</td>\n",
       "      <td>0.283903</td>\n",
       "      <td>0.663023</td>\n",
       "      <td>0.775529</td>\n",
       "      <td>0.635747</td>\n",
       "      <td>0.698715</td>\n",
       "      <td>0.667481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.160800</td>\n",
       "      <td>0.285202</td>\n",
       "      <td>0.672669</td>\n",
       "      <td>0.779783</td>\n",
       "      <td>0.651584</td>\n",
       "      <td>0.709942</td>\n",
       "      <td>0.685383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.160800</td>\n",
       "      <td>0.300943</td>\n",
       "      <td>0.667524</td>\n",
       "      <td>0.752902</td>\n",
       "      <td>0.684766</td>\n",
       "      <td>0.717220</td>\n",
       "      <td>0.694573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>0.306030</td>\n",
       "      <td>0.681029</td>\n",
       "      <td>0.758143</td>\n",
       "      <td>0.702112</td>\n",
       "      <td>0.729052</td>\n",
       "      <td>0.711974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>0.322226</td>\n",
       "      <td>0.672026</td>\n",
       "      <td>0.749390</td>\n",
       "      <td>0.694570</td>\n",
       "      <td>0.720939</td>\n",
       "      <td>0.701485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>0.327216</td>\n",
       "      <td>0.674598</td>\n",
       "      <td>0.754591</td>\n",
       "      <td>0.681750</td>\n",
       "      <td>0.716323</td>\n",
       "      <td>0.698538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.333296</td>\n",
       "      <td>0.674598</td>\n",
       "      <td>0.760720</td>\n",
       "      <td>0.668929</td>\n",
       "      <td>0.711878</td>\n",
       "      <td>0.684678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.89      0.90       362\n",
      "                sara       0.62      0.46      0.53       237\n",
      "         radikalisme       0.74      0.71      0.73       235\n",
      "pencemaran_nama_baik       0.70      0.67      0.69       492\n",
      "\n",
      "           micro avg       0.76      0.70      0.73      1326\n",
      "           macro avg       0.74      0.69      0.71      1326\n",
      "        weighted avg       0.75      0.70      0.73      1326\n",
      "         samples avg       0.42      0.41      0.40      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2394: Accuracy: 0.6810289389067524, F1 Micro: 0.7290524667188724, F1 Macro: 0.7119744884793027\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.89      0.90       362\n",
      "                sara       0.62      0.46      0.53       237\n",
      "         radikalisme       0.74      0.71      0.73       235\n",
      "pencemaran_nama_baik       0.70      0.67      0.69       492\n",
      "\n",
      "           micro avg       0.76      0.70      0.73      1326\n",
      "           macro avg       0.74      0.69      0.71      1326\n",
      "        weighted avg       0.75      0.70      0.73      1326\n",
      "         samples avg       0.42      0.41      0.40      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 21.014312744140625\n",
      "Samples above threshold: 384\n",
      "Acquired samples: 384\n",
      "Sampling duration: 13.4156014919281 seconds\n",
      "New train size: 2778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1740' max='1740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1740/1740 06:09, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.345789</td>\n",
       "      <td>0.609646</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.332579</td>\n",
       "      <td>0.483023</td>\n",
       "      <td>0.385406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.307891</td>\n",
       "      <td>0.651447</td>\n",
       "      <td>0.856135</td>\n",
       "      <td>0.457768</td>\n",
       "      <td>0.596560</td>\n",
       "      <td>0.494183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.178900</td>\n",
       "      <td>0.265356</td>\n",
       "      <td>0.679100</td>\n",
       "      <td>0.813131</td>\n",
       "      <td>0.607089</td>\n",
       "      <td>0.695164</td>\n",
       "      <td>0.663426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.178900</td>\n",
       "      <td>0.277710</td>\n",
       "      <td>0.671383</td>\n",
       "      <td>0.793446</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>0.684955</td>\n",
       "      <td>0.655765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.178900</td>\n",
       "      <td>0.283980</td>\n",
       "      <td>0.668810</td>\n",
       "      <td>0.743550</td>\n",
       "      <td>0.717195</td>\n",
       "      <td>0.730134</td>\n",
       "      <td>0.712087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.077700</td>\n",
       "      <td>0.299652</td>\n",
       "      <td>0.663023</td>\n",
       "      <td>0.736963</td>\n",
       "      <td>0.724736</td>\n",
       "      <td>0.730798</td>\n",
       "      <td>0.710261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.077700</td>\n",
       "      <td>0.304510</td>\n",
       "      <td>0.677170</td>\n",
       "      <td>0.748031</td>\n",
       "      <td>0.716440</td>\n",
       "      <td>0.731895</td>\n",
       "      <td>0.722502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.077700</td>\n",
       "      <td>0.322348</td>\n",
       "      <td>0.668810</td>\n",
       "      <td>0.737125</td>\n",
       "      <td>0.723228</td>\n",
       "      <td>0.730110</td>\n",
       "      <td>0.709198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.324098</td>\n",
       "      <td>0.660450</td>\n",
       "      <td>0.732673</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.729064</td>\n",
       "      <td>0.713951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.327233</td>\n",
       "      <td>0.668810</td>\n",
       "      <td>0.734866</td>\n",
       "      <td>0.723228</td>\n",
       "      <td>0.729000</td>\n",
       "      <td>0.713871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.87      0.90       362\n",
      "                sara       0.60      0.55      0.57       237\n",
      "         radikalisme       0.74      0.72      0.73       235\n",
      "pencemaran_nama_baik       0.69      0.68      0.69       492\n",
      "\n",
      "           micro avg       0.75      0.72      0.73      1326\n",
      "           macro avg       0.74      0.71      0.72      1326\n",
      "        weighted avg       0.75      0.72      0.73      1326\n",
      "         samples avg       0.42      0.42      0.41      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2778: Accuracy: 0.6771704180064309, F1 Micro: 0.7318952234206472, F1 Macro: 0.7225016898977357\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.87      0.90       362\n",
      "                sara       0.60      0.55      0.57       237\n",
      "         radikalisme       0.74      0.72      0.73       235\n",
      "pencemaran_nama_baik       0.69      0.68      0.69       492\n",
      "\n",
      "           micro avg       0.75      0.72      0.73      1326\n",
      "           macro avg       0.74      0.71      0.72      1326\n",
      "        weighted avg       0.75      0.72      0.73      1326\n",
      "         samples avg       0.42      0.42      0.41      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 20.6895471572876\n",
      "Samples above threshold: 344\n",
      "Acquired samples: 344\n",
      "Sampling duration: 12.037031173706055 seconds\n",
      "New train size: 3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='1960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/1960 06:43, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.317437</td>\n",
       "      <td>0.620579</td>\n",
       "      <td>0.835843</td>\n",
       "      <td>0.418552</td>\n",
       "      <td>0.557789</td>\n",
       "      <td>0.472766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.261823</td>\n",
       "      <td>0.675241</td>\n",
       "      <td>0.714187</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.744857</td>\n",
       "      <td>0.734724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.189000</td>\n",
       "      <td>0.255753</td>\n",
       "      <td>0.679743</td>\n",
       "      <td>0.805061</td>\n",
       "      <td>0.647813</td>\n",
       "      <td>0.717927</td>\n",
       "      <td>0.678224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.189000</td>\n",
       "      <td>0.258444</td>\n",
       "      <td>0.684244</td>\n",
       "      <td>0.760474</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.742570</td>\n",
       "      <td>0.728163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.189000</td>\n",
       "      <td>0.279612</td>\n",
       "      <td>0.674598</td>\n",
       "      <td>0.759839</td>\n",
       "      <td>0.713424</td>\n",
       "      <td>0.735900</td>\n",
       "      <td>0.712510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.093300</td>\n",
       "      <td>0.284823</td>\n",
       "      <td>0.686817</td>\n",
       "      <td>0.753058</td>\n",
       "      <td>0.742836</td>\n",
       "      <td>0.747912</td>\n",
       "      <td>0.739550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.093300</td>\n",
       "      <td>0.296491</td>\n",
       "      <td>0.688103</td>\n",
       "      <td>0.748489</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.747925</td>\n",
       "      <td>0.739972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.055600</td>\n",
       "      <td>0.314237</td>\n",
       "      <td>0.680386</td>\n",
       "      <td>0.752329</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.741393</td>\n",
       "      <td>0.726286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.055600</td>\n",
       "      <td>0.321179</td>\n",
       "      <td>0.676527</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.741463</td>\n",
       "      <td>0.730869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.055600</td>\n",
       "      <td>0.322834</td>\n",
       "      <td>0.681672</td>\n",
       "      <td>0.739421</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.745230</td>\n",
       "      <td>0.735185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.88      0.91       362\n",
      "                sara       0.62      0.54      0.58       237\n",
      "         radikalisme       0.78      0.77      0.77       235\n",
      "pencemaran_nama_baik       0.66      0.74      0.70       492\n",
      "\n",
      "           micro avg       0.75      0.75      0.75      1326\n",
      "           macro avg       0.75      0.73      0.74      1326\n",
      "        weighted avg       0.75      0.75      0.75      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3122: Accuracy: 0.6881028938906752, F1 Micro: 0.7479245283018867, F1 Macro: 0.7399724271076312\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.88      0.91       362\n",
      "                sara       0.62      0.54      0.58       237\n",
      "         radikalisme       0.78      0.77      0.77       235\n",
      "pencemaran_nama_baik       0.66      0.74      0.70       492\n",
      "\n",
      "           micro avg       0.75      0.75      0.75      1326\n",
      "           macro avg       0.75      0.73      0.74      1326\n",
      "        weighted avg       0.75      0.75      0.75      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 20.16983699798584\n",
      "Samples above threshold: 310\n",
      "Acquired samples: 310\n",
      "Sampling duration: 10.85038423538208 seconds\n",
      "New train size: 3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2150/2150 07:15, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.275758</td>\n",
       "      <td>0.649518</td>\n",
       "      <td>0.775647</td>\n",
       "      <td>0.610106</td>\n",
       "      <td>0.682989</td>\n",
       "      <td>0.613259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.244922</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.789923</td>\n",
       "      <td>0.697587</td>\n",
       "      <td>0.740889</td>\n",
       "      <td>0.726491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.200400</td>\n",
       "      <td>0.244179</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.782367</td>\n",
       "      <td>0.742836</td>\n",
       "      <td>0.762089</td>\n",
       "      <td>0.747683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.200400</td>\n",
       "      <td>0.257493</td>\n",
       "      <td>0.681672</td>\n",
       "      <td>0.733939</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.762146</td>\n",
       "      <td>0.759026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.277812</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.785345</td>\n",
       "      <td>0.687029</td>\n",
       "      <td>0.732904</td>\n",
       "      <td>0.712303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.280349</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.758955</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.762941</td>\n",
       "      <td>0.751360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>0.301474</td>\n",
       "      <td>0.678457</td>\n",
       "      <td>0.738197</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.757709</td>\n",
       "      <td>0.747572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.772586</td>\n",
       "      <td>0.748115</td>\n",
       "      <td>0.760153</td>\n",
       "      <td>0.749092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>0.304851</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.755720</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.763894</td>\n",
       "      <td>0.755944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.308992</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.751852</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.758595</td>\n",
       "      <td>0.748806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.89      0.90       362\n",
      "                sara       0.66      0.59      0.62       237\n",
      "         radikalisme       0.78      0.77      0.78       235\n",
      "pencemaran_nama_baik       0.68      0.77      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.77      0.76      1326\n",
      "           macro avg       0.76      0.76      0.76      1326\n",
      "        weighted avg       0.76      0.77      0.76      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3432: Accuracy: 0.6971061093247588, F1 Micro: 0.7638940693770981, F1 Macro: 0.755943778185957\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.89      0.90       362\n",
      "                sara       0.66      0.59      0.62       237\n",
      "         radikalisme       0.78      0.77      0.78       235\n",
      "pencemaran_nama_baik       0.68      0.77      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.77      0.76      1326\n",
      "           macro avg       0.76      0.76      0.76      1326\n",
      "        weighted avg       0.76      0.77      0.76      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 19.897738456726074\n",
      "Samples above threshold: 279\n",
      "Acquired samples: 279\n",
      "Sampling duration: 9.827316284179688 seconds\n",
      "New train size: 3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2320/2320 07:44, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.278483</td>\n",
       "      <td>0.645659</td>\n",
       "      <td>0.815696</td>\n",
       "      <td>0.517345</td>\n",
       "      <td>0.633133</td>\n",
       "      <td>0.582296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243671</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.772222</td>\n",
       "      <td>0.733786</td>\n",
       "      <td>0.752514</td>\n",
       "      <td>0.740063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.212600</td>\n",
       "      <td>0.241705</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.758775</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.762477</td>\n",
       "      <td>0.754928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.212600</td>\n",
       "      <td>0.252509</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.783828</td>\n",
       "      <td>0.716440</td>\n",
       "      <td>0.748621</td>\n",
       "      <td>0.725565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.114300</td>\n",
       "      <td>0.264730</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.743205</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.762849</td>\n",
       "      <td>0.756579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.114300</td>\n",
       "      <td>0.290614</td>\n",
       "      <td>0.681029</td>\n",
       "      <td>0.730526</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.756816</td>\n",
       "      <td>0.757159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.296347</td>\n",
       "      <td>0.686817</td>\n",
       "      <td>0.748547</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.762398</td>\n",
       "      <td>0.752924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.319362</td>\n",
       "      <td>0.677814</td>\n",
       "      <td>0.721733</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.760614</td>\n",
       "      <td>0.757847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.046300</td>\n",
       "      <td>0.310909</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.764165</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.758359</td>\n",
       "      <td>0.750005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.046300</td>\n",
       "      <td>0.316255</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.749088</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.761587</td>\n",
       "      <td>0.756268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.88      0.90       362\n",
      "                sara       0.65      0.62      0.64       237\n",
      "         radikalisme       0.73      0.79      0.76       235\n",
      "pencemaran_nama_baik       0.67      0.79      0.73       492\n",
      "\n",
      "           micro avg       0.74      0.78      0.76      1326\n",
      "           macro avg       0.75      0.77      0.76      1326\n",
      "        weighted avg       0.75      0.78      0.76      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3711: Accuracy: 0.6893890675241158, F1 Micro: 0.762848751835536, F1 Macro: 0.756579481023691\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.88      0.90       362\n",
      "                sara       0.65      0.62      0.64       237\n",
      "         radikalisme       0.73      0.79      0.76       235\n",
      "pencemaran_nama_baik       0.67      0.79      0.73       492\n",
      "\n",
      "           micro avg       0.74      0.78      0.76      1326\n",
      "           macro avg       0.75      0.77      0.76      1326\n",
      "        weighted avg       0.75      0.78      0.76      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 19.181897735595705\n",
      "Samples above threshold: 251\n",
      "Acquired samples: 175\n",
      "Sampling duration: 9.009800910949707 seconds\n",
      "New train size: 3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2430' max='2430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2430/2430 08:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.269893</td>\n",
       "      <td>0.646945</td>\n",
       "      <td>0.772334</td>\n",
       "      <td>0.606335</td>\n",
       "      <td>0.679341</td>\n",
       "      <td>0.672329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.246316</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.792672</td>\n",
       "      <td>0.668929</td>\n",
       "      <td>0.725562</td>\n",
       "      <td>0.711026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.220200</td>\n",
       "      <td>0.246687</td>\n",
       "      <td>0.688103</td>\n",
       "      <td>0.749633</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.759673</td>\n",
       "      <td>0.752652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.220200</td>\n",
       "      <td>0.255564</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.734973</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.771326</td>\n",
       "      <td>0.769214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>0.261297</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.794362</td>\n",
       "      <td>0.722474</td>\n",
       "      <td>0.756714</td>\n",
       "      <td>0.740430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>0.281387</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.749641</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.768382</td>\n",
       "      <td>0.763325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.300727</td>\n",
       "      <td>0.686817</td>\n",
       "      <td>0.739192</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.762148</td>\n",
       "      <td>0.754907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.300108</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.770479</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.761069</td>\n",
       "      <td>0.748085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.756439</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.765736</td>\n",
       "      <td>0.757669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>0.312100</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.741637</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.763090</td>\n",
       "      <td>0.756276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.89      0.92       362\n",
      "                sara       0.60      0.74      0.66       237\n",
      "         radikalisme       0.72      0.82      0.77       235\n",
      "pencemaran_nama_baik       0.69      0.78      0.73       492\n",
      "\n",
      "           micro avg       0.73      0.81      0.77      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.44      0.46      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3886: Accuracy: 0.6977491961414791, F1 Micro: 0.7713261648745521, F1 Macro: 0.7692144456485993\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.89      0.92       362\n",
      "                sara       0.60      0.74      0.66       237\n",
      "         radikalisme       0.72      0.82      0.77       235\n",
      "pencemaran_nama_baik       0.69      0.78      0.73       492\n",
      "\n",
      "           micro avg       0.73      0.81      0.77      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.44      0.46      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 18.456042098999024\n",
      "Samples above threshold: 234\n",
      "Acquired samples: 234\n",
      "Sampling duration: 8.266539096832275 seconds\n",
      "New train size: 4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 08:26, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.270710</td>\n",
       "      <td>0.646302</td>\n",
       "      <td>0.808808</td>\n",
       "      <td>0.567873</td>\n",
       "      <td>0.667257</td>\n",
       "      <td>0.581424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.231600</td>\n",
       "      <td>0.239113</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.768936</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.763388</td>\n",
       "      <td>0.756720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.231600</td>\n",
       "      <td>0.249106</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.736915</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.770338</td>\n",
       "      <td>0.764955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.128700</td>\n",
       "      <td>0.251368</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.757957</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.765035</td>\n",
       "      <td>0.755084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.128700</td>\n",
       "      <td>0.261872</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.760822</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.771290</td>\n",
       "      <td>0.766791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.280054</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.738440</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.771171</td>\n",
       "      <td>0.764001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.288967</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.765554</td>\n",
       "      <td>0.760935</td>\n",
       "      <td>0.763238</td>\n",
       "      <td>0.755374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>0.318181</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.726725</td>\n",
       "      <td>0.818250</td>\n",
       "      <td>0.769777</td>\n",
       "      <td>0.767071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>0.311511</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.743041</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.763476</td>\n",
       "      <td>0.754639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.043800</td>\n",
       "      <td>0.309043</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.756914</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.762555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.67      0.66      0.67       237\n",
      "         radikalisme       0.72      0.81      0.76       235\n",
      "pencemaran_nama_baik       0.71      0.75      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.78      0.77      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.76      0.78      0.77      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4120: Accuracy: 0.7022508038585209, F1 Micro: 0.7712904425436965, F1 Macro: 0.7667911880925126\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.67      0.66      0.67       237\n",
      "         radikalisme       0.72      0.81      0.76       235\n",
      "pencemaran_nama_baik       0.71      0.75      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.78      0.77      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.76      0.78      0.77      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 19.52783031463623\n",
      "Samples above threshold: 210\n",
      "Acquired samples: 210\n",
      "Sampling duration: 7.39797568321228 seconds\n",
      "New train size: 4330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2710' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2710/2710 08:46, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.273442</td>\n",
       "      <td>0.648875</td>\n",
       "      <td>0.830012</td>\n",
       "      <td>0.533937</td>\n",
       "      <td>0.649839</td>\n",
       "      <td>0.616883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.237800</td>\n",
       "      <td>0.241966</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.783182</td>\n",
       "      <td>0.716440</td>\n",
       "      <td>0.748326</td>\n",
       "      <td>0.730284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.237800</td>\n",
       "      <td>0.240304</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.759559</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.769173</td>\n",
       "      <td>0.759477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.132500</td>\n",
       "      <td>0.245769</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.773819</td>\n",
       "      <td>0.753394</td>\n",
       "      <td>0.763470</td>\n",
       "      <td>0.748734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.132500</td>\n",
       "      <td>0.280913</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.732215</td>\n",
       "      <td>0.822775</td>\n",
       "      <td>0.774858</td>\n",
       "      <td>0.771964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.088900</td>\n",
       "      <td>0.273256</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.781903</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.772050</td>\n",
       "      <td>0.763668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.088900</td>\n",
       "      <td>0.299523</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.754323</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.771555</td>\n",
       "      <td>0.766624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>0.319496</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.738652</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.772662</td>\n",
       "      <td>0.769974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>0.312608</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.759764</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.768543</td>\n",
       "      <td>0.761476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.318807</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.754825</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.775046</td>\n",
       "      <td>0.771235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.91      0.92       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.69      0.76      0.72       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4330: Accuracy: 0.7099678456591639, F1 Micro: 0.775045871559633, F1 Macro: 0.771234887696188\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.91      0.92       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.69      0.76      0.72       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 18.73076629638672\n",
      "Samples above threshold: 189\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.681150436401367 seconds\n",
      "New train size: 4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2840' max='2840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2840/2840 09:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.280399</td>\n",
       "      <td>0.650161</td>\n",
       "      <td>0.836145</td>\n",
       "      <td>0.523379</td>\n",
       "      <td>0.643785</td>\n",
       "      <td>0.601690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.242000</td>\n",
       "      <td>0.245544</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.737131</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.771829</td>\n",
       "      <td>0.767701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.242000</td>\n",
       "      <td>0.240870</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.782780</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.764660</td>\n",
       "      <td>0.747014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.143600</td>\n",
       "      <td>0.257082</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.753571</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.774028</td>\n",
       "      <td>0.765412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.143600</td>\n",
       "      <td>0.273427</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.737526</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.773754</td>\n",
       "      <td>0.770038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.098400</td>\n",
       "      <td>0.276648</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.766390</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.766679</td>\n",
       "      <td>0.758492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.098400</td>\n",
       "      <td>0.299647</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.751061</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.769066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.319295</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.732519</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.770990</td>\n",
       "      <td>0.767401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.327191</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.737449</td>\n",
       "      <td>0.819759</td>\n",
       "      <td>0.776429</td>\n",
       "      <td>0.773833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.317851</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.751070</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.771994</td>\n",
       "      <td>0.767091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.62      0.73      0.67       237\n",
      "         radikalisme       0.71      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.80      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.82      0.78      1326\n",
      "           macro avg       0.74      0.82      0.77      1326\n",
      "        weighted avg       0.75      0.82      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4530: Accuracy: 0.707395498392283, F1 Micro: 0.7764285714285715, F1 Macro: 0.7738330229960001\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.62      0.73      0.67       237\n",
      "         radikalisme       0.71      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.80      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.82      0.78      1326\n",
      "           macro avg       0.74      0.82      0.77      1326\n",
      "        weighted avg       0.75      0.82      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 18.276095390319824\n",
      "Samples above threshold: 169\n",
      "Acquired samples: 133\n",
      "Sampling duration: 6.120131254196167 seconds\n",
      "New train size: 4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2920' max='2920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2920/2920 09:21, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.261237</td>\n",
       "      <td>0.673312</td>\n",
       "      <td>0.811550</td>\n",
       "      <td>0.604072</td>\n",
       "      <td>0.692607</td>\n",
       "      <td>0.675354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.247800</td>\n",
       "      <td>0.245051</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.805240</td>\n",
       "      <td>0.695324</td>\n",
       "      <td>0.746257</td>\n",
       "      <td>0.735243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.247800</td>\n",
       "      <td>0.233334</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.780109</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>0.768465</td>\n",
       "      <td>0.753380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.145800</td>\n",
       "      <td>0.254871</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.739876</td>\n",
       "      <td>0.812971</td>\n",
       "      <td>0.774704</td>\n",
       "      <td>0.768449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.145800</td>\n",
       "      <td>0.274319</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.721897</td>\n",
       "      <td>0.837858</td>\n",
       "      <td>0.775567</td>\n",
       "      <td>0.775734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.286539</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.740055</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.775144</td>\n",
       "      <td>0.770951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.069900</td>\n",
       "      <td>0.291773</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.760319</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.775767</td>\n",
       "      <td>0.769190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069900</td>\n",
       "      <td>0.301399</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.767374</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.779057</td>\n",
       "      <td>0.771991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.050200</td>\n",
       "      <td>0.312230</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.756184</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.780737</td>\n",
       "      <td>0.776272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.050200</td>\n",
       "      <td>0.317870</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.754423</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.778386</td>\n",
       "      <td>0.772536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.92       362\n",
      "                sara       0.64      0.68      0.66       237\n",
      "         radikalisme       0.75      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.70      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.78      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4663: Accuracy: 0.7131832797427653, F1 Micro: 0.7807369573148486, F1 Macro: 0.7762723791776763\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.92       362\n",
      "                sara       0.64      0.68      0.66       237\n",
      "         radikalisme       0.75      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.70      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.78      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 18.13023452758789\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.517064094543457 seconds\n",
      "New train size: 4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3040' max='3040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3040/3040 09:42, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.251115</td>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.782379</td>\n",
       "      <td>0.669683</td>\n",
       "      <td>0.721658</td>\n",
       "      <td>0.711253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.253900</td>\n",
       "      <td>0.245247</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.716389</td>\n",
       "      <td>0.843891</td>\n",
       "      <td>0.774931</td>\n",
       "      <td>0.771872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.253900</td>\n",
       "      <td>0.239990</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.745775</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.771304</td>\n",
       "      <td>0.764810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.159900</td>\n",
       "      <td>0.252418</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.735951</td>\n",
       "      <td>0.819759</td>\n",
       "      <td>0.775598</td>\n",
       "      <td>0.771776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.110700</td>\n",
       "      <td>0.267204</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.744314</td>\n",
       "      <td>0.814480</td>\n",
       "      <td>0.777818</td>\n",
       "      <td>0.770268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.110700</td>\n",
       "      <td>0.280721</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.749298</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.768753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.078400</td>\n",
       "      <td>0.281475</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.761632</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.781491</td>\n",
       "      <td>0.774153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.078400</td>\n",
       "      <td>0.300241</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.759745</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.783339</td>\n",
       "      <td>0.777187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.310573</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.763899</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.780524</td>\n",
       "      <td>0.772081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.315407</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.779636</td>\n",
       "      <td>0.773722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.91      0.92       362\n",
      "                sara       0.63      0.70      0.66       237\n",
      "         radikalisme       0.72      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.78      1326\n",
      "           macro avg       0.75      0.81      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4863: Accuracy: 0.7196141479099678, F1 Micro: 0.7833394227256121, F1 Macro: 0.7771865529110269\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.91      0.92       362\n",
      "                sara       0.63      0.70      0.66       237\n",
      "         radikalisme       0.72      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.78      1326\n",
      "           macro avg       0.75      0.81      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 18.711044311523438\n",
      "Samples above threshold: 136\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.799919128417969 seconds\n",
      "New train size: 5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3170' max='3170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3170/3170 10:04, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250220</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.759690</td>\n",
       "      <td>0.739065</td>\n",
       "      <td>0.749235</td>\n",
       "      <td>0.746265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.258800</td>\n",
       "      <td>0.233578</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.774517</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.765357</td>\n",
       "      <td>0.763342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.258800</td>\n",
       "      <td>0.232211</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.766396</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.775252</td>\n",
       "      <td>0.770681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.162400</td>\n",
       "      <td>0.238723</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.772455</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.775357</td>\n",
       "      <td>0.769160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.117600</td>\n",
       "      <td>0.277495</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.717185</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.779194</td>\n",
       "      <td>0.776604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.117600</td>\n",
       "      <td>0.276841</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.772495</td>\n",
       "      <td>0.763311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.084600</td>\n",
       "      <td>0.284403</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.753879</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.779155</td>\n",
       "      <td>0.772234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.308663</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.738292</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.771778</td>\n",
       "      <td>0.765484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.314762</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.745179</td>\n",
       "      <td>0.815988</td>\n",
       "      <td>0.778978</td>\n",
       "      <td>0.772360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.047900</td>\n",
       "      <td>0.310960</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.751233</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.776685</td>\n",
       "      <td>0.769557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.88      0.91       362\n",
      "                sara       0.57      0.81      0.67       237\n",
      "         radikalisme       0.69      0.86      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.85      0.76       492\n",
      "\n",
      "           micro avg       0.72      0.85      0.78      1326\n",
      "           macro avg       0.72      0.85      0.78      1326\n",
      "        weighted avg       0.74      0.85      0.79      1326\n",
      "         samples avg       0.46      0.48      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5063: Accuracy: 0.7016077170418007, F1 Micro: 0.779193937306235, F1 Macro: 0.7766044113195493\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.88      0.91       362\n",
      "                sara       0.57      0.81      0.67       237\n",
      "         radikalisme       0.69      0.86      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.85      0.76       492\n",
      "\n",
      "           micro avg       0.72      0.85      0.78      1326\n",
      "           macro avg       0.72      0.85      0.78      1326\n",
      "        weighted avg       0.74      0.85      0.79      1326\n",
      "         samples avg       0.46      0.48      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 17.793231582641603\n",
      "Samples above threshold: 116\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.168260335922241 seconds\n",
      "New train size: 5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3290' max='3290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3290/3290 10:25, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.253653</td>\n",
       "      <td>0.687460</td>\n",
       "      <td>0.768020</td>\n",
       "      <td>0.699095</td>\n",
       "      <td>0.731938</td>\n",
       "      <td>0.713182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.261900</td>\n",
       "      <td>0.232087</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.747022</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.774428</td>\n",
       "      <td>0.771784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.261900</td>\n",
       "      <td>0.228674</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.770310</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.778358</td>\n",
       "      <td>0.771680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.177000</td>\n",
       "      <td>0.242484</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.761388</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.777409</td>\n",
       "      <td>0.771272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.122800</td>\n",
       "      <td>0.261087</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.749644</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.771596</td>\n",
       "      <td>0.758625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.122800</td>\n",
       "      <td>0.265538</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.763756</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.774266</td>\n",
       "      <td>0.764402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.090500</td>\n",
       "      <td>0.276805</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.760965</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.772829</td>\n",
       "      <td>0.763295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.065600</td>\n",
       "      <td>0.293010</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.759300</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.771969</td>\n",
       "      <td>0.761577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.065600</td>\n",
       "      <td>0.297070</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.766052</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.774338</td>\n",
       "      <td>0.763750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.053200</td>\n",
       "      <td>0.307359</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.748945</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.775109</td>\n",
       "      <td>0.768134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.87      0.91       362\n",
      "                sara       0.67      0.64      0.65       237\n",
      "         radikalisme       0.71      0.87      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5263: Accuracy: 0.7183279742765273, F1 Micro: 0.778358208955224, F1 Macro: 0.7716804581807537\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.87      0.91       362\n",
      "                sara       0.67      0.64      0.65       237\n",
      "         radikalisme       0.71      0.87      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 16.97161102294922\n",
      "Samples above threshold: 96\n",
      "Acquired samples: 178\n",
      "Sampling duration: 3.6850056648254395 seconds\n",
      "New train size: 5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3410' max='3410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3410/3410 10:44, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256064</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.791552</td>\n",
       "      <td>0.650075</td>\n",
       "      <td>0.713872</td>\n",
       "      <td>0.710991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.273700</td>\n",
       "      <td>0.230590</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.752113</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.777859</td>\n",
       "      <td>0.775469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.179500</td>\n",
       "      <td>0.227126</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.774854</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.786934</td>\n",
       "      <td>0.778269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.179500</td>\n",
       "      <td>0.236808</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.780938</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.773506</td>\n",
       "      <td>0.765048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.129800</td>\n",
       "      <td>0.271146</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.837104</td>\n",
       "      <td>0.777311</td>\n",
       "      <td>0.774201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.092400</td>\n",
       "      <td>0.294727</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.722149</td>\n",
       "      <td>0.831071</td>\n",
       "      <td>0.772791</td>\n",
       "      <td>0.769202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.092400</td>\n",
       "      <td>0.296836</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.740868</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.774217</td>\n",
       "      <td>0.765775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.296465</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.775188</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.776355</td>\n",
       "      <td>0.766868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.309089</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.759339</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.771005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.307054</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.764069</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.780973</td>\n",
       "      <td>0.772791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.96      0.88      0.91       362\n",
      "                sara       0.67      0.64      0.66       237\n",
      "         radikalisme       0.72      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.80      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5441: Accuracy: 0.7266881028938906, F1 Micro: 0.7869339272457313, F1 Macro: 0.7782690336215752\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.96      0.88      0.91       362\n",
      "                sara       0.67      0.64      0.66       237\n",
      "         radikalisme       0.72      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.80      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 16.60842971801758\n",
      "Samples above threshold: 78\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.92208194732666 seconds\n",
      "New train size: 5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3530' max='3530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3530/3530 11:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.245555</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.766983</td>\n",
       "      <td>0.732278</td>\n",
       "      <td>0.749228</td>\n",
       "      <td>0.742360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.276000</td>\n",
       "      <td>0.225357</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.792875</td>\n",
       "      <td>0.721719</td>\n",
       "      <td>0.755626</td>\n",
       "      <td>0.743323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.183700</td>\n",
       "      <td>0.223681</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.790297</td>\n",
       "      <td>0.761689</td>\n",
       "      <td>0.775730</td>\n",
       "      <td>0.759386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.183700</td>\n",
       "      <td>0.241759</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.750345</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.783862</td>\n",
       "      <td>0.774990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.138700</td>\n",
       "      <td>0.244093</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.764448</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.776086</td>\n",
       "      <td>0.767200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.103100</td>\n",
       "      <td>0.270668</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.758496</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.774456</td>\n",
       "      <td>0.765352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.103100</td>\n",
       "      <td>0.273731</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.766035</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.779096</td>\n",
       "      <td>0.771782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.079300</td>\n",
       "      <td>0.295055</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.761665</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.780434</td>\n",
       "      <td>0.771317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.058800</td>\n",
       "      <td>0.301626</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.768833</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.776866</td>\n",
       "      <td>0.765678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.051600</td>\n",
       "      <td>0.315089</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.752793</td>\n",
       "      <td>0.812971</td>\n",
       "      <td>0.781726</td>\n",
       "      <td>0.774105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.91       362\n",
      "                sara       0.62      0.68      0.65       237\n",
      "         radikalisme       0.71      0.86      0.77       235\n",
      "pencemaran_nama_baik       0.73      0.80      0.76       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.82      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5641: Accuracy: 0.715112540192926, F1 Micro: 0.7838616714697405, F1 Macro: 0.7749897005763335\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.91       362\n",
      "                sara       0.62      0.68      0.65       237\n",
      "         radikalisme       0.71      0.86      0.77       235\n",
      "pencemaran_nama_baik       0.73      0.80      0.76       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.82      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 16.23237724304199\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.2188174724578857 seconds\n",
      "New train size: 5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3660' max='3660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3660/3660 11:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.242101</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.792388</td>\n",
       "      <td>0.690799</td>\n",
       "      <td>0.738114</td>\n",
       "      <td>0.728879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.282700</td>\n",
       "      <td>0.236381</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.742994</td>\n",
       "      <td>0.819759</td>\n",
       "      <td>0.779491</td>\n",
       "      <td>0.773811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.188800</td>\n",
       "      <td>0.226691</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.764875</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.784270</td>\n",
       "      <td>0.778141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.188800</td>\n",
       "      <td>0.249999</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.733157</td>\n",
       "      <td>0.837104</td>\n",
       "      <td>0.781690</td>\n",
       "      <td>0.778130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.146800</td>\n",
       "      <td>0.253543</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.761087</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.781204</td>\n",
       "      <td>0.775591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>0.265362</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.784024</td>\n",
       "      <td>0.775033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>0.289379</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.761364</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.784199</td>\n",
       "      <td>0.778332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>0.299266</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.768158</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.778728</td>\n",
       "      <td>0.773353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.304407</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.775130</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.780067</td>\n",
       "      <td>0.774568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>0.313060</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.783824</td>\n",
       "      <td>0.777159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.65      0.69      0.67       237\n",
      "         radikalisme       0.71      0.88      0.79       235\n",
      "pencemaran_nama_baik       0.75      0.75      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.80      0.78      1326\n",
      "           macro avg       0.75      0.81      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5841: Accuracy: 0.7209003215434083, F1 Micro: 0.7842704887908857, F1 Macro: 0.7781410278314324\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.65      0.69      0.67       237\n",
      "         radikalisme       0.71      0.88      0.79       235\n",
      "pencemaran_nama_baik       0.75      0.75      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.80      0.78      1326\n",
      "           macro avg       0.75      0.81      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 15.26936779022217\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 200\n",
      "Sampling duration: 1.5443365573883057 seconds\n",
      "New train size: 6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3780' max='3780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3780/3780 11:49, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.240717</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.777152</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.752044</td>\n",
       "      <td>0.736825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.287200</td>\n",
       "      <td>0.229039</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.708899</td>\n",
       "      <td>0.751699</td>\n",
       "      <td>0.726207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.197200</td>\n",
       "      <td>0.219516</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.774295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.151100</td>\n",
       "      <td>0.238750</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.765086</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.783664</td>\n",
       "      <td>0.775304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.151100</td>\n",
       "      <td>0.262668</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.747779</td>\n",
       "      <td>0.825038</td>\n",
       "      <td>0.784511</td>\n",
       "      <td>0.781091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.114000</td>\n",
       "      <td>0.262945</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.777654</td>\n",
       "      <td>0.772337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.084800</td>\n",
       "      <td>0.287063</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.761024</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.783309</td>\n",
       "      <td>0.776311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.287621</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.779522</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.783033</td>\n",
       "      <td>0.776791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.304812</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.766112</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.781677</td>\n",
       "      <td>0.776152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.304762</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.770468</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.782480</td>\n",
       "      <td>0.776941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.65      0.69      0.67       237\n",
      "         radikalisme       0.77      0.81      0.79       235\n",
      "pencemaran_nama_baik       0.67      0.84      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.83      0.78      1326\n",
      "           macro avg       0.76      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.83      0.79      1326\n",
      "         samples avg       0.47      0.47      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6041: Accuracy: 0.7086816720257235, F1 Micro: 0.7845105772678379, F1 Macro: 0.78109113869405\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.65      0.69      0.67       237\n",
      "         radikalisme       0.77      0.81      0.79       235\n",
      "pencemaran_nama_baik       0.67      0.84      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.83      0.78      1326\n",
      "           macro avg       0.76      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.83      0.79      1326\n",
      "         samples avg       0.47      0.47      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 14.128590774536132\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 177\n",
      "Sampling duration: 1.107177495956421 seconds\n",
      "New train size: 6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3890/3890 12:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.242019</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.744928</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.759793</td>\n",
       "      <td>0.750383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.297700</td>\n",
       "      <td>0.223420</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.790660</td>\n",
       "      <td>0.740573</td>\n",
       "      <td>0.764798</td>\n",
       "      <td>0.755066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.204700</td>\n",
       "      <td>0.218579</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.768895</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.783124</td>\n",
       "      <td>0.776561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.158000</td>\n",
       "      <td>0.233555</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.781722</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.781132</td>\n",
       "      <td>0.774697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.158000</td>\n",
       "      <td>0.243784</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.762348</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.782225</td>\n",
       "      <td>0.771391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.262557</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.764085</td>\n",
       "      <td>0.818250</td>\n",
       "      <td>0.790240</td>\n",
       "      <td>0.782974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.093700</td>\n",
       "      <td>0.279064</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.760854</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.782863</td>\n",
       "      <td>0.775345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.294827</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.762074</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.784931</td>\n",
       "      <td>0.779366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>0.303275</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.764037</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.786681</td>\n",
       "      <td>0.780281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>0.304875</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.766262</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.786789</td>\n",
       "      <td>0.779535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.93      0.91       362\n",
      "                sara       0.65      0.68      0.66       237\n",
      "         radikalisme       0.74      0.88      0.80       235\n",
      "pencemaran_nama_baik       0.74      0.77      0.76       492\n",
      "\n",
      "           micro avg       0.76      0.82      0.79      1326\n",
      "           macro avg       0.75      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.82      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6218: Accuracy: 0.7254019292604501, F1 Micro: 0.7902403495994172, F1 Macro: 0.7829741257550714\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.93      0.91       362\n",
      "                sara       0.65      0.68      0.66       237\n",
      "         radikalisme       0.74      0.88      0.80       235\n",
      "pencemaran_nama_baik       0.74      0.77      0.76       492\n",
      "\n",
      "           micro avg       0.76      0.82      0.79      1326\n",
      "           macro avg       0.75      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.82      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n",
      "Total sampling time: 180.31 seconds\n",
      "Total runtime: 11130.863033294678 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43466405",
   "metadata": {},
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ed8b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b113876e511049e19d9c10eef659bb18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241219_090220-uq7347ks\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m./results/netifier-coreset-3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/nicost918-petra-christian-university/huggingface\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/nicost918-petra-christian-university/huggingface/runs/uq7347ks\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 02:24, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.466312</td>\n",
       "      <td>0.447588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.022427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.392322</td>\n",
       "      <td>0.554984</td>\n",
       "      <td>0.920290</td>\n",
       "      <td>0.191554</td>\n",
       "      <td>0.317104</td>\n",
       "      <td>0.211713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.349551</td>\n",
       "      <td>0.584566</td>\n",
       "      <td>0.834646</td>\n",
       "      <td>0.319759</td>\n",
       "      <td>0.462377</td>\n",
       "      <td>0.381456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.331326</td>\n",
       "      <td>0.586495</td>\n",
       "      <td>0.799035</td>\n",
       "      <td>0.374811</td>\n",
       "      <td>0.510267</td>\n",
       "      <td>0.438305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.317812</td>\n",
       "      <td>0.590997</td>\n",
       "      <td>0.812303</td>\n",
       "      <td>0.388386</td>\n",
       "      <td>0.525510</td>\n",
       "      <td>0.465296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.312626</td>\n",
       "      <td>0.603859</td>\n",
       "      <td>0.802213</td>\n",
       "      <td>0.437406</td>\n",
       "      <td>0.566130</td>\n",
       "      <td>0.506563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.301693</td>\n",
       "      <td>0.610289</td>\n",
       "      <td>0.758030</td>\n",
       "      <td>0.533937</td>\n",
       "      <td>0.626549</td>\n",
       "      <td>0.600378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.300017</td>\n",
       "      <td>0.610932</td>\n",
       "      <td>0.759957</td>\n",
       "      <td>0.532428</td>\n",
       "      <td>0.626164</td>\n",
       "      <td>0.598342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.301048</td>\n",
       "      <td>0.610289</td>\n",
       "      <td>0.765419</td>\n",
       "      <td>0.524133</td>\n",
       "      <td>0.622202</td>\n",
       "      <td>0.587982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.300751</td>\n",
       "      <td>0.610289</td>\n",
       "      <td>0.768632</td>\n",
       "      <td>0.521116</td>\n",
       "      <td>0.621124</td>\n",
       "      <td>0.587391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.81      0.86       362\n",
      "                sara       0.64      0.25      0.36       237\n",
      "         radikalisme       0.68      0.66      0.67       235\n",
      "pencemaran_nama_baik       0.69      0.41      0.51       492\n",
      "\n",
      "           micro avg       0.76      0.53      0.63      1326\n",
      "           macro avg       0.73      0.53      0.60      1326\n",
      "        weighted avg       0.74      0.53      0.61      1326\n",
      "         samples avg       0.35      0.31      0.32      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 388: Accuracy: 0.6102893890675242, F1 Micro: 0.6265486725663717, F1 Macro: 0.6003779383425171\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.81      0.86       362\n",
      "                sara       0.64      0.25      0.36       237\n",
      "         radikalisme       0.68      0.66      0.67       235\n",
      "pencemaran_nama_baik       0.69      0.41      0.51       492\n",
      "\n",
      "           micro avg       0.76      0.53      0.63      1326\n",
      "           macro avg       0.73      0.53      0.60      1326\n",
      "        weighted avg       0.74      0.53      0.61      1326\n",
      "         samples avg       0.35      0.31      0.32      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 24.150782012939455\n",
      "Samples above threshold: 583\n",
      "Acquired samples: 583\n",
      "Sampling duration: 20.896555423736572 seconds\n",
      "New train size: 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [610/610 03:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.352159</td>\n",
       "      <td>0.567203</td>\n",
       "      <td>0.767169</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.476339</td>\n",
       "      <td>0.384188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.338369</td>\n",
       "      <td>0.590354</td>\n",
       "      <td>0.826230</td>\n",
       "      <td>0.380090</td>\n",
       "      <td>0.520661</td>\n",
       "      <td>0.428523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.325773</td>\n",
       "      <td>0.617363</td>\n",
       "      <td>0.839130</td>\n",
       "      <td>0.436652</td>\n",
       "      <td>0.574405</td>\n",
       "      <td>0.509877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.312565</td>\n",
       "      <td>0.627010</td>\n",
       "      <td>0.774228</td>\n",
       "      <td>0.548265</td>\n",
       "      <td>0.641943</td>\n",
       "      <td>0.595012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.311162</td>\n",
       "      <td>0.626367</td>\n",
       "      <td>0.735185</td>\n",
       "      <td>0.598793</td>\n",
       "      <td>0.660017</td>\n",
       "      <td>0.636888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.313549</td>\n",
       "      <td>0.632154</td>\n",
       "      <td>0.750695</td>\n",
       "      <td>0.610860</td>\n",
       "      <td>0.673597</td>\n",
       "      <td>0.637218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.317825</td>\n",
       "      <td>0.639871</td>\n",
       "      <td>0.755140</td>\n",
       "      <td>0.609351</td>\n",
       "      <td>0.674457</td>\n",
       "      <td>0.648364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.323047</td>\n",
       "      <td>0.635370</td>\n",
       "      <td>0.746175</td>\n",
       "      <td>0.625189</td>\n",
       "      <td>0.680345</td>\n",
       "      <td>0.650232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.122100</td>\n",
       "      <td>0.327552</td>\n",
       "      <td>0.635370</td>\n",
       "      <td>0.750234</td>\n",
       "      <td>0.604827</td>\n",
       "      <td>0.669729</td>\n",
       "      <td>0.644107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.122100</td>\n",
       "      <td>0.327740</td>\n",
       "      <td>0.639228</td>\n",
       "      <td>0.749314</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.677139</td>\n",
       "      <td>0.653861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.85      0.87       362\n",
      "                sara       0.63      0.34      0.44       237\n",
      "         radikalisme       0.76      0.56      0.64       235\n",
      "pencemaran_nama_baik       0.66      0.63      0.65       492\n",
      "\n",
      "           micro avg       0.75      0.63      0.68      1326\n",
      "           macro avg       0.74      0.59      0.65      1326\n",
      "        weighted avg       0.74      0.63      0.67      1326\n",
      "         samples avg       0.38      0.35      0.36      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 971: Accuracy: 0.6353697749196141, F1 Micro: 0.6803446860894543, F1 Macro: 0.6502318077631655\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.85      0.87       362\n",
      "                sara       0.63      0.34      0.44       237\n",
      "         radikalisme       0.76      0.56      0.64       235\n",
      "pencemaran_nama_baik       0.66      0.63      0.65       492\n",
      "\n",
      "           micro avg       0.75      0.63      0.68      1326\n",
      "           macro avg       0.74      0.59      0.65      1326\n",
      "        weighted avg       0.74      0.63      0.67      1326\n",
      "         samples avg       0.38      0.35      0.36      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 23.501198196411135\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 18.843034982681274 seconds\n",
      "New train size: 1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [940/940 04:16, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.327477</td>\n",
       "      <td>0.587138</td>\n",
       "      <td>0.670937</td>\n",
       "      <td>0.631976</td>\n",
       "      <td>0.650874</td>\n",
       "      <td>0.639136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.287769</td>\n",
       "      <td>0.646302</td>\n",
       "      <td>0.818792</td>\n",
       "      <td>0.552036</td>\n",
       "      <td>0.659459</td>\n",
       "      <td>0.642996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.278813</td>\n",
       "      <td>0.650161</td>\n",
       "      <td>0.764279</td>\n",
       "      <td>0.635747</td>\n",
       "      <td>0.694113</td>\n",
       "      <td>0.684108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.282871</td>\n",
       "      <td>0.657878</td>\n",
       "      <td>0.799401</td>\n",
       "      <td>0.604072</td>\n",
       "      <td>0.688144</td>\n",
       "      <td>0.655135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.283773</td>\n",
       "      <td>0.669453</td>\n",
       "      <td>0.805093</td>\n",
       "      <td>0.619910</td>\n",
       "      <td>0.700469</td>\n",
       "      <td>0.680241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.172700</td>\n",
       "      <td>0.296026</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.794428</td>\n",
       "      <td>0.623680</td>\n",
       "      <td>0.698775</td>\n",
       "      <td>0.681163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.172700</td>\n",
       "      <td>0.294243</td>\n",
       "      <td>0.668810</td>\n",
       "      <td>0.776386</td>\n",
       "      <td>0.654600</td>\n",
       "      <td>0.710311</td>\n",
       "      <td>0.696036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.172700</td>\n",
       "      <td>0.298232</td>\n",
       "      <td>0.663023</td>\n",
       "      <td>0.772968</td>\n",
       "      <td>0.659879</td>\n",
       "      <td>0.711961</td>\n",
       "      <td>0.693799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.172700</td>\n",
       "      <td>0.304357</td>\n",
       "      <td>0.662379</td>\n",
       "      <td>0.777575</td>\n",
       "      <td>0.643288</td>\n",
       "      <td>0.704086</td>\n",
       "      <td>0.683782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.172700</td>\n",
       "      <td>0.306928</td>\n",
       "      <td>0.666238</td>\n",
       "      <td>0.778890</td>\n",
       "      <td>0.645551</td>\n",
       "      <td>0.705979</td>\n",
       "      <td>0.685988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.84      0.89       362\n",
      "                sara       0.66      0.46      0.55       237\n",
      "         radikalisme       0.72      0.62      0.67       235\n",
      "pencemaran_nama_baik       0.72      0.64      0.68       492\n",
      "\n",
      "           micro avg       0.77      0.66      0.71      1326\n",
      "           macro avg       0.76      0.64      0.69      1326\n",
      "        weighted avg       0.77      0.66      0.71      1326\n",
      "         samples avg       0.38      0.37      0.36      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1496: Accuracy: 0.6630225080385852, F1 Micro: 0.7119609438567942, F1 Macro: 0.6937989937835953\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.84      0.89       362\n",
      "                sara       0.66      0.46      0.55       237\n",
      "         radikalisme       0.72      0.62      0.67       235\n",
      "pencemaran_nama_baik       0.72      0.64      0.68       492\n",
      "\n",
      "           micro avg       0.77      0.66      0.71      1326\n",
      "           macro avg       0.76      0.64      0.69      1326\n",
      "        weighted avg       0.77      0.66      0.71      1326\n",
      "         samples avg       0.38      0.37      0.36      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 22.331089019775394\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 16.89799737930298 seconds\n",
      "New train size: 1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1240' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1240/1240 05:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.342170</td>\n",
       "      <td>0.546624</td>\n",
       "      <td>0.597681</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.675844</td>\n",
       "      <td>0.677464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.282993</td>\n",
       "      <td>0.659807</td>\n",
       "      <td>0.740408</td>\n",
       "      <td>0.684012</td>\n",
       "      <td>0.711094</td>\n",
       "      <td>0.699169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.270309</td>\n",
       "      <td>0.676527</td>\n",
       "      <td>0.775952</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.722804</td>\n",
       "      <td>0.709675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.275297</td>\n",
       "      <td>0.676527</td>\n",
       "      <td>0.796364</td>\n",
       "      <td>0.660633</td>\n",
       "      <td>0.722176</td>\n",
       "      <td>0.704324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.280244</td>\n",
       "      <td>0.681672</td>\n",
       "      <td>0.799445</td>\n",
       "      <td>0.652338</td>\n",
       "      <td>0.718439</td>\n",
       "      <td>0.697830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.287215</td>\n",
       "      <td>0.677170</td>\n",
       "      <td>0.811357</td>\n",
       "      <td>0.635747</td>\n",
       "      <td>0.712896</td>\n",
       "      <td>0.701643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.292400</td>\n",
       "      <td>0.684244</td>\n",
       "      <td>0.798541</td>\n",
       "      <td>0.660633</td>\n",
       "      <td>0.723071</td>\n",
       "      <td>0.713550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.303012</td>\n",
       "      <td>0.676527</td>\n",
       "      <td>0.797373</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.710702</td>\n",
       "      <td>0.693827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>0.302632</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.784777</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.726610</td>\n",
       "      <td>0.715172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>0.305481</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.794595</td>\n",
       "      <td>0.665158</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.710019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.85      0.89       362\n",
      "                sara       0.69      0.53      0.60       237\n",
      "         radikalisme       0.71      0.68      0.69       235\n",
      "pencemaran_nama_baik       0.74      0.62      0.68       492\n",
      "\n",
      "           micro avg       0.78      0.68      0.73      1326\n",
      "           macro avg       0.77      0.67      0.72      1326\n",
      "        weighted avg       0.78      0.68      0.72      1326\n",
      "         samples avg       0.39      0.37      0.37      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1969: Accuracy: 0.682315112540193, F1 Micro: 0.7266099635479952, F1 Macro: 0.7151724376760238\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.85      0.89       362\n",
      "                sara       0.69      0.53      0.60       237\n",
      "         radikalisme       0.71      0.68      0.69       235\n",
      "pencemaran_nama_baik       0.74      0.62      0.68       492\n",
      "\n",
      "           micro avg       0.78      0.68      0.73      1326\n",
      "           macro avg       0.77      0.67      0.72      1326\n",
      "        weighted avg       0.78      0.68      0.72      1326\n",
      "         samples avg       0.39      0.37      0.37      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 20.69972801208496\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 425\n",
      "Sampling duration: 15.247282266616821 seconds\n",
      "New train size: 2394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:48, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.302687</td>\n",
       "      <td>0.621222</td>\n",
       "      <td>0.748609</td>\n",
       "      <td>0.608597</td>\n",
       "      <td>0.671381</td>\n",
       "      <td>0.660752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.270020</td>\n",
       "      <td>0.670740</td>\n",
       "      <td>0.752205</td>\n",
       "      <td>0.707391</td>\n",
       "      <td>0.729110</td>\n",
       "      <td>0.723677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.267610</td>\n",
       "      <td>0.669453</td>\n",
       "      <td>0.782918</td>\n",
       "      <td>0.663650</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.695206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.255400</td>\n",
       "      <td>0.268625</td>\n",
       "      <td>0.684244</td>\n",
       "      <td>0.771452</td>\n",
       "      <td>0.705128</td>\n",
       "      <td>0.736801</td>\n",
       "      <td>0.719063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.255400</td>\n",
       "      <td>0.273752</td>\n",
       "      <td>0.674598</td>\n",
       "      <td>0.779913</td>\n",
       "      <td>0.673454</td>\n",
       "      <td>0.722784</td>\n",
       "      <td>0.700433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.255400</td>\n",
       "      <td>0.286058</td>\n",
       "      <td>0.676527</td>\n",
       "      <td>0.761280</td>\n",
       "      <td>0.699849</td>\n",
       "      <td>0.729273</td>\n",
       "      <td>0.717167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.293800</td>\n",
       "      <td>0.674598</td>\n",
       "      <td>0.780786</td>\n",
       "      <td>0.674208</td>\n",
       "      <td>0.723594</td>\n",
       "      <td>0.704145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.300532</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.784400</td>\n",
       "      <td>0.674962</td>\n",
       "      <td>0.725578</td>\n",
       "      <td>0.714924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.304463</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.787798</td>\n",
       "      <td>0.671946</td>\n",
       "      <td>0.725275</td>\n",
       "      <td>0.710587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.308849</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.789615</td>\n",
       "      <td>0.665158</td>\n",
       "      <td>0.722063</td>\n",
       "      <td>0.706880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.88      0.89       362\n",
      "                sara       0.70      0.50      0.58       237\n",
      "         radikalisme       0.72      0.68      0.70       235\n",
      "pencemaran_nama_baik       0.72      0.69      0.71       492\n",
      "\n",
      "           micro avg       0.77      0.71      0.74      1326\n",
      "           macro avg       0.76      0.69      0.72      1326\n",
      "        weighted avg       0.77      0.71      0.73      1326\n",
      "         samples avg       0.40      0.40      0.39      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2394: Accuracy: 0.6842443729903537, F1 Micro: 0.7368006304176518, F1 Macro: 0.7190626440150769\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.88      0.89       362\n",
      "                sara       0.70      0.50      0.58       237\n",
      "         radikalisme       0.72      0.68      0.70       235\n",
      "pencemaran_nama_baik       0.72      0.69      0.71       492\n",
      "\n",
      "           micro avg       0.77      0.71      0.74      1326\n",
      "           macro avg       0.76      0.69      0.72      1326\n",
      "        weighted avg       0.77      0.71      0.73      1326\n",
      "         samples avg       0.40      0.40      0.39      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 19.679644966125487\n",
      "Samples above threshold: 383\n",
      "Acquired samples: 383\n",
      "Sampling duration: 13.782339334487915 seconds\n",
      "New train size: 2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1740' max='1740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1740/1740 06:28, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.287616</td>\n",
       "      <td>0.643730</td>\n",
       "      <td>0.730739</td>\n",
       "      <td>0.693816</td>\n",
       "      <td>0.711799</td>\n",
       "      <td>0.696464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.255076</td>\n",
       "      <td>0.677170</td>\n",
       "      <td>0.788121</td>\n",
       "      <td>0.670437</td>\n",
       "      <td>0.724531</td>\n",
       "      <td>0.714757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.264500</td>\n",
       "      <td>0.253367</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.778418</td>\n",
       "      <td>0.712670</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.730843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.264500</td>\n",
       "      <td>0.247571</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.782784</td>\n",
       "      <td>0.733786</td>\n",
       "      <td>0.757493</td>\n",
       "      <td>0.744109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.264500</td>\n",
       "      <td>0.263012</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.780788</td>\n",
       "      <td>0.717195</td>\n",
       "      <td>0.747642</td>\n",
       "      <td>0.738763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.135600</td>\n",
       "      <td>0.272571</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.777152</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.752044</td>\n",
       "      <td>0.743249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.135600</td>\n",
       "      <td>0.285980</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.810762</td>\n",
       "      <td>0.681750</td>\n",
       "      <td>0.740680</td>\n",
       "      <td>0.728377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.135600</td>\n",
       "      <td>0.291021</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.783429</td>\n",
       "      <td>0.720211</td>\n",
       "      <td>0.750491</td>\n",
       "      <td>0.741682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.297811</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.778148</td>\n",
       "      <td>0.703620</td>\n",
       "      <td>0.739010</td>\n",
       "      <td>0.726249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.299523</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.783122</td>\n",
       "      <td>0.699849</td>\n",
       "      <td>0.739148</td>\n",
       "      <td>0.726175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.87      0.90       362\n",
      "                sara       0.70      0.53      0.60       237\n",
      "         radikalisme       0.75      0.74      0.75       235\n",
      "pencemaran_nama_baik       0.72      0.73      0.72       492\n",
      "\n",
      "           micro avg       0.78      0.73      0.76      1326\n",
      "           macro avg       0.78      0.72      0.74      1326\n",
      "        weighted avg       0.78      0.73      0.76      1326\n",
      "         samples avg       0.42      0.41      0.41      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2777: Accuracy: 0.7028938906752411, F1 Micro: 0.7574931880108992, F1 Macro: 0.744109197913649\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.87      0.90       362\n",
      "                sara       0.70      0.53      0.60       237\n",
      "         radikalisme       0.75      0.74      0.75       235\n",
      "pencemaran_nama_baik       0.72      0.73      0.72       492\n",
      "\n",
      "           micro avg       0.78      0.73      0.76      1326\n",
      "           macro avg       0.78      0.72      0.74      1326\n",
      "        weighted avg       0.78      0.73      0.76      1326\n",
      "         samples avg       0.42      0.41      0.41      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 18.968320846557617\n",
      "Samples above threshold: 345\n",
      "Acquired samples: 345\n",
      "Sampling duration: 12.440654754638672 seconds\n",
      "New train size: 3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='1960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/1960 07:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.279596</td>\n",
       "      <td>0.648875</td>\n",
       "      <td>0.787819</td>\n",
       "      <td>0.604827</td>\n",
       "      <td>0.684300</td>\n",
       "      <td>0.648976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.249990</td>\n",
       "      <td>0.686817</td>\n",
       "      <td>0.806066</td>\n",
       "      <td>0.661388</td>\n",
       "      <td>0.726595</td>\n",
       "      <td>0.705154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.276000</td>\n",
       "      <td>0.248482</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.745416</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.770408</td>\n",
       "      <td>0.766723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.276000</td>\n",
       "      <td>0.251979</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.747285</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.762468</td>\n",
       "      <td>0.758564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.276000</td>\n",
       "      <td>0.251024</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.803223</td>\n",
       "      <td>0.714178</td>\n",
       "      <td>0.756088</td>\n",
       "      <td>0.742625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.151400</td>\n",
       "      <td>0.266674</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.800169</td>\n",
       "      <td>0.712670</td>\n",
       "      <td>0.753889</td>\n",
       "      <td>0.742723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.151400</td>\n",
       "      <td>0.279807</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.791974</td>\n",
       "      <td>0.729261</td>\n",
       "      <td>0.759325</td>\n",
       "      <td>0.749037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.284115</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.786872</td>\n",
       "      <td>0.732278</td>\n",
       "      <td>0.758594</td>\n",
       "      <td>0.750300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.287161</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.783373</td>\n",
       "      <td>0.739065</td>\n",
       "      <td>0.760574</td>\n",
       "      <td>0.751246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.290687</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.788399</td>\n",
       "      <td>0.727753</td>\n",
       "      <td>0.756863</td>\n",
       "      <td>0.746836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.87      0.90       362\n",
      "                sara       0.65      0.68      0.66       237\n",
      "         radikalisme       0.72      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.69      0.79      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.77      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.75      0.80      0.77      1326\n",
      "         samples avg       0.44      0.45      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3122: Accuracy: 0.7086816720257235, F1 Micro: 0.7704081632653063, F1 Macro: 0.7667227205222228\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.87      0.90       362\n",
      "                sara       0.65      0.68      0.66       237\n",
      "         radikalisme       0.72      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.69      0.79      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.77      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.75      0.80      0.77      1326\n",
      "         samples avg       0.44      0.45      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 18.648527145385742\n",
      "Samples above threshold: 310\n",
      "Acquired samples: 310\n",
      "Sampling duration: 11.20482873916626 seconds\n",
      "New train size: 3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2150/2150 07:30, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.263584</td>\n",
       "      <td>0.684887</td>\n",
       "      <td>0.771186</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.726257</td>\n",
       "      <td>0.722243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.246616</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.768868</td>\n",
       "      <td>0.737557</td>\n",
       "      <td>0.752887</td>\n",
       "      <td>0.739274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.279000</td>\n",
       "      <td>0.246168</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.815217</td>\n",
       "      <td>0.678733</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.731948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.279000</td>\n",
       "      <td>0.249132</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.767196</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.766327</td>\n",
       "      <td>0.759271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.155900</td>\n",
       "      <td>0.261709</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.759851</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.765256</td>\n",
       "      <td>0.760416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.155900</td>\n",
       "      <td>0.275177</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.790429</td>\n",
       "      <td>0.722474</td>\n",
       "      <td>0.754925</td>\n",
       "      <td>0.746557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.103300</td>\n",
       "      <td>0.287787</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.762980</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.763842</td>\n",
       "      <td>0.758655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.103300</td>\n",
       "      <td>0.298115</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.765613</td>\n",
       "      <td>0.748869</td>\n",
       "      <td>0.757148</td>\n",
       "      <td>0.749542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.103300</td>\n",
       "      <td>0.292927</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.783279</td>\n",
       "      <td>0.727753</td>\n",
       "      <td>0.754496</td>\n",
       "      <td>0.744823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.294144</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.721719</td>\n",
       "      <td>0.752358</td>\n",
       "      <td>0.742898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.87      0.90       362\n",
      "                sara       0.69      0.62      0.65       237\n",
      "         radikalisme       0.71      0.81      0.76       235\n",
      "pencemaran_nama_baik       0.72      0.74      0.73       492\n",
      "\n",
      "           micro avg       0.77      0.77      0.77      1326\n",
      "           macro avg       0.76      0.76      0.76      1326\n",
      "        weighted avg       0.77      0.77      0.77      1326\n",
      "         samples avg       0.44      0.43      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3432: Accuracy: 0.7067524115755627, F1 Micro: 0.7663269158172896, F1 Macro: 0.7592713474674339\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.87      0.90       362\n",
      "                sara       0.69      0.62      0.65       237\n",
      "         radikalisme       0.71      0.81      0.76       235\n",
      "pencemaran_nama_baik       0.72      0.74      0.73       492\n",
      "\n",
      "           micro avg       0.77      0.77      0.77      1326\n",
      "           macro avg       0.76      0.76      0.76      1326\n",
      "        weighted avg       0.77      0.77      0.77      1326\n",
      "         samples avg       0.44      0.43      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 18.3694429397583\n",
      "Samples above threshold: 279\n",
      "Acquired samples: 279\n",
      "Sampling duration: 10.093319177627563 seconds\n",
      "New train size: 3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2320/2320 08:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.282262</td>\n",
       "      <td>0.645016</td>\n",
       "      <td>0.682446</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.729189</td>\n",
       "      <td>0.734206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256747</td>\n",
       "      <td>0.684887</td>\n",
       "      <td>0.835378</td>\n",
       "      <td>0.616139</td>\n",
       "      <td>0.709201</td>\n",
       "      <td>0.673060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.289900</td>\n",
       "      <td>0.241341</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.808341</td>\n",
       "      <td>0.687029</td>\n",
       "      <td>0.742764</td>\n",
       "      <td>0.731387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.289900</td>\n",
       "      <td>0.251401</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.761285</td>\n",
       "      <td>0.750377</td>\n",
       "      <td>0.755792</td>\n",
       "      <td>0.744889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.250972</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.771863</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.768648</td>\n",
       "      <td>0.762528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.265240</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.789896</td>\n",
       "      <td>0.742836</td>\n",
       "      <td>0.765643</td>\n",
       "      <td>0.755047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.113600</td>\n",
       "      <td>0.274471</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.797521</td>\n",
       "      <td>0.727753</td>\n",
       "      <td>0.761041</td>\n",
       "      <td>0.751970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.113600</td>\n",
       "      <td>0.285120</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.798046</td>\n",
       "      <td>0.739065</td>\n",
       "      <td>0.767424</td>\n",
       "      <td>0.756925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>0.290849</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.784144</td>\n",
       "      <td>0.753394</td>\n",
       "      <td>0.768462</td>\n",
       "      <td>0.759709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>0.290817</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.779859</td>\n",
       "      <td>0.753394</td>\n",
       "      <td>0.766398</td>\n",
       "      <td>0.759317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.74      0.79      0.76       235\n",
      "pencemaran_nama_baik       0.73      0.72      0.73       492\n",
      "\n",
      "           micro avg       0.77      0.77      0.77      1326\n",
      "           macro avg       0.76      0.76      0.76      1326\n",
      "        weighted avg       0.77      0.77      0.77      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3711: Accuracy: 0.7080385852090032, F1 Micro: 0.7686482393032942, F1 Macro: 0.7625280656241644\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.74      0.79      0.76       235\n",
      "pencemaran_nama_baik       0.73      0.72      0.73       492\n",
      "\n",
      "           micro avg       0.77      0.77      0.77      1326\n",
      "           macro avg       0.76      0.76      0.76      1326\n",
      "        weighted avg       0.77      0.77      0.77      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 18.05417823791504\n",
      "Samples above threshold: 253\n",
      "Acquired samples: 175\n",
      "Sampling duration: 9.425967454910278 seconds\n",
      "New train size: 3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2430' max='2430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2430/2430 08:22, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.275327</td>\n",
       "      <td>0.638585</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.685520</td>\n",
       "      <td>0.710434</td>\n",
       "      <td>0.682935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.242098</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.757463</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.761440</td>\n",
       "      <td>0.754863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.294900</td>\n",
       "      <td>0.240544</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.751265</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.767073</td>\n",
       "      <td>0.762087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.294900</td>\n",
       "      <td>0.237522</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.779767</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.767522</td>\n",
       "      <td>0.763121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.177100</td>\n",
       "      <td>0.254332</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.807725</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.764402</td>\n",
       "      <td>0.755107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.177100</td>\n",
       "      <td>0.266138</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.761488</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.772688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.116300</td>\n",
       "      <td>0.278111</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.775019</td>\n",
       "      <td>0.753394</td>\n",
       "      <td>0.764054</td>\n",
       "      <td>0.757467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.116300</td>\n",
       "      <td>0.284165</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.761161</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.766292</td>\n",
       "      <td>0.761986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.081600</td>\n",
       "      <td>0.290630</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.776074</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.769582</td>\n",
       "      <td>0.763212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.081600</td>\n",
       "      <td>0.291238</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.791534</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.768813</td>\n",
       "      <td>0.761771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.89      0.92       362\n",
      "                sara       0.64      0.71      0.67       237\n",
      "         radikalisme       0.76      0.79      0.78       235\n",
      "pencemaran_nama_baik       0.70      0.75      0.72       492\n",
      "\n",
      "           micro avg       0.76      0.79      0.77      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3886: Accuracy: 0.7112540192926045, F1 Micro: 0.7741935483870968, F1 Macro: 0.7726875134138671\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.89      0.92       362\n",
      "                sara       0.64      0.71      0.67       237\n",
      "         radikalisme       0.76      0.79      0.78       235\n",
      "pencemaran_nama_baik       0.70      0.75      0.72       492\n",
      "\n",
      "           micro avg       0.76      0.79      0.77      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 17.63262348175049\n",
      "Samples above threshold: 234\n",
      "Acquired samples: 234\n",
      "Sampling duration: 8.507975578308105 seconds\n",
      "New train size: 4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 08:48, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.265665</td>\n",
       "      <td>0.654019</td>\n",
       "      <td>0.736280</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.732373</td>\n",
       "      <td>0.716500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.304700</td>\n",
       "      <td>0.235634</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.767816</td>\n",
       "      <td>0.754339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.304700</td>\n",
       "      <td>0.233756</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.797364</td>\n",
       "      <td>0.730015</td>\n",
       "      <td>0.762205</td>\n",
       "      <td>0.750218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.243488</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.764007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.249907</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.770089</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.771532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.261445</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.774637</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.769639</td>\n",
       "      <td>0.764253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.279450</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.783931</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.770706</td>\n",
       "      <td>0.762896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.088700</td>\n",
       "      <td>0.294797</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.764003</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.767730</td>\n",
       "      <td>0.761837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.088700</td>\n",
       "      <td>0.294776</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.786454</td>\n",
       "      <td>0.744344</td>\n",
       "      <td>0.764820</td>\n",
       "      <td>0.757661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.296227</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.783359</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.767692</td>\n",
       "      <td>0.760607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.87      0.90       362\n",
      "                sara       0.66      0.68      0.67       237\n",
      "         radikalisme       0.72      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.73      0.74      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.78      0.78      1326\n",
      "           macro avg       0.77      0.78      0.77      1326\n",
      "        weighted avg       0.78      0.78      0.78      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4120: Accuracy: 0.712540192926045, F1 Micro: 0.7752808988764044, F1 Macro: 0.7715316430299167\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.87      0.90       362\n",
      "                sara       0.66      0.68      0.67       237\n",
      "         radikalisme       0.72      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.73      0.74      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.78      0.78      1326\n",
      "           macro avg       0.77      0.78      0.77      1326\n",
      "        weighted avg       0.78      0.78      0.78      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 17.26502170562744\n",
      "Samples above threshold: 210\n",
      "Acquired samples: 210\n",
      "Sampling duration: 7.690026760101318 seconds\n",
      "New train size: 4330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2710' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2710/2710 09:09, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.257262</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.739097</td>\n",
       "      <td>0.719380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.235056</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.761624</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.769862</td>\n",
       "      <td>0.765317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.233858</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.758646</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.775976</td>\n",
       "      <td>0.770519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.185800</td>\n",
       "      <td>0.237005</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.804401</td>\n",
       "      <td>0.744344</td>\n",
       "      <td>0.773208</td>\n",
       "      <td>0.764082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.185800</td>\n",
       "      <td>0.252114</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.818884</td>\n",
       "      <td>0.719457</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.751946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.129200</td>\n",
       "      <td>0.268808</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.784760</td>\n",
       "      <td>0.753394</td>\n",
       "      <td>0.768757</td>\n",
       "      <td>0.760003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.129200</td>\n",
       "      <td>0.276399</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.793715</td>\n",
       "      <td>0.742836</td>\n",
       "      <td>0.767433</td>\n",
       "      <td>0.757291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.089800</td>\n",
       "      <td>0.284590</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.781298</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.771756</td>\n",
       "      <td>0.764392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.089800</td>\n",
       "      <td>0.288280</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.790865</td>\n",
       "      <td>0.744344</td>\n",
       "      <td>0.766900</td>\n",
       "      <td>0.759491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.292432</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.781734</td>\n",
       "      <td>0.761689</td>\n",
       "      <td>0.771581</td>\n",
       "      <td>0.765400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.88      0.91       362\n",
      "                sara       0.63      0.69      0.66       237\n",
      "         radikalisme       0.73      0.81      0.77       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.79      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4330: Accuracy: 0.7099678456591639, F1 Micro: 0.7759764185703758, F1 Macro: 0.7705191968953091\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.88      0.91       362\n",
      "                sara       0.63      0.69      0.66       237\n",
      "         radikalisme       0.73      0.81      0.77       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.79      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 17.26460704803467\n",
      "Samples above threshold: 189\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.956068992614746 seconds\n",
      "New train size: 4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2840' max='2840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2840/2840 09:28, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.251927</td>\n",
       "      <td>0.681029</td>\n",
       "      <td>0.779762</td>\n",
       "      <td>0.691554</td>\n",
       "      <td>0.733014</td>\n",
       "      <td>0.718789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.298800</td>\n",
       "      <td>0.239302</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.750897</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.769401</td>\n",
       "      <td>0.765392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.298800</td>\n",
       "      <td>0.231824</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.772218</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.775985</td>\n",
       "      <td>0.771216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.241471</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.784591</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.768283</td>\n",
       "      <td>0.759614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.246709</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.786499</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.770769</td>\n",
       "      <td>0.756339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.133300</td>\n",
       "      <td>0.264806</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.787133</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.766731</td>\n",
       "      <td>0.755954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.133300</td>\n",
       "      <td>0.285435</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.781421</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.767932</td>\n",
       "      <td>0.759780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>0.284926</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.761696</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.773571</td>\n",
       "      <td>0.766938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.290262</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.786385</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.771889</td>\n",
       "      <td>0.763299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.295664</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.782041</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.775200</td>\n",
       "      <td>0.769212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.88      0.90       362\n",
      "                sara       0.66      0.70      0.68       237\n",
      "         radikalisme       0.73      0.81      0.76       235\n",
      "pencemaran_nama_baik       0.75      0.73      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.78      0.78      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.78      0.78      0.78      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4530: Accuracy: 0.7131832797427653, F1 Micro: 0.775984990619137, F1 Macro: 0.7712157681973895\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.88      0.90       362\n",
      "                sara       0.66      0.70      0.68       237\n",
      "         radikalisme       0.73      0.81      0.76       235\n",
      "pencemaran_nama_baik       0.75      0.73      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.78      0.78      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.78      0.78      0.78      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 16.439130783081055\n",
      "Samples above threshold: 169\n",
      "Acquired samples: 133\n",
      "Sampling duration: 6.550201416015625 seconds\n",
      "New train size: 4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2920' max='2920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2920/2920 09:43, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250570</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.802880</td>\n",
       "      <td>0.672700</td>\n",
       "      <td>0.732048</td>\n",
       "      <td>0.726257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.300200</td>\n",
       "      <td>0.234295</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.775621</td>\n",
       "      <td>0.753394</td>\n",
       "      <td>0.764346</td>\n",
       "      <td>0.762887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.300200</td>\n",
       "      <td>0.230869</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.778207</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.768702</td>\n",
       "      <td>0.764807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>0.246024</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.771129</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.774315</td>\n",
       "      <td>0.767162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>0.258595</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.753541</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.777210</td>\n",
       "      <td>0.773438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.134300</td>\n",
       "      <td>0.273114</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.767662</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.781030</td>\n",
       "      <td>0.775359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.096800</td>\n",
       "      <td>0.284437</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.796862</td>\n",
       "      <td>0.727753</td>\n",
       "      <td>0.760741</td>\n",
       "      <td>0.753449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.096800</td>\n",
       "      <td>0.285451</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.790716</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.773970</td>\n",
       "      <td>0.764385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.293554</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.789433</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.777650</td>\n",
       "      <td>0.770862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.298125</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.783179</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.774218</td>\n",
       "      <td>0.765250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.89      0.91       362\n",
      "                sara       0.65      0.68      0.66       237\n",
      "         radikalisme       0.72      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.76      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4663: Accuracy: 0.7170418006430869, F1 Micro: 0.7810300111152279, F1 Macro: 0.7753594639251972\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.89      0.91       362\n",
      "                sara       0.65      0.68      0.66       237\n",
      "         radikalisme       0.72      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.76      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 16.788074493408203\n",
      "Samples above threshold: 157\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.79302716255188 seconds\n",
      "New train size: 4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3040' max='3040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3040/3040 10:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.251355</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.742468</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.761029</td>\n",
       "      <td>0.755978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.301100</td>\n",
       "      <td>0.231111</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.821942</td>\n",
       "      <td>0.689291</td>\n",
       "      <td>0.749795</td>\n",
       "      <td>0.733307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.301100</td>\n",
       "      <td>0.232230</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.811644</td>\n",
       "      <td>0.714932</td>\n",
       "      <td>0.760225</td>\n",
       "      <td>0.750801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.191000</td>\n",
       "      <td>0.241468</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.752628</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.780240</td>\n",
       "      <td>0.775651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.138500</td>\n",
       "      <td>0.248187</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.779908</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.773384</td>\n",
       "      <td>0.764600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.138500</td>\n",
       "      <td>0.266864</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.767425</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.777984</td>\n",
       "      <td>0.768724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.097300</td>\n",
       "      <td>0.271443</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.792320</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.777095</td>\n",
       "      <td>0.770380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.097300</td>\n",
       "      <td>0.282432</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.803731</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.774521</td>\n",
       "      <td>0.765457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>0.295793</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.787136</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.781155</td>\n",
       "      <td>0.774264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.296691</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.788417</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.779092</td>\n",
       "      <td>0.771374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.68      0.64      0.66       237\n",
      "         radikalisme       0.77      0.80      0.78       235\n",
      "pencemaran_nama_baik       0.75      0.73      0.74       492\n",
      "\n",
      "           micro avg       0.79      0.78      0.78      1326\n",
      "           macro avg       0.78      0.77      0.77      1326\n",
      "        weighted avg       0.79      0.78      0.78      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4863: Accuracy: 0.7228295819935692, F1 Micro: 0.7811550151975684, F1 Macro: 0.7742639100166211\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.68      0.64      0.66       237\n",
      "         radikalisme       0.77      0.80      0.78       235\n",
      "pencemaran_nama_baik       0.75      0.73      0.74       492\n",
      "\n",
      "           micro avg       0.79      0.78      0.78      1326\n",
      "           macro avg       0.78      0.77      0.77      1326\n",
      "        weighted avg       0.79      0.78      0.78      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 15.702507400512696\n",
      "Samples above threshold: 136\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.029996156692505 seconds\n",
      "New train size: 5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3170' max='3170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3170/3170 10:26, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250167</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.760530</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.747699</td>\n",
       "      <td>0.738388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.302000</td>\n",
       "      <td>0.231156</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.777001</td>\n",
       "      <td>0.754148</td>\n",
       "      <td>0.765404</td>\n",
       "      <td>0.756046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.302000</td>\n",
       "      <td>0.237735</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.742838</td>\n",
       "      <td>0.821267</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.775634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.195200</td>\n",
       "      <td>0.248952</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.747940</td>\n",
       "      <td>0.821267</td>\n",
       "      <td>0.782890</td>\n",
       "      <td>0.777077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.138500</td>\n",
       "      <td>0.238887</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.781532</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.783296</td>\n",
       "      <td>0.775590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.138500</td>\n",
       "      <td>0.280006</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.752113</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.777859</td>\n",
       "      <td>0.770541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.106300</td>\n",
       "      <td>0.272558</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.795419</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.777006</td>\n",
       "      <td>0.768179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.285407</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.746606</td>\n",
       "      <td>0.774042</td>\n",
       "      <td>0.760355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.292189</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.779052</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.773728</td>\n",
       "      <td>0.765847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.063400</td>\n",
       "      <td>0.293588</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.784404</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.779043</td>\n",
       "      <td>0.770145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.92       362\n",
      "                sara       0.64      0.65      0.65       237\n",
      "         radikalisme       0.78      0.79      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.78      1326\n",
      "           macro avg       0.78      0.78      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5063: Accuracy: 0.7209003215434083, F1 Micro: 0.783295711060948, F1 Macro: 0.7755897973547299\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.92       362\n",
      "                sara       0.64      0.65      0.65       237\n",
      "         radikalisme       0.78      0.79      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.78      1326\n",
      "           macro avg       0.78      0.78      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 15.575226211547852\n",
      "Samples above threshold: 116\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.369675397872925 seconds\n",
      "New train size: 5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3290' max='3290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3290/3290 10:47, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241189</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.774557</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.749221</td>\n",
       "      <td>0.743959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.298300</td>\n",
       "      <td>0.227305</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.779953</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.765271</td>\n",
       "      <td>0.753500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.298300</td>\n",
       "      <td>0.231364</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.770880</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.778649</td>\n",
       "      <td>0.772784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.199400</td>\n",
       "      <td>0.231999</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.808667</td>\n",
       "      <td>0.745852</td>\n",
       "      <td>0.775991</td>\n",
       "      <td>0.765174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.144700</td>\n",
       "      <td>0.248375</td>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.782840</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.780174</td>\n",
       "      <td>0.773211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.144700</td>\n",
       "      <td>0.257907</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.779043</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.776390</td>\n",
       "      <td>0.769515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.111400</td>\n",
       "      <td>0.275810</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.775888</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.783420</td>\n",
       "      <td>0.777921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.078600</td>\n",
       "      <td>0.290211</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.782905</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.781722</td>\n",
       "      <td>0.773480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.078600</td>\n",
       "      <td>0.298403</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.770540</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.777736</td>\n",
       "      <td>0.772109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.065600</td>\n",
       "      <td>0.301091</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.768382</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.778109</td>\n",
       "      <td>0.770759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.76      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.78      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5263: Accuracy: 0.7254019292604501, F1 Micro: 0.7834204630321134, F1 Macro: 0.777920802361302\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.76      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.78      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 15.184699821472169\n",
      "Samples above threshold: 96\n",
      "Acquired samples: 178\n",
      "Sampling duration: 3.882734537124634 seconds\n",
      "New train size: 5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3410' max='3410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3410/3410 11:09, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.249215</td>\n",
       "      <td>0.684887</td>\n",
       "      <td>0.737491</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.751941</td>\n",
       "      <td>0.752796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.299300</td>\n",
       "      <td>0.224966</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.794955</td>\n",
       "      <td>0.736802</td>\n",
       "      <td>0.764775</td>\n",
       "      <td>0.756655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.201000</td>\n",
       "      <td>0.229147</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.827061</td>\n",
       "      <td>0.696078</td>\n",
       "      <td>0.755938</td>\n",
       "      <td>0.739960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.201000</td>\n",
       "      <td>0.232613</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.793538</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.776108</td>\n",
       "      <td>0.765120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.148400</td>\n",
       "      <td>0.240610</td>\n",
       "      <td>0.729260</td>\n",
       "      <td>0.797972</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.784509</td>\n",
       "      <td>0.778416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.264123</td>\n",
       "      <td>0.732476</td>\n",
       "      <td>0.777531</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.785368</td>\n",
       "      <td>0.779627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.282841</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.761024</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.783309</td>\n",
       "      <td>0.778043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.083800</td>\n",
       "      <td>0.288992</td>\n",
       "      <td>0.735691</td>\n",
       "      <td>0.781319</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.788037</td>\n",
       "      <td>0.782553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.298582</td>\n",
       "      <td>0.733762</td>\n",
       "      <td>0.775837</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.789630</td>\n",
       "      <td>0.783305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.298680</td>\n",
       "      <td>0.735048</td>\n",
       "      <td>0.788015</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.790680</td>\n",
       "      <td>0.783815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.91      0.92       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.77      0.84      0.80       235\n",
      "pencemaran_nama_baik       0.75      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.79      0.79      0.79      1326\n",
      "           macro avg       0.78      0.79      0.78      1326\n",
      "        weighted avg       0.79      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5441: Accuracy: 0.735048231511254, F1 Micro: 0.7906801954152574, F1 Macro: 0.7838151192013332\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.91      0.92       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.77      0.84      0.80       235\n",
      "pencemaran_nama_baik       0.75      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.79      0.79      0.79      1326\n",
      "           macro avg       0.78      0.79      0.78      1326\n",
      "        weighted avg       0.79      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 14.203713226318358\n",
      "Samples above threshold: 78\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.0741727352142334 seconds\n",
      "New train size: 5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3530' max='3530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3530/3530 11:36, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241834</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.771987</td>\n",
       "      <td>0.714932</td>\n",
       "      <td>0.742365</td>\n",
       "      <td>0.730859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.305300</td>\n",
       "      <td>0.227744</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.762825</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.768252</td>\n",
       "      <td>0.760827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.202400</td>\n",
       "      <td>0.232018</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.791033</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.767379</td>\n",
       "      <td>0.753467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.202400</td>\n",
       "      <td>0.235458</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.793049</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>0.774691</td>\n",
       "      <td>0.762683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.247523</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.791894</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.778842</td>\n",
       "      <td>0.769324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.112600</td>\n",
       "      <td>0.276278</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.749827</td>\n",
       "      <td>0.818250</td>\n",
       "      <td>0.782546</td>\n",
       "      <td>0.776589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.112600</td>\n",
       "      <td>0.280199</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.778707</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.775464</td>\n",
       "      <td>0.765472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.084400</td>\n",
       "      <td>0.299204</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.773696</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.783774</td>\n",
       "      <td>0.777198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>0.306336</td>\n",
       "      <td>0.727974</td>\n",
       "      <td>0.777122</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.785528</td>\n",
       "      <td>0.780190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.306639</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.778689</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.783358</td>\n",
       "      <td>0.778649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.69      0.65      0.67       237\n",
      "         radikalisme       0.76      0.84      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5641: Accuracy: 0.7279742765273312, F1 Micro: 0.7855277881387542, F1 Macro: 0.7801898232328032\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.69      0.65      0.67       237\n",
      "         radikalisme       0.76      0.84      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 13.968971061706544\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.4231081008911133 seconds\n",
      "New train size: 5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3660' max='3660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3660/3660 12:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.245192</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.772364</td>\n",
       "      <td>0.729261</td>\n",
       "      <td>0.750194</td>\n",
       "      <td>0.741318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.300300</td>\n",
       "      <td>0.224666</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.801956</td>\n",
       "      <td>0.742081</td>\n",
       "      <td>0.770858</td>\n",
       "      <td>0.760450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.204700</td>\n",
       "      <td>0.222597</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.784781</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.777313</td>\n",
       "      <td>0.763949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.204700</td>\n",
       "      <td>0.252321</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.739218</td>\n",
       "      <td>0.827300</td>\n",
       "      <td>0.780783</td>\n",
       "      <td>0.776105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.156800</td>\n",
       "      <td>0.251551</td>\n",
       "      <td>0.730547</td>\n",
       "      <td>0.788679</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.788382</td>\n",
       "      <td>0.781927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.117500</td>\n",
       "      <td>0.274725</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.756401</td>\n",
       "      <td>0.824284</td>\n",
       "      <td>0.788885</td>\n",
       "      <td>0.781515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.087200</td>\n",
       "      <td>0.289781</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.763830</td>\n",
       "      <td>0.812217</td>\n",
       "      <td>0.787281</td>\n",
       "      <td>0.779265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.087200</td>\n",
       "      <td>0.300288</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.769841</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.786873</td>\n",
       "      <td>0.781585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.074700</td>\n",
       "      <td>0.297530</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.779259</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.786248</td>\n",
       "      <td>0.781838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.059700</td>\n",
       "      <td>0.304217</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.777452</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.789004</td>\n",
       "      <td>0.784789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.68      0.68      0.68       237\n",
      "         radikalisme       0.75      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.78      0.80      0.79      1326\n",
      "           macro avg       0.77      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5841: Accuracy: 0.7260450160771704, F1 Micro: 0.7890044576523031, F1 Macro: 0.7847891993803159\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.68      0.68      0.68       237\n",
      "         radikalisme       0.75      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.78      0.80      0.79      1326\n",
      "           macro avg       0.77      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 13.482587814331055\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 200\n",
      "Sampling duration: 1.6313214302062988 seconds\n",
      "New train size: 6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3780' max='3780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3780/3780 12:22, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.240890</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.798969</td>\n",
       "      <td>0.701357</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.733726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.299200</td>\n",
       "      <td>0.234664</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.729855</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.778169</td>\n",
       "      <td>0.775170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.203200</td>\n",
       "      <td>0.222459</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.793774</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.781310</td>\n",
       "      <td>0.771449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.159900</td>\n",
       "      <td>0.225435</td>\n",
       "      <td>0.729260</td>\n",
       "      <td>0.799216</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.783545</td>\n",
       "      <td>0.776082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.159900</td>\n",
       "      <td>0.241929</td>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.790078</td>\n",
       "      <td>0.781449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.118400</td>\n",
       "      <td>0.254069</td>\n",
       "      <td>0.727974</td>\n",
       "      <td>0.777213</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.792160</td>\n",
       "      <td>0.783964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.089900</td>\n",
       "      <td>0.278167</td>\n",
       "      <td>0.729260</td>\n",
       "      <td>0.778839</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.788984</td>\n",
       "      <td>0.782201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.283616</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.788354</td>\n",
       "      <td>0.782832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.293062</td>\n",
       "      <td>0.727974</td>\n",
       "      <td>0.780074</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.788512</td>\n",
       "      <td>0.783334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>0.298288</td>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.776076</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.789025</td>\n",
       "      <td>0.783061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.92       362\n",
      "                sara       0.66      0.66      0.66       237\n",
      "         radikalisme       0.75      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.79      0.77       492\n",
      "\n",
      "           micro avg       0.78      0.81      0.79      1326\n",
      "           macro avg       0.77      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6041: Accuracy: 0.7279742765273312, F1 Micro: 0.7921597633136094, F1 Macro: 0.7839641111088721\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.92       362\n",
      "                sara       0.66      0.66      0.66       237\n",
      "         radikalisme       0.75      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.79      0.77       492\n",
      "\n",
      "           micro avg       0.78      0.81      0.79      1326\n",
      "           macro avg       0.77      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 15.571789169311524\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 177\n",
      "Sampling duration: 1.2089743614196777 seconds\n",
      "New train size: 6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3890/3890 12:40, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.244868</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.739193</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.756080</td>\n",
       "      <td>0.752791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.299400</td>\n",
       "      <td>0.229451</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.755462</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.781056</td>\n",
       "      <td>0.777654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.201500</td>\n",
       "      <td>0.229321</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.789100</td>\n",
       "      <td>0.753394</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.760804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.236474</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.781643</td>\n",
       "      <td>0.775143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.262678</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.747222</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.778019</td>\n",
       "      <td>0.772567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.120500</td>\n",
       "      <td>0.272648</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.767374</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.779057</td>\n",
       "      <td>0.770581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.286161</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.774024</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.775771</td>\n",
       "      <td>0.769947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.316560</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.742877</td>\n",
       "      <td>0.825792</td>\n",
       "      <td>0.782143</td>\n",
       "      <td>0.777019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>0.314058</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.815234</td>\n",
       "      <td>0.785610</td>\n",
       "      <td>0.779983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>0.305254</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.777531</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.785368</td>\n",
       "      <td>0.780653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.91       362\n",
      "                sara       0.64      0.68      0.66       237\n",
      "         radikalisme       0.75      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.71      0.79      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.82      0.79      1326\n",
      "           macro avg       0.75      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.82      0.79      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6218: Accuracy: 0.7202572347266881, F1 Micro: 0.7856104651162791, F1 Macro: 0.7799831994430899\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.91       362\n",
      "                sara       0.64      0.68      0.66       237\n",
      "         radikalisme       0.75      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.71      0.79      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.82      0.79      1326\n",
      "           macro avg       0.75      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.82      0.79      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\n",
      "Total sampling time: 185.95 seconds\n",
      "Total runtime: 11630.969444036484 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACCoAAAHqCAYAAADInz0eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzde3zO9f/H8cd17WjYmLGZ0xzKoWZyWsqpUsghxZCYJDopWQeUU1JTyk9JSd8piqYVpUS0ktNYEVIIOdvmvDF2vK7fH5+Mqw0b2z47PO+32+e2z+f9Ob3e+n7z7trzer8tdrvdjoiIiIiIiIiIiIiIiIiIiEghsJpdgIiIiIiIiIiIiIiIiIiIiJQeCiqIiIiIiIiIiIiIiIiIiIhIoVFQQURERERERERERERERERERAqNggoiIiIiIiIiIiIiIiIiIiJSaBRUEBERERERERERERERERERkUKjoIKIiIiIiIiIiIiIiIiIiIgUGgUVREREREREREREREREREREpNAoqCAiIiIiIiIiIiIiIiIiIiKFRkEFERERERERERERERERERERKTQKKoiIiIiIiIhIkfbwww8TEBBgdhkiIiIiIiIikk8UVBARyaP3338fi8VCcHCw2aWIiIiIiOSLTz75BIvFkuM2atSorOuWL1/O4MGDufnmm3FycspzeODCMx999NEcz7/88stZ1xw/fvx6uiQiIiIipZTGtiIixYOz2QWIiBQ38+bNIyAggNjYWHbv3k29evXMLklEREREJF9MnDiR2rVrO7TdfPPNWfvz589nwYIFNG3aFH9//2t6h7u7O1999RXvv/8+rq6uDuc+//xz3N3dSUlJcWj/6KOPsNls1/Q+ERERESmdiurYVkREDJpRQUQkD/bu3cu6deuYOnUqlStXZt68eWaXlKPk5GSzSxARERGRYqhz587079/fYWvSpEnW+ddff52kpCTWrl1LUFDQNb2jU6dOJCUlsXTpUof2devWsXfvXrp06ZLtHhcXF9zc3K7pfZey2Wz6oFhERESklCiqY9uCps+GRaS4UFBBRCQP5s2bR8WKFenSpQu9evXKMahw+vRpRowYQUBAAG5ublSvXp3Q0FCH6b1SUlKYMGECN954I+7u7lStWpUHHniAPXv2ALBy5UosFgsrV650ePa+ffuwWCx88sknWW0PP/ww5cqVY8+ePdx7772UL1+ehx56CIDVq1cTEhJCzZo1cXNzo0aNGowYMYLz589nq3vHjh307t2bypUrU6ZMGerXr8/LL78MwM8//4zFYmHRokXZ7ps/fz4Wi4WYmJg8/3mKiIiISPHi7++Pi4vLdT2jWrVqtG3blvnz5zu0z5s3j8DAQIdvuV3w8MMPZ5uK12az8c477xAYGIi7uzuVK1emU6dO/Pbbb1nXWCwWhg0bxrx587jppptwc3Nj2bJlAPz+++907twZT09PypUrx1133cX69euvq28iIiIiUnyYNbbNr89sASZMmIDFYuGvv/6iX79+VKxYkdatWwOQkZHBq6++St26dXFzcyMgIICXXnqJ1NTU6+qziEh+0dIPIiJ5MG/ePB544AFcXV158MEH+eCDD/j1119p0aIFAGfPnqVNmzZs376dRx55hKZNm3L8+HEWL17MoUOH8PHxITMzk65duxIdHU3fvn0ZPnw4Z86cYcWKFWzbto26devmua6MjAw6duxI69ateeutt/Dw8AAgKiqKc+fO8cQTT1CpUiViY2OZPn06hw4dIioqKuv+rVu30qZNG1xcXBg6dCgBAQHs2bOHb7/9ltdee4327dtTo0YN5s2bx/3335/tz6Ru3bq0atXqOv5kRURERKQoSExMzLZ+ro+PT76/p1+/fgwfPpyzZ89Srlw5MjIyiIqKIiwsLNczHgwePJhPPvmEzp078+ijj5KRkcHq1atZv349zZs3z7rup59+4osvvmDYsGH4+PgQEBDAn3/+SZs2bfD09OTFF1/ExcWFDz/8kPbt2/PLL78QHByc730WERERkcJVVMe2+fWZ7aVCQkK44YYbeP3117Hb7QA8+uijzJkzh169evHcc8+xYcMGwsPD2b59e45fSBMRKWwKKoiI5NLGjRvZsWMH06dPB6B169ZUr16defPmZQUVpkyZwrZt21i4cKHDL/THjBmTNUCcO3cu0dHRTJ06lREjRmRdM2rUqKxr8io1NZWQkBDCw8Md2t944w3KlCmTdTx06FDq1avHSy+9xIEDB6hZsyYATz/9NHa7nU2bNmW1AUyePBkwvonWv39/pk6dSmJiIl5eXgAcO3aM5cuXO6R4RURERKT46tChQ7a2ax2jXkmvXr0YNmwYX3/9Nf3792f58uUcP36cBx98kI8//viq9//888988sknPPPMM7zzzjtZ7c8991y2enfu3Mkff/xBo0aNstruv/9+0tPTWbNmDXXq1AEgNDSU+vXr8+KLL/LLL7/kU09FRERExCxFdWybX5/ZXiooKMhhVoctW7YwZ84cHn30UT766CMAnnzySapUqcJbb73Fzz//zB133JFvfwYiItdCSz+IiOTSvHnz8PX1zRrAWSwW+vTpQ2RkJJmZmQB89dVXBAUFZZt14ML1F67x8fHh6aefvuw11+KJJ57I1nbpgDc5OZnjx49z2223Ybfb+f333wEjbLBq1SoeeeQRhwHvf+sJDQ0lNTWVL7/8MqttwYIFZGRk0L9//2uuW0RERESKjhkzZrBixQqHrSBUrFiRTp068fnnnwPGcmK33XYbtWrVytX9X331FRaLhfHjx2c7998xdbt27RxCCpmZmSxfvpwePXpkhRQAqlatSr9+/VizZg1JSUnX0i0RERERKUKK6tg2Pz+zveDxxx93OP7+++8BCAsLc2h/7rnnAFiyZEleuigiUiA0o4KISC5kZmYSGRnJHXfcwd69e7Pag4ODefvtt4mOjuaee+5hz5499OzZ84rP2rNnD/Xr18fZOf/+Fezs7Ez16tWztR84cIBx48axePFiTp065XAuMTERgH/++Qcgx/XSLtWgQQNatGjBvHnzGDx4MGCEN2699Vbq1auXH90QEREREZO1bNnSYdmEgtSvXz8GDBjAgQMH+Prrr3nzzTdzfe+ePXvw9/fH29v7qtfWrl3b4fjYsWOcO3eO+vXrZ7u2YcOG2Gw2Dh48yE033ZTrekRERESk6CmqY9v8/Mz2gv+Oeffv34/Vas32ua2fnx8VKlRg//79uXquiEhBUlBBRCQXfvrpJ+Li4oiMjCQyMjLb+Xnz5nHPPffk2/suN7PChZkb/svNzQ2r1Zrt2rvvvpuTJ08ycuRIGjRoQNmyZTl8+DAPP/wwNpstz3WFhoYyfPhwDh06RGpqKuvXr+e9997L83NERERERLp3746bmxsDBw4kNTWV3r17F8h7Lv3GmoiIiIhIQcjt2LYgPrOFy495r2cGXxGRgqaggohILsybN48qVaowY8aMbOcWLlzIokWLmDlzJnXr1mXbtm1XfFbdunXZsGED6enpuLi45HhNxYoVATh9+rRDe16Srn/88Qd///03c+bMITQ0NKv9v1OcXZju9mp1A/Tt25ewsDA+//xzzp8/j4uLC3369Ml1TSIiIiIiF5QpU4YePXrw2Wef0blzZ3x8fHJ9b926dfnhhx84efJkrmZVuFTlypXx8PBg586d2c7t2LEDq9VKjRo18vRMERERESndcju2LYjPbHNSq1YtbDYbu3btomHDhlntCQkJnD59OtdLromIFCTr1S8RESndzp8/z8KFC+natSu9evXKtg0bNowzZ86wePFievbsyZYtW1i0aFG259jtdgB69uzJ8ePHc5yJ4MI1tWrVwsnJiVWrVjmcf//993Ndt5OTk8MzL+y/8847DtdVrlyZtm3bMnv2bA4cOJBjPRf4+PjQuXNnPvvsM+bNm0enTp3y9IGyiIiIiMilnn/+ecaPH8/YsWPzdF/Pnj2x2+288sor2c79dwz7X05OTtxzzz1888037Nu3L6s9ISGB+fPn07p1azw9PfNUj4iIiIhIbsa2BfGZbU7uvfdeAKZNm+bQPnXqVAC6dOly1WeIiBQ0zaggInIVixcv5syZM3Tv3j3H87feeiuVK1dm3rx5zJ8/ny+//JKQkBAeeeQRmjVrxsmTJ1m8eDEzZ84kKCiI0NBQ5s6dS1hYGLGxsbRp04bk5GR+/PFHnnzySe677z68vLwICQlh+vTpWCwW6taty3fffcfRo0dzXXeDBg2oW7cuzz//PIcPH8bT05Ovvvoq27pnAO+++y6tW7emadOmDB06lNq1a7Nv3z6WLFnC5s2bHa4NDQ2lV69eALz66qu5/4MUERERkWJv69atLF68GIDdu3eTmJjIpEmTAAgKCqJbt255el5QUBBBQUF5ruOOO+5gwIABvPvuu+zatYtOnTphs9lYvXo1d9xxB8OGDbvi/ZMmTWLFihW0bt2aJ598EmdnZz788ENSU1OvuJ6wiIiIiJQcZoxtC+oz25xqGThwILNmzeL06dO0a9eO2NhY5syZQ48ePbjjjjvy1DcRkYKgoIKIyFXMmzcPd3d37r777hzPW61WunTpwrx580hNTWX16tWMHz+eRYsWMWfOHKpUqcJdd91F9erVASM1+/333/Paa68xf/58vvrqKypVqkTr1q0JDAzMeu706dNJT09n5syZuLm50bt3b6ZMmcLNN9+cq7pdXFz49ttveeaZZwgPD8fd3Z3777+fYcOGZRswBwUFsX79esaOHcsHH3xASkoKtWrVynEttW7dulGxYkVsNttlwxsiIiIiUjJt2rQp2zfELhwPHDgwzx/mXo+PP/6Yxo0bExERwQsvvICXlxfNmzfntttuu+q9N910E6tXr2b06NGEh4djs9kIDg7ms88+Izg4uBCqFxERERGzmTG2LajPbHPyv//9jzp16vDJJ5+waNEi/Pz8GD16NOPHj8/3fomIXAuLPTdzxIiIiPwrIyMDf39/unXrRkREhNnliIiIiIiIiIiIiIiISDFjNbsAEREpXr7++muOHTtGaGio2aWIiIiIiIiIiIiIiIhIMaQZFUREJFc2bNjA1q1befXVV/Hx8WHTpk1mlyQiIiIiIiIiIiIiIiLFkGZUEBGRXPnggw944oknqFKlCnPnzjW7HBERERERERERERERESmmNKOCiIiIiIiIiIiIiIiIiIiIFBrNqCAiIiIipcKMGTMICAjA3d2d4OBgYmNjr3j9tGnTqF+/PmXKlKFGjRqMGDGClJSUPD0zJSWFp556ikqVKlGuXDl69uxJQkJCvvdNREREREREREREpDhRUEFERERESrwFCxYQFhbG+PHj2bRpE0FBQXTs2JGjR4/meP38+fMZNWoU48ePZ/v27URERLBgwQJeeumlPD1zxIgRfPvtt0RFRfHLL79w5MgRHnjggQLvr4iIiIiIiIiIiEhRVmKWfrDZbBw5coTy5ctjsVjMLkdERERE8oHdbufMmTP4+/tjtV57xjY4OJgWLVrw3nvvAcbYsUaNGjz99NOMGjUq2/XDhg1j+/btREdHZ7U999xzbNiwgTVr1uTqmYmJiVSuXJn58+fTq1cvAHbs2EHDhg2JiYnh1ltvvWrdGuOKiIiIlEz5Nc4trjTOFRERESmZ8jTOtV+D9957z16rVi27m5ubvWXLlvYNGzZc9tp27drZgWzbvffem+P1jz32mB2w/9///V+eajp48GCO79GmTZs2bdq0adNW/LeDBw/maWx4qdTUVLuTk5N90aJFDu2hoaH27t2753jPvHnz7F5eXlnj3D179tgbNGhgf+2113L9zOjoaDtgP3XqlMM1NWvWtE+dOjXH96akpNgTExOztr/++sv0P3tt2rRp06ZNmzZtBbddzzi3ONNnudq0adOmTZs2bSV7y80415k8ujDF7cyZMwkODmbatGl07NiRnTt3UqVKlWzXL1y4kLS0tKzjEydOEBQUREhISLZrFy1axPr16/H3989rWZQvXx6AgwcP4unpmef7RURERKToSUpKokaNGlljvWtx/PhxMjMz8fX1dWj39fVlx44dOd7Tr18/jh8/TuvWrbHb7WRkZPD4449nLf2Qm2fGx8fj6upKhQoVsl0THx+f43vDw8N55ZVXsrVrjCsiIiJSsuTHOLc402e5IiIiIiVTXsa5eQ4qTJ06lSFDhjBo0CAAZs6cyZIlS5g9e3aO0+Z6e3s7HEdGRuLh4ZEtqHD48GGefvppfvjhB7p06ZLXsrKmCPP09NTgVkRERKSEKezpYFeuXMnrr7/O+++/T3BwMLt372b48OG8+uqrjB07tsDeO3r0aMLCwrKOLwzsNcYVERERKZlK67IH+ixXREREpGTLzTg3T0GFtLQ0Nm7cyOjRo7ParFYrHTp0ICYmJlfPiIiIoG/fvpQtWzarzWazMWDAAF544QVuuummXD0nNTWV1NTUrOOkpKRc9kJEREREShMfHx+cnJxISEhwaE9ISMDPzy/He8aOHcuAAQN49NFHAQgMDCQ5OZmhQ4fy8ssv5+qZfn5+pKWlcfr0aYdZFa70Xjc3N9zc3K61qyIiIiIiIiIiIiLFgjUvF19pitvLTV97qdjYWLZt25b1ge8Fb7zxBs7OzjzzzDO5riU8PBwvL6+srUaNGrm+V0RERERKD1dXV5o1a0Z0dHRWm81mIzo6mlatWuV4z7lz57BaHYfKTk5OANjt9lw9s1mzZri4uDhcs3PnTg4cOHDZ94qIiIiIiIiIiIiUBnle+uF6REREEBgYSMuWLbPaNm7cyDvvvMOmTZvyNNXZ5abFFRERERH5r7CwMAYOHEjz5s1p2bIl06ZNIzk5OWs5s9DQUKpVq0Z4eDgA3bp1Y+rUqdxyyy1ZSz+MHTuWbt26ZQUWrvZMLy8vBg8eTFhYGN7e3nh6evL000/TqlUrbr31VnP+IERERERERERERESKgDwFFa5l2twLkpOTiYyMZOLEiQ7tq1ev5ujRo9SsWTOrLTMzk+eee45p06axb9++HJ+naXFFREREJLf69OnDsWPHGDduHPHx8TRp0oRly5ZlzRR24MABhxkUxowZg8ViYcyYMRw+fJjKlSvTrVs3XnvttVw/E+D//u//sFqt9OzZk9TUVDp27Mj7779feB0XERERERERERERKYIsdrvdnpcbgoODadmyJdOnTweMKW5r1qzJsGHDGDVq1GXv++STT3j88cc5fPgwlSpVymo/ceIEcXFxDtd27NiRAQMGMGjQIOrXr5+rupKSkvDy8iIxMRFPT8+8dElEREREiqjSPsYr7f0XERERKalK+zivtPdfREREpKTKyzgvz0s/5HXa3AsiIiLo0aOHQ0gBoFKlStnaXFxc8PPzy3VIQURERERERERERERERERERIqHPAcV8jptLsDOnTtZs2YNy5cvz5+qRUREREREREREREREREREpFjK89IPRZWmCxMREREpeUr7GK+0919ERESkpCrt47zS3n8RERGRkiov4zzrFc+KiIiIiIiIiIiIiIiIiIiI5CMFFURERERERERERERERERERKTQKKggIiIiIiIiIiIiIiIiIiIihUZBBRERERERERERERERERERESk0CiqIiIiIiIiIiIiIiIiIiIhIoVFQQURERERERERERERERERERAqNs9kFiIiIiJhl0yZo2BDKlDG7EhERERERybOMc3B8HXi3AFcvs6sRERERkVLqfPp5ftn/C65OrlT2qEzlspXx8fDB2apfxV+J/nRERESkVPq//4OwMAgKgp9+Am9vsysSEREREZGrsqVD/I+wbz4c+hoyzkLZ2tBuMVS42ezqRERERKQUOZN6hg9++4CpMVNJSE7Idr6ie0Uql61MlbJVjADDvyGGy/10dXI1oRfmUVBBRERESp39+2HMGGN/yxbo1Al+/BE8Pc2tS0REREREcmC3wbF1sH8+HIiC1OMXz1ldIHkvLG8Ft30G1e8zr04RERERKTDHzx3ntyO/0dy/OT4ePqbWcuLcCd7d8C7vxr7L6ZTTAFQtVxUvdy+OJR/j5PmT2LFzKuUUp1JO8feJv3P1XE83z6zQQtVyVenVqBchjUJwcXIpwN6YR0EFERERKVXsdhg2DM6dg6ZNYd8++PVX6NoVli6FsmXNrlBERERE5DrZbWCxml3F9bHb4fRW2P857Psczh24eM69CtTsDbX6QfkbYG1vSPgZVt0PQZOg0WiwWMyrXURERETyjd1uZ8GfCxj2/TBOnD+Bs9WZe2+4lwGNB9D1xq64O7sXWi1Hzhzh7XVv8+HGD0lOTwbgxko3Mrr1aPoF9suaESHTlsmJ8yc4lnyMY+eOZf95yf7R5KMcP3ccm91GUmoSSalJ7Dm1B4BFOxYx6sdRPBP8DEOaDsHLvWQtd2ax2+12s4vID0lJSXh5eZGYmIinvg4pIiIil7FwIfTsCS4uxmwK587BnXdCUhLcfTcsXgzuhTe2laso7WO80t5/ERERySO7Hf58Hf58DarfD00mQ9kaZleVN2f/MYIJ++dD4l8X253LQ40HIKAf+N4Jl673a0uHjSNg1wzjuNaDEBwBzmUKt/Y8KO3jvNLefxEREcmdhLMJPPn9kyzcvhAwllI4lXIq67yXmxchjULo37g/bWq1wVpAYd1/Tv3Dm2vf5OPNH5OWmQZAE78mvNT6JR5o+ABOVqfrer7NbuPU+VMOAYatCVv54LcPOJp8FIDyruV5tOmjDA8eTq0Kta67TwUlL+M8BRVERESk1DhzBho2hMOH4eWXYdIko33dOrjnHkhOhm7d4KuvjCCDmK+0j/FKe/9FREQkD+w2+O2Zi7+sB3AqA41GQsMXwNnDvNqu5nw8HPjCCCicWH+x3eoK1boaMyf433v14MGuD+G3YWDPAO9m0PYb8KhWsLVfo9I+zivt/RcREZEry2kWhZfbvMxLbV5i14ldfLb1M+b9MY+DSQez7qnlVYuHAh+if+P+NKzcMF/q2HZ0G5PXTObzbZ9js9sAuL3G7bzc5mU61euEpYBn8UrJSGHe1nlMXT+Vv44ZIV4nixO9GvXiuVbP0aJaiwJ9/7VQUEGDWxEREcnBs8/CO+9A3brwxx9Q5pLPOX/6Ce69F1JToXdvmD8fnK4vCCv5oLSP8Up7/0VERCSXMlMhZiAcWABY4KaX4ejPcGytcd6jOjR5w5hpoKgsiZCWCIcWwb75kBBtBC3AWLLC904jnFDjfnCtkLfnJvwCa3pC6glw94O2X4NPcH5Xf91K+zivtPdfRERELi/+bDxPLnmSRTsWARDkG8QnPT6hiV8Th+tsdhu/7PuFz7Z+RtRfUZxJO5N1rlnVZgxoPIC+N/fFt5xvnmv49fCvvL7mdb7e8XVWW8e6HXm5zcu0qdXmmvp1Pex2O8t2L+PtmLeJ3hud1d6mZhuea/Uc3ep3K7DZJPJKQQUNbkVEROQ/Nm2CFi3AZoMffjBmUPiv77+HHj0gPR0GDoTZs8FaNMZ3pVZpH+OV9v6LiIhILqSfgdUPQPyPYHWBW+dCQF9jGYgDUfD7C3DugHGtTytoOg18WppTa2YaHPkO9s2Dw0vAlnrxXKVgY1mHmr2hjN/1vefsXvilOyRuA6sbBP8Pave/vmfms9I+zivt/RcREZHs7HY7n2/7nKeXPs3J8ydxtjozps0YRrcZjauT6xXvPZ9+nsU7F/PZH5+xbPcyMmwZgDH7wD1172FA4wHc1+A+PFwuP8uY3W5n5b6VvL7mdX7850cALFh4oOEDjG49mmb+zfKvs9dhc/xmpsZM5fNtn2f18wbvGwhrFUZoUOgV+1gYFFTQ4FZEREQukZkJt94Kv/0GDz5ozJZwOV99BX36GPc88QTMmFF0vnRWGpX2MV5p77+IiIhcRcoxWHkvnPwNnMtCm4VQ9T+J3IzzsONt+DMcMs8ZbQEDoEl44S2LcPYf2D0L/vkYUo5ebPdsAAEPGTM9lK+bv+9MPwMxA+DQN8ZxwxcgKByuc/3g/FLax3mlvf8iIiLiKP5sPE8seSJrBoMmfk345L5PCPILyvOzjiUfY8GfC/h066fEHo7Nai/nWo6eDXsyoPEA2ge0x+nfcaHdbmfJriW8vvp1Yg7FAEbA4aHGDzHq9lH5toxEfjucdJjpsdP5cOOHnE45DUClMpV4ssWTPNXiqWuaSSI/KKigwa2IiIhcYvp0eOYZ8PKCHTvA7ypf0Jo3DwYMML6E9vzz8OabCiuYpbSP8Up7/0VEROQKkvfDT/fAmb/BrRK0+/7KMyWcOwJbRsPeucaxkwc0GgUNnwfnMpe/71rZ0uHQYtj9IcSvuNju7ge1BxizJ1QIKtiBtt0GW8fBn68Zx/5d4Pb54GL+uKq0j/NKe/9FRETEYLfbmf/HfJ5e+jSnUk7hYnVhbNuxjGo9Chcnl+t+/s7jO5n3xzw+2/oZe0/vzWqvVr4a/QL70cCnAe9seIetCVsBcHNyY/Atg3nh9hcIqBBw3e8vDGfTzjL799lMWz8tq49uTm70b9yfsFZhNKrcqFDrUVBBg1sRERH51+HD0LAhnDkDH3wAjz+eu/s++giGDjX2x4+HCRMKrES5gtI+xivt/RcREZHLOL0Nfu4I54+AR024czl41s/dvSd+hY3PwvF1xrFHTbjlTWPJhfwIDZzdB3s+gj2zISX+30aLMdNDvaFQrZuxREVh2hcJGwZBZgp4NoR2i6F8vcKt4T9K+zivtPdfREREIO5MHI8veZzFOxcDcIvfLXzS4xMa+zbO93fZ7XbWHVzHp1s/5Ys/v+BUyimH8+Vcy/Fk8ycZ0WoEfuWucxkyk2TaMlm0YxFvx7zN+kPrs9o71+vMpDsn0bRq00KpQ0EFDW5FRETkXyEh8OWXxtIPa9eC1Zr7e995B5591th/4w148cUCKVGuoLSP8Up7/0VERCQHx9bCyq6Qfhq8boI7fsj7Eg52O+yPhM0j4dxBo63y7dB0GlRqnveabBlw+FtjeYe4H4B/P25094U6j0C9IVCudt6fm59O/AaresD5w+BaEVpHgd9dppVT2sd5pb3/IiIipZndbmfeH/N4ZukzWbMojGs3jpG3j8yXWRSuJjUjle93fc+nWz9l54md9LmpD8NaDsO7jHeBv7uwxByM4e2Yt1m0YxE2u42VA1fSLqBdobxbQQUNbkVERARYsgS6dgUnJ9i0CRpfQxg3PBxeesnYnz4dhg3L3xrlykr7GK+0919ERET+4/B3sCbEmBnA5zZo9y24XccHqhnnYPtb8NcbkHnOaKvzMDR+DTz8r35/8n7Y/T/4JwLOx11s9+sA9R6Dat3ByfXa68tv5+Ng1f1wYgNYnIxgxo1PmbLOW2kf55X2/ouIiJRWR84c4fHvHufbv78FoGnVpnxy3ycE+gaaXFnJtOfkHqL+imLk7SOxFNKYNy/jvDx8p1BERESk+EhOhqeeMvZHjLi2kALA6NHw8svG/tNPw+zZ+VOfiIiIiEie/DPHmBEgMwX8u8CdK64vpADg7AGB46DbTgjo/+97PoHvboQ/X4eM89nvsWXAocWwsgt8Uxv+nGQEANwqQ8MXodsuo7aavYpWSAGgTFXosBICBoA9EzY+Db8+DplpZlcmIiIiUqLZ7XbmbpnLTe/fxLd/f4uL1YVJd0xi/eD1CikUoLredRnVelShhRTyytnsAkREREQKwsSJsH8/1KwJEyZc37NefdUIPkybBo8+Ch4e0LdvflQpIiIiIpILf02Bzf+uQ1Y7FIL/B9Z8nBbXozrc9qkxu8DGZ40ZB7a8bCzlcMsUqNHLWDJh9/9gz/+M/Qt87zRmT6jeo+gFE3Li5A6t5kCFQGPpi92zIGkHtP4S3CubXZ2IiIhIiWG329l1chdrDqzhiz+/4Ic9PwDQrGozPunxCTdXudnkCsVsCiqIiIhIifPHHzB1qrH/3ntQtuz1Pc9iMZ53/jx8+CH07w9lysB9911/rSIiIiIil2W3GwGF7W8Zxw2fhyZvgKWAJkn1uRXuWQf7Pjd+iZ+8H9b0hvI3wtndYLcZ17n5GEtE1B0CnjcWTC0FyWKBRi+A102w7kE4ugp+aAltv4GK1zgVm4iIiEgpl5aZxqa4Taw5sIa1B9ey9sBajp07lnXe1cmVCe0m8MLtL+Bs1a+oRUEFERERKWFsNnjsMcjIgAcegG7d8ue5Fgu8/z6cOweffgq9e8PixdCxY/48X0RERETEgS0dNgyBvXOM4yZvGr9cL2gWK9R+CGr0MGZy2P4mnPnbOFelnTF7Qo0HwMmt4GspaNXuhXvWwy/d4OweiPtBQQURERGRXDqdcpp1B9ex9sBa1hxcQ+zhWFIyUhyucXNyo0W1Ftxe43YGBg2kYeWGJlUrRZGCCiIiIlKi/O9/EBMD5crBO+/k77OtVpg925hZ4csvoUcPWLYM2rXL3/eIiIiISCmXcQ7W9IEj34HFyVjqoc7DhVuDc1loPAHqDoaEaKh0K3g1KNwaCoNXQ+gYC3sijBkriqEZM2YwZcoU4uPjCQoKYvr06bRs2TLHa9u3b88vv/ySrf3ee+9lyZIlAJddw/jNN9/khReMsExAQAD79+93OB8eHs6oUaOupysiIiJSRNntdvYn7jdCCf/OmLDt6Dbs2B2uq1SmErfXvJ3WNVpze83baVa1GW7OJSDgKgVCQQUREREpMRISYORIY3/SJKhePf/f4ewM8+YZYYUlS6BrV1ixAm69Nf/fJSIiIiKlUNop4xv+x9aCkzvc/gVUz6dpwq5F2RqFH5IobG7ehTNbRQFYsGABYWFhzJw5k+DgYKZNm0bHjh3ZuXMnVapUyXb9woULSUtLyzo+ceIEQUFBhISEZLXFxcU53LN06VIGDx5Mz549HdonTpzIkCFDso7Lly+fX90SERERk2XYMvgj4Q/WHFjDmoNrWHtgLYfPHM52XT3verSu2TormFC/Uv3Lhh5F/ktBBRERESkxnnsOTp+Gpk1h2LCCe4+rqzGjQteuEB0NnTvDzz9DkyYF904RERERKQXOHYafO0Lin+BSAdp9C1Vam12VFGFTp05lyJAhDBo0CICZM2eyZMkSZs+enePsBt7e3g7HkZGReHh4OAQV/Pz8HK755ptvuOOOO6hTp45De/ny5bNdKyIiIrkTdyaOuVvm4ubsRnXP6lmbXzk/nK2F8+vb9Mx09ifuZ8/JPew+uZs9p/YY20nj53+XcXC2OtO0atOsUMLtNW7Ht5xvodQqJZOCCiIiIlIi/PijMdOB1QoffghOTgX7Pnd3+OYb6NgR1q6Fu++GX36BRo0K9r0iIiIiUgScj4OEX+DYakg9DvYMsGeC7d+fDse5OHfhZ3oSZKZAGX+4YxlUCDS7p1KEpaWlsXHjRkaPHp3VZrVa6dChAzExMbl6RkREBH379qVs2bI5nk9ISGDJkiXMmTMn27nJkyfz6quvUrNmTfr168eIESNwds754+bU1FRSU1OzjpOSknJVn4iISEljs9uYtXEWo34cRWJqYrbzVouVquWqOoQX/rv5l/fH1ck1V+9LTkvmn1P/sOfUv2GEf0MIe07tYf/p/WTaMy97r6ebJ7fVuC0rmNCyWks8XDyuue8i/6WggoiIiBR7KSnw5JPG/lNPQfPmhfPesmWN5R86dIDffjN+fvwx3HGHMetCUWC3w44dRoji9tshUJ91i4iIiOTduUNGMOHoL3B0JZzZVXDv8mwA7ZdCuYCCe4eUCMePHyczMxNfX8dvMvr6+rJjx46r3h8bG8u2bduIiIi47DVz5syhfPnyPPDAAw7tzzzzDE2bNsXb25t169YxevRo4uLimDp1ao7PCQ8P55VXXslFr0REREquv479xdBvh7L24FoAmlZtSj3vehxKOsShpEMcTjpMpj2Tw2cOc/jMYTYc3nDZZ/mW9c0WYKjsUZkjZ45kBRF2n9xN/Nn4K9ZUxrkMdSrWoa53XepWrEs973rUrViXut51qV2hNk7WAv42mJRqCiqIiIhIsRceDrt2gb8/TJpUuO/28oJly4xwwh9/QKdOUL483HOPsTRE587gW8gzoJ09ayxJsXSpUdv+/UZ7xYqwcSPUrl249YiIiIgUO8kHIGHlv8GEX+Dsnv9cYIGKTaBKeyhXG6zOYLmwOf177HRtx+VvMI5FClhERASBgYG0bNnystfMnj2bhx56CHd3d4f2sLCwrP3GjRvj6urKY489Rnh4OG5ubtmeM3r0aId7kpKSqFGjRj70QkREpOhLyUjh9dWvM3nNZNJt6ZR1Kcvrd73OUy2ecggCZNoyOZp8NCu4kLWdcTxOy0wjITmBhOQENsZtvOr7K7pXzDGIULdiXaqWr4rVYi3I7otclv6rR0RERIq1HTuMoALAO++Ap2fh11CpkrH0xNixxnIQCQnw1VfGZrFAixZGaKFrV2jSxGjLT3Y7/PWXEUxYuhRWr4b09Ivn3dyMkEJ8PPTqZSxV8Z/PGUVERERKL7sdkvcZgYQL4YTkfY7XWKxQsSlUaffv1gZcKxR+rSKX8PHxwcnJiYSEBIf2hIQE/Pz8rnhvcnIykZGRTJw48bLXrF69mp07d7JgwYKr1hIcHExGRgb79u2jfv362c67ubnlGGAQEREp6X7Z9wtDvxvK3yf+BqDrjV2Zce8ManrVzHatk9WJquWrUrV8VVpUa5Hj8+x2O8fPHc8xzJBwNgH/8v4OQYS63nXxLuNdoH0UuVYKKoiIiEixZbfD448bv5Tv0gV69jSvlipV4MMP4YMPYNMm+O47Y9u4EWJjjW3cOGPWhy5djNDCXXcZy0dci6Qkx1kTDh50PF+3rjGbQ6dOxmwPx49D06ZGbcOGwf/+d/19FhERESmW7HY4+4+xhMOF5RzOHXC8xuIE3s2MGROqtIPKt4OrlxnVilyWq6srzZo1Izo6mh49egBgs9mIjo5m2LBhV7w3KiqK1NRU+vfvf9lrIiIiaNasGUFBQVetZfPmzVitVqpUqZKnPoiISMlxMPEgaZlpVC1fFQ8XD7PLMd3J8yd5ccWLRPxuLLHkV86P6Z2n07NhTyzX8S0mi8VC5bKVqVy2MrdUvSW/yhUxhYIKIiIiUmzNnQu//AJlysB77+X/TAXXwmqF5s2NbcIEiIuD7783QgsrVsCRI/DRR8bm5gZ33mmEFrp0gVq1Lv9cux22bbs4a8KaNZCRcfG8uzu0b2+EEzp3hhtucLy/Zk34/HPo2BEiIqBVKxg8uCD+BERERETyUepJ2P4mnDsM9kywZxg/bRkXjy/dzzqXU9u/xxnnIO2k43sszuDdHHzbXwwmuJQ3pcsieREWFsbAgQNp3rw5LVu2ZNq0aSQnJzNo0CAAQkNDqVatGuEXpqH7V0REBD169KBSpUo5PjcpKYmoqCjefvvtbOdiYmLYsGEDd9xxB+XLlycmJoYRI0bQv39/KlasmP+dFBGRIm/h9oX0jupNpj0TAC83L/zL+1O1fFXjZznj56X7JTXQYLfbWfDnAoYvG87R5KMAPNbsMSZ3mEwF9wrmFidSxCioICIiIsXSiRPw/PPG/oQJEBBgZjWXV7WqEQgYPBhSUoxgxZIl8O23sG/fxeDBU0/BzTdfXCLi1lvh7FljSYkLsyYcPuz47BtuMGZM6NzZCCmUKXPlWu6+G159FcaMMd53yy3GLAsiIiIiRdKZ3bDyXjizK/+fbXWBSi3/XcahPfi0Apdy+f8ekQLWp08fjh07xrhx44iPj6dJkyYsW7YMX19fAA4cOIDV6rju9M6dO1mzZg3Lly+/7HMjIyOx2+08+OCD2c65ubkRGRnJhAkTSE1NpXbt2owYMYKwsLD87ZyIiBQLMQdjeGjhQ2TaM3GxupBuSycxNZHE1ES2H99+xXu93LyywgwOIYZLwgz+5f2LTaBh3+l9PLnkSZbuXgpAQ5+GzOo2i9Y1W5tcmUjRZLHb7Xazi8gPSUlJeHl5kZiYiKcZi1OLiIhIoRo8GGbPhsBAY3kFFxezK8obux22b7+4RMTatWCzXTxfoYIRVLh01oQyZYxlHC7MmlC3bt7fa7NBjx5GUCIgwPiz8y7Cy9SV9jFeae+/iIiUYkfXwOoekHoCPGrCjcOMcIHFGaxOxk+Ls7FEg/Xfnw7HVzlX/gZwLh4feEvJVNrHeaW9/yIiJcXuk7tpFdGK4+eO0/XGrizqs4jktGTizsZx5MwRjpw5QtwZY//StiNnjnA+43yu3+Pp5knVclWpWr6q8fPS/Ut+erl5XdeyCnlhs9tISk3i5PmTnDp/ip/3/cz4leM5l34OVydXxrQZw4u3v4ibs1uh1CNSVORlnKcZFURERKTYWb3aCCkAzJxZ/EIKYCxT0aiRsb34Ipw8CT/8YIQWli6FU6eM62688WIwoW3bq8+acDVWq7FkRrNm8M8/MGCAEVr4z5esRERERMyzbz6sHwS2NGM5hnbfQhk/s6sSERERkUscP3eczvM6c/zccZpVbUZkz0icrc54uXvh5e5FA58Gl73XbreTlJqUFV64EGa4NNBw4ee59HMkpSaRlJrEzhM7r1iTu7P7ZQMNfuX8svYrl62M1WJ8GJaWmcap86c4lXKKk+dPOmynzv/blpK97VTKKWx2W7Ya2tZqy6yus6jvU//6/oBFSgEFFURERKRY+esveOQRY3/oULjtNnPryS/e3vDgg8aWkQGbNxttderk/7sqVICvvoJWreD772HSJBg3Lv/fIyIiIpIndjtsmwR//DswqX4/3PaZZj4QERERKWLOp5/nvsj72H1yN7W8avFdv+8o61o21/dbLJY8BRqOnDlC/Nl44s7GEXcmzvh56f6ZOBJTE0nJSGHv6b3sPb33iu93sjhRyaMS59LPcTbtbK7rzomHiwfeZbypUrYKTzR/gkdueSQrBCEiV6aggoiIiBQLGRnw1lswfjykpYG/P0yebHZVBcPZGZo3L9h3NGlizEbx8MMwYQK0bAmdOhXsO0VEREQuKzMVYofC3rnGccPnockboA95RURERIoUm93GwK8Hsu7gOrzcvPj+oe/xK1cws19dGmhoWLnhFa89l37OCDOccQwx/DfgcCz5GJn2TI4mH734Hoz3eJfxdtzcvalYpmL29jLeVHSvSMUyFXF3di+QvouUBgoqiIiISJH355/GL9R/+8047tIFPvwQKlY0taxib+BAiIkx/iwfegg2boSAALOrEhERkVIn9SSsfgCO/gIWJ2j+HtzwuNlViYiIiEgORq4YSdRfUbhYXfi679c0qtzI7JIAY2aDOhXrUKfilacnTc9M52jyUY6dO0Y513J4l/HGy80LJ6tTIVUqIhcoqCAiIiJFVkYGvPkmvPKKMYtChQrwzjswYABYLGZXVzK8844RUPjtN+jVC9asAXcFwUVERKSwnNkNK7vAmb/BuTy0jgL/jmZXJSIiIiI5mBE7g7di3gLg4/s+pn1Ae3MLugYuTi5U86xGNc9qZpciUupp/jwREREpkv74A269FV5+2QgpdO1qzKwQGqqQQn5yc4MvvwRvbyOw8MwzZlckIiIipcaxtbD8ViOk4FED7lmrkIKIiIhIEfXtzm95ZpnxwdGkOybxUOOHTK5IRIo7BRVERESkSElPh0mToFkz4xfnFSvCp5/C4sXg7292dSVTrVrw+edGAOSjj+Djj82uSEREREq8fZ9D9J2QegK8m0PHDVAh0OyqRERERCQHvx7+lb5f9cVmt/HoLY/yUpuXzC5JREoABRVERESkyNi6FYKDYexYI7DQvbsxi0L//ppFoaDdc4+xxAbAk0/C5s2mllMgZsyYQUBAAO7u7gQHBxMbG3vZa9u3b4/FYsm2denSJeuanM5bLBamTJmSdU1AQEC285MnTy7QfoqIiBRpdjtsmwTr+oEtDar3gA4roUxVsysTERERkRzsPbWXrp935Vz6OTrW7cj7Xd7Hog/qRCQfOJtdgIiIiBRNsbFQrhw0bFjwIYH0dAgPN2ZSSE83liGYPh0efFABhcL08suwYQMsWQIPPHBxRouSYMGCBYSFhTFz5kyCg4OZNm0aHTt2ZOfOnVSpUiXb9QsXLiQtLS3r+MSJEwQFBRESEpLVFhcX53DP0qVLGTx4MD179nRonzhxIkOGDMk6Ll++fH51S0REJH9lpkHaCWOWg9QT/+6fBHvGJRfZHe+x/+f4auePr4X9kcZ+g+egyRtgdcqP6kVERETyVaYtk/WH1nNL1VvwcPEwuxxTnDp/invn38vR5KME+QYRFRKFi5OL2WWJSAmhoIKIiIg4sNlg5Eh46y3juHZt6NIFunaFdu3A3T1/37d5MwwadPEb/D16wAcfgJ9f/r5Hrs5qNZbZaNYM9u6FAQOMJTesJWAOrqlTpzJkyBAGDRoEwMyZM1myZAmzZ89m1KhR2a739vZ2OI6MjMTDw8MhqOD3n/+RfvPNN9xxxx3UqVPHob18+fLZrhURESlQdjtknPk3cHD8P8GDK+xnnC2c+ixO0Pw9uOHxwnmfiIiISB7Z7XYeWfwIc7fMpbJHZZ5r9RxPtHgCTzdPs0srNKkZqfRY0IMdx3dQ3bM6S/otobybvnwhIvnHYrdni74XS0lJSXh5eZGYmIinZ+n5i0JERCQ/nTtnLLOwaJFx7OoKl3ypnLJl4e67jdDCvfdC1euYoTctDV5/HV57DTIyjFkU3nsP+vbVLApm+/13uO02SEmBV1+FMWPMqyU/xnhpaWl4eHjw5Zdf0qNHj6z2gQMHcvr0ab755purPiMwMJBWrVoxa9asHM8nJCRQvXp15syZQ79+/bLaAwICSElJIT09nZo1a9KvXz9GjBiBs3Pu8sIa44qIiAO7DVKOwfnDcP4InDts7F/4ef4IpBw1QgcOsyDkgcUKrt7gVglcKxn7Tq7/vejKx9kGc5ccW12gziPgd+e11SdSQpT2cV5p77+IFH2zNs7ise8ec2ir6F6R4cHDeTr4abzLeF/mzpLBZrfRf2F/Pt/2OZ5unqwZtIZA30CzyxKRYiAv4zzNqCAiIiIAxMVB9+7w229GQOHjj43j6GhjKYDvvjOu+fprYwPjm/dduxpb06a5/+b977/Dww/D1q3G8QMPwPvvg69vAXRM8uyWW4x/Ho88AuPGQcuWcM89Zld17Y4fP05mZia+//kfmK+vLzt27Ljq/bGxsWzbto2IiIjLXjNnzhzKly/PAw884ND+zDPP0LRpU7y9vVm3bh2jR48mLi6OqVOn5vic1NRUUlNTs46TkpKuWp+IiJQQGcmXBA+OZA8gnDsMKXFgS8/9M53KXAwcuFW6wr7PxTYXLyOsICIiIlJKbTyykaeXPg3ApDsmUcOrBq+vfp2dJ3Yy4ZcJvBXzFk+1eIqwVmFUKZt9OcmSYMxPY/h82+c4W535qvdXCimISIHQjAoiIiLC1q1G2ODgQahUCb75Bm6/3fEau90IGHz3nRFciI11PO/re3GJiA4doHwOM8GlpcGkSRAebsyiUKkSzJgBvXtrFoWiaOhQ+Ogj45/Txo1Qq1bh15AfY7wjR45QrVo11q1bR6tWrbLaX3zxRX755Rc2bNhwxfsfe+wxYmJi2HohWZODBg0acPfddzN9+vQrPmv27Nk89thjnD17Fjc3t2znJ0yYwCuvvJKtXWNcEZESwm6HQ9/AyV+zhxDSE3P5EAu4+0IZf/CoBmWqOf50970YQnAuU6DdEZFrV9o/yyzt/ReRouvU+VM0m9WMvaf30u3Gbnzd92usFiuZtky+2v4Vr61+ja0JxucDZZzLMLTZUJ6/7Xmqe1Y3ufL8c+lsEh/f9zEPN3nY3IJEpFjJyzhPQQUREZFSbulSIyhw9izUr2+EEOrWvfp98fHGvd99B8uXG/df4OoK7dtfDC7UqWP8onvQIPjjD+Oanj2Nb+1XKZnB8xIhJQVatzb+2bVoAatXQw6/Wy9QZi/9kJycjL+/PxMnTmT48OE5XrN69Wratm3L5s2bCQoKumItf/75JzfffDM7duygfv362c7nNKNCjRo1NMYVESkJzifAhkfhyHeXv8a5bPbgQRl/x7YyfsbyCSJSrJX2zzJLe/9FpGiy2W30iOzBt39/S+0Ktdk4dCMVy1R0uMZut/Pd398xafUkYg8b3+JxdXLl4aCHGdl6JHUq1jGj9HyzdNdSun3ejUx7JuPbjWdC+wlmlyQixUxexnnXNJffjBkzCAgIwN3dneDgYGL/+5XKS7Rv3x6LxZJt69KlCwDp6emMHDmSwMBAypYti7+/P6GhoRw5cuRaShMREZE8mDHDCBKcPQt33AExMbkLKQD4+RnBg6++guPHYcUKGD7cCCWkpRnhheHDjefdeCMEBxshBR8f+OIL+PJLhRSKOnd345+Ttzf8+is8+6zZFV0bV1dXmjVrRnR0dFabzWYjOjraYYaFnERFRZGamkr//v0ve01ERATNmjW7akgBYPPmzVitVqpc5n/8bm5ueHp6OmwiIlICHFoM3wcaIQWrK9R9FIJeg1s/gTtXQJc/oddpCDkD3XbCXT/BbZ9Ck8lQ/xmo2RN8boWyNRRSEBERESkgU9ZO4du/v8XNyY0ve3+ZLaQAYLFY6Fa/G+sHr2d5/+W0q9WOtMw0Zm2axY3Tb2Tg1wPZcfzqy0wWRb/H/U5IVAiZ9kwGBg1kfLvxZpckIiVcnoMKCxYsICwsjPHjx7Np0yaCgoLo2LEjR48ezfH6hQsXEhcXl7Vt27YNJycnQkJCADh37hybNm1i7NixbNq0iYULF7Jz5066d+9+fT0TERGRy8rMNH7pPGwY2GxG4GDZMqiY/b+/csXNzVjuYdo02L0btm+Ht94yZlVwcoJdu4x39u4Nf/0F/w4DpBgICIB584ylOWbOhLlzza7o2oSFhfHRRx8xZ84ctm/fzhNPPEFycjKDBg0CIDQ0lNGjR2e7LyIigh49elCpUqUcn5uUlERUVBSPPvpotnMxMTFMmzaNLVu28M8//zBv3jxGjBhB//79qXit/2cTEZHiJf2MMYvCqvsg9RhUaAydfoPgj+Cml6DOQPDrAF6NwNVLa2GJiIiImGTlvpW89NNLALzb+V2aVm16xestFgt3172blQ+vZNXDq+hYtyOZ9kzmbplLoxmN6B3Vmy3xWwqj9HxxIPEAXeZ3ITk9mTtr38msbrOwaGwqIgUsz0s/BAcH06JFC9577z3A+DZajRo1ePrppxk1atRV7582bRrjxo0jLi6OsmXL5njNr7/+SsuWLdm/fz81a9bMVV2aLkxERCR3zp6FBx80lmwAeP11GDWq4D4XP30aoqOhcmVo27Zg3iEF75VXYMIEY5aF9eshF5MH5Iv8HOO99957TJkyhfj4eJo0acK7775LcHAwYMwCFhAQwCeffJJ1/c6dO2nQoAHLly/n7rvvzvGZs2bN4tlnnyUuLg4vLy+Hc5s2beLJJ59kx44dpKamUrt2bQYMGEBYWBhuuVxDQ2NcEZFi7Ng6iBkAZ/8BLNDweWj8KjgV8jpKIlIklfZxXmnvv4gULXFn4rjlw1tISE5gQOMBzOkx55p+Sf/r4V95fc3rfL3j66y2bjd24+U2LxNcPTgfK85fp1NO03p2a/489ic3V7mZNYPW4OXudfUbRURykJdxXp6CCtezvu8FgYGBtGrVilmzZl32mh9//JF77rmH06dPX7YDWr9XREQk7w4dgm7dYPNm4xfOc+dqdgPJHZvNWCZk6VIj6DJ/fuG8t7R/gFna+y8iUixlpsG2V+CvyWC3gUdNaDUXfNuZXZmIFCGlfZxX2vsvIkVHhi2Du+bexar9q7i5ys2sH7yesq45f8k2t/5I+IPX17zOgm0LsGP8Cq5DnQ6MaTOGtrXaFomZCg4mHmT1gdWs2r+KH/b8wL7T+6hariobHt1ADa8aZpcnIsVYXsZ5znl58PHjx8nMzMTX19eh3dfXlx07rr7mTmxsLNu2bSMiIuKy16SkpDBy5EgefPDBKxYfHh7OK6+8kvviRURESrnffzd+0XzkCFSpAt98A7feanZVUlxYrfDZZ8byHmPGmF2NiIhIEZW4Hdb1h1ObjOPaodDsXWNZBxEREREpcsb8NIZV+1dRzrUcX4Z8ed0hBYBA30A+7/k5E9pNYPLayXy29TN+/OdHfvznR1rXbM2YNmO4p+49hRZYsNvt7D65m1X7V7HqwCpW7V/FvtP7HK6p4F6BJf2WKKQgIoUqT0GF6xUREUFgYCAtW7bM8Xx6ejq9e/fGbrfzwQcfXPFZo0ePJiwsLOv4wowKIiIikt3ixca34M+dg0aNYMkSCAgwuyopbry9YeJEs6sQEREpguw2+HsGbH4RMlPA1Rtafgg1e5ldmYiIiIhcxuKdi3lj7RsARHSPoL5P/Xx9fn2f+nx838eMbzeeN9e+ScTvEaw5sIZO8zrRrGozxrQdQ/f63bFarPn6Xpvdxraj21i1f1XWrAnxZ+MdrrFarDSt2pS2NdvSplYb2ge0p4J7hXytQ0TkavIUVPDx8cHJyYmEhASH9oSEBPz8/K54b3JyMpGRkUy8zKfbF0IK+/fv56effrrqVBBubm65XttXRESktLLbjW/AP/ecsX/33RAVBV76Up+IiIjkJ7sN8vkD1mLj3GFYPwjiVxjHVTtC8Gzw8De3LhERERG5rH9O/UPoolAAnmn5DL1v6l1g7wqoEMD7Xd5nTNsxvLXuLWb+NpONcRu5f8H93FzlZl5u8zIhjUJwsjpd0/PTM9P5Pf53Y8aE/atYc2ANp1JOOVzj6uRKcLVg2tRsQ9tabWlVoxWeblp6R0TMlaeggqurK82aNSM6OpoePXoAYLPZiI6OZtiwYVe8NyoqitTUVPr375/t3IWQwq5du/j555+pVKlSXsoSERGRHGRkwDPPwIVJioYOhffeAxcXc+sSERGREubv9+H356BsbajWFfy7QOXbwFoKBh37v4BfH4e0U+BUBm6ZAjc8CUVg3WERERERyVlKRgq9vuhFYmoit1a/lSn3TCmU9/qX92dqx6mMbj2aaeunMT12OtuObuPBrx5k3M/jGN16NP0b98fF6crj6PPp54k9HJu1lEPMwRiS05MdrinrUpbbatxG21ptaVurLS2rtcTd2b0guycikmcWu91uz8sNCxYsYODAgXz44Ye0bNmSadOm8cUXX7Bjxw58fX0JDQ2lWrVqhIeHO9zXpk0bqlWrRmRkpEN7eno6vXr1YtOmTXz33Xf4+vpmnfP29sbV1TVXdSUlJeHl5UViYuJVZ2MQEREp6ZKSoE8fWLbM+Jx8yhQIC9Nn5lL8lPYxXmnvv4gUcbZ02DgcduWwdKNLBWNmgWpdoWoncPcp9PIKVNpp+G0Y7JtnHHs3h1afglcDU8sSkeKjtI/zSnv/RcRcj337GLM2zaJSmUr8/tjv1PAyZ1nxU+dP8V7se0zbMI2T508CUMurFiNvH8mgWwZlBQuSUpNYd3Adq/evZtWBVcQejiUtM83hWRXdK9KmVhva1jSCCU38mlw18CAiUhDyMs7L04wKAH369OHYsWOMGzeO+Ph4mjRpwrJly7ICBgcOHMBqdZzucefOnaxZs4bly5dne97hw4dZvHgxAE2aNHE49/PPP9O+ffu8ligiIlKq7d8PXbvCtm3g4QHz5sG/EyGJiIiI5I/Uk7AmBBJ+AiwQ9BqUqwOHv4O4pZB6Ag4sMDaLFSrdCtW6gH9XqBBYvNOTCT9DzEA4d9Do200vw81jS8cMEiIiIiLF3Nwtc5m1aRYWLMzvOd+0kAJAxTIVGdtuLM/e+iwzf5vJ2zFvsz9xP09+/ySvrnqVbjd2Y2PcRn6P/x2b3eZwr185P9rVape1lMNNVW7CWlqXYhORYivPMyoUVUrhioiIwK+/QrdukJAAfn7w3XfQrJnZVYlcu9I+xivt/ReRIipxO/zSDc7uAedycNt8qN7t4nlbJpzYAEeWGMGF01sd7/eoYSwPUa0L+N4Jzh6FW/+1yjgHW8fBjqmAHcrVhds+A59bza5MRIqh0j7OK+39FxFz/JHwB8H/C+Z8xnkmtJvA+PbjzS7Jwfn080T8HsEba9/gUNIhh3O1K9TOWsahba221K1YF0txDv+KSImVl3GeggoiIiIlxMKF0L8/nD8PjRsbIYUa5oXCRfJFaR/jlfb+i0gRdGQZrO0D6UlQNgDaLTZmSLiS5ANw5Hs4vAQSfoTMlIvnnNyNsEK1rkZ4oWzNAi0/19JOw6nNcOp3OPm78TNpO9gzjfP1hsItb4NLOTOrFJFirLSP80p7/0Wk8CWlJtF8VnN2ndzFPXXv4ft+3+NkdTK7rBylZabx2dbP2HZ0Gy38W9CmVhuqe1Y3uywRkVwp0KUfREREpGix22HqVHjhBWO/c2dYsADKlze7MhERESkx7HbY+Q78/hzYbVC5DbT5CtwrX/3esjXhhseNLeO8sXTCke+M4MK5f0MMR743rq0Q+O9sC12N5SIK48Pj83FwcpMRRrgQTEjem/O1HjWhxQyjPhEREREpFux2O48ufpRdJ3dR3bM68x6YV2RDCgCuTq48cssjZpchIlLgFFQQEREpxjIzYfhwmDHDOH7qKZg2DZz1N7yIiIjkl8w0+O1J2BNhHNcdDM3fByfXvD/LuQxUu9fYmtshcZsRWDjyHRyPgdN/GNtfk8HVG/w7G8EF/07gWvH6+mG3wdl/HGdJOPU7pCTkfH3ZWlDxloub9y1Qphpoil0RERGRYmV67HSi/orC2epMVEgUPh4+ZpckIiIoqCAiIlJsJSfDgw/Ct98an5e/9RaMGKHPzkVERCQfpRyD1T3h2GqwWI3lDuoPz58Bh8VizKBQIRBuGgWpJ4ylJY4sgSNLIe0k7JtnbBYn8Lnt4hIRXo2uXIMtHRL/+k8oYTNknMmhDit4NnAMJVRsAm7e199HERERETFVzMEYnlv+HABv3/M2t1a/1eSKRETkAgUVREREiqH4eOjWDX77Ddzd4bPPoGdPs6sSERGREuX0H/BLd0jeBy6ecPsCY2aDguJWCWo/ZGy2DGOGhcPfGcGFxD+NsMSx1bB5JJQNuGSJiBaQtNNx6YbEbWBLy/4Oq5sRjPBuejGUUCEQnD0Krl8iIiIiYopjycfo/WVvMmwZhDQK4emWT5tdkoiIXEJBBRERkWJm+3bo3Bn27wcfH1i8GFq1MrsqERERKVEOfQvr+kHGWShXF9p9C14NC+/9Vmeo0sbYbnkDzu4zAguHv4OEn43wxK4ZxnY5Ll7GzAiXLt3g2QCsLoXUCRERERExS6Ytk/6L+nMo6RA3VrqR/3X/HxZNQyoiUqQoqCAiIlKMrFwJ998Pp09DvXqwdKnxU0RERCRf2O2wfQpsHgXYwfdOaP2FMduBmcoFwI1PGVtGMsRH/xtcWALnD0OZqo5LN3jfAmVra00sERERkVJq0qpJLN+znDLOZfiq91d4unmaXZKIiPyHggoiIiLFxGefwSOPQHo63HYbfPONMaOCiIiISL7ITIENQ2Hfp8bxDU9As3eK3gwEzmWhendjs9shPQlcvcyuSkRERESKiB92/8Arv7wCwIddP+TmKjebXJGIiOTEanYBIiIicmV2O0yaBAMGGCGFkBD48UeFFERERCQfnY+HH+8wQgoWJ2g+A1q8X/RCCv9lsSikICIiIiJZDiYe5KGFD2HHztCmQxkQNMDskkRE5DI0o4KIiEgRlp4OTzwBERHG8QsvwOTJYFXUUERERPLLyd9h1X1w7iC4VIA2UeDXweyqRERERETyJC0zjd5f9ubE+RM0rdqUdzq/Y3ZJIiJyBQoqiIiIFFFJScbsCcuXG8GE6dPhySfNrkpERERKlANfQUwoZJ4Dz/rQ9lvwvMHsqkRERERE8uzFFS+y/tB6KrhX4MuQL3F3dje7JBERuQIFFURERIqgQ4egSxfYuhU8PGDBAuja1eyqREREpMSw22HbJPhjnHHsdw+0XgCuFUwtS0RERETkWnzx5xe8s8GYQWFuj7nUrljb5IpERORqNHG0iIhIEZKSAjNnQsuWRkjBzw9WrVJIQURERPJRxnlY1+9iSKH+cGi/RCEFERERESmWdh7fyeDFgwEYdfsoutXvZnJFIiKSG5pRQUREpAg4c8YIKEydCvHxRlujRvD991Crlrm1iYiISAly7gisug9O/gYWZ2jxPtQbYnZVIiIiIiLXJDktmZ5f9ORs2lna1WrHq3e+anZJIiKSS5pRQURESiy7HY4cgR9/hHffhccfhzZtoFIlqF4dnn8etmwxt8bjx2HcOCOM8OKLRkihRg145x349VeFFERERCQfnfgVfmhhhBTcKsGdPyqkICJSAsyYMYOAgADc3d0JDg4mNjb2ste2b98ei8WSbevSpUvWNQ8//HC28506dXJ4zsmTJ3nooYfw9PSkQoUKDB48mLNnzxZYH0VEcmK323liyRP8eexP/Mr5EdkrEmervp8rIlJc6N/YIiJS7NntcPAg/PVX9i0x8fL3vf22sTVuDAMGQL9+4O9fODUfOmS8e9YsOHfOaKtfH0aNMupwdS2cOkRERKSU2BcJGwZBZgp43QTtFkO5OmZXJSIi12nBggWEhYUxc+ZMgoODmTZtGh07dmTnzp1UqVIl2/ULFy4kLS0t6/jEiRMEBQUREhLicF2nTp34+OOPs47d3Nwczj/00EPExcWxYsUK0tPTGTRoEEOHDmX+/Pn53EMRkcv7aNNHfLr1U5wsTkT2jMSvnJ/ZJYmISB4oqCAiIsWGzQb79+ccSLjcFzecnKBePWMZhUaN4KaboGFDI9gwdy4sXgxbt8ILL8DIkXD33UZooUcPKFs2//uwaxe88Ybx7vR0o61pU3jpJeOdTk75/04REREpxew22Doe/pxkHPt3gdvng4unuXWJiEi+mDp1KkOGDGHQoEEAzJw5kyVLljB79mxGjRqV7Xpvb2+H48jISDw8PLIFFdzc3PDzy/kXftu3b2fZsmX8+uuvNG/eHIDp06dz77338tZbb+FfWN8AEJFSbeORjTy99GkAXr/rddoFtDO5IhERySsFFUREpEg6ehRiYhzDCNu3w/nzOV/v4gI33ngxkHBhu+EG+M8XPwBo0gS6dYNTpyAqyggOrF0LP/xgbOXKQc+eEBoK7duD9ToXS9q8GcLD4csvjcAFGM8dPdoIR1gs1/d8ERERkWwykiEmFA4uNI4bvgBB4WBVMlJEpCRIS0tj48aNjB49OqvNarXSoUMHYmJicvWMiIgI+vbtS9n/JPVXrlxJlSpVqFixInfeeSeTJk2iUqVKAMTExFChQoWskAJAhw4dsFqtbNiwgfvvvz/be1JTU0lNTc06TkpKylNfRUQuder8KUKiQkjLTKN7/e48f9vzZpckIiLXQEEFEREpUk6ehMmTYfp0SEnJft7VFRo0yB5IqFfPCCvkVcWKMHSose3ZA599ZoQW/vkH5swxturVoX9/Y6aFRo3y9vzVq42AwtKlF9u6dTMCCq1a5b1eERERkVxJPgCr7oNTm8HqCi1nQZ2BZlclIiL56Pjx42RmZuLr6+vQ7uvry44dO656f2xsLNu2bSMiIsKhvVOnTjzwwAPUrl2bPXv28NJLL9G5c2diYmJwcnIiPj4+27ISzs7OeHt7Ex8fn+O7wsPDeeWVV/LYQxGR7Gx2GwO/Hsje03upXaE2n9z3CVbLdX7DSERETKGggoiIFAnnzhnhhMmT4fRpo61RI7jlFsdlG2rXBucC+turbl0YPx7GjYN16+DTT2HBAjh0yKhr8mRo1syYZaFvX8hhuU8A7HYjmBAeDmvWGG1Wq3HPqFEQGFgw9YuIiIgAcCwGVt8PKQngXgXaLILKt5ldlYiIFDEREREEBgbSsmVLh/a+fftm7QcGBtK4cWPq1q3LypUrueuuu67pXaNHjyYsLCzrOCkpiRo1alxb4SJSqk1ZO4Vv//4WNyc3vuz9JRXLVDS7JBERuUYKKoiIiKkyMuDjj2HCBDhyxGgLDDRCAZ07m7MkgsUCt99ubNOmwZIlxiwL338PGzcaW1iYUd+AAdC9O7i7Q2amsbRDeDhs2WI8y9UVBg2CF14wghAiIiIiBWrvp7DhUbClQYUgaPcNlK1ldlUiIlIAfHx8cHJyIiEhwaE9ISEBPz+/K96bnJxMZGQkEydOvOp76tSpg4+PD7t37+auu+7Cz8+Po0ePOlyTkZHByZMnL/teNzc33HJal1FEJA9W7lvJSz+9BMD0ztNpWrWpyRWJiMj10Hw4IiJiCrsdFi6Em282ll04cgRq1TICAb//Dvfea05I4b/c3aFnT/jmG6PG6dOhRQsjlPDdd9CnD/j5wcCBxpIUffsaIYVy5eD552HvXpg5UyEFERERKWC2TNg8CmJCjZBC9fvh7jUKKYiIlGCurq40a9aM6OjorDabzUZ0dDStrrLWYFRUFKmpqfTv3/+q7zl06BAnTpygatWqALRq1YrTp0+zcePGrGt++uknbDYbwcHB19gbEZErizsTR98v+2Kz2wgNCuXRpo+aXZKIiFwnBRVERKTQrVwJrVoZAYCdO6FSJfi//zP2BwwAJyezK8xZ5cowbBjExsL27fDSS1CzJiQmGgGL3bvB2xteeQX274cpU8Df3+yqRUREpMRLP2Ms9fDXG8bxTS9Dmy/BpZy5dYmISIELCwvjo48+Ys6cOWzfvp0nnniC5ORkBg0aBEBoaCijR4/Odl9ERAQ9evSgUqVKDu1nz57lhRdeYP369ezbt4/o6Gjuu+8+6tWrR8eOHQFo2LAhnTp1YsiQIcTGxrJ27VqGDRtG37598dd/BItIAciwZdD3q74kJCdwc5Wb+aDLB1iKwjecRETkumjpBxERKTRbtsDo0bB0qXHs4WEsofD88+DlZW5tedWgAbz2Grz6KqxaBYsXQ0AAPPKIMZuCiIiISKE4uxd+6Q6J28DqBrfOhoB+ZlclIiKFpE+fPhw7doxx48YRHx9PkyZNWLZsGb6+vgAcOHAAq9Xxu2o7d+5kzZo1LF++PNvznJyc2Lp1K3PmzOH06dP4+/tzzz338Oqrrzos3TBv3jyGDRvGXXfdhdVqpWfPnrz77rsF21kRKbXG/DSGVftXUd61PF/1/goPFw+zSxIRkXxgsdvtdrOLyA9JSUl4eXmRmJiIp6en2eWIiMgl9u6FceNg3jxjyQdnZxgyxGi7yrKZIlLKlfYxXmnvv4hcxdHVsPoBSD0O7n7Q9hvwaWl2VSIikgulfZxX2vsvIrm3eOdi7ou8D4Aven1ByE0hJlckIiJXkpdxnmZUEBEpJH//Df/7H7i4QJMmEBQE9eqBtQQvwnPsGEyaBB98AOnpRlufPkZbvXrm1iYiIiJSrJ3aDD93gsxz4N0M2n4NHtXNrkpEREREJN/8c+ofBn49EIDhwcMVUhARKWEUVBARKWDbtxtLBHz+OdhsjufKloXAQCO0cCG8EBhY/JcOOHsWpk6FKVOMfYAOHWDyZGjWzNzaRERERIq9lKPwy31GSMGvgzGTgrOmvxURERGRkiMlI4WQqBBOp5ymVfVWvHn3m2aXJCIi+UxBBRGRAvLnn8bMAQsWGMsdAHTpAlWrwpYt8McfkJwM69cb2wUWizHbwKXhhaAgqF7dOFfUnDoFu3c7bsuWwdGjxvlmzYyAQocO5tYpIiIiUiJkpsHqXnDuAJS/AVp/oZCCiIiIiJQ4w5cOZ1PcJnw8fFjQawGuTq5mlyQiIvlMQQURkXy2dSu8+ip8+eXFth49YOxYaNr0YltGBuzaZYQWNm82fm7ZAnFxRvuuXY7P8PbOHl5o1AhcC3iMbrfDiROOQYRduy7unzyZ83116xozSYSElOzlLUREREQKjd0Ovw2DY6vBxRPaLgbXimZXJSIiIiKSr+ZumcusTbOwYGH+A/Op4VXD7JJERKQAKKggIpJPNm+GiRNh0aKLbb16wZgxRqjgv5ydoWFDY+vb92L70aPZwwvbtxuBgJ9/NrYLXFyM+y8NLwQFgY9P3mq32433XhpAuHRLTLzy/VWrGrNAXNgaNTJmj3BxyVsdIiIiInIFu96HPR8BFrjtc/BqYHZFIiIiIiL5atvRbTz+3eMATGg/gbvr3m1yRSIiUlAUVBARuU6//WbMoLB4sXFssUDv3kZA4eab8/68KlXg7ruN7YKUFPjrr+wBhtOnjRkctm51fEa1ao7hhSZNoE4dSEjIOYiwezecPXvluqpXN0IIN9zgGEqoUwfKlct7P0VEREQkD+J/go3Djf0mb0C1e82tR0REREQkn51NO0tIVAjnM85zT917GNN2jNkliYhIAVJQQUTkGm3YYMyg8P33xrHVasyM8PLLxowC+cnd3Vg24tKlI+x2OHDgYmjhQoBhzx44fNjYliy5eL3FYtxzORYL1KrlGEK4NIxQpkz+9klEREREcunsP7AmBOyZENAfGj5vdkUiIiIiIvnKbrfzxJIn2HF8B/7l/fns/s+wWrSerIhISaaggohIHq1bZwQUfvjBOLZaoX9/eOklqF+/8Oq4ECyoVQu6d7/YnpQEf/zhGF744w84fx6cnCAgIHsQ4YYbjHY3t8KrX0RERERyIf0M/NId0k5CpZYQ/JExEBQRERERKUEifo/gs62f4WRxIrJnJJXLVja7JBERKWAKKoiI5NLq1fDKKxAdbRw7OUFoqBFQqFfP3Nou5ekJt99ubBdkZkJ8vLGshIuLebWJiIiISB7YbbCuPyT+CWWqQptF4ORudlUiIiIiIvlqa8JWnl76NACT7pxEm1ptTK5IREQKg4IKIiJXYLfDL78YAYWVK402Z2d4+GEYPdpYEqE4cHKCatXMrkJERERE8mTrODi8GKxuRkjBw9/sikRERERE8tWZ1DOERIWQkpHCvTfcy4u3v2h2SSIiUkgUVBARyYHdbsycMHGiMZMCGDMRPPKIEVCoVcvc+kRERESkhNu/AP58zdgP/gh8gs2tR0REREQkn9ntdoZ+N5S/T/xNdc/qzOkxB6vFanZZIiJSSBRUEBG5hN0Oy5cbAYV164w2V1cYMgRGjoQaNcytT0RERERKgZObYP0gY7/h81B7gLn1iIiIiIgUgA83fkjktkicrc4s6LUAHw8fs0sSEZFCpKCCiAhGQOH7742AQmys0ebuDkOHwosvatkEERERESkk5xNg1X2QeR6qdoKgyWZXJCIiIiKS736P+51nlz0LQPhd4dxW4zZzCxIRkUKnOXREpFSz22HxYmjRArp2NUIKZcpAWBj88w+8845CCiIiJcWMGTMICAjA3d2d4OBgYi8k03LQvn17LBZLtq1Lly5Z1zz88MPZznfq1MnhOSdPnuShhx7C09OTChUqMHjwYM6ePVtgfRSRYi4zFVY/AOcOgWd9uP1zsDqZXZWIiIiISL5KTEkkJCqE1MxUut3YjedaPWd2SSIiYgLNqCAipZLNBt98Y8ygsHmz0ebhAU89Bc89B76+ppYnIiL5bMGCBYSFhTFz5kyCg4OZNm0aHTt2ZOfOnVSpUiXb9QsXLiQtLS3r+MSJEwQFBRESEuJwXadOnfj444+zjt3c3BzOP/TQQ8TFxbFixQrS09MZNGgQQ4cOZf78+fncQxEp9ux2+PVJOL4OXLyg7WJwrWB2VSIiIiIi+cputzPk2yHsObWHWl61+KTHJ1gsFrPLEhEREyioICKlis0GCxfCq6/C1q1GW7lyMGyYMYtC5crm1iciIgVj6tSpDBkyhEGDjDXfZ86cyZIlS5g9ezajRo3Kdr23t7fDcWRkJB4eHtmCCm5ubvj5+eX4zu3bt7Ns2TJ+/fVXmjdvDsD06dO59957eeutt/D398+ProlISfH3dPhnNliscPsC8LzR7IpERERERPLd+7++T9RfUbhYXVjQawHeZbyvfpOIiJRIWvpBREqFzEyIjITAQAgJMUIKnp4wZgzs2wfh4QopiIiUVGlpaWzcuJEOHTpktVmtVjp06EBMTEyunhEREUHfvn0pW7asQ/vKlSupUqUK9evX54knnuDEiRNZ52JiYqhQoUJWSAGgQ4cOWK1WNmzYkON7UlNTSUpKcthEpBSIWwGbRhj7TaaAf0dz6xERERERKQAbj2wkbHkYAG/e/SbB1YNNrkhERMykGRVEpMRbsQKeeQZ27DCOvbzg2Wdh+HCoWNHU0kREpBAcP36czMxMfP+zro+vry87LvzlcAWxsbFs27aNiIgIh/ZOnTrxwAMPULt2bfbs2cNLL71E586diYmJwcnJifj4+GzLSjg7O+Pt7U18fHyO7woPD+eVV17JYw9FpFg7sxvW9gG7DWoPhAYjzK5IRERERCTfnU45TUhUCGmZadzf4H6GBw83uyQRETGZggoiUqLt3g09esC5c0YoISwMnn7aCCuIiIjkRkREBIGBgbRs2dKhvW/fvln7gYGBNG7cmLp167Jy5Uruuuuua3rX6NGjCQsLyzpOSkqiRo0a11a4iBR96UnwS3dIOwWVboWWM0Hr84qIiIhICWO323nkm0fYe3ovtSvUZvZ9s7Fo3CsiUuopqCAiJVZmJgwcaIQU2rWDxYuN5R5ERKR08fHxwcnJiYSEBIf2hIQE/Pz8rnhvcnIykZGRTJw48arvqVOnDj4+PuzevZu77roLPz8/jh496nBNRkYGJ0+evOx73dzccHNzu+q7RKQEsGXC2n6QtB3KVIO2C8HJ3eyqRERERETy3bsb3mXRjkW4OrnyRcgXVHCvYHZJIiJSBFjNLkBEpKC89RasWwfly8OcOQopiIiUVq6urjRr1ozo6OisNpvNRnR0NK1atbrivVFRUaSmptK/f/+rvufQoUOcOHGCqlWrAtCqVStOnz7Nxo0bs6756aefsNlsBAdrHU6RUm/rGDiyxAgntF0EZaqaXZGIiIiISL6LPRzLCyteAODte96muX9zkysSEZGiQkEFESmRtm6FceOM/XfegVq1zK1HRETMFRYWxkcffcScOXPYvn07TzzxBMnJyQwaNAiA0NBQRo8ene2+iIgIevToQaVKlRzaz549ywsvvMD69evZt28f0dHR3HfffdSrV4+OHTsC0LBhQzp16sSQIUOIjY1l7dq1DBs2jL59++Lv71/wnRaRomvffPhrsrEfHAGVWphbj4iIiIhIATh5/iS9o3qTbksnpFEIT7V4yuySRESkCLmmoMKMGTMICAjA3d2d4OBgYmNjL3tt+/btsVgs2bYuXbpkXWO32xk3bhxVq1alTJkydOjQgV27dl1LaSIipKVBaKjxs1s3ePhhsysSERGz9enTh7feeotx48bRpEkTNm/ezLJly/D19QXgwIEDxMXFOdyzc+dO1qxZw+DBg7M9z8nJia1bt9K9e3duvPFGBg8eTLNmzVi9erXD0g3z5s2jQYMG3HXXXdx77720bt2aWbNmFWxnRaRoO/EbbPj33yuNRkFAP3PrEREREREpAHa7nUHfDGJ/4n7qVqzLR90+wmKxmF2WiIgUIRa73W7Pyw0LFiwgNDSUmTNnEhwczLRp04iKimLnzp1UqVIl2/UnT54kLS0t6/jEiRMEBQXxv//9j4f//e3hG2+8QXh4OHPmzKF27dqMHTuWP/74g7/++gt399yt0ZmUlISXlxeJiYl4an53kVLt5Zfh9dfBxwe2bYN/fwclIiLFUGkf45X2/ouUOOfjYFkLOH8Y/LtA22/A6mR2VSIiYoLSPs4r7f0XKQ3eXvc2z694HjcnN2IGx3BL1VvMLklERApBXsZ5eZ5RYerUqQwZMoRBgwbRqFEjZs6ciYeHB7Nnz87xem9vb/z8/LK2FStW4OHhQUhICGCk6qZNm8aYMWO47777aNy4MXPnzuXIkSN8/fXXeS1PREq59eth8r+z6M6cqZCCiIiIiBQRmSmw6n4jpODZEG6fr5CCiIiIiJRIMQdjGBU9CoBpnaYppCAiIjnKU1AhLS2NjRs30qFDh4sPsFrp0KEDMTExuXpGREQEffv2pWzZsgDs3buX+Ph4h2d6eXkRHByc62eKiAAkJxtLPths8NBD0LOn2RWJiIiIiAB2O8Q+Dic2gGtFaLcYXPTtUREREREpeU6cO0GfL/uQYcug7819eazZY2aXJCIiRZRzXi4+fvw4mZmZWWv5XuDr68uOHTuuen9sbCzbtm0jIiIiqy0+Pj7rGf995oVzOUlNTSU1NTXrOCkpKVd9EJGSa9Qo2LULqlWD6dPNrkZERERE5F87p8HeOWBxgtZfQPl6ZlckIiIiIpLvbHYboV+HcjDpIDdWupFZXWdhsVjMLktERIqoPC/9cD0iIiIIDAykZcuW1/2s8PBwvLy8srYaNWrkQ4UiUlz9+CO8956xP3s2VKxobj0iIiIiIgAc+QF+f97Yv+Vt8Otw5etFRERERIqpKWun8P2u73F3dicqJIrybuXNLklERIqwPAUVfHx8cHJyIiEhwaE9ISEBPz+/K96bnJxMZGQkgwcPdmi/cF9enzl69GgSExOztoMHD+alKyJSgpw+DYMGGftPPAH33GNqOSIiIiIihqS/YW0fsNugziNQ/xmzKxIRERERKRBrDqzh5Z9eBmB65+k09m1sckUiIlLU5Smo4OrqSrNmzYiOjs5qs9lsREdH06pVqyveGxUVRWpqKv3793dor127Nn5+fg7PTEpKYsOGDVd8ppubG56eng6biJROw4fDoUNQty5MmWJ2NSIiIiIiQFoirOoO6Yngcxu0eB807a2IiIiIlEDHko/R58s+ZNoz6d+4P4NvGXz1m0REpNRzzusNYWFhDBw4kObNm9OyZUumTZtGcnIyg/79OnNoaCjVqlUjPDzc4b6IiAh69OhBpUqVHNotFgvPPvsskyZN4oYbbqB27dqMHTsWf39/evToce09E5FSYdEimDsXrFbjZ9myZlckIiIiIqWeLRPWPghJO8GjOrRZCE5uZlclIiIiIpLvbHYbAxYN4MiZIzTwacAHXT7AooCuiIjkQp6DCn369OHYsWOMGzeO+Ph4mjRpwrJly/D19QXgwIEDWK2OEzXs3LmTNWvWsHz58hyf+eKLL5KcnMzQoUM5ffo0rVu3ZtmyZbi7u19Dl0SktDh6FB57zNh/4QW47TZz6xERERERAWDLaIhbCk5loO03UMbX7IpERERERApE+OpwftjzA2WcyxAVEkU513JmlyQiIsWExW63280uIj8kJSXh5eVFYmKiloEQKQXsdnjgAfj6awgMhF9/BTd9SU1EpMQp7WO80t5/kWJp76cQE2rs3x4JtfqYW4+IiBRJpX2cV9r7L1JSrNy3krvm3oXNbmN299kMumWQ2SWJiIjJ8jLOs17xrIhIEfXpp0ZIwcXF2FdIQURERERMdzwWNgwx9m96WSEFERERESmxEs4m8OBXD2Kz2xgYNFAhBRERyTMFFUSk2DlwAJ5+2tifMAGCgkwtR0REREQEzh2B1T3AlgrV74PGE82uSERERESkQGTaMnlo4UPEn42nUeVGzLh3htkliYhIMaSggogUKzYbPPIIJCXBrbfCiy+aXZGIiIiIlHoZ52FVDzgfB143QatPwaL/3BYRERGRkmnSqklE743Gw8WDqJAoyrqWNbskEREphvTJiYgUK++/D9HRUKYMzJ0Lzs5mVyQiIiIipZrdDrFD4eSv4OoNbb8Bl/JmVyUiIiIiUiCi/4nmlV9eAWBml5k0qtzI5IpERKS4UlBBRIqNv/++OIPCm2/CDTeYW4+IiIiICNvfgn2fgcUJWkdB+bpmVyQiIiIiUiDizsTRb2E/7NgZfMtgBgQNMLskEREpxhRUEJFiISMDQkPh/Hno0AGefNLsikRERESk1Dv8PWweaew3ewf87jS3HhERKZVmzJhBQEAA7u7uBAcHExsbe9lr27dvj8ViybZ16dIFgPT0dEaOHElgYCBly5bF39+f0NBQjhw54vCcgICAbM+YPHlygfZTRMyVYcug38J+HE0+SmCVQKZ3nm52SSIiUswpqCAixcKbb8KGDeDlBbNng1X/9hIRERERMyXugHUPAnaoOwRuUJJWREQK34IFCwgLC2P8+PFs2rSJoKAgOnbsyNGjR3O8fuHChcTFxWVt27Ztw8nJiZCQEADOnTvHpk2bGDt2LJs2bWLhwoXs3LmT7t27Z3vWxIkTHZ719NNPF2hfRcRcr6x8hZX7VlLOtRxRIVGUcSljdkkiIlLMaXV3ESnyNm+GCROM/XffhRo1zKxGREREREq9tFOwqjukJ0Hl1tD8PbBYzK5KRERKoalTpzJkyBAGDRoEwMyZM1myZAmzZ89m1KhR2a739vZ2OI6MjMTDwyMrqODl5cWKFSscrnnvvfdo2bIlBw4coGbNmlnt5cuXx8/PL7+7JCJF0PI9y3lt9WsAzOo6i/o+9U2uSERESgJ9J1lEirTUVBgwANLT4f77jX0REREREdPYMmBNXzizCzxqQpuvwMnV7KpERKQUSktLY+PGjXTo0CGrzWq10qFDB2JiYnL1jIiICPr27UvZsmUve01iYiIWi4UKFSo4tE+ePJlKlSpxyy23MGXKFDIyMq6pHyJStB1OOsxDCx/Cjp3Hmj3Gg4EPml2SiIiUEJpRQUSKtPHjYds2qFwZPvxQX1QTEREREZNtHgnxy8HJA9p9A+5VzK5IRERKqePHj5OZmYmvr69Du6+vLzt27Ljq/bGxsWzbto2IiIjLXpOSksLIkSN58MEH8fT0zGp/5plnaNq0Kd7e3qxbt47Ro0cTFxfH1KlTc3xOamoqqampWcdJSUlXrU9EzJdhy+DBrx7k+LnjNPFrwrRO08wuSUREShAFFUSkyFq7FqZMMfZnzTLCCiIiIiIipvnnE9jx7y9gWs2Bik3MrEZEROS6REREEBgYSMuWLXM8n56eTu/evbHb7XzwwQcO58LCwrL2GzdujKurK4899hjh4eG4ublle1Z4eDivvPJK/nZARArc2J/GsvrAasq7licqJAp3Z3ezSxIRkRJESz+ISJF09iwMHAg2m/GzRw+zKxIRERGRUu1YDMQ+ZuzfPA5q9jK3HhERKfV8fHxwcnIiISHBoT0hIQE/P78r3pucnExkZCSDBw/O8fyFkML+/ftZsWKFw2wKOQkODiYjI4N9+/bleH706NEkJiZmbQcPHrzi80TEfEt3LWXy2skARHSPoJ53PZMrEhGRkkZBBREpkl58EfbsgRo14J13zK5GREREREq1s//A6vvBlgbV74fA8WZXJCIigqurK82aNSM6OjqrzWazER0dTatWra54b1RUFKmpqfTv3z/buQshhV27dvHjjz9SqVKlq9ayefNmrFYrVarkvCSSm5sbnp6eDpuIFF0HEw8yYNEAAJ5q8RQhN4WYXJGIiJREWvpBRIqcH36ACzMKfvwxeHmZW4+IiIiIlFKpJ+DPcPj7PbClQoVAaDUXLMr8i4hI0RAWFsbAgQNp3rw5LVu2ZNq0aSQnJzNo0CAAQkNDqVatGuHh4Q73RURE0KNHj2whhPT0dHr16sWmTZv47rvvyMzMJD4+HgBvb29cXV2JiYlhw4YN3HHHHZQvX56YmBhGjBhB//79qVixYuF0XEQKTHpmOn2/6suJ8ydoVrUZb9/zttkliYhICaWggogUKadOwSOPGPvDhsFdd5lbj4iIiIiUQhnJsPMd+OsNSE8y2qq0M0IKLuXMrU1EROQSffr04dixY4wbN474+HiaNGnCsmXL8PX1BeDAgQNYrY4Bu507d7JmzRqWL1+e7XmHDx9m8eLFADRp0sTh3M8//0z79u1xc3MjMjKSCRMmkJqaSu3atRkxYgRhYWEF00kRKVQv//Qy6w6uw8vNiy9CvsDN2c3skkREpISy2O12u9lF5IekpCS8vLxITEzU1GEixVj//jBvHtx4I/z+O3h4mF2RiIiYqbSP8Up7/0UKnS0d9kTAH69AivHtUSoEQZPJULUjWCzm1iciIiVGaR/nlfb+ixRV3/39Hd0+7wbAwt4Lub/h/SZXJCIixU1exnmaUUFEiowvvzRCClYrzJmjkIKIiIiIFBK7HQ5EwdYxcGaX0Va2NgRNglp9tdSDiIiIiJR4+0/vJ3RRKADDg4crpCAiIgVOQQURKRLi4+Hxx439UaPg1lvNrUdERERESon4aNg8Ck7+Zhy7VYabx0K9x8DJ1dzaREREREQKQVpmGn2+7MOplFO0rNaSN+9+0+ySRESkFFBQQURMZ7fD0KFw4gQEBcH48WZXJCIiIiIl3smNsHk0xK8wjp3LQcPnoUEYuJQ3tzYRERERkUI06sdRbDi8gQruFVjQawGuCuyKiEghUFBBREz3ySfw7bfg6gqffmr8FBEREREpEEm7jCUeDnxhHFtdoN4TcPPL4F7F3NpERERERArZ1zu+5v/W/x8Ac3rMIaBCgLkFiYhIqaGggoiYat8+GD7c2J84EQIDTS1HREREREqq8/GwbSLs/gjsGYAFAh6CxhOhXG2zqxMRERERKVTpmelsjNvIw18/DMBzrZ6je/3u5hYlIiKlioIKImIamw0GDYIzZ+C22+D5582uSERERERKnLRE2D4FdvwfZJ4z2vzvhaBwqNjY3NpERERERArBiXMn2JKwhS3xW4yfCVv469hfpGWmAdCqeivC7wo3uUoRESltFFQQEdNMnw4rV4KHB8yZA05OZlckIiIiIiVGZgr8/T789TqknjDaKt0Kt7wBVdqaW5uIiIiISAHItGWy6+Quh0DClvgtHD5zOMfry7uWp3XN1szqNgsXJ5dCrlZEREo7BRVExBQ7dsCoUcb+W29BvXrm1iMiIiIiJYQtE/Z9ClvHw7kDRptnQwh6HarfBxaLufWJiIiIiOSDpNQktiZsZXP85qxgwraj2zifcT7H62tXqE2QXxBBvv9ufkEEVAjAarEWcuUiIiIGBRVEpNBlZEBoKKSkQMeO8PjjZlckIiIiIsWe3Q6Hv4UtL0Hin0ZbmWrQeCLUDgWr/vNXRERERIofm93GvtP7ss2SsPf03hyvL+NchkDfQIdAQmPfxni6eRZy5SIiIlemT2pEpNCFh8Ovv0KFChARoS+1iYiIiMh1OrYWNo80fgK4VoRGo+HGYeBcxtzaRERERERyKTktmW1Ht2WFEbYkbGFrwlbOpJ3J8frqntUdAglBvkHU866Hk1Vr7IqISNGnoIKIFKqNG2HiRGP/vfegWjVz6xERERGRYuz0NmMGhcPfGsdOZaD+cGg0ElwrmFqaiIiIiMjl2O12DiUdcggkbEnYwq4Tu7Bjz3a9q5MrN1W+yWHphsa+jankUcmE6kVERPKHggoiUmhSUowlHzIyoFcv6NfP7IpEREREpFhK3g9bx8PeuYAdLE5QdzDcPB48/M2uTkREREQkS0pGCn8d+yvb0g2nUk7leL1vWV+HQEKQXxD1K9XHxcmlkCsXEREpWAoqiEihGTsW/voLfH3hgw+05IOIiIiI5FHKcfjzddg1A2xpRluNXhA0CTzrm1ubiIiIiMi/vt7xNVF/RbElfgs7ju8g056Z7RpnqzMNfBpkW7rBt5yvCRWLiIgUPgUVRKRQrFoFb79t7H/0Efj4mFuPiIiIiBQjGcmw4/9g+xRITzLafO+AoMng09Lc2kRERERE/mW325m0ahLjVo5zaPcu450tkNCociPcnN1MqlRERMR8CiqISIE7cwYefhjsdnjkEejWzeyKRERERKRYsKXD7o9g20RISTDaKjYxAgpV79EUXSIiIiJSZGTaMhm+bDgzfp0BwBPNn6DLDV0I8guiWvlqWDR2FRERcaCggogUuOefh717oVYt+L//M7saERERESny7DbY/wVsHQNn9xht5epA40lQqw9YrObWJyIiIiJyidSMVEK/DuWLP7/AgoV3O7/LsJbDzC5LRESkSFNQQUQK1NKlMGuWsf/xx+DpaW49IiIiIlLExa2AzaPg1Cbj2L0K3DwO6g4BJ1dzaxMRERER+Y8zqWe4f8H9RO+NxsXqwmcPfEbvm3qbXZaIiEiRp6CCiBSYkydh8GBj/9ln4Y47TC1HRERERIqyE78ZAYWEaOPYuTw0fAEajACXcubWJiIiIiKSg6PJR+k8rzOb4jZRzrUci/osokOdDmaXJSIiUiwoqCAiBeappyAuDho0gNdfN7saERERESmSkv42lng4EGUcW13hhifhppfAvbK5tYmIiIiIXMbeU3u557N72H1yN5U9KrP0oaU0829mdlkiIiLFhhb2FJECsWABREaCkxPMnQtlyphdkYiIlHYzZswgICAAd3d3goODiY2Nvey17du3x2KxZNu6dOkCQHp6OiNHjiQwMJCyZcvi7+9PaGgoR44ccXhOQEBAtmdMnjy5QPspUmxknIONI2BJo39DChYIGABdd0Kz/1NIQURERESKrC3xW7ht9m3sPrmbgAoBrH1krUIKIiIieaQZFUQk38XFwZNPGvsvvwwtWphbj4iIyIIFCwgLC2PmzJkEBwczbdo0OnbsyM6dO6lSpUq26xcuXEhaWlrW8YkTJwgKCiIkJASAc+fOsWnTJsaOHUtQUBCnTp1i+PDhdO/end9++83hWRMnTmTIkCFZx+XLly+gXooUIyd+g5gBkLTDOPbvAkGvQ8XG5tYlIiIiInIVv+z7he6R3UlKTaKxb2OWPbSMquWrml2WiIhIsaOggojkK7sdHn0UTp6Epk1hzBizKxIREYGpU6cyZMgQBg0aBMDMmTNZsmQJs2fPZtSoUdmu9/b2djiOjIzEw8MjK6jg5eXFihUrHK557733aNmyJQcOHKBmzZpZ7eXLl8fPzy+/uyRSPNky4M9w2DYR7BlQpioER4B/Z7MrExERERG5qkXbF/HgVw+SmplK21pt+abvN1Rwr2B2WSIiIsWSln4QkXwVEQHffw9ubsaSDy4uZlckIiKlXVpaGhs3bqRDhw5ZbVarlQ4dOhATE5OrZ0RERNC3b1/Kli172WsSExOxWCxUqFDBoX3y5MlUqlSJW265hSlTppCRkXFN/RAp9pJ2wYrW8Mc4I6RQMwTu/UMhBREREREpFj7a+BG9onqRmplKjwY9+KH/DwopiIiIXAfNqCAi18xuh6NH4Z9/jG3PHpgyxTj32mtw003m1iciIgJw/PhxMjMz8fX1dWj39fVlx44dV70/NjaWbdu2ERERcdlrUlJSGDlyJA8++CCenp5Z7c888wxNmzbF29ubdevWMXr0aOLi4pg6dWqOz0lNTSU1NTXrOCkp6ar1iRR5djvsngWbwiDzHLh4QfMZENAPLBazqxMRERERuSK73c5rq19j7M9jARjSdAjvd3kfZ6t+vSIiInI99DepiFxRWhrs2+cYRrj0Z3Jy9nvatIFnny3sSkVERApGREQEgYGBtGzZMsfz6enp9O7dG7vdzgcffOBwLiwsLGu/cePGuLq68thjjxEeHo6bm1u2Z4WHh/PKK6/kbwdEzHQ+DjY8Cke+N45974RbP4GyNUwtS0REREQkN2x2G88sfYYZv84AYEybMUy8YyIWBW5FRESum4IKIqWc3Q6nTl0MHvw3jHDoENhsl7/fYoEaNaBuXahTB+rXh6FDwcmp8PogIiJyJT4+Pjg5OZGQkODQnpCQgJ+f3xXvTU5OJjIykokTJ+Z4/kJIYf/+/fz0008OsynkJDg4mIyMDPbt20f9+vWznR89erRDuCEpKYkaNfQLXSmmDnwFvz4GqSfA6gZNJkP9Z8CiFQhFREREpOhLzUgl9OtQvvjzCyxYeKfTOzwd/LTZZYmIiJQYCiqIlAIZGXDwYM4zIuzZA4mJV77fw+NiEOG/P2vVghy+ECoiIlJkuLq60qxZM6Kjo+nRowcANpuN6Ohohg0bdsV7o6KiSE1NpX///tnOXQgp7Nq1i59//plKlSpdtZbNmzdjtVqpUqVKjufd3NxynGlBpFhJS4SNz8DeucZxxVug1adQQeuCiYiIiEjxcCb1DPcvuJ/ovdG4WF349P5P6XNzH7PLEhERKVEUVBApIZKSLr88w/79RljhSqpWvRg++G8g4f/Zu/O4qOr9j+PvYXcFN9ZQzDJ3LVQiLL2FonUrr96ulf1c0zJcsVIyRbMkM01NEzU1W0zNNm8apmh2TU3Fa11LQdxTQQ0BRQVkzu+Puc2VxAUDDgyv5+MxD75z5nu+5/0dZ+ArfOYcb28uHwwAKN+ioqLUu3dvtW7dWm3bttX06dOVnZ2tvn37SpJ69eqlgIAAxcbGFthvwYIF6tq16xVFCHl5efr73/+unTt36quvvlJ+fr5SU1MlSTVr1pSbm5u2bNmiH374QX/5y19UrVo1bdmyRSNGjNBTTz2lGjVqlM7EgdKWtlHa0ks6f8R25oQmo6VmMZKzm9nJAAAAgBtyMvukHvzoQSWeSFRVt6r6vMfnCr813OxYAAA4HAoVgHLCapWOHy/8jAgHDkinT197f3d3qX79ws+KUL++7awJAAA4qh49eujUqVMaN26cUlNT1apVK8XHx8vHx0eSdOTIETk5FTwdfVJSkjZt2qRvvvnmivGOHTumlStXSpJatWpV4LENGzaoQ4cOcnd319KlSzV+/Hjl5OSofv36GjFiRIFLOwAOI/+i9NNYac9USYZU9VYp9H2pTpjZyQAAAIAbdvDMQXX6sJNS0lNUp3Idre65Wq39W5sdCwAAh2QxDMMwO0RxyMrKkqenpzIzM697bWCgvHn9demVV6QLF67dr3btK4sQfm/7+0tOXA4YAFDOVPQ1XkWfP8qJMz9Km5+SMnfb7jcYIN01VXKtZm4uAADKsIq+zqvo80fZ9GPqj+r8UWelnktVkFeQ1jy1Rg1rNTQ7FgAA5UpR1nmcUQEo495/X4qOtrVdXKR69Qo/K8Ktt0r8vw4AAAClxpov7X3TdiYFa57k4S21fVe65WGzkwEAAABF8t3h7/Twxw8rKydLzb2bK/6pePlX8zc7FgAADo1CBaAM27pVGjDA1o6Otp1VwYV3LQAAAMx27qC0pZd0apPt/i1dpbbzJI86psYCAAAAiuqLvV/o8RWPKyc/R/fWvVcrn1gpLw8vs2MBAODwbupE8LNnz1ZQUJA8PDwUEhKibdu2XbN/RkaGIiMj5efnJ3d3dzVs2FCrV6+2P56fn6+xY8eqfv36qlSpkho0aKCJEyfKQa5KAdyUX3+VunaVcnNtX199lSIFAAAAmMwwpP0LpdUtbEUKLtWkkIXSvZ9RpAAAAIBy592d76r78u7Kyc9R10ZdteapNRQpAABQSor8Z89ly5YpKipKcXFxCgkJ0fTp0xUREaGkpCR5e3tf0T83N1cdO3aUt7e3VqxYoYCAAB0+fFheXl72PpMnT9acOXO0ePFiNW3aVDt27FDfvn3l6empoUOH/qkJAuXR+fPSo49KaWlS8+bSBx9ITjdVVgQAAAAUk4snpW0DpV+/tN2vc68UuliqWt/cXAAAAEARGYahSf+apJc3vCxJevrOpzXnr3Pk4sQnxQAAKC1F/qk7bdo0DRgwQH379pUkxcXFadWqVVq4cKFGjx59Rf+FCxcqPT1dmzdvlqurqyQpKCioQJ/Nmzfr0Ucf1UMPPWR//OOPP77umRoAR2QYUr9+0s6dUu3a0sqVUtWqZqcCAABAhfbrP6VtT9uKFZxcpRavSo1GSk7OZicDAAAAisRqWDXs62GatX2WJGnMvWM08S8TZbFYTE4GAEDFUqTPaOfm5ioxMVHh4eH/G8DJSeHh4dqyZUuh+6xcuVKhoaGKjIyUj4+PmjVrpkmTJik/P9/e55577lFCQoKSk5MlST/++KM2bdqkLl263MycgHLttdekZctsl3n49FPpD3U9AAAAQOnJOyv9MED67hFbkYJnMyliu9TkRYoUAAAAUO7kXMrRk58+qVnbZ8kii2Z2nqlX73+VIgUAAExQpDMqnD59Wvn5+fLx8Smw3cfHR3v37i10nwMHDmj9+vXq2bOnVq9erZSUFD333HPKy8tTTEyMJGn06NHKyspSo0aN5OzsrPz8fL322mvq2bPnVbPk5OQoJyfHfj8rK6soUwHKpM8/l8aOtbXfeUe67z5z8wAAAKACO/W9tKWXdO6AJIvUeKTUYqLk7GF2MgAAAKDIzuacVbfl3bTuwDq5Ornq/b+9r8ebPW52LAAAKqwSv+CS1WqVt7e35s2bJ2dnZwUHB+vYsWOaMmWKvVBh+fLl+uijj7RkyRI1bdpUu3bt0vDhw+Xv76/evXsXOm5sbKwmTJhQ0vGBUvPTT9L//Z+tPWSINGCAuXkAAABQQeXnSv8ZL+2ZLBlWqXJdKfR9yae92ckAAACAm3Iy+6QeWvKQdhzfoSquVfR5j8/VsUFHs2MBAFChFalQoXbt2nJ2dlZaWlqB7WlpafL19S10Hz8/P7m6usrZ+X+nBW3cuLFSU1OVm5srNzc3vfDCCxo9erQef9xWvdi8eXMdPnxYsbGxVy1UiI6OVlRUlP1+VlaWAgMDizIdoMw4eVJ65BEpO1sKD5emTTM7EQAAACqkjJ+lLU9JZ3bZ7tfvLQXPkNw8TY0FAAAA3KyDZw4q4sMI7Uvfp9qVa+vrnl+rtX9rs2MBAFDhORWls5ubm4KDg5WQkGDfZrValZCQoNDQ0EL3CQsLU0pKiqxWq31bcnKy/Pz85ObmJkk6f/68nJwKRnF2di6wzx+5u7urevXqBW5AeZSbK/3979Lhw9Jtt0nLlkkuJX6uEwAAAOAyhlXa+5YUH2wrUnCvJd37qRT6HkUKAACUcbNnz1ZQUJA8PDwUEhKibdu2XbVvhw4dZLFYrrg99NBD9j6GYWjcuHHy8/NTpUqVFB4ern379hUYJz09XT179lT16tXl5eWl/v3769y5cyU2R+Bm/ZT2k8IWhmlf+j7V86yn7/t9T5ECAABlRJEKFSQpKipK8+fP1+LFi7Vnzx4NGjRI2dnZ6tu3rySpV69eio6OtvcfNGiQ0tPTNWzYMCUnJ2vVqlWaNGmSIiMj7X0efvhhvfbaa1q1apUOHTqkzz//XNOmTdPf/va3YpgiUHYZhhQZKf3rX1L16tI//ynVrGl2KgAAAFQo2Uek9R2lnVGSNUfyf1B6cLcU2M3sZAAA4DqWLVumqKgoxcTEaOfOnWrZsqUiIiJ08uTJQvt/9tlnOnHihP22e/duOTs767HHHrP3eeONNzRz5kzFxcXphx9+UJUqVRQREaGLFy/a+/Ts2VM///yz1q5dq6+++krfffedBg4cWOLzBYriu8Pf6b5F9+nEuRNq7t1cm/tvVsNaDc2OBQAA/stiGIZR1J1mzZqlKVOmKDU1Va1atdLMmTMVEhIiyVaVGxQUpPfee8/ef8uWLRoxYoR27dqlgIAA9e/fX6NGjbJfDuLs2bMaO3asPv/8c508eVL+/v564oknNG7cOPtZF64nKytLnp6eyszM5OwKKDdmzpSGDZOcnKSvvpK6dDE7EQAAZUtFX+NV9PmjhBmGdOgjacdgKS9Tcq4s3TVNum2gZLGYnQ4AAIdWXOu8kJAQtWnTRrNmzZJkO/ttYGCghgwZotGjR193/+nTp2vcuHE6ceKEqlSpIsMw5O/vr5EjR+r555+XJGVmZsrHx0fvvfeeHn/8ce3Zs0dNmjTR9u3b1bq17ZPp8fHxevDBB/Xrr7/K39+/1OYPXM0Xe7/Q4yseV05+ju6te69WPrFSXh5eZscCAMDhFWWdd1OFCmURi1uUN2vXSp07S1ar9Oab0siRZicCAKDsqehrvIo+f5SgnN+k7YOkI5/Y7te6Wwp9X6p+u7m5AACoIIpjnZebm6vKlStrxYoV6tq1q3177969lZGRoS+//PK6YzRv3lyhoaGaN2+eJOnAgQNq0KCB/v3vf6tVq1b2fu3bt1erVq00Y8YMLVy4UCNHjtSZM2fsj1+6dEkeHh765JNPbugsuaxzUZLe3fmunvnqGVkNqx6941F93P1jVXKtZHYsAAAqhKKs81xKKROAyyQnS//4h61IoU8fKSrK7EQAAACoMI7HSz/0ky6ckCwuUvMYqcloyYn/HgIAUJ6cPn1a+fn58vHxKbDdx8dHe/fuve7+27Zt0+7du7VgwQL7ttTUVPsYfxzz98dSU1Pl7e1d4HEXFxfVrFnT3uePcnJylJOTY7+flZV13XxAURmGodhNsRqzfowkqf+d/RX31zi5sM4FAKBMcjI7AFDRZGRIjzxi+xoaKsXFcWZdAAAAlIJL2dL2SOnbLrYiheqNpIitUrOXKVIAAKACWrBggZo3b662bduW+LFiY2Pl6elpvwUGBpb4MVGxWA2rhsUPsxcpvNTuJc1/eD5FCgAAlGEUKgClKD9feuIJKSlJuuUW6bPPJHd3s1MBAADA4Z3eJn19l7TvHdv9hkOlzjulmsHm5gIAADetdu3acnZ2VlpaWoHtaWlp8vX1vea+2dnZWrp0qfr3719g++/7XWtMX19fnTx5ssDjly5dUnp6+lWPGx0drczMTPvt6NGj158gcINy83PV87Oeenvb25KkGZ1n6LUHXpOFT4cBAFCmUagAlKIXX5Ti46VKlaSVK6Xr/J8RAAAA+HOsedJP46W190hnk6VKAdL9a6XWMyQXrtMLAEB55ubmpuDgYCUkJNi3Wa1WJSQkKDQ09Jr7fvLJJ8rJydFTTz1VYHv9+vXl6+tbYMysrCz98MMP9jFDQ0OVkZGhxMREe5/169fLarUqJCSk0OO5u7urevXqBW5AcTibc1Z/XfJXLd29VK5OrlrSbYmGhgw1OxYAALgBnPcIKCXvvSdNm2ZrL14s3XmnqXEAAADg6LKSpM3/J6Vvt92v94TUZrbkVsPcXAAAoNhERUWpd+/eat26tdq2bavp06crOztbffv2lST16tVLAQEBio2NLbDfggUL1LVrV9WqVavAdovFouHDh+vVV1/V7bffrvr162vs2LHy9/dX165dJUmNGzdW586dNWDAAMXFxSkvL0+DBw/W448/Ln9//1KZNyBJp7JP6cElD2rH8R2q4lpFn/X4TJ0adDI7FgAAuEEUKgClYPNm6ZlnbO1x46THHjM3DwAAAByYYdgu8fDvF6T8C5Krl9RmjhT0uNnJAABAMevRo4dOnTqlcePGKTU1Va1atVJ8fLx8fHwkSUeOHJGTU8GT6iYlJWnTpk365ptvCh3zxRdfVHZ2tgYOHKiMjAy1a9dO8fHx8vDwsPf56KOPNHjwYD3wwANycnJS9+7dNXPmzJKbKPAHhzIOqdMHnbQvfZ9qV66t1U+uVpuANmbHAgAARWAxDMMwO0RxyMrKkqenpzIzMzl1GMqUI0ekNm2kkyel7t2l5cslJy66AgDADanoa7yKPn/chPPHpR/6SSfW2O77dpTuXihVvsXcXAAAoICKvs6r6PPHn/NT2k/q/GFnnTh3QvU862nNU2t0R+07zI4FAABUtHUeZ1QASlB2tvToo7YihZYtbZd8oEgBAAAAJeLIJ9K2Z6TcM5Kzh9TqDalhpGRhAQoAAADH8K/D/9LDHz+szJxMNfNupjVPrZF/NS45AgBAeUShAlBCrFapTx9p1y6pTh3pyy+lKlXMTgUAAACHk5sp7YiUDn1ku18zWAr9UPJsZG4uAAAAoBitTFqpHit66OKli2pXt51WPr5SNSrVMDsWAAC4SRQqACVk4kRpxQrJ1VX6/HOpXj2zEwEAAMDhWC9JG/8qndokWZylpmOkZi9LTq5mJwMAAACKzYKdCzTwq4GyGlY9cscjWtp9qSq5VjI7FgAA+BMoVABKwKefSuPH29pxcVJYmKlxAAAA4Kj+M8FWpOBSTfrLGqlOqNmJAAAAgGJjGIZe3/S6Xlr/kiSpX6t+mvvwXLk48acNAADKO36aA8Vs1y6pVy9be/hwqV8/M9MAAADAYaVtkH5+zdYOmU+RAgAAAByK1bAqak2UZvwwQ5IU3S5ar93/miwWi8nJAABAcaBQAShGaWnSI49I589LERHSlClmJwIAAIBDunhK2txTkiE1eFqq18PsRAAAAECxGrx6sObsmCNJmh4xXcPuHmZyIgAAUJwoVACKSU6O1K2bdPSo1LChtHSp5MI7DAAAAMXNsEpbeksXTkjVG0vBM8xOBAAAABSrfx3+l+bsmCOLLPqw24d6svmTZkcCAADFzMnsAIAjMAxp0CBp82bJ01NauVLy8jI7FQAAABzS3unSia8lJ3ep3TLJpbLZiQAAAIBik2/N15Cvh0iSBtw1gCIFAAAcFIUKQDGYPl1atEhycpKWL5fuuMPsRAAAAHBIv+2QfhxtawdPl7yamxoHAAAAKG5zE+fqx7QfVcOjhl574DWz4wAAgBJCoQLwJ61ZIz3/vK09darUqZO5eQAAAOCg8rKk7x+XrHlSYHfptmfMTgQAAAAUq1PZpzRm/RhJ0mv3v6balWubnAgAAJQUChWAPyEpSerRQ7JapX79pGHDzE4EAAAAh2QY0rZB0rn9UuW6Ush8yWIxOxUAAABQrMasH6OMixlq5dtKA4MHmh0HAACUIAoVgJt05oz08MNSZqYUFia98w6/KwYAAEAJObhYOrxEsjhLYR9LbjXMTgQAAAAUqx3Hd+jdne9KkmZ1mSVnJ2eTEwEAgJJEoQJwEy5dsp1JYd8+qW5d6bPPJHd3s1MBAADAIWXulbZH2totXpHq3GNuHgAAAKCYWQ2rBq8eLEOG/q/F/ymsbpjZkQAAQAmjUAG4Cc8/L61dK1WuLH35peTtbXYiAAAAOKT8i9L3PaT885LPA1LjUWYnAgAAAIrd4l2L9cOxH1TNrZomh082Ow4AACgFFCoARbRggTRjhq39wQdSq1amxgEAAIAj2/m8lPGT5F5HuucDidPfAgAAwMFkXMzQqHW2gtyY9jHyq+ZnciIAAFAaKFQAimDTJmnQIFt7wgSpWzdz8wAAAMCBHf1C2jfb1g59X6rEL2wBAADgeMZ/O16nzp9S49qNNTRkqNlxAABAKaFQAbhBhw/bChPy8qTHHpPGjjU7EQAAABxW9hHph362duPnJf/O5uYBAAAASsB/0v6jWdtmSZJmdpkpV2dXkxMBAIDSQqECcAPOnZMeeUQ6dUq6807pvfcki8XsVAAAAHBI1kvS5iel3DNSzTZSi9fMTgQAAAAUO8MwNOTrIco38tW9cXeF3xpudiQAAFCKKFQArsNqlXr1kn76SfLxkb78Uqpc2exUAAAAcFi7X5FOfS+5VpfaLZWc3cxOBAAAABS75T8v18bDG1XJpZKmdppqdhwAAFDKKFQArmP8eOnzzyU3N9vXwECzEwEAAMBhpW2Qdr9qa7eZK1W91dw8AAAAQAk4l3tOI78ZKUmKbhetel71TE4EAABKG4UKwDUsXy5NnGhrz5snhYaamwcAAAAO7OIpaXNPSYbUoL8U9LjZiQAAAIAS8dp3r+nY2WO6tcateiHsBbPjAAAAE1CoAFzFzp1Snz629siRUu/epsYBAACAIzMMaWsf6cIJqXpjKXiG2YkAAACAEpH8W7KmbrFd6mF6xHR5uHiYnAgAAJiBQgWgEKmp0qOPShcuSF26SJMnm50IAAAADi1punR8teTkLrVbJrlUMTsRAAAAUOwMw9Cw+GHKs+apy21d9NeGfzU7EgAAMAmFCsAfXLwo/e1v0q+/So0aSR9/LDk7m50KAAAADuu3HdKuUbZ28FuSV3Nz8wAAAAAl5J/J/1R8SrzcnN00o/MMWSwWsyMBAACTUKgAXMYwpGeekbZulWrUkFaulDw9zU4FAAAAh5WXJX3/uGTNkwK7Sbc9a3YiAAAAoERcvHRRw+OHS5JGho7U7bVuNzcQAAAwFYUKwGWmTpXef992BoXly6XbWSsDAOAwZs+eraCgIHl4eCgkJETbtm27at8OHTrIYrFccXvooYfsfQzD0Lhx4+Tn56dKlSopPDxc+/btKzBOenq6evbsqerVq8vLy0v9+/fXuXPnSmyOKGcMQ9o2SDq3X6pcVwp5V+ITZQAAAHBQU76fooMZBxVQLUAv3fuS2XEAAIDJKFQA/mv1aunFF23tt96SwsPNzQMAAIrPsmXLFBUVpZiYGO3cuVMtW7ZURESETp48WWj/zz77TCdOnLDfdu/eLWdnZz322GP2Pm+88YZmzpypuLg4/fDDD6pSpYoiIiJ08eJFe5+ePXvq559/1tq1a/XVV1/pu+++08CBA0t8vignDi6WDi+RLM5S2MeSWw2zEwEAAAAl4lDGIU3aNEmSNLXTVFV1q2pyIgAAYDYKFQBJe/ZITzxh+1DbgAHS4MFmJwIAAMVp2rRpGjBggPr27asmTZooLi5OlStX1sKFCwvtX7NmTfn6+tpva9euVeXKle2FCoZhaPr06Xr55Zf16KOPqkWLFnr//fd1/PhxffHFF5KkPXv2KD4+Xu+++65CQkLUrl07vf3221q6dKmOHz9eWlNHWZW5V9oeaWu3eEWqc4+5eQAAAIASNPKbkbp46aI6BHXQP5r+w+w4AACgDKBQARVeerr08MNSVpZ0333SrFmccRcAAEeSm5urxMREhV92uiQnJyeFh4dry5YtNzTGggUL9Pjjj6tKlSqSpIMHDyo1NbXAmJ6engoJCbGPuWXLFnl5eal169b2PuHh4XJyctIPP/xQ6HFycnKUlZVV4AYHlH9R+v5xKf+85POA1HiU2YkAAACAErN2/1p9tuczOVuc9XaXt2Xhl68AAEAUKqCCy8uT/vEPaf9+KShIWrFCcnMzOxUAAChOp0+fVn5+vnx8fAps9/HxUWpq6nX337Ztm3bv3q2nn37avu33/a41Zmpqqry9vQs87uLiopo1a171uLGxsfL09LTfAgMDrz9BlD//fkHK+FFyryPd84Hk5Gx2IgAAAKBE5Obnamj8UEnS4LaD1cy7mcmJAABAWUGhAiq0qCgpIUGqUkX68kupTh2zEwEAgLJmwYIFat68udq2bVvix4qOjlZmZqb9dvTo0RI/JkrZ0S+k5Fm2duj7UiU/U+MAAAAAJWnmDzO19/ReeVfx1vgO482OAwAAyhAKFVBhzZtnu8yDJH34odSihbl5AABAyahdu7acnZ2VlpZWYHtaWpp8fX2vuW92draWLl2q/v37F9j++37XGtPX11cnT54s8PilS5eUnp5+1eO6u7urevXqBW5wINlHpB/62dqNn5f8O5ubBwAAAChBJ86e0ISNEyRJrz/wurw8vMwNBAAAyhQKFVAhbdwoRUba2q++KnXtamocAABQgtzc3BQcHKyEhAT7NqvVqoSEBIWGhl5z308++UQ5OTl66qmnCmyvX7++fH19C4yZlZWlH374wT5maGioMjIylJiYaO+zfv16Wa1WhYSEFMfUUJ5YL0mbe0q5Z6SabaQWr5mdCAAAAChRL657UedyzykkIES9W/U2Ow4AAChjXMwOAJS2gwel7t2lS5ekxx+XXnrJ7EQAAKCkRUVFqXfv3mrdurXatm2r6dOnKzs7W3379pUk9erVSwEBAYqNjS2w34IFC9S1a1fVqlWrwHaLxaLhw4fr1Vdf1e2336769etr7Nix8vf3V9f/VkA2btxYnTt31oABAxQXF6e8vDwNHjxYjz/+uPz9/Utl3ihDdr8indokuVST2i2VnN3MTgQAAACUmE1HNunDnz6URRbNenCWnCx8ZhIAABREoQIqlLNnpUcekX77TQoOlhYskCwWs1MBAICS1qNHD506dUrjxo1TamqqWrVqpfj4ePn4+EiSjhw5Iiengr84S0pK0qZNm/TNN98UOuaLL76o7OxsDRw4UBkZGWrXrp3i4+Pl4eFh7/PRRx9p8ODBeuCBB+Tk5KTu3btr5syZJTdRlE1pG6Tdr9rabedJVW81Nw8AAABQgvKt+Rq8erAkacBdA9Tav7XJiQAAQFlkMQzDMDtEccjKypKnp6cyMzO5li8KZbVK3bpJX34p+fpKO3ZIAQFmpwIAANdS0dd4FX3+DuHiKenrVtKF41KD/lLIu2YnAgAAZUBFX+dV9Pk7une2v6PI1ZGq4VFDyUOSVbtybbMjAQCAUlKUdR7nW0KF8frrtiIFd3fpiy8oUgAAAEAJMwxpax9bkUL1RlLwDLMTAQAAACXq9PnTenn9y5KkV+9/lSIFAABwVRQqoEJISpImTLC158yRQkLMzQMAAIAKIGm6dHy15OQuhS2TXKqYnQgAAAAoUWMSxujMxTNq5dtKzwQ/Y3YcAABQhlGoAIdnGNIzz0i5uVLnzlKfPmYnAgAAgMNLT5R2jbK1g9+SarQwNw8AAABQwnYc36H5O+dLkt7u8racnZxNTgQAAMoyChXg8BYtkjZulCpXlt55R7JYzE4EAAAAh5aXJW3qIVnzpMBu0m3Pmp0IAAA4sNmzZysoKEgeHh4KCQnRtm3brtk/IyNDkZGR8vPzk7u7uxo2bKjVq1fbHw8KCpLFYrniFhkZae/ToUOHKx5/9lnWPBWZ1bBq8OrBMmToqRZPqV3ddmZHAgAAZZyL2QGAknTypPT887b2hAlS/frm5gEAAICDMwxp2yDp3H6pcl0p5F0qZQEAQIlZtmyZoqKiFBcXp5CQEE2fPl0RERFKSkqSt7f3Ff1zc3PVsWNHeXt7a8WKFQoICNDhw4fl5eVl77N9+3bl5+fb7+/evVsdO3bUY489VmCsAQMG6JVXXrHfr1y5cvFPEOXG4l2L9cOxH1TVrareCH/D7DgAAKAcuKkzKhR3la4kHTt2TE899ZRq1aqlSpUqqXnz5tqxY8fNxAPsRoyQzpyRWrWShg83Ow0AAAAc3sHF0uElksVZClsiudUwOxEAAHBg06ZN04ABA9S3b181adJEcXFxqly5shYuXFho/4ULFyo9PV1ffPGFwsLCFBQUpPbt26tly5b2PnXq1JGvr6/99tVXX6lBgwZq3759gbEqV65coF/16tVLdK4ouzIuZmh0wmhJUkz7GPlV8zM5EQAAKA+KXKjwe5VuTEyMdu7cqZYtWyoiIkInT54stP/vVbqHDh3SihUrlJSUpPnz5ysgIMDe58yZMwoLC5Orq6u+/vpr/fLLL5o6dapq1OCXerh58fHSkiWSk5M0f77kwvlDAAAAUJKykqTt/z0lcotXpDph5uYBAAAOLTc3V4mJiQoPD7dvc3JyUnh4uLZs2VLoPitXrlRoaKgiIyPl4+OjZs2aadKkSQXOoPDHY3z44Yfq16+fLH84S9RHH32k2rVrq1mzZoqOjtb58+eLb3IoV8Z/O14ns0+qUe1GGhoy1Ow4AACgnCjyn24vr9KVpLi4OK1atUoLFy7U6NGjr+j/e5Xu5s2b5erqKsl2nbPLTZ48WYGBgVq0aJF9W33O0Y8/ITtbGjTI1h46VGrd2tw8AAAAcHD5F6VNPaT885LP/VLjUWYnAgAADu706dPKz8+Xj49Pge0+Pj7au3dvofscOHBA69evV8+ePbV69WqlpKToueeeU15enmJiYq7o/8UXXygjI0N9+vQpsP3JJ59UvXr15O/vr59++kmjRo1SUlKSPvvss0KPm5OTo5ycHPv9rKysIs4WZdXuk7s1a9ssSdLMzjPl5uxmciIAAFBeFOmMCiVVpbty5Uq1bt1ajz32mLy9vXXnnXdq/vz5NzklQJowQTp0SKpbV5o40ew0AAAAcHj/fkHK+FFyryOFfiA5OZudCAAA4ApWq1Xe3t6aN2+egoOD1aNHD40ZM0ZxcXGF9l+wYIG6dOkif3//AtsHDhyoiIgINW/eXD179tT777+vzz//XPv37y90nNjYWHl6etpvgYGBxT43lD7DMDTk6yHKN/LVrXE3dWzQ0exIAACgHClSocK1qnRTU1ML3efAgQNasWKF8vPztXr1ao0dO1ZTp07Vq6++WqDPnDlzdPvtt2vNmjUaNGiQhg4dqsWLF181S05OjrKysgrcAEnatUuaNs3WfucdqWpVU+MAAADA0f36pZRs+xSZQhdLlf2v3R8AAKAY1K5dW87OzkpLSyuwPS0tTb6+voXu4+fnp4YNG8rZ+X9FlY0bN1Zqaqpyc3ML9D18+LDWrVunp59++rpZQkJCJEkpKSmFPh4dHa3MzEz77ejRo9cdE2Xf8p+X69tD38rDxUPTOk0zOw4AAChnilSocDNupErXarXqrrvu0qRJk3TnnXdq4MCBGjBgwFUreSWqcFG4/HxpwADb18cekx56yOxEAAAAcGjZR6WttsviqfHzkn8Xc/MAAIAKw83NTcHBwUpISLBvs1qtSkhIUGhoaKH7hIWFKSUlRVar1b4tOTlZfn5+cnMreMr+RYsWydvbWw/dwC/Ydu3aJclWCFEYd3d3Va9evcAN5du53HMa+c1ISdJL7V5SPa96JicCAADlTZEKFUqqStfPz09NmjQpsF/jxo115MiRq2ahCheFmTVL2rFD8vSUZswwOw0AAAAcmvWStPlJKfeMVLON1OI1sxMBAIAKJioqSvPnz9fixYu1Z88eDRo0SNnZ2erb11ZI2atXL0VHR9v7Dxo0SOnp6Ro2bJiSk5O1atUqTZo0SZGRkQXGtVqtWrRokXr37i0XF5cCj+3fv18TJ05UYmKiDh06pJUrV6pXr16677771KJFi5KfNMqESf+apGNnj6m+V329EPaC2XEAAEA55HL9Lv9zeZVu165dJf2vSnfw4MGF7hMWFqYlS5bIarXKyclWF/HHKt2wsDAlJSUV2C85OVn16l29CtPd3V3u7u5FiQ8Hd+SINGaMrT15snSVAm4AAACgeOx+RTq1SXKpJoV9LDm7XX8fAACAYtSjRw+dOnVK48aNU2pqqlq1aqX4+Hj7pXuPHDli/52sJAUGBmrNmjUaMWKEWrRooYCAAA0bNkyjRo0qMO66det05MgR9evX74pjurm5ad26dZo+fbqys7MVGBio7t276+WXXy7ZyaLMSP4tWW9uflOSNL3zdHm4eJicCAAAlEcWwzCMouywbNky9e7dW3PnzlXbtm01ffp0LV++XHv37pWPj4969eqlgIAAxcbGSpKOHj2qpk2bqnfv3hoyZIj27dunfv36aejQoRrz378qb9++Xffcc48mTJigf/zjH9q2bZsGDBigefPmqWfPnjeUKysrS56ensrMzOTUYRWQYUiPPCJ99ZUUFiZ9953kVOIXNgEAACWtoq/xKvr8y7S0DVLCA5IM6Z6PpaDHzU4EAADKkYq+zqvo8y/PDMPQQ0se0tcpX6vLbV206slVslgsZscCAABlRFHWeUU6o4JUMlW6bdq00eeff67o6Gi98sorql+/vqZPn37DRQrAp5/aihRcXaV58yhSAAAAQAm6eEra/JQkQ7q1H0UKAAAAqDC+Sv5KX6d8LVcnV03vPJ0iBQAAcNOKfEaFsooq3IorI0Nq3FhKTZXGjpVeecXsRAAAoLhU9DVeRZ9/mWQY0saHpeOrpOqNpM47JJcqZqcCAADlTEVf51X0+ZdXFy9dVJPZTXQw46BGh41WbHis2ZEAAEAZU5R1Hp87R7kXHW0rUmjYUHrpJbPTAAAAwKElzbAVKTi5S2HLKFIAAABAhTHl+yk6mHFQAdUCNOa+MWbHAQAA5RyFCijXNm2S4uJs7XnzJA8Pc/MAAADAgaUnSrtetLWD35JqtDA3DwAAAFBKDmccVuwm2xkU3uz0pqq6VTU5EQAAKO8oVEC5lZsrPfOMrd2vn9S+vbl5AAAA4MDysqRNPSRrnnTL36TbnjU7EQAAAFBqRn4zUhcuXVD7eu3Vo2kPs+MAAAAHQKECyq033pB++UWqU0eaMsXsNAAAAHBYhiFtf046t1+qXFe6e4FksZidCgAAACgVa/ev1ad7PpWzxVlvd3lbFtbCAACgGFCogHIpKUmaONHWnjFDqlnT3DwAAABwYAfflw59JFmcpbAlklsNsxMBAAAApSI3P1dD44dKkga3HazmPs1NTgQAABwFhQoodwxDevZZ26UfIiKkxx83OxEAAAAcVlaS7WwKktR8glQnzNw8AAAAQCl6+4e3tff0XtWpXEfjO4w3Ow4AAHAgFCqg3HnvPenbb6VKlaQ5czjrLgAAAEpI/kVpUw8p/7zkc7/UZLTZiQAAAIBSc+LsCY3fOF6SNDl8srw8vEzNAwAAHAuFCihXTp6URo60tV95Rapf39w8AAAAcGD/flHK+FFyryOFfiA5OZudCAAAACg1L657UedyzykkIES9W/U2Ow4AAHAwFCqgXBkxQjpzRmrVSho+3Ow0AAAAcFi/fiklv21rhy6WKvubmwcAAAAoRZuObNKHP30oiyya9eAsOVn4UwIAACherC5QbqxZIy1ZIjk5SfPmSS4uZicCAACAQ8o+Km3ta2s3Gin5dzE3DwAAAFCK8q35Grx6sCTp6bueVmv/1iYnAgAAjohCBZQL2dnSs8/a2kOHSm3amJsHAAAADsp6SdrcU8o9I9VsLbWcZHYiAAAAoFTNTZyrH9N+VA2PGpr0AOthAABQMihUQLkwYYJ06JAUGChNnGh2GgAAADis3ROlU/+SXKpJYUslZzezEwEAAACl5vT503p5/cuSpIl/majalWubnAgAADgqChVQ5u3aJU2bZmvPni1VrWpqHAAAADiqtA22QgVJajtXqtbA3DwAAABAKRuTMEZnLp5RS5+Weqb1M2bHAQAADoxCBZRp+fnSgAG2r489Jj38sNmJAAAA4JAunpY2PyXJkG7tJwU9YXYiAAAAoFTtOL5D83fOlyTNenCWXJxcTE4EAAAcGYUKKNNmzZJ27JA8PaUZM8xOAwAAAIdkGNLWPtKF41L1RlLrmWYnAgAAAEqV1bBqyNdDZMhQz+Y91a5uO7MjAQAAB0ehAsqsI0ekMWNs7cmTJT8/c/MAAADAQSXNkI6vkpzcpbBlkksVsxMBAAAAper9H9/X1l+3qqpbVb3R8Q2z4wAAgAqAQgWUSYYhRUZK2dlSWJjt8g8AAABAsUtPlHa9aGvfNU2q0cLcPAAAAEApy7yYqVHrRkmSYtrHyL+av8mJAABARUChAsqkTz+VvvpKcnWV5s2TnHilAgAAoLjlnZU2PS5Z86Rb/ibdPsjsRAAAAECpG//teJ3MPqk7at2hoSFDzY4DAAAqCP78izInI0Ma+t/18OjRUpMmpsYBAACAIzIMafsg6VyKVLmudPcCyWIxOxUAAABQqnaf3K23t70tSZrZZabcnN1MTgQAACoKChVQ5kRHSydOSA0bSi+9ZHYaAAAAOKSD70uHPpIszlLYEsmthtmJAAAAgFJlGIaGfD1E+Ua+ujXupk4NOpkdCQAAVCAUKqBM+f57KS7O1p47V/LwMDcPAAAAHND5Y9KOSFu7+QSpTpi5eQAAAAATLP95ub499K08XDw0tdNUs+MAAIAKhkIFlBm5udLAgbZ2v35Shw6mxgEAAICj2vOmdClbqnW31GS02WkAAACAUncu95yeX/u8JCm6XbSCvILMDQQAACocChVQZrzxhvTLL1KdOtKUKWanAQAAgEO6eEpKmWtrt5ggOTmbmwcAAAAwwaR/TdKvWb+qvld9vXDPC2bHAQAAFRCFCigTkpOlV1+1tadPl2rWNDUOAAAAHNXet6T8C1LN1pJvR7PTAAAAAKVu32/79ObmNyVJb0W8pUqulUxOBAAAKiIKFWA6w5CeeUbKyZEiIqQnnjA7EQAAABxS7hkpeZat3exlyWIxNw8AAABQygzD0LD4Ycqz5qnzbZ31yB2PmB0JAABUUBQqwHTvvSd9+61UqZI0Zw6/LwYAAEAJSZolXToreTaTAh42Ow0AAABQ6r5K/kpfp3wtVydXzeg8QxZ+GQsAAExCoQJMdfKkNHKkrT1hglS/vrl5AAAA4KDyzklJ023tpmMkC/8VAgAAQMVy8dJFDV8zXJIUFRqlhrUamhsIAABUaPx2DqaKipLOnJFatZJGjDA7DQAAABxWSpyUmy5Vu12q+5jZaQAAAIBS9+bmN3XgzAH5V/PXy/e9bHYcAABQwVGoANOsWSN99JHk5CTNmye5uJidCAAAOLLZs2crKChIHh4eCgkJ0bZt267ZPyMjQ5GRkfLz85O7u7saNmyo1atX2x8PCgqSxWK54hYZGWnv06FDhysef/bZZ0tsjriKSxekPVNt7SajJSdnc/MAAAAApexwxmFN+tckSdLUTlNV1a2qyYkAAEBFx5+GYYrz56VBg2ztIUOkNm3MzQMAABzbsmXLFBUVpbi4OIWEhGj69OmKiIhQUlKSvL29r+ifm5urjh07ytvbWytWrFBAQIAOHz4sLy8ve5/t27crPz/ffn/37t3q2LGjHnus4Kf1BwwYoFdeecV+v3LlysU/QVzbgYXSxVSpcl0p6Cmz0wAAAAClbuQ3I3Xh0gW1r9dePZr2MDsOAAAAhQowx4QJ0sGDUmCgNHGi2WkAAICjmzZtmgYMGKC+fftKkuLi4rRq1SotXLhQo0ePvqL/woULlZ6ers2bN8vV1VWS7QwKl6tTp06B+6+//roaNGig9u3bF9heuXJl+fr6FuNsUCT5udIvb9jaTV6UnN3MzQMAAACUsnUH1unTPZ/K2eKst7u8LYvFYnYkAAAALv2A0rdrlzT1v2fenT1bqlbN1DgAAMDB5ebmKjExUeHh4fZtTk5OCg8P15YtWwrdZ+XKlQoNDVVkZKR8fHzUrFkzTZo0qcAZFP54jA8//FD9+vW74pd+H330kWrXrq1mzZopOjpa58+fL77J4foOfSidPyJ5+Eq39jM7DQAAAFCqcvNzNeTrIZKkyDaRau7T3OREAAAANpxRAaUqP18aMMD29e9/lx5+2OxEAADA0Z0+fVr5+fny8fEpsN3Hx0d79+4tdJ8DBw5o/fr16tmzp1avXq2UlBQ999xzysvLU0xMzBX9v/jiC2VkZKhPnz4Ftj/55JOqV6+e/P399dNPP2nUqFFKSkrSZ599Vuhxc3JylJOTY7+flZVVxNmiAGu+9HOsrd14pORSydw8AAAAQCl7+4e3tff0XtWpXEcT/jLB7DgAAAB2FCqgVM2eLe3YIXl6SjNnmp0GAACgcFarVd7e3po3b56cnZ0VHBysY8eOacqUKYUWKixYsEBdunSRv79/ge0DBw60t5s3by4/Pz898MAD2r9/vxo0aHDFOLGxsZowgV8eFpsjy6VzKZJbTem2Z81OAwAAAJSqE2dPaMJG2/8vXg9/XV4eXuYGAgAAuAyXfkCpOXpUGjPG1p48WfLzMzcPAACoGGrXri1nZ2elpaUV2J6WliZfX99C9/Hz81PDhg3l7Oxs39a4cWOlpqYqNze3QN/Dhw9r3bp1evrpp6+bJSQkRJKUkpJS6OPR0dHKzMy0344ePXrdMXEVhlX6eZKtfcdwybWqqXEAAACA0jZq3SidzT2rtgFt1adVH7PjAAAAFEChAkqFYUiRkdK5c1JYmO3yDwAAAKXBzc1NwcHBSkhIsG+zWq1KSEhQaGhoofuEhYUpJSVFVqvVvi05OVl+fn5yc3Mr0HfRokXy9vbWQw89dN0su3btkmQrhCiMu7u7qlevXuCGm/TrSilzt+RaXbpjiNlpAAAAgFK16cgmffDTB7LIolldZsnJwp8CAABA2cLqBKXis8+kf/5TcnWV5s6VnHjlAQCAUhQVFaX58+dr8eLF2rNnjwYNGqTs7Gz17dtXktSrVy9FR0fb+w8aNEjp6ekaNmyYkpOTtWrVKk2aNEmRkZEFxrVarVq0aJF69+4tF5eCV1Xbv3+/Jk6cqMTERB06dEgrV65Ur169dN9996lFixYlP+mKzDCkn1+ztW+PlNy8TI0DAAAAlKZ8a76GfG0r1u1/Z3+1CWhjciIAAIAr8edilLjMTGnIfz/ENnq01LSpuXkAAEDF06NHD7355psaN26cWrVqpV27dik+Pl4+Pj6SpCNHjujEiRP2/oGBgVqzZo22b9+uFi1aaOjQoRo2bJhGjx5dYNx169bpyJEj6tev3xXHdHNz07p169SpUyc1atRII0eOVPfu3fXPf/6zZCcL6cQ3UvoOybmS1GiE2WkAAABK1OzZsxUUFCQPDw+FhIRo27Zt1+yfkZGhyMhI+fn5yd3dXQ0bNtTq1avtj48fP14Wi6XArVGjRgXGuHjxoiIjI1WrVi1VrVpV3bt3v+JSazDPvMR52pW6S14eXpr0wCSz4wAAABTK5fpdgD8nOlo6cUJq2FB66SWz0wAAgIpq8ODBGjx4cKGPffvtt1dsCw0N1datW685ZqdOnWQYRqGPBQYGauPGjUXOiWLw+9kUbntG8qhjbhYAAIAStGzZMkVFRSkuLk4hISGaPn26IiIilJSUJG9v7yv65+bmqmPHjvL29taKFSsUEBCgw4cPy8vLq0C/pk2bat26dfb7fzx72IgRI7Rq1Sp98skn8vT01ODBg9WtWzd9//33JTJP3LjT509rzPoxkqRX//Kq6lRhPQwAAMomChVQor7/Xpozx9aeO1fy8DA3DwAAABzcye+kU/+SnNykxs+bnQYAAKBETZs2TQMGDLBf0iwuLk6rVq3SwoULrzgbmCQtXLhQ6enp2rx5s1xdXSVJQUFBV/RzcXGRr69vocfMzMzUggULtGTJEt1///2SpEWLFqlx48baunWr7r777mKaHW7GmIQxOnPxjFr4tNAzrZ8xOw4AAMBVcekHlJjcXGngQFu7Xz+pQwdT4wAAAKAi2P3fsync2leqHGBuFgAAgBKUm5urxMREhYeH27c5OTkpPDxcW7ZsKXSflStXKjQ0VJGRkfLx8VGzZs00adIk5efnF+i3b98++fv769Zbb1XPnj115MgR+2OJiYnKy8srcNxGjRqpbt26Vz1uTk6OsrKyCtxQ/Hae2Kn5O+dLkmZ1mSUXJz6nCAAAyi4KFVBipkyRfvlFqlPH1gYAAABK1G/bpdRvJIuz1GSU2WkAAABK1OnTp5Wfny8fH58C2318fJSamlroPgcOHNCKFSuUn5+v1atXa+zYsZo6dapeffVVe5+QkBC99957io+P15w5c3Tw4EHde++9Onv2rCQpNTVVbm5uV1wu4lrHjY2Nlaenp/0WGBj4J2aOwhiGoaFfD5UhQ082f1L31rvX7EgAAADXREklSkRysjRxoq09fbpUs6apcQAAAFAR/PzfsykE9ZSq1jc3CwAAQBlktVrl7e2tefPmydnZWcHBwTp27JimTJmimJgYSVKXLl3s/Vu0aKGQkBDVq1dPy5cvV//+/W/quNHR0YqKirLfz8rKolihmC3dvVTfH/1elV0ra3L4ZLPjAAAAXBeFCih2hiE9+6yUkyNFREhPPGF2IgAAADi8jP9Iv34pySI1iTY7DQAAQImrXbu2nJ2dlZaWVmB7WlqafH19C93Hz89Prq6ucnZ2tm9r3LixUlNTlZubKzc3tyv28fLyUsOGDZWSkiJJ8vX1VW5urjIyMgqcVeFax3V3d5e7u3tRp4gblJ2brRfXvShJim4XrVuq32JyIgAAgOvj0g8odosXSxs2SJUqSXPmSBaL2YkAAADg8H6eZPta9++SZyNzswAAAJQCNzc3BQcHKyEhwb7NarUqISFBoaGhhe4TFhamlJQUWa1W+7bk5GT5+fkVWqQgSefOndP+/fvl5+cnSQoODparq2uB4yYlJenIkSNXPS5K1uTvJ+vXrF8V5BWkkaEjzY4DAABwQyhUQLE6eVIa+d+18IQJUn3OuAsAAICSlpUsHVluazcdY24WAACAUhQVFaX58+dr8eLF2rNnjwYNGqTs7Gz17dtXktSrVy9FR//vbFODBg1Senq6hg0bpuTkZK1atUqTJk1SZGSkvc/zzz+vjRs36tChQ9q8ebP+9re/ydnZWU/897Spnp6e6t+/v6KiorRhwwYlJiaqb9++Cg0N1d133126TwB0KOOQpmyeIkl6s+ObquRayeREAAAAN4ZLP6BYRUVJ6elSq1bSiBFmpwEAAECF8MvrkmGV/P8q1WhpdhoAAIBS06NHD506dUrjxo1TamqqWrVqpfj4ePn4+EiSjhw5Iien/31WLTAwUGvWrNGIESPUokULBQQEaNiwYRo1apS9z6+//qonnnhCv/32m+rUqaN27dpp69atqlOnjr3PW2+9JScnJ3Xv3l05OTmKiIjQO++8U3oTh92La1/UxUsX9Zegv6hb425mxwEAALhhFsMwDLNDFIesrCx5enoqMzNT1atXNztOhfTNN1JEhOTkJG3dKrVpY3YiAABQ3lX0NV5Fn/8NyT4srbxNMi5JnbZItfkUHwAAKPsq+jqvos+/uHx76Fv9ZfFf5GRx0r+f+bda+LQwOxIAAKjgirLOu6lLP8yePVtBQUHy8PBQSEiItm3bds3+GRkZioyMlJ+fn9zd3dWwYUOtXr260L6vv/66LBaLhg8ffjPRYJLz56Vnn7W1hwyhSAEAAACl5Jc3bEUKPg9QpAAAAIAKI9+ar2HxwyRJzwQ/Q5ECAAAod4p86Ydly5YpKipKcXFxCgkJ0fTp0xUREaGkpCR5e3tf0T83N1cdO3aUt7e3VqxYoYCAAB0+fFheXl5X9N2+fbvmzp2rFi1YVJU3EyZIBw9KgYHSxIlmpwEAAECFcOGEtH+Brd3sZXOzAAAAAKVo/s75+intJ9XwqKGJf+EXsgAAoPwp8hkVpk2bpgEDBqhv375q0qSJ4uLiVLlyZS1cuLDQ/gsXLlR6erq++OILhYWFKSgoSO3bt1fLlgWvHXvu3Dn17NlT8+fPV40aNW5uNjDFjz9KU6fa2rNnS9WqmZsHAAAAFcSeqZI1R6p9j+Td3uw0AAAAQKk4c+GMXl5vK9Sd0GGCalWuZXIiAACAoitSoUJubq4SExMVHh7+vwGcnBQeHq4tW7YUus/KlSsVGhqqyMhI+fj4qFmzZpo0aZLy8/ML9IuMjNRDDz1UYGyUffn50oABtq9//7v08MNmJwIAAECFcPG0lBJnazd7WbJYzM0DAAAAlJIJGyfotwu/qUmdJnq29bNmxwEAALgpRbr0w+nTp5Wfny8fH58C2318fLR3795C9zlw4IDWr1+vnj17avXq1UpJSdFzzz2nvLw8xcTESJKWLl2qnTt3avv27TecJScnRzk5Ofb7WVlZRZkKisns2dL27ZKnpzRzptlpAAAAUGEkzZAuZUs17pL8OpudBgAAACgVv5z6RbO2zZIkzeg8Q67OriYnAgAAuDlFKlS4GVarVd7e3po3b56cnZ0VHBysY8eOacqUKYqJidHRo0c1bNgwrV27Vh4eHjc8bmxsrCZMmFCCyXE9R49KY8bY2q+/Lvn5mZsHAAAAFURuppT8tq3dbAxnUwAAAECFYBiGhscPV76Rr0fveFTht3J2YgAAUH4V6dIPtWvXlrOzs9LS0gpsT0tLk6+vb6H7+Pn5qWHDhnJ2drZva9y4sVJTU+2Xkjh58qTuuusuubi4yMXFRRs3btTMmTPl4uJyxSUifhcdHa3MzEz77ejRo0WZCv4kw5AiI6Vz56R77pEGDjQ7EQAAACqMfbOlvEzJs4l0S1ez0wAAAACl4qvkr7T2wFq5ObtpaqepZscBAAD4U4pUqODm5qbg4GAlJCTYt1mtViUkJCg0NLTQfcLCwpSSkiKr1WrflpycLD8/P7m5uemBBx7Qf/7zH+3atct+a926tXr27Kldu3YVKHC4nLu7u6pXr17ghtLz2WfSP/8pubpK8+ZJTkV6JQEAAAA36VK2tPctW7vJS5KFhSgAAAAcX86lHI1YM0KSFHV3lBrUbGByIgAAgD+nyJd+iIqKUu/evdW6dWu1bdtW06dPV3Z2tvr27StJ6tWrlwICAhQbGytJGjRokGbNmqVhw4ZpyJAh2rdvnyZNmqShQ4dKkqpVq6ZmzZoVOEaVKlVUq1atK7ajbMjMlIYMsbVHjZKaNjU3DwAAACqQlHlSzmmp6q1SvR5mpwEAAABKxYwfZmj/mf3yq+qnl+59yew4AAAAf1qRCxV69OihU6dOady4cUpNTVWrVq0UHx8vHx8fSdKRI0fkdNnH6wMDA7VmzRqNGDFCLVq0UEBAgIYNG6ZRo0YV3yxQqqKjpRMnpNtvl8aMMTsNAAAAKoz8i9KeN23tJtGSU5H/OwMAAACUOyfOntDE7yZKkl4Pf13V3KuZnAgAAODPsxiGYZgdojhkZWXJ09NTmZmZXAaiBG3eLIWF2drr10t/+Yu5eQAAgGOr6Gu8ij7/K+yLk7YPkirfIj28X3J2MzsRAADATano67yKPv+i6vtlX7236z21DWirLf23yInLnwEAgDKqKOs8VjS4Ybm50sCBtnbfvhQpAAAAoBRZ86RfJtvajV+kSAEAAAAVwvZj2/XervckSTM7z6RIAQAAOAxWNbhhU6ZIP/8s1aljawMAAACl5tASKfuQ5OEtNXja7DQAAABAibMaVg2NHypJ6tWyl0JuCTE5EQAAQPGhUAE3JDlZmmi7DJreekuqVcvcPAAAAKhArPnSL7G2dqORkkslc/MAAAAApWDJf5Zo669bVcW1imIfiDU7DgAAQLGiUAHXZRjSs89KOTlSp07Sk0+anQgAAAAVytFPpawkya2GdPsgs9MAAAAAJe5c7jmNWjdKkvTyfS/Lv5q/yYkAAACKF4UKuK7Fi6UNG6RKlaQ5cySLxexEAAAAqDAMQ/r5NVv7jmGSazVz8wAAAAClIPZfsTp+9rhurXGrht893Ow4AAAAxY5CBVzTqVPSyJG29vjx0q23mhoHAAAAFc2xr6SMnySXqlLDIWanAQAAAErcgTMHNHXLVEnS1E5T5eHiYXIiAACA4kehAq5pxAgpPV1q2dLWBgAAAErN5WdTaBgpudc0Nw8AAABQCp7/5nnl5Oco/NZwPXrHo2bHAQAAKBEUKuCqFi+WPvrIdqmH+fMlV1ezEwEAAKBCSUuQfvtBcvaQ7qBqFgAAAI4v4UCCPt/7uZwtzpoeMV0WrsMLAAAcFIUKKNSuXdKzz9raMTFSmzamxgEAAEBFtPu/Z1NoMFCq5GNuFgAAAKCEXbJe0vA1wyVJz7V5Tk29m5obCAAAoARRqIArnDkjde8uXbwoPfigNHas2YkAAABQ4Zz6Xjr5reTkKjV5wew0AAAAQImbu2Oudp/crZqVamp8h/FmxwEAAChRFCqgAKtV+r//kw4ckIKCpA8+kJx4lQAAAKC0/X42hfp9pMq3mBoFAAAAKGm/nf9NYzfYPjE28S8TVbNSTZMTAQAAlCz+BI0CJk2SVq2SPDykzz6TarIeBgAAQGlLT5ROfC1ZnKQmo8xOAwAAAJS4mG9jdObiGTX3bq6BwQPNjgMAAFDiKFSA3Zo10rhxtvacOdKdd5qbBwAAABXUz5NsX+s9KVVrYG4WAAAAoIT9J+0/mrNjjiRpeufpcnFyMTkRAABAyaNQAZKkQ4ekJ5+UDEMaOFDq08fsRAAAAKiQMn6Wjn5mazeNNjcLAAAAUMIMw9DwNcNlNazq1rib7q9/v9mRAAAASgWFCtDFi9Lf/y6lp0tt2kgzZ5qdCAAAABXWL7G2r4HdJc8m5mYBAAAAStgXe7/Q+oPr5e7srjc7vml2HAAAgFJDoQI0ZIiUmCjVqiWtWCG5u5udCAAAABXS2RTp8Me2dtMx5mYBAAAAStjFSxc18puRkqTn73le9WvUNzkRAABA6aFQoYJbsEB6913JYpE+/liqW9fsRAAAAKiwfpksGVbJr4tU806z0wAAAAAl6q0tb+lgxkEFVAtQdDsuewYAACoWChUqsMREKTLS1p44UerY0dw8AAAAqMCyj0oHF9vazV42NwsAAABQwo5lHdNr/3pNkjQ5fLKquFUxOREAAEDpolChgvrtN+nvf5dycqSHH5aiKdgFAACAmfZMkax5kncHqc49ZqcBAAAASlR0QrSy87IVekuonmz+pNlxAAAASh2FChVQfr701FPSoUNSgwbS++9LTrwSAAAAYJYLadL++bY2Z1MAAACAg9v661Z98NMHkqSZXWbKYrGYnAgAAKD08efpCmjiRCk+XqpUSfr0U8nLy+xEAAAAqND2TpPyL0q1QiSf+81OAwAAAJQYq2HV0K+HSpL6tuqr1v6tTU4EAABgDgoVKpjVq6UJE2ztuXOlli3NzQMAAIAKLidd2veOrd3sZYlPkwEAAMCBffDjB9p+fLuquVXTpAcmmR0HAADANBQqVCAHDkg9e9razz0n/d//mZsHAAAAUNJM6dI5yaul5P+Q2WkAAACAEnM256xGJ4yWJI29b6x8q/qanAgAAMA8FCpUEBcuSN27SxkZUkiING2a2YkAAABQ4eVlSUkzbO1mYzibAgAAABzaa/96TannUnVbzds0NGSo2XEAAABMRaFCBWAYtjMo7Nol1akjrVghububnQoAAAAV3r45Ul6GVP0O6ZZuZqcBAAAASkxKeore2vqWJOmtiLfk7sIvaAEAQMVGoUIFMH++9N57kpOTtHSpdMstZicCAAAofbNnz1ZQUJA8PDwUEhKibdu2XbN/RkaGIiMj5efnJ3d3dzVs2FCrV6+2Pz5+/HhZLJYCt0aNGhUY4+LFi4qMjFStWrVUtWpVde/eXWlpaSUyv3Ln0nlpz1Rbu8lLkpOzuXkAAACAEjTym5HKzc9VRIMIPXQ7lzwDAACgUMHBbd8uDRlia0+aJN1/v7l5AAAAzLBs2TJFRUUpJiZGO3fuVMuWLRUREaGTJ08W2j83N1cdO3bUoUOHtGLFCiUlJWn+/PkKCAgo0K9p06Y6ceKE/bZp06YCj48YMUL//Oc/9cknn2jjxo06fvy4unXjzAGSpP3vSjmnpCpBUtATZqcBAAAASsw3+7/RyqSVcnFy0VsRb8nCJc8AAADkYnYAlJzTp6Xu3aXcXKlrV+nFF81OBAAAYI5p06ZpwIAB6tu3ryQpLi5Oq1at0sKFCzV69Ogr+i9cuFDp6enavHmzXF1dJUlBQUFX9HNxcZGvr2+hx8zMzNSCBQu0ZMkS3f/fatFFixapcePG2rp1q+6+++5iml05lJ8j/fKGrd1ktOTkam4eAAAAoITk5edpePxwSdLgNoPVuE5jcwMBAACUEZxRwUHl50tPPCEdPSrdfrvt0g8U6gIAgIooNzdXiYmJCg8Pt29zcnJSeHi4tmzZUug+K1euVGhoqCIjI+Xj46NmzZpp0qRJys/PL9Bv37598vf316233qqePXvqyJEj9scSExOVl5dX4LiNGjVS3bp1r3rcnJwcZWVlFbg5pIPvSxeOSZX8pVv7mJ0GAACgXCvuS5zFxsaqTZs2qlatmry9vdW1a1clJSUVGKNDhw5XXAbt2WefLZH5lXdzdszRntN7VLtybcV0iDE7DgAAQJlBoYKDiomR1q2TKleWPvtM8vQ0OxEAAIA5Tp8+rfz8fPn4+BTY7uPjo9TU1EL3OXDggFasWKH8/HytXr1aY8eO1dSpU/Xqq6/a+4SEhOi9995TfHy85syZo4MHD+ree+/V2bNnJUmpqalyc3OTl5fXDR83NjZWnp6e9ltgYOCfmHkZZb0k/fK6rd34BcnZ3dw8AAAA5VhJXOJs48aNioyM1NatW7V27Vrl5eWpU6dOys7OLjDWgAEDClwG7Y033ijRuZZHp8+fVsy3tuKE1+5/TV4eXuYGAgAAKEO49IMDWrlSeu01W/vdd6VmzczNAwAAUN5YrVZ5e3tr3rx5cnZ2VnBwsI4dO6YpU6YoJsb2i8YuXbrY+7do0UIhISGqV6+eli9frv79+9/UcaOjoxUVFWW/n5WV5XjFCoeXSucOSO61pdsGmJ0GAACgXCuJS5zFx8cXuP/ee+/J29tbiYmJuu++++zbK1eufNXLoMFm7PqxyriYoZY+LdX/zpv7PwIAAICj4owKDiYlRerVy9YeOtR2+QcAAICKrHbt2nJ2dlZaWlqB7WlpaVf9xaqfn58aNmwoZ2dn+7bGjRsrNTVVubm5he7j5eWlhg0bKiUlRZLk6+ur3NxcZWRk3PBx3d3dVb169QI3h2JYpZ8n2dqNoiSXKubmAQAAKMdK8hJnl8vMzJQk1axZs8D2jz76SLVr11azZs0UHR2t8+fPX3WMCnOJs8v8mPqj5u2cJ0ma2WWmnJ2cr7MHAABAxUKhggM5f17q3l3KzJTuuUeaMsXsRAAAAOZzc3NTcHCwEhIS7NusVqsSEhIUGhpa6D5hYWFKSUmR1Wq1b0tOTpafn5/c3NwK3efcuXPav3+//Pz8JEnBwcFydXUtcNykpCQdOXLkqsd1eEc/l7L2SK6e0u3PmZ0GAACgXCupS5xdzmq1avjw4QoLC1Ozy07b+uSTT+rDDz/Uhg0bFB0drQ8++EBPPfXUVbNWiEucXcYwDA2LHyarYdU/mv5D99W77/o7AQAAVDBc+sFBGIb0zDPSTz9JPj7SJ59IV/kdOgAAQIUTFRWl3r17q3Xr1mrbtq2mT5+u7Oxs+ylye/XqpYCAAMXGxkqSBg0apFmzZmnYsGEaMmSI9u3bp0mTJmno0KH2MZ9//nk9/PDDqlevno4fP66YmBg5Ozvrif+e0srT01P9+/dXVFSUatasqerVq2vIkCEKDQ3V3XffXfpPgtkMQ/r5v9cnu2Oo5OZpbh4AAIAK6EYucXa5yMhI7d69W5s2bSqwfeDAgfZ28+bN5efnpwceeED79+9XgwYNrhinQlzi7DKf7vlUGw9vlIeLh94If8PsOAAAAGUShQoOYs4c6cMPJWdnadkyyd/f7EQAAABlR48ePXTq1CmNGzdOqampatWqleLj4+2fPjty5IicnP53srHAwECtWbNGI0aMUIsWLRQQEKBhw4Zp1KhR9j6//vqrnnjiCf3222+qU6eO2rVrp61bt6pOnTr2Pm+99ZacnJzUvXt35eTkKCIiQu+8807pTbwsOf61dObftss93DHM7DQAAADl3s1e4szV1fWqlzi7/OxhgwcP1ldffaXvvvtOt9xyyzWzhISESJJSUlIKLVRwd3eXu7v7Dc+tPLuQd0HPf/O8JGlU2CjV86pnciIAAICyiUIFB7B1qzR8uK09ebLUvr2pcQAAAMqkwYMHa/DgwYU+9u23316xLTQ0VFu3br3qeEuXLr3uMT08PDR79mzNnj37hnM6JMOQfv7v6YRvHyS51zI3DwAAgAO4/BJnXbt2lfS/S5xdbd0bFhamJUuWyGq12gt1/3iJM8MwNGTIEH3++ef69ttvVb9+/etm2bVrlyTZL4NWkb25+U0dzjysW6rfohfDXjQ7DgAAQJnldP0uKMtOnpT+/ncpL8/29bIzqAEAAABlw8lvpdNbJCd3qRELVgAAgOISFRWl+fPna/HixdqzZ48GDRp0xSXOoqOj7f0HDRqk9PR0DRs2TMnJyVq1apUmTZqkyMhIe5/IyEh9+OGHWrJkiapVq6bU1FSlpqbqwoULkqT9+/dr4sSJSkxM1KFDh7Ry5Ur16tVL9913n1q0aFG6T0AZczTzqGI32S4nN6XjFFV2rWxyIgAAgLKLMyqUY5cuSY8/Lh07JjVqJC1cKFksZqcCAAAA/mD3f8+m0OBpqRKfsgMAACguJXGJszlz5kiSOnToUOBYixYtUp8+feTm5qZ169Zp+vTpys7OVmBgoLp3766XX3655Cdcxo1OGK0Lly6oXd126tG0h9lxAAAAyjSLYRiG2SGKQ1ZWljw9PZWZmanq1aubHadUjB5tu9RDlSrS9u1S48ZmJwIAACheFXGNdzmHmP+pLdLaeySLi/TIfqlKXbMTAQAAmM4h1nl/giPO//sj36vdonayyKIdA3foLr+7zI4EAABQ6oqyzuPSD+XU55/bihQk25kUKFIAAABAmfTza7av9XtRpAAAAACHZDWsGho/VJLU/87+FCkAAADcAAoVyqHkZKl3b1t7xAjpH/8wNw8AAABQqPR/S8dXSRYnqclos9MAAAAAJWLRvxdp54mdqu5eXa898JrZcQAAAMoFChXKmexsqVs36exZ6d57/3dWBQAAAKDM+XmS7WvdHlL1283NAgAAAJSAzIuZemn9S5KkmPYx8q7ibXIiAACA8oFChXLEMKQBA6Sff5Z8faVlyyRXV7NTAQAAAIXI3CMd/dTWbvqSuVkAAACAEvLqd6/qZPZJ3VHrDg1uO9jsOAAAAOUGhQrlyNtvSx9/LLm4SJ98Ivn5mZ0IAAAAuIqfYyUZ0i1dJa9mZqcBAAAAil3yb8ma8cMMSdJbEW/JzdnN5EQAAADlB4UK5cT330sjR9raU6ZI7dqZmwcAAAC4qnMHpMNLbO2mY8zNAgAAAJSQqDVRyrPm6cHbH1SX27uYHQcAAKBcoVChHEhNlR57TLp0SerRQxo2zOxEAAAAwDX8Mlky8iW/CKlWa7PTAAAAAMXu631fa9W+VXJxctFbEW+ZHQcAAKDcoVChjMvLsxUnnDghNWkivfuuZLGYnQoAAAC4ivPHpAPv2dqcTQEAAAAOKDc/VyPWjJAkDQsZpoa1GpqcCAAAoPyhUKGMi46WvvtOqlZN+vRTqWpVsxMBAAAA17DnTcmaK3nfJ3nfa3YaAAAAoNjN3jZbSb8lybuKt8beN9bsOAAAAOXSTRUqzJ49W0FBQfLw8FBISIi2bdt2zf4ZGRmKjIyUn5+f3N3d1bBhQ61evdr+eGxsrNq0aaNq1arJ29tbXbt2VVJS0s1EcygrVkhTp9ra770nNWpkahwAAADg2i6elFLm2tqcTQEAAAAO6GT2SY3fOF6SNOn+SfL08DQ3EAAAQDlV5EKFZcuWKSoqSjExMdq5c6datmypiIgInTx5stD+ubm56tixow4dOqQVK1YoKSlJ8+fPV0BAgL3Pxo0bFRkZqa1bt2rt2rXKy8tTp06dlJ2dffMzK+f27JH69rW1X3hB6tbN3DwAAADAde2dLuVfkGq2kXw7mp0GAAAAKHYvr39ZWTlZusvvLvVp1cfsOAAAAOWWS1F3mDZtmgYMGKC+//0relxcnFatWqWFCxdq9OjRV/RfuHCh0tPTtXnzZrm6ukqSgoKCCvSJj48vcP+9996Tt7e3EhMTdd999xU1Yrl39qzUvbt07pzUoYM0aZLZiQAAAIDryD0jJc+ytZuNkSwWc/MAAAAAxezfJ/6td3e+K0ma2XmmnJ2cTU4EAABQfhXpjAq5ublKTExUeHj4/wZwclJ4eLi2bNlS6D4rV65UaGioIiMj5ePjo2bNmmnSpEnKz8+/6nEyMzMlSTVr1ixKPIdgGFL//rYzKvj7S0uXSi5FLicBAAAASlnSLOnSWcmruRTwsNlpAAAAgGJlGIaGxg+VIUNPNHtCYXXDzI4EAABQrhXpT+CnT59Wfn6+fHx8Cmz38fHR3r17C93nwIEDWr9+vXr27KnVq1crJSVFzz33nPLy8hQTE3NFf6vVquHDhyssLEzNmjW7apacnBzl5OTY72dlZRVlKmXW9OnSJ59Irq7SihXSH55qAAAAoOzJOyclTbe1m7wkWYp8hTkAAACgTFv+83JtOrJJlVwqaXL4ZLPjAAAAlHsl/ll9q9Uqb29vzZs3T87OzgoODtaxY8c0ZcqUQgsVIiMjtXv3bm3atOma48bGxmrChAklFdsU330nvfCCrT1tmhQaam4eAAAA4IakxEm56VK126W6j5mdBgAAAChW5/PO64W1tl/cRreLVqBnoMmJAAAAyr8ifdSpdu3acnZ2VlpaWoHtaWlp8vX1LXQfPz8/NWzYUM7O/7teV+PGjZWamqrc3NwCfQcPHqyvvvpKGzZs0C233HLNLNHR0crMzLTfjh49WpSplDnHj0v/+IeUny/17ClFRpqdCAAAALgBly5Ie960tZtES1ynFwAAAA7mje/f0NGso6rnWU/P3/O82XEAAAAcQpEKFdzc3BQcHKyEhAT7NqvVqoSEBIVe5eP/YWFhSklJkdVqtW9LTk6Wn5+f3NzcJNmu7zV48GB9/vnnWr9+verXr3/dLO7u7qpevXqBW3mVl2crUkhLk5o1k+bOlSwWs1MBAAAAN+DAQulimlS5rlT/KbPTAAAAAMXqSOYRTf7edqmHNzu9qUqulUxOBAAA4BiKfPHYqKgozZ8/X4sXL9aePXs0aNAgZWdnq2/fvpKkXr16KTo62t5/0KBBSk9P17Bhw5ScnKxVq1Zp0qRJirzslAGRkZH68MMPtWTJElWrVk2pqalKTU3VhQsXimGKZd8LL0jffy9Vry599plUpYrZiQAAAIAbkJ8r/fLf6/M2GSU5uZqbBwAAAChmL6x9QRcvXVT7eu3VvXF3s+MAAAA4DJei7tCjRw+dOnVK48aNU2pqqlq1aqX4+Hj5+PhIko4cOSInp//VPwQGBmrNmjUaMWKEWrRooYCAAA0bNkyjRo2y95kzZ44kqUOHDgWOtWjRIvXp0+cmplV+LF0qzZhha7//vnT77ebmAQAAAG7YoQ+l80clD1+pQT+z0wAAAADF6rvD32n5z8vlZHHSjM4zZOE0uAAAAMWmyIUKkjR48GANHjy40Me+/fbbK7aFhoZq69atVx3PMIybiVHu/fyz1L+/rR0dLT36qLl5AAAAgBtmvST9HGtrN35ecvYwNw8AAABQjPKt+RoWP0ySNPCugWrp29LkRAAAAI6lyJd+QPHIypK6dZPOn5ceeECaONHsRAAAAEARHPlEOpciudeSbnvG7DQAAABAsVrw7wXalbpLXh5eeuUvr5gdBwAAwOFQqGACw5D69pWSk6VbbpE+/lhydjY7FQAAAHCDDKv082u29h3DJdeqpsYBAAAAilPGxQyNWT9GkjS+/XjVqVLH5EQAAACOh0IFE7z5pvTZZ5Krq7RihVSHdS4AAADKk19XSpk/S67VpYaFXxIOAAAAKK8mfDtBp8+fVuPajfVcm+fMjgMAAOCQKFQoZRs2SKNH29ozZ0ohIebmAQAAAIrEMKSfX7W1Gw6W3LxMjQMAAAAUpz2n9mjW9lmSpOmdp8vV2dXkRAAAAI6JQoVS9OuvUo8ektUq9eolPcOlfAEAAFDenPhGSk+UnCvbLvsAAAAAOAjDMDRizQhdsl7SI3c8ok4NOpkdCQAAwGFRqFBKcnOlxx6TTp2SWraU5syRLBazUwEAAABF9PvZFG57RvLgGmYAAABwHKv2rdKa/Wvk6uSqqZ2mmh0HAADAoVGoUEpGjpS2bpW8vKRPP5UqVzY7EQAAAFBEJ7+TTm2SnNykxs+bnQYAAAAoNrn5uRqxZoQkacTdI3RbzdtMTgQAAODYKFQoBR9+KM2yXdZMH3wgNWhgbh4AAADgpuz+79kUbu0nVfY3NwsAAABQjGZsnaGU9BT5VvXVy/e9bHYcAAAAh0ehQgn76Sdp4EBbe+xY6a9/NTcPAAAAcFNOb5NS10oWZ6nJi2anAQAAAIpN6rlUTfxuoiQp9oFYVXOvZnIiAAAAx0ehQgnKyJC6d5cuXJA6dZJiYsxOBAAAANykn1+zfQ16Sqpa39wsAAAAQDEakzBGZ3PPqo1/G/Vq2cvsOAAAABUChQolxGqVeveWUlKkevWkJUskZ2ezUwEAAAA34cxP0rGVkixS02iz0wAAAADFZsfxHVq0a5EkaUbnGXKy8CtzAACA0sCqq4RMniytXCm5uUkrVki1apmdCAAAALhJP0+yfa37mFT9DnOzAAAAAMXEMAwN/XqoDBl6qsVTCg0MNTsSAABAhUGhQglYt056+WVbe/ZsqXVrc/MAAAAANy0rSTqy3NZu+pK5WQAAAIBi9PHuj7Xl1y2q4lpFrz/wutlxAAAAKhQKFYrZkSPSE0/YLv3Qr5/09NNmJwIAAAD+hF9el2RIAQ9LNVqanQYAAAAoFtm52Xpx7YuSpJfufUkB1QNMTgQAAFCxUKhQjHJypL//XTp9WrrrLmnWLLMTAQAAAH/CuUPSwQ9t7aZjTI0CAAAAFKfXN72uY2ePqb5XfUWFRpkdBwAAoMKhUKEYDR8ubd8u1aghrVghVapkdiIAAADgT9jzhmRcknzDpdohZqcBAAAAisXBMwc1ZfMUSdLUTlPl4eJhciIAAICKh0KFYrJ4sRQXJ1ks0kcfSfXrm50IAAAA+BPOH5f2L7S1OZsCAAAAHMgLa19QTn6O7q9/v7o26mp2HAAAgAqJQoVisGuX9OyztnZMjNSli6lxAAAAgD9v71TJmiPVCZO825udBgAAACgWGw5u0Kd7PpWTxUkzOs+QxWIxOxIAAECFRKHCn3TmjNStm3TxovTgg9LYsWYnAgAAAP6ki6elfXG2dtMxttOGAQAAAOXcJeslDYsfJkka1HqQmnk3MzkRAABAxUWhwp9gtUr/93/SwYNSUJD0wQeSE88oAAAAyruk6VL+eanGXZJfZ7PTAAAA4Bpmz56toKAgeXh4KCQkRNu2bbtm/4yMDEVGRsrPz0/u7u5q2LChVq9eXaQxL168qMjISNWqVUtVq1ZV9+7dlZaWVuxzK27zE+frPyf/oxoeNTShwwSz4wAAAFRo/Fn9T3jtNWnVKsnDQ/rsM6lmTbMTAQAAAH9SboaU/Lat3YyzKQAAAJRly5YtU1RUlGJiYrRz5061bNlSEREROnnyZKH9c3Nz1bFjRx06dEgrVqxQUlKS5s+fr4CAgCKNOWLECP3zn//UJ598oo0bN+r48ePq1q1bic/3z0i/kK6xG2ynw534l4mqVbmWyYkAAAAqNgoVblJ8vBQTY2u/8450553m5gEAAMC1FfcnzWJjY9WmTRtVq1ZN3t7e6tq1q5KSkgqM0aFDB1kslgK3Z599tkTmV2ySZ0t5WZJnE+mWrmanAQAAwDVMmzZNAwYMUN++fdWkSRPFxcWpcuXKWrhwYaH9Fy5cqPT0dH3xxRcKCwtTUFCQ2rdvr5YtW97wmJmZmVqwYIGmTZum+++/X8HBwVq0aJE2b96srVu3lsq8b8b4b8frtwu/qZl3Mz3T+hmz4wAAAFR4FCrcBKtVio6WDEMaOFDq29fsRAAAALiWkvik2caNGxUZGamtW7dq7dq1ysvLU6dOnZSdnV1grAEDBujEiRP22xtvvFGic/1TrHn/O5tCk5ckC/9dAAAAKKtyc3OVmJio8PBw+zYnJyeFh4dry5Ythe6zcuVKhYaGKjIyUj4+PmrWrJkmTZqk/Pz8Gx4zMTFReXl5Bfo0atRIdevWvepxc3JylJWVVeBWmtLOpWlu4lxJ0vSI6XJxcinV4wMAAOBKrMhugpOT9M03tks/vP662WkAAABwPZd/KkyS4uLitGrVKi1cuFCjR4++ov/vnzTbvHmzXF1dJUlBQUEF+sTHxxe4/95778nb21uJiYm677777NsrV64sX1/fYp5RCXFylTpuklLmS/V6mJ0GAAAA13D69Gnl5+fLx8enwHYfHx/t3bu30H0OHDig9evXq2fPnlq9erVSUlL03HPPKS8vTzExMTc0Zmpqqtzc3OTl5XVFn9TU1EKPGxsbqwkTJtzkTP88n6o+2vb0Nn2Z9KUeuPUB03IAAADgf/iI1E2qU0eaPl3y8DA7CQAAAK6lJD5pVpjMzExJUs2aNQts/+ijj1S7dm01a9ZM0dHROn/+fDHMqgRVu026c7LEp8wAAAAcjtVqlbe3t+bNm6fg4GD16NFDY8aMUVxcXIkeNzo6WpmZmfbb0aNHS/R4hWnp21Lj2o8r9eMCAACgcPz2EQAAAA6tJD5p9kdWq1XDhw9XWFiYmjVrZt/+5JNPql69evL399dPP/2kUaNGKSkpSZ999lmhx83JyVFOTo79fmmfEhcAAADlR+3ateXs7Ky0tLQC29PS0q56Ri8/Pz+5urrK2dnZvq1x48ZKTU1Vbm7uDY3p6+ur3NxcZWRkFDirwrWO6+7uLnd395uZJgAAABwUZ1QAAAAA/qConzSLjIzU7t27tXTp0gLbBw4cqIiICDVv3lw9e/bU+++/r88//1z79+8vdJzY2Fh5enrab4GBgcU+NwAAADgGNzc3BQcHKyEhwb7NarUqISFBoaGhhe4TFhamlJQUWa1W+7bk5GT5+fnJzc3thsYMDg6Wq6trgT5JSUk6cuTIVY8LAAAA/BGFCgAAAHBoN/tJs4YNG171k2aXGzx4sL766itt2LBBt9xyyzWzhISESJJSUlIKfbwsnBIXAAAA5UdUVJTmz5+vxYsXa8+ePRo0aJCys7PVt29fSVKvXr0UHR1t7z9o0CClp6dr2LBhSk5O1qpVqzRp0iRFRkbe8Jienp7q37+/oqKitGHDBiUmJqpv374KDQ3V3XffXbpPAAAAAMotLv0AAAAAh3b5p8K6du0q6X+fChs8eHCh+4SFhWnJkiWyWq1ycrLV9l7+STNJMgxDQ4YM0eeff65vv/1W9evXv26WXbt2SbIVQhSGU+ICAACgKHr06KFTp05p3LhxSk1NVatWrRQfH2+/7NmRI0fs61lJCgwM1Jo1azRixAi1aNFCAQEBGjZsmEaNGnXDY0rSW2+9JScnJ3Xv3l05OTmKiIjQO++8U3oTBwAAQLlnMQzDMDtEccjKypKnp6cyMzNVvXp1s+MAAACgGBTXGm/ZsmXq3bu35s6dq7Zt22r69Olavny59u7dKx8fH/Xq1UsBAQGKjY2VJB09elRNmzZV7969NWTIEO3bt0/9+vXT0KFDNWbMGEnSc889pyVLlujLL7/UHXfcYT+Wp6enKlWqpP3792vJkiV68MEHVatWLf30008aMWKEbrnlFm3cuLFU5w8AAICypaKv8yr6/AEAABxVUdZ5nFEBAAAADq8kPmk2Z84cSVKHDh0KHGvRokXq06eP3NzctG7dOk2fPl3Z2dkKDAxU9+7d9fLLL5f8hAEAAAAAAACgDOOMCgAAACizKvoar6LPHwAAwFFV9HVeRZ8/AACAoyrKOs/pmo8CAAAAAAAAAAAAAAAUIwoVAAAAAAAAAAAAAABAqaFQAQAAAAAAAAAAAAAAlBoKFQAAAAAAAAAAAAAAQKmhUAEAAAAAAAAAAAAAAJQaChUAAAAAAAAAAAAAAECpoVABAAAAAAAAAAAAAACUGgoVAAAAAAAAAAAAAABAqXExO0BxMQxDkpSVlWVyEgAAABSX39d2v6/1KhrWuAAAAI6JdS7rXAAAAEdUlHWuwxQqnD17VpIUGBhochIAAAAUt7Nnz8rT09PsGKWONS4AAIBjY53LOhcAAMAR3cg612I4SNmu1WrV8ePHVa1aNVkslhI/XlZWlgIDA3X06FFVr169xI9nFkeaZ3meS3nKXhazlqVMZmUpzeMW17FKMnNJjF3cY97MeGUhQ3nLVlZzldVsZnwPMwxDZ8+elb+/v5ycKt5Vy0p7jSuVrZ+bJcmR5lme51JespfVnGUpF+vc0h+ntMYuC2uSspChvGWrCHMszvFY55Y+1rklx5HmWZ7nUl6yl9WcZSkX69zSH6e0xi4La5KykKE8ZSuLmcr6eGV9neswZ1RwcnLSLbfcUurHrV69uuk/KEuDI82zPM+lPGUvi1nLUiazspTmcYvrWCWZuSTGLu4xb2a8spChNMYqzvHKaq7iHqu4xivt72EV8RNmvzNrjSuVrZ+bJcmR5lme51JespfVnGUpF+vc0h+ntMYuC2uSspChNMYqzvEqwhyLczzWuaWHdW7Jc6R5lue5lJfsZTVnWcrFOrf0xymtscvCmqQsZCiNsYprvLKYqayPV1bXuRWvXBcAAAAAAAAAAAAAAJiGQgUAAAAAAAAAAAAAAFBqKFS4Se7u7oqJiZG7u7vZUUqUI82zPM+lPGUvi1nLUiazspTmcYvrWCWZuSTGLu4xb2a8spChNMYqzvHKaq7iHqu4xitL309RcirKv7MjzbM8z6W8ZC+rOctSLta5pT9OaY1dFtYkZSFDaYxVnONVhDkW53hl6fspSk5F+Xd2pHmW57mUl+xlNWdZysU6t/THKa2xy8KapCxkKI2ximu8spiprI9Xlr6fFsZiGIZhdggAAAAAAAAAAAAAAFAxcEYFAAAAAAAAAAAAAABQaihUAAAAAAAAAAAAAAAApYZCBQAAAAAAAAAAAAAAUGooVLiK8ePHy2KxFLg1atTomvt88sknatSokTw8PNS8eXOtXr26lNLemO+++04PP/yw/P39ZbFY9MUXX9gfy8vL06hRo9S8eXNVqVJF/v7+6tWrl44fP37NMW/meSou15qPJKWlpalPnz7y9/dX5cqV1blzZ+3bt++aY86fP1/33nuvatSooRo1aig8PFzbtm0r1tyxsbFq06aNqlWrJm9vb3Xt2lVJSUkF+nTo0OGK5/XZZ5+95rjjx49Xo0aNVKVKFXv2H3744aZzzpkzRy1atFD16tVVvXp1hYaG6uuvv7Y/fvHiRUVGRqpWrVqqWrWqunfvrrS0tGuOee7cOQ0ePFi33HKLKlWqpCZNmiguLq5Yc93Mc/fH/r/fpkyZcsO5Xn/9dVksFg0fPty+rajP0c2+Dws79u8Mw1CXLl0KfY/czLH/eKxDhw5d9fn75JNP7PsV9r2isFuVKlVu+PVkGIbGjRunqlWrXvP70DPPPKMGDRqoUqVKqlOnjh599FHt3bv3mmPHxMRcMeatt95qf7wor7PrzX3cuHH6v//7P/n6+qpKlSq666679Omnn+rYsWN66qmnVKtWLVWqVEnNmzfXjh07JNneB82bN5e7u7ucnJzk5OSkO++885rf434fr0qVKvZ9mjZtqm3btt3Ua+/38WrUqCEXFxe5uLjI3d3dnrNPnz5XzLVz587XHK9Tp05yc3Oz93/zzTftj1/vfRoUFHRDrzGLxSJXV9frvsauNl7Pnj2Vnp6uIUOG6I477lClSpVUt25dDR06VJmZmUUez9vbW0eOHCny966rjRcZGXnD78v8/HyNHTtW9evXV6VKla66T3h4uPz8/FSpUiWFh4df92epJM2ePVtBQUHy8PBQSEhIsf8sxc1zxDWu5Fjr3PK6xpVY57LOZZ1b1te5hWWtUqWK/XtIUV9j15r7lClTlJqaWu7WuZdn8/DwkJeXlzw9Pe05//rXv5bqGle68XWuh4fHDb3GinOde7WxXF1d1aZNG4WGhpb6GlcquM692j5vvPGGxo0bxzrXgbDOZZ3LOpd1LuvcK499s2tc6cbWuffcc0+RXk+sc1nnss5lnXsFA4WKiYkxmjZtapw4ccJ+O3Xq1FX7f//994azs7PxxhtvGL/88ovx8ssvG66ursZ//vOfUkx9batXrzbGjBljfPbZZ4Yk4/PPP7c/lpGRYYSHhxvLli0z9u7da2zZssVo27atERwcfM0xi/o8FadrzcdqtRp33323ce+99xrbtm0z9u7dawwcONCoW7euce7cuauO+eSTTxqzZ882/v3vfxt79uwx+vTpY3h6ehq//vprseWOiIgwFi1aZOzevdvYtWuX8eCDD16Rq3379saAAQMKPK+ZmZnXHPejjz4y1q5da+zfv9/YvXu30b9/f6N69erGyZMnbyrnypUrjVWrVhnJyclGUlKS8dJLLxmurq7G7t27DcMwjGeffdYIDAw0EhISjB07dhh33323cc8991xzzAEDBhgNGjQwNmzYYBw8eNCYO3eu4ezsbHz55ZfFlutmnrvL+544ccJYuHChYbFYjP37999Qpm3bthlBQUFGixYtjGHDhtm3F/U5upn34dWO/btp06YZXbp0ueI9cjPHLuxYly5duuL5mzBhglG1alXj7Nmz9n3/+L3ixx9/NHbv3m2/36FDB0OS8cEHH9zw6+n11183PD09jR49ehgNGjQwOnXqZAQGBhoHDx4s8H1o7ty5xsaNG42DBw8aiYmJxsMPP2wEBgYaly5duurYDzzwgOHk5GQsWrTISEhIMDp16mTUrVvXuHDhgmEYRXud/T73H3/80X7bvXu3/XXWrl07o02bNsYPP/xg7N+/35g4caJhsVgMPz8/o0+fPsYPP/xgHDhwwFizZo2RkpJiGIbtfdCnTx+jWrVqxuzZs42nn37asFgsxi233GLPeLn09HSjXr16Rvv27Q0XFxdj8uTJxrx584wePXoYXl5exr59+4r02vt9vCeeeMLw9fU1unfvbsyYMcPYsGGDPWfv3r2Nzp07F3iO0tPTrzleeHi40adPH2POnDmGJOOdd96x97ne+/TkyZMFHl+7dq0hyfj000+NEydOGL169TLq1KljSDLi4uKu+xo7efKkMWbMGKNatWrGokWLjLlz5xqSDF9fX2PHjh1Gt27djJUrVxopKSlGQkKCcfvttxvdu3e/5nhbtmwxvLy8jEGDBtnn+OqrrxppaWlF/t518uRJY+bMmcbzzz9vvPnmm4YkQ5KxYcOGG35fvvbaa0atWrWMr776yjh48KAxf/58o0qVKsbEiRPtz7Eko1q1asYXX3xh/Pjjj8Yjjzxi1K9fv9DX2e+WLl1quLm5GQsXLjR+/vlnY8CAAYaXl5eRlpZ21X1QehxxjWsYjrXOLa9rXMNgncs6l3VuWV/nxsTEGD4+Pvb1TUJCghEREWH/2V7U11hMTIxxxx13FFjnzpgxw/4a69ixY7la5/4+Vp8+fYy1a9ca/v7+RseOHY1PP/3UnrNbt26lusY1jCvXuZ988kmBde5f//pXQ5IxderUG3qNFec69/dsv69zH3vsMUOS8eGHHxpffvmlcc8995T6GtcwCq5zt23bVmCd+/tz/OKLLxqenp6scx0I61zWuaxzWeeyzi147D+zxjWMgt8rLv+d5uW/M/Lz8yvS64l1Lutc1rmsc/+IQoWriImJMVq2bHnD/f/xj38YDz30UIFtISEhxjPPPFPMyYrH9X7IGYbtB5kk4/Dhw1ftU9TnqaT8cT5JSUmGJPtixzAMIz8/36hTp44xf/78Gx730qVLRrVq1YzFixcXZ9wCTp48aUgyNm7caN/Wvn37QhcpRZGZmWlIMtatW/cnE/5PjRo1jHfffdfIyMgwXF1djU8++cT+2J49ewxJxpYtW666f9OmTY1XXnmlwLa77rrLGDNmTLHkMoziee4effRR4/7777+hvmfPnjVuv/12Y+3atQWOfbPP0R9d6314tWP/7t///rcREBBgnDhx4obe89c69vWOdblWrVoZ/fr1K7DtWt8rMjIyDIvFYjRr1sy+7XrPldVqNXx9fY0pU6bYx87IyDDc3d2Njz/++Jrz+vHHHw1J9kViYWNXqVLF8PPzK5Dx8rGL8jq72tx/f51VqVLFeP/99ws85uHhYdx2221XHfPy+f/Oy8vLcHFxKXT+o0aNMtq1a2e0bdvWiIyMtG/Pz883/P39jdjY2Cv2udZr7/fxfv9amN69exuPPvroVedQ2HiXu95r9nrv02HDhhkNGjQwrFar/f344IMP2rcV5TX2+3j169c33NzcCn2Oly9fbri5uRl5eXlXzdSjRw/jqaeeuiKfYfy5710HDx40JBmBgYH28f6osPflQw89dMW2bt26GT179jQMwzAeeeQRw83NrcDr7EbeZ0V5naH0Ofoa1zAca51bnte4hsE6l3XutbHOLf117rhx4wwXF5er/mwv6mussLlf/horb+vcy9ekV1vnmr3GNYwr17lOTk6Gj4+PfR1o5jq3LKxxDePa69xHH33U+Mtf/nLF64x1bvnHOteGdS7r3D9inXulirDO/eWXX/7UGtcwrv294sEHHzQsFkuRnivWuaxzWefasM4tiEs/XMO+ffvk7++vW2+9VT179tSRI0eu2nfLli0KDw8vsC0iIkJbtmwp6ZglJjMzUxaLRV5eXtfsV5TnqbTk5ORIkjw8POzbnJyc5O7urk2bNt3wOOfPn1deXp5q1qxZ7Bl/9/upZf54jI8++ki1a9dWs2bNFB0drfPnz9/wmLm5uZo3b548PT3VsmXLP50xPz9fS5cuVXZ2tkJDQ5WYmKi8vLwCr/lGjRqpbt2613zN33PPPVq5cqWOHTsmwzC0YcMGJScnq1OnTsWS63d/5rlLS0vTqlWr1L9//xvqHxkZqYceeuiK9//NPkd/dK334dWOLdleu08++aRmz54tX1/fGz7e1Y59rWNdLjExUbt27Sr0+bva94p169bJMAwNHTrU3vd6z9XBgweVmppqz7Nv3z41btxYFotF48ePv+r3oezsbC1atEj169dXYGDgVcfOzs7WmTNn7Hmfe+45tWzZskCeorzO/jj3xMRE++vsnnvu0bJly5Seni6r1aqlS5cqJydH7dq102OPPSZvb2/deeedmj9/fqHz//19cP78ebVq1arQ52zlypW68847tW3bNn3wwQf28ZycnBQeHl7oPtd67a1cuVKtW7fWO++8o8TERNWoUUPVqlW7Iue3334rb29v3XHHHRo0aJB+++23Qp+f38e7fL7Xcr33aW5urj788EP169dPFovF/n7csmWLfVtRXmO/j/f000/r7rvvvurzVb16dbm4uBQ6ntVq1apVq9SwYUN17NhRM2fOVE5Ojr788kt7n5v93pWbmytJevTRR2WxWK54/Grvy3vuuUcJCQlKTk6WJP3444/atGmTunTpYn+Oc3NzC7zvPT09FRISctXnLTc3V4mJiQX2udbrDOao6Gtcqfyuc8vTGldincs699pY55b+OjcjI0OXLl3S5MmT7VkzMzML/Gwv6mvs8rl3795dX331lf05Km/r3MvXpG+++aaSkpIUHBx8RU6z1rjSlevcrVu3ymq1asCAAfZ1oFnr3FtvvVXvvPOOTpw4obvvvtt+qurSXuNKV1/n3nPPPVq1apUeeeSRAu8ziXWuo2CdyzqXde7/sM69uoqwzp04ceKfXuNKhX+vSEtLU3x8vAzDKNJzxTqXdS7r3P/NVWKda1fipRDl1OrVq43ly5cbP/74oxEfH2+EhoYadevWNbKysgrt7+rqaixZsqTAttmzZxve3t6lEbfIdJ3qpgsXLhh33XWX8eSTT15znKI+TyXlj/PJzc016tatazz22GNGenq6kZOTY7z++uuGJKNTp043PO6gQYOMW2+99ZqnRPkz8vPzjYceesgICwsrsH3u3LlGfHy88dNPPxkffvihERAQYPztb3+77nj//Oc/jSpVqhgWi8Xw9/c3tm3b9qfy/fTTT0aVKlUMZ2dnw9PT01i1apVhGLbTkrm5uV3Rv02bNsaLL7541fEuXrxo9OrVy5BkuLi4GG5ubjdV4Xy1XIZx88/d7yZPnmzUqFHjhv7NP/74Y6NZs2YFLgfwexXdzT5Hl7vW+/BaxzYMwxg4cKDRv39/+/3rveevdezrHetygwYNMho3bnzF9mt9r3j88ccNSVc859d6rr7//ntDknH8+PECY997771GrVq1rvg+NHv2bKNKlSqGJOOOO+64avXt5WPPnTu3QN7KlSvbX0tFeZ0VNncvLy/Dy8vLuHDhgnHmzBmjU6dO9vdF9erVDVdXV8Pd3d2Ijo42du7cacydO9fw8PAw3nvvvQIZK1WqVOB98Nhjjxn/+Mf/t3fvYVVV+RvA33MXRAUVEISDFoKXyAuoYeMVU6xB0byk5l2xFK0ZKdHKTCe7aBfHRtOpcJxMs7yOmgoqTqEp+ICUOYAIaoZaptVRA4Xv7w+es39ny4EDiEeh9/M8PnH2Za21F2uv8+qs2Xt4mTaYTCYxmUwCQHnslbW85557Trp06aI63tF3gLU8nU4nBoNBIiMjxWQyyfjx45Vy161bJ1u3bpXMzEzZvHmztGnTRjp37mz3EW3W8myvF4DMmDHDbv2O7tNPP/1UdDqdnDt3TkRK70e9Xq/aJlL5MWZbnr0+/vHHH8VsNsvcuXPtliUiykp4V1dXGTt2rOh0OpkzZ45oNBpJTk6+rblr2bJlAkB2795td39592VxcbHMnj1bNBqN6PV60Wg0smjRIhEp7eMGDRoofWCrvHEmInLu3DkBIAcPHlRttzfO6O6o6xlXpG7l3NqacUWYc5lzK8ace3dyrvURo0lJSaq2RkdHy/Dhw6s8xm69drPZLFqtVnlcdW3LubaZ1GAwiF6vF71eL6+88opS7lNPPXXXMq5I2Zw7Y8YMAaDKuCJ3J+cajUbRarWye/duee2110Sj0cisWbOcnnFFys+51j7et28fc24dxJzLnCvCnCvCnOvIHyHnduvW7bYzrkj5c8WCBQukfv36Ve4r5lzmXObcUsy5alyoUEmXL1+Whg0bKo8julVtC7cVfckVFRVJVFSUdOzY0eG7oG7lqJ/uFHvXk5aWJu3btxcAotPppH///jJgwACJjIysVJmvvfaaeHh4yLFjx+5Ai0s99dRTEhAQIGfPnq3wuL1791b4aCMri8UiOTk5cujQIZk4caK0aNHitt4hU1hYKDk5OZKWlibx8fHStGlTOX78eLVD2+LFiyUoKEi2bdsmx44dk2XLlombm5skJibWSLvsqWzfWQUHB0tsbKzD486cOSNeXl6q8VGTwbai+9BR3Vu3bpXAwEDV+4uqEmxt6z5+/HiFddm6du2aNGrUSJYsWeKwDtu5wsfHR7RabZljKhs6bA0bNkyio6PLzENXrlyR7OxsOXDggERFRUmnTp3KDUb2yr58+bLo9XoJCwuze05Vxtnly5dFq9Uqj7qKjY2VLl26SFJSkmRkZMj8+fMFQJnHi82YMUMeeughVRtTUlJU90H//v3tBg6DwSChoaGqwGEt79bAUZnvAIPBIOHh4cp/bcuzbaet3Nzcch9faFuOFQAJCgqyW7+j+7Rfv37y5z//Wfm8du1a0Wg0qm0ilR9jtuXdGup++eUX6dKli0RGRkpRUVG5bbIGvpEjR6rKi4qKkieeeKLM8VUZU927dxcAkp6eXmZfRfflunXrxM/PT9atWyeZmZmyZs0aady4saxevVqCg4Pl8ccfr3XBlqqurmVckbqVc2trxhVhzmXOLR9z7r2Tc61tDQsLs/vdXtUxFhgYKEajUWlfbcu5tpnU+rNt2+zlXGdmXJGyOTckJOS2xlhN5txmzZqp2mYv5zoj44qUn3ObNWsmsbGxFd5nzLl1B3Nu5THnVg1zLnNuee6FnNuuXTvx9PSs8Ywr8v9zhbe3tzzyyCO3tVDBFnMuc64Ic67VHzHncqFCFYSFhUl8fLzdff7+/vLOO++ots2bN08efPBBJ7Ss6sr7kisqKpLo6Gh58MEH5aeffqpW2RX1051S0Zf2lStXlJVuXbp0kWnTpjksb/HixdKoUSNJTU2tyWaqTJ8+Xfz8/OTUqVMOj7VYLAJAdu3aVaU6AgMDlf93bE2IiIiQmJgYZdK9fPmyar/ZbJa3337b7rnXrl0Tg8Eg27dvV22fNGmS9O/fv0baZU9V+u6///2vAJCMjAyHx27evFn5i5P1DwDRaDSi0+kkKSmpyn1k5eg+dFR3bGys8rPtfq1WKz179qxS3Y7qsl1RuWbNGjEYDMr95khYWJiMHj1aAFS5r6xB6dYv8x49esjMmTMrnIcKCwvF1dW1zD9IOCrbzc1NQkND7Z5TnXE2ceJEOXnypADqdzCKlL7TrHXr1qpty5cvF19f33LbGBERIT4+PjJz5swydZrNZpkwYYLodDplrrSWN3bsWBk4cKCIVP47wGw2y6RJk5T/2pZn285bNW3aVN5///1yy7MFQBo3blzmWEf3aX5+vmi1WtmyZYuy7ZNPPhEA8vHHH5ep19EY27Fjh6o86xgTEfn1118lPDxcIiIiHK7aLywsFL1eL7NmzVKV9/zzz0u3bt3KHF/ZMWW93vLCbUX3pZ+fn7z33nuqbQsXLhSz2SwAZPv27RXeZ+Vdp+04s7IdZ3TvqUsZV6Ru5dzamHFFmHOtmHPLYs513FfOzrlhYWHi7+9v97u9OmOsbdu2Eh8fXytzrm0mtf5s27bycq4zMq5I2Zybn58vGo2m2mOsJnOuTqcTjUajyuD2cq4zMq6I/Zw7adIkpY8d3WcVXSdzbu3CnFt5zLmVw5xbijm3rHsl565Zs+aOZVwRkdatWwsAWbVqFXMuc65qG3Muc251aUGVYrFYkJubCx8fH7v7w8PDsXfvXtW2xMRE1XuW7nU3btzA8OHDkZOTg6SkJDRp0qTKZTjqp7uhUaNG8PT0RE5ODtLS0jBo0KAKj3/zzTexcOFC7Nq1C2FhYTXeHhFBbGwsNm/ejH379qFly5YOz8nIyACAKvdrSUmJ8o63mmAtLzQ0FAaDQTXms7KycObMmXLH/I0bN3Djxg1oteppR6fToaSkpEbaZU9V+u7DDz9EaGhopd4DFxERgW+++QYZGRnKn7CwMIwePVr5uap9BFTuPnRU9wsvvIDMzEzVfgB45513kJCQUKW6HdWl0+lU/Tdw4EB4eno67D/rXJGTk4MOHTpUua9atmyJZs2aqc759ddfcfjwYXTs2LHCeUhKF+mVO2bslf3DDz/AYrHggQcesHtOVcbZ+++/D51Oh/bt2yvvrbr1vnB3d8fly5dV27KzsxEQEFBuG4uKinDhwgW7ffbwww8jJycHoaGhyjnW8vbu3Yvw8PAqfQc8/PDDyMrKUv5rW55tO219//33uHTpkt0+si3Hlr2x5Og+TUhIgJeXFx577DFl27FjxwAABoNB2VbZMfbuu+8q5VnHWHh4OH799Vf069cPRqMR27ZtU71H0x6j0YjOnTtjz549qvaV11+VHVMJCQkV/q4qui+vXbtmd06+cuUKQkND8eijj5Z7n5XXb0ajUTXOgNI52jrO6N7zR8i4QN3MufdaxgWYc5lzmXOB2pVzLRYLTp48iR9++MFue6o6xjp06ICCggL4+PjUypxrm0mtP9u2zV5uc1bGBcrm3ISEBHh6elZ7jNVkzvXx8YHJZFJlcHv95YyMC9jPuenp6TCZTGjfvn2F9xlzbt3BnFt5zLmOMecy59aWnBsdHX1HMi5QOlecOnUK/v7+GD58OHMuc26Z7cy5zLnVcseXQtRSs2bNkuTkZMnLy5OUlBTp27evNG3aVFnFMmbMGNXqrpSUFNHr9bJkyRI5ceKEvPzyy2IwGOSbb765W5dQxm+//Sbp6emSnp4uAOTtt9+W9PR0OX36tBQVFcnAgQPFz89PMjIypKCgQPlTWFiolNGnTx9ZtmyZ8tlRP92t6xER2bBhg+zfv19yc3Nly5YtEhAQIEOGDFGVcevv8fXXXxej0Siff/65qg9sH7l0u55++mlp1KiRJCcnq+q4du2aiIicPHlSFixYIGlpaZKXlydbt26V++67T3r06KEqJzg4WDZt2iQipau15syZI4cOHZL8/HxJS0uTCRMmiMlkKrOyr7Li4+PlwIEDkpeXJ5mZmRIfHy8ajUb27NkjIqWPOTObzbJv3z5JS0uT8PDwMo/7sW2jSOljptq1ayf79++XU6dOSUJCgtSrV0+WL19eI+2qTt9Z/fLLL+Lq6iorVqyoaleprs/2MVpV7aPK3oeVqftWsLNSvbp126srJydHNBqNfPHFF3br9/DwkIULF6rmiiZNmoiLi4usWLGiWuPp9ddfF3d3d4mOjpaPPvpIHnnkEfHx8ZE+ffoo81Bubq4sWrRI0tLS5PTp05KSkiJRUVHSuHFj1WP0bi27e/fu4ubmJqtWrZI1a9aIp6enaLVaOXPmTJXHme08uWfPHtFqteLm5iYXL16UoqIiCQwMlO7du8vhw4fl5MmTyjvVdDqdvPrqq5KTkyNt27YVo9GoPBEgPj5epk6dKg0bNpSlS5fKxIkTlcdQ2a4Etc7ZR44cEb1eLyNGjBCj0ShTp04VFxcX6d27t7i7u8vZs2er9B1gLe/pp58WnU4nw4cPFxcXF5k2bZq4urrKBx98IHFxcXLo0CHJy8uTpKQk6dSpk7Rq1Up+//33csubN2+ebN26VRYtWiQAZPTo0ap53dF92rt3b/Hw8JDZs2crZK00jAAAE8pJREFU24qLi8VsNkuHDh2qPMYWLVokGo1GhgwZIpmZmTJo0CBp2bKlXLhwQbp27SohISFy8uRJVX/Zrky/tbzPP/9cAEhkZKTk5OTIsmXLRKfTyfr166s1d/3444/SrFkzGTp0qACQ9evXS3p6uhQUFIiI4/uyYcOG0rhxY9m+fbvk5eXJpk2bpEmTJqLX65U+tt5n1nfUWfvA3jizWr9+vZhMJlm9erV89913EhMTI+7u7nL+/Hm77SDnqosZV6Ru5dzamnFFmHOZc5lz7/WcO2vWLImJiZEGDRrI66+/Lg899JAYjUYxm81y/PjxKo8x6zyZmZkpJpNJWrdurbSvNubcuLg40ev18uqrr8rGjRtFq9WKwWCQJUuWyNq1a8XFxUUeffRRp2fcPn36yNKlS8VsNis515pxZ8+eXa0xVpM5t7i4WJo2bSparVZWrVql5FytViuTJk1yesYNDg6W3r17S/PmzZWc+/HHHwugfs89c27dw5zLnMucy5xbHX+EnFudjBscHCwDBw5UzRW9evUSAPLmm29Wq69EmHOZc9WYc5lzRfjqh3KNGDFCfHx8xGg0SvPmzWXEiBGqd4v07NlTxo0bpzpnw4YNEhQUJEajUdq1ayc7duxwcqsrtn//fuXRk7Z/xo0bJ3l5eXb3AZD9+/crZQQEBMjLL7+sfHbUT3frekREli5dKn5+fmIwGMRsNsuLL75o9x+ibH+PAQEBdsu0vebbVV4/JyQkiEjp+6p69OghjRs3FpPJJIGBgfLcc8+VebeQ7TnXr1+XwYMHi6+vrxiNRvHx8ZGBAwfKkSNHqt3OiRMnSkBAgBiNRvH09JSIiAgl1FrrnDZtmnh4eIirq6sMHjxYmVDttVFEpKCgQMaPHy++vr5Sr149CQ4OlrfeektKSkpqpF3V6TurlStXiouLi1y5cqXSbbnVraGvqn1U2fuwMnXfyl6wrW7d9uqaM2eO+Pv7S3Fxcbn1u7u7q+aKv/3tb0qfV2c8lZSUyEsvvSQmk0l5hJm3t7dqHjp37pwMGDBAvLy8xGAwiJ+fn4waNUr+97//VVj2iBEjxM3NTekDLy8v5d17VR1ntvOku7u76HQ61aOXsrOzZciQIeLl5SWurq7KY9r+85//yAMPPCAmk0n0er3qPVgTJ04Us9ksWq1WNBqNaLVa6dixo2RlZanaYDtnW8vT6/Wi1+tFp9NJly5d5Ouvv67Wd4C1PIPBoLSxdevWsmrVKrl27Zr069dPPD09xWAwSEBAgEyZMqVMsLm1vJYtW1Y4rzu6T728vASAqh92794tACQzM7PKY2zXrl0CQJo0aSImk0kiIiIkKyur3O8fAJKXl1dueda2mM1mqVevnrRv3162bNlS7blr1qxZFX5nVea+fOSRR5T23HfffTJgwACpV6+e0sfW+8zb21vVB+X9Hq2WLVsmZrNZjEajMs7o3lAXM65I3cq5tTXjijDnMucy597rOdc6r+l0OtFqtaLVaiU8PFyysrKqNcas5en1egEgQ4YMUc2TtTHn2rbNz89PfH19lX+cfu+99+5Kxg0ICJAnn3xSlXOtuTIrK6taY6wmc661La+++qoEBgYqOfef//znXcu4y5cvl2eeeUbJuU2bNhW9Xq/6H2GZc+se5lzmXOZc5tzq+CPk3Opm3C5duqjmirCwMDGZTEp/M+cy5zLnMufWBI2ICIiIiIiIiIiIiIiIiIiIiIicQOv4ECIiIiIiIiIiIiIiIiIiIqKawYUKRERERERERERERERERERE5DRcqEBEREREREREREREREREREROw4UKRERERERERERERERERERE5DRcqEBEREREREREREREREREREROw4UKRERERERERERERERERERE5DRcqEBEREREREREREREREREREROw4UKRERERERERERERERERERE5DRcqEBEVEfNnz8f3t7e0Gg02LJlS6XOSU5OhkajwZUrV+5o2+4lLVq0wLvvvnu3m0FERERElcCMWznMuERERES1C3Nu5TDnEtUtXKhARE4zfvx4aDQaaDQaGI1GBAYGYsGCBbh58+bdbppDVQmI94ITJ07glVdewcqVK1FQUIABAwbcsbp69eqFZ5999o6VT0RERHQvY8Z1HmZcIiIiIudhznUe5lwi+qPS3+0GENEfS2RkJBISElBYWIidO3di+vTpMBgMmDNnTpXLKi4uhkajgVbLNVe3ys3NBQAMGjQIGo3mLreGiIiIqG5jxnUOZlwiIiIi52LOdQ7mXCL6o+I3AhE5lclkQrNmzRAQEICnn34affv2xbZt2wAAhYWFiIuLQ/PmzVG/fn107doVycnJyrmrV6+Gu7s7tm3bhrZt28JkMuHMmTMoLCzE7Nmz4e/vD5PJhMDAQHz44YfKed9++y0GDBgANzc3eHt7Y8yYMfjpp5+U/b169cLMmTPx/PPPo3HjxmjWrBnmz5+v7G/RogUAYPDgwdBoNMrn3NxcDBo0CN7e3nBzc0Pnzp2RlJSkut6CggI89thjcHFxQcuWLfHJJ5+UeTzVlStXMHnyZHh6eqJhw4bo06cPjh07VmE/fvPNN+jTpw9cXFzQpEkTxMTEwGKxACh9TFhUVBQAQKvVVhhud+7ciaCgILi4uKB3797Iz89X7b906RJGjhyJ5s2bw9XVFSEhIVi3bp2yf/z48Thw4ACWLl2qrLDOz89HcXExJk2ahJYtW8LFxQXBwcFYunRphddk/f3a2rJli6r9x44dQ+/evdGgQQM0bNgQoaGhSEtLU/Z/9dVX6N69O1xcXODv74+ZM2fi6tWryv6LFy8iKipK+X2sXbu2wjYRERERVQYzLjNueZhxiYiIqDZjzmXOLQ9zLhHVBC5UIKK7ysXFBUVFRQCA2NhYHDp0COvXr0dmZiaGDRuGyMhI5OTkKMdfu3YNb7zxBj744AMcP34cXl5eGDt2LNatW4e///3vOHHiBFauXAk3NzcApcGxT58+6NixI9LS0rBr1y5cuHABw4cPV7XjX//6F+rXr4/Dhw/jzTffxIIFC5CYmAgASE1NBQAkJCSgoKBA+WyxWPDoo49i7969SE9PR2RkJKKionDmzBml3LFjx+KHH35AcnIyNm7ciFWrVuHixYuquocNG4aLFy/iiy++wNGjR9GpUydERETg559/tttnV69eRf/+/eHh4YHU1FR89tlnSEpKQmxsLAAgLi4OCQkJAErDdUFBgd1yzp49iyFDhiAqKgoZGRmYPHky4uPjVcf8/vvvCA0NxY4dO/Dtt98iJiYGY8aMwZEjRwAAS5cuRXh4OKZMmaLU5e/vj5KSEvj5+eGzzz7Dd999h3nz5mHu3LnYsGGD3bZU1ujRo+Hn54fU1FQcPXoU8fHxMBgMAEr/shEZGYnHH38cmZmZ+PTTT/HVV18p/QKUhvGzZ89i//79+Pzzz7F8+fIyvw8iIiKi28WMy4xbFcy4REREVFsw5zLnVgVzLhE5JERETjJu3DgZNGiQiIiUlJRIYmKimEwmiYuLk9OnT4tOp5Nz586pzomIiJA5c+aIiEhCQoIAkIyMDGV/VlaWAJDExES7dS5cuFD69eun2nb27FkBIFlZWSIi0rNnT/nTn/6kOqZz584ye/Zs5TMA2bx5s8NrbNeunSxbtkxERE6cOCEAJDU1Vdmfk5MjAOSdd94REZEvv/xSGjZsKL///ruqnPvvv19Wrlxpt45Vq1aJh4eHWCwWZduOHTtEq9XK+fPnRURk8+bN4miKnzNnjrRt21a1bfbs2QJALl++XO55jz32mMyaNUv53LNnT3nmmWcqrEtEZPr06fL444+Xuz8hIUEaNWqk2nbrdTRo0EBWr15t9/xJkyZJTEyMatuXX34pWq1Wrl+/royVI0eOKPutvyPr74OIiIioqphxmXGZcYmIiKguYs5lzmXOJaI7TX/HV0IQEdnYvn073NzccOPGDZSUlGDUqFGYP38+kpOTUVxcjKCgINXxhYWFaNKkifLZaDTiwQcfVD5nZGRAp9OhZ8+edus7duwY9u/fr6zKtZWbm6vUZ1smAPj4+DhcnWmxWDB//nzs2LEDBQUFuHnzJq5fv66sws3KyoJer0enTp2UcwIDA+Hh4aFqn8ViUV0jAFy/fl15N9mtTpw4gfbt26N+/frKtocffhglJSXIysqCt7d3he22Ladr166qbeHh4arPxcXFWLRoETZs2IBz586hqKgIhYWFcHV1dVj+P/7xD3z00Uc4c+YMrl+/jqKiInTo0KFSbSvPX//6V0yePBn//ve/0bdvXwwbNgz3338/gNK+zMzMVD0CTERQUlKCvLw8ZGdnQ6/XIzQ0VNnfunXrMo8oIyIiIqoqZlxm3NvBjEtERET3KuZc5tzbwZxLRI5woQIROVXv3r2xYsUKGI1G+Pr6Qq8vnYYsFgt0Oh2OHj0KnU6nOsc2mLq4uKjec+Xi4lJhfRaLBVFRUXjjjTfK7PPx8VF+tj5yykqj0aCkpKTCsuPi4pCYmIglS5YgMDAQLi4uGDp0qPL4s8qwWCzw8fFRvb/N6l4IXYsXL8bSpUvx7rvvIiQkBPXr18ezzz7r8BrXr1+PuLg4vPXWWwgPD0eDBg2wePFiHD58uNxztFotRES17caNG6rP8+fPx6hRo7Bjxw588cUXePnll7F+/XoMHjwYFosFU6dOxcyZM8uUbTabkZ2dXYUrJyIiIqo8Ztyy7WPGLcWMS0RERLUZc27Z9jHnlmLOJaKawIUKRORU9evXR2BgYJntHTt2RHFxMS5evIju3btXuryQkBCUlJTgwIED6Nu3b5n9nTp1wsaNG9GiRQslSFeHwWBAcXGxaltKSgrGjx+PwYMHAygNqvn5+cr+4OBg3Lx5E+np6crKz5MnT+Ly5cuq9p0/fx56vR4tWrSoVFvatGmD1atX4+rVq8pK3JSUFGi1WgQHB1f6mtq0aYNt27aptn399ddlrnHQoEF48sknAQAlJSXIzs5G27ZtlWOMRqPdvunWrRumTZumbCtvVbGVp6cnfvvtN9V1ZWRklDkuKCgIQUFB+Mtf/oKRI0ciISEBgwcPRqdOnfDdd9/ZHV9A6Yrbmzdv4ujRo+jcuTOA0pXSV65cqbBdRERERI4w4zLjlocZl4iIiGoz5lzm3PIw5xJRTdDe7QYQEQGlgWX06NEYO3YsNm3ahLy8PBw5cgSvvfYaduzYUe55LVq0wLhx4zBx4kRs2bIFeXl5SE5OxoYNGwAA06dPx88//4yRI0ciNTUVubm52L17NyZMmFAmkFWkRYsW2Lt3L86fP6+E01atWmHTpk3IyMjAsWPHMGrUKNXK3datW6Nv376IiYnBkSNHkJ6ejpiYGNVK4r59+yI8PBzR0dHYs2cP8vPzcfDgQbzwwgtIS0uz25bRo0ejXr16GDduHL799lvs378fM2bMwJgxYyr9qDAAeOqpp5CTk4PnnnsOWVlZ+OSTT7B69WrVMa1atUJiYiIOHjyIEydOYOrUqbhw4UKZvjl8+DDy8/Px008/oaSkBK1atUJaWhp2796N7OxsvPTSS0hNTa2wPV27doWrqyvmzp2L3NzcMu25fv06YmNjkZycjNOnTyMlJQWpqalo06YNAGD27Nk4ePAgYmNjkZGRgZycHGzduhWxsbEASv+yERkZialTp+Lw4cM4evQoJk+e7HAlNxEREVF1MeMy4zLjEhERUV3EnMucy5xLRDWBCxWI6J6RkJCAsWPHYtasWQgODkZ0dDRSU1NhNpsrPG/FihUYOnQopk2bhtatW2PKlCm4evUqAMDX1xcpKSkoLi5Gv379EBISgmeffRbu7u7Qais/Bb711ltITEyEv78/OnbsCAB4++234eHhgW7duiEqKgr9+/dXvcMMANasWQNvb2/06NEDgwcPxpQpU9CgQQPUq1cPQOljyXbu3IkePXpgwoQJCAoKwhNPPIHTp0+XG1RdXV2xe/du/Pzzz+jcuTOGDh2KiIgIvPfee5W+HqD0EVobN27Eli1b0L59e7z//vtYtGiR6pgXX3wRnTp1Qv/+/dGrVy80a9YM0dHRqmPi4uKg0+nQtm1beHp64syZM5g6dSqGDBmCESNGoGvXrrh06ZJqRa49jRs3xscff4ydO3ciJCQE69atw/z585X9Op0Oly5dwtixYxEUFIThw4djwIABeOWVVwCUvpvuwIEDyM7ORvfu3dGxY0fMmzcPvr6+ShkJCQnw9fVFz549MWTIEMTExMDLy6tK/UZERERUFcy4zLjMuERERFQXMecy5zLnEtHt0sitL5EhIqI75vvvv4e/vz+SkpIQERFxt5tDRERERHTbmHGJiIiIqC5iziUiurO4UIGI6A7at28fLBYLQkJCUFBQgOeffx7nzp1DdnY2DAbD3W4eEREREVGVMeMSERERUV3EnEtE5Fz6u90AIqK67MaNG5g7dy5OnTqFBg0aoFu3bli7di2DLRERERHVWsy4RERERFQXMecSETkXn6hARERERERERERERERERERETqO92w0gIiIiIiIiIiIiIiIiIiKiPw4uVCAiIiIiIiIiIiIiIiIiIiKn4UIFIiIiIiIiIiIiIiIiIiIichouVCAiIiIiIiIiIiIiIiIiIiKn4UIFIiIiIiIiIiIiIiIiIiIichouVCAiIiIiIiIiIiIiIiIiIiKn4UIFIiIiIiIiIiIiIiIiIiIichouVCAiIiIiIiIiIiIiIiIiIiKn4UIFIiIiIiIiIiIiIiIiIiIicpr/Ayt4286C+BV+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b14ab7",
   "metadata": {},
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679b4e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 02:25, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.463594</td>\n",
       "      <td>0.462379</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.030166</td>\n",
       "      <td>0.058522</td>\n",
       "      <td>0.049751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.391793</td>\n",
       "      <td>0.568489</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>0.278281</td>\n",
       "      <td>0.416949</td>\n",
       "      <td>0.340929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.357158</td>\n",
       "      <td>0.562701</td>\n",
       "      <td>0.873684</td>\n",
       "      <td>0.250377</td>\n",
       "      <td>0.389215</td>\n",
       "      <td>0.305181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.331397</td>\n",
       "      <td>0.590354</td>\n",
       "      <td>0.783858</td>\n",
       "      <td>0.432127</td>\n",
       "      <td>0.557122</td>\n",
       "      <td>0.487882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.317543</td>\n",
       "      <td>0.603215</td>\n",
       "      <td>0.790637</td>\n",
       "      <td>0.458522</td>\n",
       "      <td>0.580430</td>\n",
       "      <td>0.516101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.307228</td>\n",
       "      <td>0.619293</td>\n",
       "      <td>0.780571</td>\n",
       "      <td>0.515083</td>\n",
       "      <td>0.620627</td>\n",
       "      <td>0.590389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.304412</td>\n",
       "      <td>0.622508</td>\n",
       "      <td>0.775442</td>\n",
       "      <td>0.528658</td>\n",
       "      <td>0.628700</td>\n",
       "      <td>0.586116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.301726</td>\n",
       "      <td>0.622508</td>\n",
       "      <td>0.763407</td>\n",
       "      <td>0.547511</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.605725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.302151</td>\n",
       "      <td>0.625723</td>\n",
       "      <td>0.764644</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.640666</td>\n",
       "      <td>0.610989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.300772</td>\n",
       "      <td>0.628939</td>\n",
       "      <td>0.751984</td>\n",
       "      <td>0.571644</td>\n",
       "      <td>0.649529</td>\n",
       "      <td>0.626356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.76      0.84       362\n",
      "                sara       0.70      0.31      0.43       237\n",
      "         radikalisme       0.65      0.62      0.63       235\n",
      "pencemaran_nama_baik       0.68      0.53      0.60       492\n",
      "\n",
      "           micro avg       0.75      0.57      0.65      1326\n",
      "           macro avg       0.74      0.56      0.63      1326\n",
      "        weighted avg       0.75      0.57      0.64      1326\n",
      "         samples avg       0.35      0.33      0.33      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 388: Accuracy: 0.6289389067524116, F1 Micro: 0.6495287060839761, F1 Macro: 0.626355645176144\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.76      0.84       362\n",
      "                sara       0.70      0.31      0.43       237\n",
      "         radikalisme       0.65      0.62      0.63       235\n",
      "pencemaran_nama_baik       0.68      0.53      0.60       492\n",
      "\n",
      "           micro avg       0.75      0.57      0.65      1326\n",
      "           macro avg       0.74      0.56      0.63      1326\n",
      "        weighted avg       0.75      0.57      0.64      1326\n",
      "         samples avg       0.35      0.33      0.33      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 25.512775421142578\n",
      "Samples above threshold: 585\n",
      "Acquired samples: 585\n",
      "Sampling duration: 20.793189764022827 seconds\n",
      "New train size: 973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [610/610 03:17, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.388779</td>\n",
       "      <td>0.564630</td>\n",
       "      <td>0.895899</td>\n",
       "      <td>0.214178</td>\n",
       "      <td>0.345709</td>\n",
       "      <td>0.221962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.344510</td>\n",
       "      <td>0.567846</td>\n",
       "      <td>0.871287</td>\n",
       "      <td>0.265460</td>\n",
       "      <td>0.406936</td>\n",
       "      <td>0.331081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.319508</td>\n",
       "      <td>0.601929</td>\n",
       "      <td>0.826299</td>\n",
       "      <td>0.383861</td>\n",
       "      <td>0.524202</td>\n",
       "      <td>0.457319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.296758</td>\n",
       "      <td>0.627653</td>\n",
       "      <td>0.758376</td>\n",
       "      <td>0.563348</td>\n",
       "      <td>0.646473</td>\n",
       "      <td>0.621173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.302068</td>\n",
       "      <td>0.645659</td>\n",
       "      <td>0.731538</td>\n",
       "      <td>0.634992</td>\n",
       "      <td>0.679855</td>\n",
       "      <td>0.663978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.306392</td>\n",
       "      <td>0.648875</td>\n",
       "      <td>0.751371</td>\n",
       "      <td>0.619910</td>\n",
       "      <td>0.679339</td>\n",
       "      <td>0.662715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.320356</td>\n",
       "      <td>0.642444</td>\n",
       "      <td>0.752153</td>\n",
       "      <td>0.592760</td>\n",
       "      <td>0.663011</td>\n",
       "      <td>0.642337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.328121</td>\n",
       "      <td>0.639228</td>\n",
       "      <td>0.723116</td>\n",
       "      <td>0.644042</td>\n",
       "      <td>0.681292</td>\n",
       "      <td>0.657464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>0.329802</td>\n",
       "      <td>0.645659</td>\n",
       "      <td>0.745170</td>\n",
       "      <td>0.610860</td>\n",
       "      <td>0.671363</td>\n",
       "      <td>0.651048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>0.332005</td>\n",
       "      <td>0.644373</td>\n",
       "      <td>0.734222</td>\n",
       "      <td>0.622926</td>\n",
       "      <td>0.674011</td>\n",
       "      <td>0.655909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.87      0.86      0.86       362\n",
      "                sara       0.66      0.42      0.51       237\n",
      "         radikalisme       0.63      0.58      0.60       235\n",
      "pencemaran_nama_baik       0.67      0.63      0.65       492\n",
      "\n",
      "           micro avg       0.72      0.64      0.68      1326\n",
      "           macro avg       0.71      0.62      0.66      1326\n",
      "        weighted avg       0.72      0.64      0.68      1326\n",
      "         samples avg       0.37      0.37      0.36      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 973: Accuracy: 0.6392282958199357, F1 Micro: 0.6812923813322697, F1 Macro: 0.6574642749954621\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.87      0.86      0.86       362\n",
      "                sara       0.66      0.42      0.51       237\n",
      "         radikalisme       0.63      0.58      0.60       235\n",
      "pencemaran_nama_baik       0.67      0.63      0.65       492\n",
      "\n",
      "           micro avg       0.72      0.64      0.68      1326\n",
      "           macro avg       0.71      0.62      0.66      1326\n",
      "        weighted avg       0.72      0.64      0.68      1326\n",
      "         samples avg       0.37      0.37      0.36      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 25.25302543640137\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 18.626831769943237 seconds\n",
      "New train size: 1498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [940/940 04:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.362726</td>\n",
       "      <td>0.576849</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.238311</td>\n",
       "      <td>0.376639</td>\n",
       "      <td>0.261267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.335524</td>\n",
       "      <td>0.603215</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.366516</td>\n",
       "      <td>0.508368</td>\n",
       "      <td>0.426669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.283112</td>\n",
       "      <td>0.639871</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.664962</td>\n",
       "      <td>0.618940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.285563</td>\n",
       "      <td>0.646945</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.629713</td>\n",
       "      <td>0.686960</td>\n",
       "      <td>0.662698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.300488</td>\n",
       "      <td>0.655305</td>\n",
       "      <td>0.747639</td>\n",
       "      <td>0.656863</td>\n",
       "      <td>0.699318</td>\n",
       "      <td>0.683741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.120600</td>\n",
       "      <td>0.305611</td>\n",
       "      <td>0.654019</td>\n",
       "      <td>0.748918</td>\n",
       "      <td>0.652338</td>\n",
       "      <td>0.697299</td>\n",
       "      <td>0.676664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.120600</td>\n",
       "      <td>0.315713</td>\n",
       "      <td>0.658521</td>\n",
       "      <td>0.747648</td>\n",
       "      <td>0.659125</td>\n",
       "      <td>0.700601</td>\n",
       "      <td>0.682864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.120600</td>\n",
       "      <td>0.333790</td>\n",
       "      <td>0.652733</td>\n",
       "      <td>0.769157</td>\n",
       "      <td>0.605581</td>\n",
       "      <td>0.677637</td>\n",
       "      <td>0.654712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.120600</td>\n",
       "      <td>0.330898</td>\n",
       "      <td>0.661093</td>\n",
       "      <td>0.726144</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.715870</td>\n",
       "      <td>0.700477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.120600</td>\n",
       "      <td>0.333088</td>\n",
       "      <td>0.659807</td>\n",
       "      <td>0.743073</td>\n",
       "      <td>0.667421</td>\n",
       "      <td>0.703218</td>\n",
       "      <td>0.684727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.87      0.88       362\n",
      "                sara       0.63      0.48      0.54       237\n",
      "         radikalisme       0.66      0.75      0.70       235\n",
      "pencemaran_nama_baik       0.68      0.67      0.68       492\n",
      "\n",
      "           micro avg       0.73      0.71      0.72      1326\n",
      "           macro avg       0.71      0.69      0.70      1326\n",
      "        weighted avg       0.72      0.71      0.71      1326\n",
      "         samples avg       0.40      0.41      0.40      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1498: Accuracy: 0.6610932475884245, F1 Micro: 0.715869980879541, F1 Macro: 0.7004769647273817\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.87      0.88       362\n",
      "                sara       0.63      0.48      0.54       237\n",
      "         radikalisme       0.66      0.75      0.70       235\n",
      "pencemaran_nama_baik       0.68      0.67      0.68       492\n",
      "\n",
      "           micro avg       0.73      0.71      0.72      1326\n",
      "           macro avg       0.71      0.69      0.70      1326\n",
      "        weighted avg       0.72      0.71      0.71      1326\n",
      "         samples avg       0.40      0.41      0.40      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 22.914454650878906\n",
      "Samples above threshold: 472\n",
      "Acquired samples: 472\n",
      "Sampling duration: 16.71440029144287 seconds\n",
      "New train size: 1970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1240' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1240/1240 05:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.377822</td>\n",
       "      <td>0.576849</td>\n",
       "      <td>0.821862</td>\n",
       "      <td>0.306184</td>\n",
       "      <td>0.446154</td>\n",
       "      <td>0.345550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.290131</td>\n",
       "      <td>0.618006</td>\n",
       "      <td>0.727029</td>\n",
       "      <td>0.614630</td>\n",
       "      <td>0.666122</td>\n",
       "      <td>0.612964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.287063</td>\n",
       "      <td>0.654662</td>\n",
       "      <td>0.701805</td>\n",
       "      <td>0.733032</td>\n",
       "      <td>0.717079</td>\n",
       "      <td>0.709022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.302687</td>\n",
       "      <td>0.650804</td>\n",
       "      <td>0.708955</td>\n",
       "      <td>0.716440</td>\n",
       "      <td>0.712678</td>\n",
       "      <td>0.687932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.139600</td>\n",
       "      <td>0.301644</td>\n",
       "      <td>0.669453</td>\n",
       "      <td>0.766245</td>\n",
       "      <td>0.640271</td>\n",
       "      <td>0.697617</td>\n",
       "      <td>0.664641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.139600</td>\n",
       "      <td>0.308103</td>\n",
       "      <td>0.659807</td>\n",
       "      <td>0.749150</td>\n",
       "      <td>0.664404</td>\n",
       "      <td>0.704237</td>\n",
       "      <td>0.676321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.139600</td>\n",
       "      <td>0.335992</td>\n",
       "      <td>0.649518</td>\n",
       "      <td>0.690102</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.724472</td>\n",
       "      <td>0.710205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.139600</td>\n",
       "      <td>0.326613</td>\n",
       "      <td>0.662379</td>\n",
       "      <td>0.732689</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.708723</td>\n",
       "      <td>0.689565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.340972</td>\n",
       "      <td>0.659807</td>\n",
       "      <td>0.721273</td>\n",
       "      <td>0.700603</td>\n",
       "      <td>0.710788</td>\n",
       "      <td>0.691349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.340274</td>\n",
       "      <td>0.664309</td>\n",
       "      <td>0.730284</td>\n",
       "      <td>0.698341</td>\n",
       "      <td>0.713955</td>\n",
       "      <td>0.694962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.88      0.88       362\n",
      "                sara       0.58      0.51      0.54       237\n",
      "         radikalisme       0.66      0.79      0.72       235\n",
      "pencemaran_nama_baik       0.63      0.78      0.70       492\n",
      "\n",
      "           micro avg       0.69      0.76      0.72      1326\n",
      "           macro avg       0.69      0.74      0.71      1326\n",
      "        weighted avg       0.69      0.76      0.72      1326\n",
      "         samples avg       0.43      0.44      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1970: Accuracy: 0.6495176848874598, F1 Micro: 0.7244715155858115, F1 Macro: 0.7102050395970949\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.88      0.88       362\n",
      "                sara       0.58      0.51      0.54       237\n",
      "         radikalisme       0.66      0.79      0.72       235\n",
      "pencemaran_nama_baik       0.63      0.78      0.70       492\n",
      "\n",
      "           micro avg       0.69      0.76      0.72      1326\n",
      "           macro avg       0.69      0.74      0.71      1326\n",
      "        weighted avg       0.69      0.76      0.72      1326\n",
      "         samples avg       0.43      0.44      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 21.80454387664795\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 425\n",
      "Sampling duration: 15.065368175506592 seconds\n",
      "New train size: 2395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:38, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.365829</td>\n",
       "      <td>0.583923</td>\n",
       "      <td>0.808028</td>\n",
       "      <td>0.349170</td>\n",
       "      <td>0.487625</td>\n",
       "      <td>0.383283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.278954</td>\n",
       "      <td>0.627010</td>\n",
       "      <td>0.739895</td>\n",
       "      <td>0.634992</td>\n",
       "      <td>0.683442</td>\n",
       "      <td>0.602613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.274187</td>\n",
       "      <td>0.668810</td>\n",
       "      <td>0.786807</td>\n",
       "      <td>0.620664</td>\n",
       "      <td>0.693929</td>\n",
       "      <td>0.659713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.301191</td>\n",
       "      <td>0.644373</td>\n",
       "      <td>0.676697</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.731994</td>\n",
       "      <td>0.728401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.319909</td>\n",
       "      <td>0.663023</td>\n",
       "      <td>0.784474</td>\n",
       "      <td>0.579186</td>\n",
       "      <td>0.666377</td>\n",
       "      <td>0.626999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.305382</td>\n",
       "      <td>0.662379</td>\n",
       "      <td>0.755864</td>\n",
       "      <td>0.656109</td>\n",
       "      <td>0.702463</td>\n",
       "      <td>0.676704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.317960</td>\n",
       "      <td>0.664309</td>\n",
       "      <td>0.739558</td>\n",
       "      <td>0.680995</td>\n",
       "      <td>0.709069</td>\n",
       "      <td>0.690728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.337328</td>\n",
       "      <td>0.671383</td>\n",
       "      <td>0.778828</td>\n",
       "      <td>0.621418</td>\n",
       "      <td>0.691275</td>\n",
       "      <td>0.663700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.331638</td>\n",
       "      <td>0.665595</td>\n",
       "      <td>0.730109</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.717791</td>\n",
       "      <td>0.698453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.334718</td>\n",
       "      <td>0.664309</td>\n",
       "      <td>0.722556</td>\n",
       "      <td>0.724736</td>\n",
       "      <td>0.723645</td>\n",
       "      <td>0.707394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.83      0.89       362\n",
      "                sara       0.54      0.69      0.61       237\n",
      "         radikalisme       0.65      0.78      0.71       235\n",
      "pencemaran_nama_baik       0.62      0.83      0.71       492\n",
      "\n",
      "           micro avg       0.68      0.80      0.73      1326\n",
      "           macro avg       0.69      0.78      0.73      1326\n",
      "        weighted avg       0.70      0.80      0.74      1326\n",
      "         samples avg       0.43      0.46      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2395: Accuracy: 0.6443729903536978, F1 Micro: 0.7319944598337951, F1 Macro: 0.7284010342823397\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.83      0.89       362\n",
      "                sara       0.54      0.69      0.61       237\n",
      "         radikalisme       0.65      0.78      0.71       235\n",
      "pencemaran_nama_baik       0.62      0.83      0.71       492\n",
      "\n",
      "           micro avg       0.68      0.80      0.73      1326\n",
      "           macro avg       0.69      0.78      0.73      1326\n",
      "        weighted avg       0.70      0.80      0.74      1326\n",
      "         samples avg       0.43      0.46      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 21.496841430664066\n",
      "Samples above threshold: 383\n",
      "Acquired samples: 383\n",
      "Sampling duration: 13.6622474193573 seconds\n",
      "New train size: 2778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1740' max='1740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1740/1740 06:21, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.355110</td>\n",
       "      <td>0.586495</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.316742</td>\n",
       "      <td>0.460526</td>\n",
       "      <td>0.364505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.310649</td>\n",
       "      <td>0.645659</td>\n",
       "      <td>0.891167</td>\n",
       "      <td>0.426094</td>\n",
       "      <td>0.576531</td>\n",
       "      <td>0.492427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>0.272241</td>\n",
       "      <td>0.666881</td>\n",
       "      <td>0.797776</td>\n",
       "      <td>0.595023</td>\n",
       "      <td>0.681641</td>\n",
       "      <td>0.641719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>0.277944</td>\n",
       "      <td>0.677170</td>\n",
       "      <td>0.792836</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.694362</td>\n",
       "      <td>0.657189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>0.288116</td>\n",
       "      <td>0.668810</td>\n",
       "      <td>0.726048</td>\n",
       "      <td>0.731523</td>\n",
       "      <td>0.728775</td>\n",
       "      <td>0.715847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.300829</td>\n",
       "      <td>0.670096</td>\n",
       "      <td>0.749369</td>\n",
       "      <td>0.671946</td>\n",
       "      <td>0.708549</td>\n",
       "      <td>0.674832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.322077</td>\n",
       "      <td>0.665595</td>\n",
       "      <td>0.699863</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.732566</td>\n",
       "      <td>0.722176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.327700</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.731615</td>\n",
       "      <td>0.727753</td>\n",
       "      <td>0.729679</td>\n",
       "      <td>0.712537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.335491</td>\n",
       "      <td>0.664952</td>\n",
       "      <td>0.720654</td>\n",
       "      <td>0.731523</td>\n",
       "      <td>0.726048</td>\n",
       "      <td>0.710341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.339989</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.720203</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.733531</td>\n",
       "      <td>0.721629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.88      0.90       362\n",
      "                sara       0.62      0.54      0.58       237\n",
      "         radikalisme       0.66      0.77      0.71       235\n",
      "pencemaran_nama_baik       0.66      0.74      0.70       492\n",
      "\n",
      "           micro avg       0.72      0.75      0.73      1326\n",
      "           macro avg       0.72      0.73      0.72      1326\n",
      "        weighted avg       0.72      0.75      0.73      1326\n",
      "         samples avg       0.42      0.43      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2778: Accuracy: 0.6681672025723473, F1 Micro: 0.7335307179866765, F1 Macro: 0.7216286556175815\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.88      0.90       362\n",
      "                sara       0.62      0.54      0.58       237\n",
      "         radikalisme       0.66      0.77      0.71       235\n",
      "pencemaran_nama_baik       0.66      0.74      0.70       492\n",
      "\n",
      "           micro avg       0.72      0.75      0.73      1326\n",
      "           macro avg       0.72      0.73      0.72      1326\n",
      "        weighted avg       0.72      0.75      0.73      1326\n",
      "         samples avg       0.42      0.43      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 22.051677322387697\n",
      "Samples above threshold: 344\n",
      "Acquired samples: 344\n",
      "Sampling duration: 12.360195875167847 seconds\n",
      "New train size: 3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='1960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/1960 07:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.302725</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.793054</td>\n",
       "      <td>0.413273</td>\n",
       "      <td>0.543381</td>\n",
       "      <td>0.450418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.277542</td>\n",
       "      <td>0.637942</td>\n",
       "      <td>0.808607</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.646446</td>\n",
       "      <td>0.561225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.182800</td>\n",
       "      <td>0.270728</td>\n",
       "      <td>0.671383</td>\n",
       "      <td>0.800976</td>\n",
       "      <td>0.619155</td>\n",
       "      <td>0.698426</td>\n",
       "      <td>0.649358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.182800</td>\n",
       "      <td>0.265586</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.745594</td>\n",
       "      <td>0.733786</td>\n",
       "      <td>0.739643</td>\n",
       "      <td>0.730648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.182800</td>\n",
       "      <td>0.281380</td>\n",
       "      <td>0.679100</td>\n",
       "      <td>0.732208</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.742283</td>\n",
       "      <td>0.735818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.088800</td>\n",
       "      <td>0.320963</td>\n",
       "      <td>0.663023</td>\n",
       "      <td>0.693717</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.742817</td>\n",
       "      <td>0.735301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.088800</td>\n",
       "      <td>0.347794</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.682489</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.737608</td>\n",
       "      <td>0.730847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>0.350008</td>\n",
       "      <td>0.672669</td>\n",
       "      <td>0.693653</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.746341</td>\n",
       "      <td>0.742057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>0.337394</td>\n",
       "      <td>0.678457</td>\n",
       "      <td>0.719085</td>\n",
       "      <td>0.758673</td>\n",
       "      <td>0.738349</td>\n",
       "      <td>0.730754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>0.345586</td>\n",
       "      <td>0.666881</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.735241</td>\n",
       "      <td>0.727337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.89      0.89       362\n",
      "                sara       0.59      0.68      0.64       237\n",
      "         radikalisme       0.67      0.82      0.73       235\n",
      "pencemaran_nama_baik       0.64      0.80      0.71       492\n",
      "\n",
      "           micro avg       0.69      0.81      0.75      1326\n",
      "           macro avg       0.70      0.80      0.74      1326\n",
      "        weighted avg       0.70      0.81      0.75      1326\n",
      "         samples avg       0.44      0.46      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3122: Accuracy: 0.6726688102893891, F1 Micro: 0.7463414634146341, F1 Macro: 0.7420568139517993\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.89      0.89       362\n",
      "                sara       0.59      0.68      0.64       237\n",
      "         radikalisme       0.67      0.82      0.73       235\n",
      "pencemaran_nama_baik       0.64      0.80      0.71       492\n",
      "\n",
      "           micro avg       0.69      0.81      0.75      1326\n",
      "           macro avg       0.70      0.80      0.74      1326\n",
      "        weighted avg       0.70      0.81      0.75      1326\n",
      "         samples avg       0.44      0.46      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 20.84160804748535\n",
      "Samples above threshold: 343\n",
      "Acquired samples: 343\n",
      "Sampling duration: 11.135061025619507 seconds\n",
      "New train size: 3465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2170' max='2170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2170/2170 07:35, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.348627</td>\n",
       "      <td>0.622508</td>\n",
       "      <td>0.915074</td>\n",
       "      <td>0.325038</td>\n",
       "      <td>0.479688</td>\n",
       "      <td>0.382204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.260134</td>\n",
       "      <td>0.651447</td>\n",
       "      <td>0.791913</td>\n",
       "      <td>0.605581</td>\n",
       "      <td>0.686325</td>\n",
       "      <td>0.604641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>0.254904</td>\n",
       "      <td>0.681672</td>\n",
       "      <td>0.709786</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.751597</td>\n",
       "      <td>0.742861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>0.258756</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.771247</td>\n",
       "      <td>0.732278</td>\n",
       "      <td>0.751257</td>\n",
       "      <td>0.734845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.282209</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.740175</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.748656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.298548</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.765922</td>\n",
       "      <td>0.698341</td>\n",
       "      <td>0.730572</td>\n",
       "      <td>0.706233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.059400</td>\n",
       "      <td>0.305437</td>\n",
       "      <td>0.683601</td>\n",
       "      <td>0.768548</td>\n",
       "      <td>0.718703</td>\n",
       "      <td>0.742790</td>\n",
       "      <td>0.725688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.059400</td>\n",
       "      <td>0.337131</td>\n",
       "      <td>0.677814</td>\n",
       "      <td>0.703826</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.750880</td>\n",
       "      <td>0.746429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.059400</td>\n",
       "      <td>0.331261</td>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.734296</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.750277</td>\n",
       "      <td>0.744251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.038100</td>\n",
       "      <td>0.337851</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.726953</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.752093</td>\n",
       "      <td>0.747243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.85      0.89       362\n",
      "                sara       0.64      0.64      0.64       237\n",
      "         radikalisme       0.68      0.83      0.75       235\n",
      "pencemaran_nama_baik       0.69      0.74      0.71       492\n",
      "\n",
      "           micro avg       0.74      0.77      0.75      1326\n",
      "           macro avg       0.74      0.76      0.75      1326\n",
      "        weighted avg       0.75      0.77      0.76      1326\n",
      "         samples avg       0.43      0.44      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3465: Accuracy: 0.6938906752411576, F1 Micro: 0.7533333333333333, F1 Macro: 0.7486556739936613\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.85      0.89       362\n",
      "                sara       0.64      0.64      0.64       237\n",
      "         radikalisme       0.68      0.83      0.75       235\n",
      "pencemaran_nama_baik       0.69      0.74      0.71       492\n",
      "\n",
      "           micro avg       0.74      0.77      0.75      1326\n",
      "           macro avg       0.74      0.76      0.75      1326\n",
      "        weighted avg       0.75      0.77      0.76      1326\n",
      "         samples avg       0.43      0.44      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 20.09557228088379\n",
      "Samples above threshold: 276\n",
      "Acquired samples: 276\n",
      "Sampling duration: 9.934978485107422 seconds\n",
      "New train size: 3741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2340' max='2340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2340/2340 08:04, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.285048</td>\n",
       "      <td>0.625080</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.514329</td>\n",
       "      <td>0.630606</td>\n",
       "      <td>0.539438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.249319</td>\n",
       "      <td>0.669453</td>\n",
       "      <td>0.779425</td>\n",
       "      <td>0.674208</td>\n",
       "      <td>0.723008</td>\n",
       "      <td>0.672700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.210700</td>\n",
       "      <td>0.260777</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.775646</td>\n",
       "      <td>0.701357</td>\n",
       "      <td>0.736634</td>\n",
       "      <td>0.719451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.210700</td>\n",
       "      <td>0.276278</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.724510</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.764517</td>\n",
       "      <td>0.760696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.111300</td>\n",
       "      <td>0.283905</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.730606</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.742652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.111300</td>\n",
       "      <td>0.289264</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.781452</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.755261</td>\n",
       "      <td>0.738416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>0.308443</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.727149</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.763610</td>\n",
       "      <td>0.762160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>0.322341</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.738028</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.763292</td>\n",
       "      <td>0.756011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.333613</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.724932</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.763740</td>\n",
       "      <td>0.762905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.336026</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.724372</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.762415</td>\n",
       "      <td>0.760372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.85      0.90       362\n",
      "                sara       0.63      0.70      0.66       237\n",
      "         radikalisme       0.67      0.85      0.75       235\n",
      "pencemaran_nama_baik       0.67      0.81      0.74       492\n",
      "\n",
      "           micro avg       0.72      0.81      0.76      1326\n",
      "           macro avg       0.73      0.80      0.76      1326\n",
      "        weighted avg       0.74      0.81      0.77      1326\n",
      "         samples avg       0.44      0.46      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3741: Accuracy: 0.7009646302250804, F1 Micro: 0.7645172782329889, F1 Macro: 0.7606958749257944\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.85      0.90       362\n",
      "                sara       0.63      0.70      0.66       237\n",
      "         radikalisme       0.67      0.85      0.75       235\n",
      "pencemaran_nama_baik       0.67      0.81      0.74       492\n",
      "\n",
      "           micro avg       0.72      0.81      0.76      1326\n",
      "           macro avg       0.73      0.80      0.76      1326\n",
      "        weighted avg       0.74      0.81      0.77      1326\n",
      "         samples avg       0.44      0.46      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 19.175918579101562\n",
      "Samples above threshold: 248\n",
      "Acquired samples: 145\n",
      "Sampling duration: 9.152729749679565 seconds\n",
      "New train size: 3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2430' max='2430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2430/2430 08:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.264816</td>\n",
       "      <td>0.663666</td>\n",
       "      <td>0.766347</td>\n",
       "      <td>0.662896</td>\n",
       "      <td>0.710877</td>\n",
       "      <td>0.677112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.240704</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.768627</td>\n",
       "      <td>0.739065</td>\n",
       "      <td>0.753556</td>\n",
       "      <td>0.734019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.215500</td>\n",
       "      <td>0.259978</td>\n",
       "      <td>0.683601</td>\n",
       "      <td>0.722488</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.757978</td>\n",
       "      <td>0.751730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.215500</td>\n",
       "      <td>0.258487</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.775397</td>\n",
       "      <td>0.736802</td>\n",
       "      <td>0.755607</td>\n",
       "      <td>0.748229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.117600</td>\n",
       "      <td>0.276696</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.763874</td>\n",
       "      <td>0.756523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.117600</td>\n",
       "      <td>0.290130</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.743407</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.764383</td>\n",
       "      <td>0.754924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.075800</td>\n",
       "      <td>0.322812</td>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.717577</td>\n",
       "      <td>0.822021</td>\n",
       "      <td>0.766257</td>\n",
       "      <td>0.762694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.075800</td>\n",
       "      <td>0.317051</td>\n",
       "      <td>0.688103</td>\n",
       "      <td>0.743253</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.755654</td>\n",
       "      <td>0.744568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.316307</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.754633</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.761121</td>\n",
       "      <td>0.752164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.324447</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.745182</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.765677</td>\n",
       "      <td>0.757721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.96      0.87      0.91       362\n",
      "                sara       0.62      0.70      0.66       237\n",
      "         radikalisme       0.67      0.83      0.74       235\n",
      "pencemaran_nama_baik       0.65      0.84      0.73       492\n",
      "\n",
      "           micro avg       0.72      0.82      0.77      1326\n",
      "           macro avg       0.73      0.81      0.76      1326\n",
      "        weighted avg       0.73      0.82      0.77      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3886: Accuracy: 0.6887459807073955, F1 Micro: 0.7662565905096661, F1 Macro: 0.762694240873816\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.96      0.87      0.91       362\n",
      "                sara       0.62      0.70      0.66       237\n",
      "         radikalisme       0.67      0.83      0.74       235\n",
      "pencemaran_nama_baik       0.65      0.84      0.73       492\n",
      "\n",
      "           micro avg       0.72      0.82      0.77      1326\n",
      "           macro avg       0.73      0.81      0.76      1326\n",
      "        weighted avg       0.73      0.82      0.77      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 19.445600700378417\n",
      "Samples above threshold: 234\n",
      "Acquired samples: 234\n",
      "Sampling duration: 8.373843431472778 seconds\n",
      "New train size: 4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 08:41, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266050</td>\n",
       "      <td>0.673312</td>\n",
       "      <td>0.757498</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.709186</td>\n",
       "      <td>0.692115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.246094</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.773632</td>\n",
       "      <td>0.703620</td>\n",
       "      <td>0.736967</td>\n",
       "      <td>0.718432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.247755</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.758569</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.763118</td>\n",
       "      <td>0.756222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.126200</td>\n",
       "      <td>0.255665</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.755374</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.761869</td>\n",
       "      <td>0.753102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.126200</td>\n",
       "      <td>0.276536</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.740899</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.761276</td>\n",
       "      <td>0.752372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.086200</td>\n",
       "      <td>0.286161</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.764365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.086200</td>\n",
       "      <td>0.304738</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.747997</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.761023</td>\n",
       "      <td>0.755847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.057900</td>\n",
       "      <td>0.322323</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.728028</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.759293</td>\n",
       "      <td>0.756127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.057900</td>\n",
       "      <td>0.331158</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.728320</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.767309</td>\n",
       "      <td>0.765627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.326688</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.738128</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.766497</td>\n",
       "      <td>0.763738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.88      0.91       362\n",
      "                sara       0.64      0.68      0.66       237\n",
      "         radikalisme       0.73      0.80      0.76       235\n",
      "pencemaran_nama_baik       0.69      0.77      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.79      0.77      1326\n",
      "           macro avg       0.75      0.78      0.76      1326\n",
      "        weighted avg       0.76      0.79      0.77      1326\n",
      "         samples avg       0.44      0.45      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4120: Accuracy: 0.7041800643086816, F1 Micro: 0.7682119205298014, F1 Macro: 0.764364826494467\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.88      0.91       362\n",
      "                sara       0.64      0.68      0.66       237\n",
      "         radikalisme       0.73      0.80      0.76       235\n",
      "pencemaran_nama_baik       0.69      0.77      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.79      0.77      1326\n",
      "           macro avg       0.75      0.78      0.76      1326\n",
      "        weighted avg       0.76      0.79      0.77      1326\n",
      "         samples avg       0.44      0.45      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 19.00348644256592\n",
      "Samples above threshold: 210\n",
      "Acquired samples: 210\n",
      "Sampling duration: 7.57072901725769 seconds\n",
      "New train size: 4330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2710' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2710/2710 09:07, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256230</td>\n",
       "      <td>0.675241</td>\n",
       "      <td>0.760669</td>\n",
       "      <td>0.685520</td>\n",
       "      <td>0.721142</td>\n",
       "      <td>0.702137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.246353</td>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.739514</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.738792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.252808</td>\n",
       "      <td>0.683601</td>\n",
       "      <td>0.795993</td>\n",
       "      <td>0.659125</td>\n",
       "      <td>0.721122</td>\n",
       "      <td>0.694815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>0.251171</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.758542</td>\n",
       "      <td>0.753394</td>\n",
       "      <td>0.755959</td>\n",
       "      <td>0.745521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>0.265364</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.762046</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.768598</td>\n",
       "      <td>0.759685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.093100</td>\n",
       "      <td>0.302899</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.721527</td>\n",
       "      <td>0.826546</td>\n",
       "      <td>0.770475</td>\n",
       "      <td>0.763852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.093100</td>\n",
       "      <td>0.307192</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.733699</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.768236</td>\n",
       "      <td>0.761133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.065600</td>\n",
       "      <td>0.310385</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.744069</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.761870</td>\n",
       "      <td>0.755982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.065600</td>\n",
       "      <td>0.317827</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.745390</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.768275</td>\n",
       "      <td>0.763246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.047900</td>\n",
       "      <td>0.324765</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.741525</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.761168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.90      0.90       362\n",
      "                sara       0.61      0.73      0.66       237\n",
      "         radikalisme       0.66      0.85      0.74       235\n",
      "pencemaran_nama_baik       0.70      0.81      0.75       492\n",
      "\n",
      "           micro avg       0.72      0.83      0.77      1326\n",
      "           macro avg       0.72      0.82      0.76      1326\n",
      "        weighted avg       0.73      0.83      0.77      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4330: Accuracy: 0.7067524115755627, F1 Micro: 0.7704745166959578, F1 Macro: 0.7638521701870034\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.90      0.90       362\n",
      "                sara       0.61      0.73      0.66       237\n",
      "         radikalisme       0.66      0.85      0.74       235\n",
      "pencemaran_nama_baik       0.70      0.81      0.75       492\n",
      "\n",
      "           micro avg       0.72      0.83      0.77      1326\n",
      "           macro avg       0.72      0.82      0.76      1326\n",
      "        weighted avg       0.73      0.83      0.77      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 19.75248794555664\n",
      "Samples above threshold: 189\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.808847188949585 seconds\n",
      "New train size: 4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2840' max='2840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2840/2840 09:37, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.259465</td>\n",
       "      <td>0.673955</td>\n",
       "      <td>0.772922</td>\n",
       "      <td>0.680241</td>\n",
       "      <td>0.723626</td>\n",
       "      <td>0.691399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.239600</td>\n",
       "      <td>0.240304</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.751163</td>\n",
       "      <td>0.730116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.239600</td>\n",
       "      <td>0.255726</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.734286</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.754219</td>\n",
       "      <td>0.748414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.138200</td>\n",
       "      <td>0.248486</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.772171</td>\n",
       "      <td>0.761689</td>\n",
       "      <td>0.766894</td>\n",
       "      <td>0.759866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.138200</td>\n",
       "      <td>0.283242</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.740638</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.771676</td>\n",
       "      <td>0.765197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>0.284975</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.756484</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.773766</td>\n",
       "      <td>0.766860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>0.293874</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.785251</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.757031</td>\n",
       "      <td>0.749438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069400</td>\n",
       "      <td>0.317700</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.747703</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.771981</td>\n",
       "      <td>0.766979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.049900</td>\n",
       "      <td>0.329670</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.742698</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.772793</td>\n",
       "      <td>0.764937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.049900</td>\n",
       "      <td>0.330150</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.747047</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.777577</td>\n",
       "      <td>0.771886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.89      0.91       362\n",
      "                sara       0.62      0.70      0.66       237\n",
      "         radikalisme       0.71      0.83      0.76       235\n",
      "pencemaran_nama_baik       0.71      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4530: Accuracy: 0.7118971061093248, F1 Micro: 0.7775768535262206, F1 Macro: 0.7718864569190863\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.89      0.91       362\n",
      "                sara       0.62      0.70      0.66       237\n",
      "         radikalisme       0.71      0.83      0.76       235\n",
      "pencemaran_nama_baik       0.71      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 19.252211380004884\n",
      "Samples above threshold: 169\n",
      "Acquired samples: 133\n",
      "Sampling duration: 6.374727249145508 seconds\n",
      "New train size: 4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2920' max='2920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2920/2920 09:55, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.257640</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.766998</td>\n",
       "      <td>0.697587</td>\n",
       "      <td>0.730648</td>\n",
       "      <td>0.715430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.245200</td>\n",
       "      <td>0.231125</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.787977</td>\n",
       "      <td>0.731523</td>\n",
       "      <td>0.758702</td>\n",
       "      <td>0.748510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.245200</td>\n",
       "      <td>0.239398</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.743080</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.765631</td>\n",
       "      <td>0.762055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.147700</td>\n",
       "      <td>0.271204</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.722907</td>\n",
       "      <td>0.840121</td>\n",
       "      <td>0.777119</td>\n",
       "      <td>0.771971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.147700</td>\n",
       "      <td>0.264761</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.750716</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.770022</td>\n",
       "      <td>0.763443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>0.301352</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.730744</td>\n",
       "      <td>0.837104</td>\n",
       "      <td>0.780316</td>\n",
       "      <td>0.777629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.291712</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.762537</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.771066</td>\n",
       "      <td>0.765194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.319911</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.744122</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.776335</td>\n",
       "      <td>0.770759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.051600</td>\n",
       "      <td>0.319477</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.749822</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.770978</td>\n",
       "      <td>0.764892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.051600</td>\n",
       "      <td>0.325191</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.745645</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.775081</td>\n",
       "      <td>0.770486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.96      0.87      0.92       362\n",
      "                sara       0.62      0.75      0.68       237\n",
      "         radikalisme       0.68      0.87      0.76       235\n",
      "pencemaran_nama_baik       0.68      0.84      0.75       492\n",
      "\n",
      "           micro avg       0.73      0.84      0.78      1326\n",
      "           macro avg       0.74      0.83      0.78      1326\n",
      "        weighted avg       0.75      0.84      0.79      1326\n",
      "         samples avg       0.46      0.48      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4663: Accuracy: 0.7118971061093248, F1 Micro: 0.7803163444639719, F1 Macro: 0.7776289392670388\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.96      0.87      0.92       362\n",
      "                sara       0.62      0.75      0.68       237\n",
      "         radikalisme       0.68      0.87      0.76       235\n",
      "pencemaran_nama_baik       0.68      0.84      0.75       492\n",
      "\n",
      "           micro avg       0.73      0.84      0.78      1326\n",
      "           macro avg       0.74      0.83      0.78      1326\n",
      "        weighted avg       0.75      0.84      0.79      1326\n",
      "         samples avg       0.46      0.48      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 18.70529556274414\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.7427003383636475 seconds\n",
      "New train size: 4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3040' max='3040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3040/3040 10:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.253167</td>\n",
       "      <td>0.688103</td>\n",
       "      <td>0.777494</td>\n",
       "      <td>0.687783</td>\n",
       "      <td>0.729892</td>\n",
       "      <td>0.710247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.247600</td>\n",
       "      <td>0.230204</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.793797</td>\n",
       "      <td>0.714178</td>\n",
       "      <td>0.751886</td>\n",
       "      <td>0.740252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.247600</td>\n",
       "      <td>0.229062</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.774340</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.774048</td>\n",
       "      <td>0.770194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.250694</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.753980</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.769572</td>\n",
       "      <td>0.762411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.106600</td>\n",
       "      <td>0.290658</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.729941</td>\n",
       "      <td>0.843891</td>\n",
       "      <td>0.782791</td>\n",
       "      <td>0.779487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.106600</td>\n",
       "      <td>0.269208</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.757948</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.774170</td>\n",
       "      <td>0.767133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.078200</td>\n",
       "      <td>0.294394</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.763061</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.772439</td>\n",
       "      <td>0.766437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.078200</td>\n",
       "      <td>0.318736</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.738160</td>\n",
       "      <td>0.822775</td>\n",
       "      <td>0.778174</td>\n",
       "      <td>0.774152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.054300</td>\n",
       "      <td>0.317463</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.748081</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.777093</td>\n",
       "      <td>0.771917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.043400</td>\n",
       "      <td>0.322076</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.749651</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.778986</td>\n",
       "      <td>0.774618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.88      0.91       362\n",
      "                sara       0.64      0.73      0.68       237\n",
      "         radikalisme       0.68      0.88      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.86      0.76       492\n",
      "\n",
      "           micro avg       0.73      0.84      0.78      1326\n",
      "           macro avg       0.74      0.84      0.78      1326\n",
      "        weighted avg       0.74      0.84      0.79      1326\n",
      "         samples avg       0.46      0.48      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4863: Accuracy: 0.7118971061093248, F1 Micro: 0.782791185729276, F1 Macro: 0.7794865401758841\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.88      0.91       362\n",
      "                sara       0.64      0.73      0.68       237\n",
      "         radikalisme       0.68      0.88      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.86      0.76       492\n",
      "\n",
      "           micro avg       0.73      0.84      0.78      1326\n",
      "           macro avg       0.74      0.84      0.78      1326\n",
      "        weighted avg       0.74      0.84      0.79      1326\n",
      "         samples avg       0.46      0.48      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 18.495538330078126\n",
      "Samples above threshold: 136\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.958630084991455 seconds\n",
      "New train size: 5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3170' max='3170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3170/3170 10:34, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.255664</td>\n",
       "      <td>0.677170</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.651584</td>\n",
       "      <td>0.713460</td>\n",
       "      <td>0.688709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.258700</td>\n",
       "      <td>0.234917</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.716440</td>\n",
       "      <td>0.747443</td>\n",
       "      <td>0.719012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.258700</td>\n",
       "      <td>0.235866</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.775229</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.769932</td>\n",
       "      <td>0.761379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.165500</td>\n",
       "      <td>0.250948</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.761834</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.757519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.331490</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.682428</td>\n",
       "      <td>0.881599</td>\n",
       "      <td>0.769332</td>\n",
       "      <td>0.766991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.286317</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.745492</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.776734</td>\n",
       "      <td>0.767445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.084800</td>\n",
       "      <td>0.300696</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.746372</td>\n",
       "      <td>0.814480</td>\n",
       "      <td>0.778940</td>\n",
       "      <td>0.773069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.060900</td>\n",
       "      <td>0.303881</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.759539</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.777164</td>\n",
       "      <td>0.772117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.060900</td>\n",
       "      <td>0.310050</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.762491</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.777983</td>\n",
       "      <td>0.772163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>0.320163</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.748588</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.773158</td>\n",
       "      <td>0.767196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.63      0.70      0.66       237\n",
      "         radikalisme       0.71      0.84      0.77       235\n",
      "pencemaran_nama_baik       0.71      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5063: Accuracy: 0.7138263665594855, F1 Micro: 0.7789397764154345, F1 Macro: 0.7730686051944189\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.63      0.70      0.66       237\n",
      "         radikalisme       0.71      0.84      0.77       235\n",
      "pencemaran_nama_baik       0.71      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 18.440899658203126\n",
      "Samples above threshold: 116\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.360881328582764 seconds\n",
      "New train size: 5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3290' max='3290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3290/3290 10:59, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.251133</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.744361</td>\n",
       "      <td>0.746606</td>\n",
       "      <td>0.745482</td>\n",
       "      <td>0.741151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.265300</td>\n",
       "      <td>0.230878</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.780159</td>\n",
       "      <td>0.741327</td>\n",
       "      <td>0.760247</td>\n",
       "      <td>0.748250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.265300</td>\n",
       "      <td>0.229501</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.761529</td>\n",
       "      <td>0.752250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.173400</td>\n",
       "      <td>0.250224</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.749637</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.764053</td>\n",
       "      <td>0.757559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>0.277973</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.727152</td>\n",
       "      <td>0.828054</td>\n",
       "      <td>0.774330</td>\n",
       "      <td>0.765558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>0.264283</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.767870</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.776742</td>\n",
       "      <td>0.768716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.090300</td>\n",
       "      <td>0.302638</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.738836</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.778887</td>\n",
       "      <td>0.773615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.065600</td>\n",
       "      <td>0.316376</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.734177</td>\n",
       "      <td>0.831071</td>\n",
       "      <td>0.779625</td>\n",
       "      <td>0.774393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.065600</td>\n",
       "      <td>0.318868</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.740918</td>\n",
       "      <td>0.815234</td>\n",
       "      <td>0.776302</td>\n",
       "      <td>0.768588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.053900</td>\n",
       "      <td>0.312355</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.753571</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.774028</td>\n",
       "      <td>0.766537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.91      0.92       362\n",
      "                sara       0.59      0.75      0.66       237\n",
      "         radikalisme       0.69      0.86      0.76       235\n",
      "pencemaran_nama_baik       0.71      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.73      0.83      0.78      1326\n",
      "           macro avg       0.73      0.83      0.77      1326\n",
      "        weighted avg       0.75      0.83      0.78      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5263: Accuracy: 0.7144694533762058, F1 Micro: 0.7796250442164839, F1 Macro: 0.7743930275749433\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.91      0.92       362\n",
      "                sara       0.59      0.75      0.66       237\n",
      "         radikalisme       0.69      0.86      0.76       235\n",
      "pencemaran_nama_baik       0.71      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.73      0.83      0.78      1326\n",
      "           macro avg       0.73      0.83      0.77      1326\n",
      "        weighted avg       0.75      0.83      0.78      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 17.949749755859376\n",
      "Samples above threshold: 96\n",
      "Acquired samples: 178\n",
      "Sampling duration: 3.8174545764923096 seconds\n",
      "New train size: 5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3410' max='3410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3410/3410 11:22, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.244464</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.780183</td>\n",
       "      <td>0.706637</td>\n",
       "      <td>0.741591</td>\n",
       "      <td>0.729286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.271400</td>\n",
       "      <td>0.229657</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.784504</td>\n",
       "      <td>0.733032</td>\n",
       "      <td>0.757895</td>\n",
       "      <td>0.744569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.183700</td>\n",
       "      <td>0.233025</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.780063</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.761390</td>\n",
       "      <td>0.755529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.183700</td>\n",
       "      <td>0.238282</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.746713</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.778780</td>\n",
       "      <td>0.774948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.263110</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.778891</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.770579</td>\n",
       "      <td>0.752215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.099100</td>\n",
       "      <td>0.280946</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.733425</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.765681</td>\n",
       "      <td>0.757530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.099100</td>\n",
       "      <td>0.293614</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.750694</td>\n",
       "      <td>0.815234</td>\n",
       "      <td>0.781634</td>\n",
       "      <td>0.772443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>0.303645</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.750357</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.771261</td>\n",
       "      <td>0.763525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.057300</td>\n",
       "      <td>0.315912</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.746844</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.773983</td>\n",
       "      <td>0.766133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.057300</td>\n",
       "      <td>0.310557</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.760492</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.776219</td>\n",
       "      <td>0.767876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.63      0.66      0.64       237\n",
      "         radikalisme       0.71      0.84      0.77       235\n",
      "pencemaran_nama_baik       0.71      0.81      0.76       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.82      0.78      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5441: Accuracy: 0.7099678456591639, F1 Micro: 0.7816341287057122, F1 Macro: 0.7724429650121575\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.63      0.66      0.64       237\n",
      "         radikalisme       0.71      0.84      0.77       235\n",
      "pencemaran_nama_baik       0.71      0.81      0.76       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.82      0.78      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 17.343746948242188\n",
      "Samples above threshold: 78\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.0365312099456787 seconds\n",
      "New train size: 5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3530' max='3530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3530/3530 11:41, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250705</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.766935</td>\n",
       "      <td>0.717195</td>\n",
       "      <td>0.741231</td>\n",
       "      <td>0.731435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.279900</td>\n",
       "      <td>0.233585</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.813406</td>\n",
       "      <td>0.677225</td>\n",
       "      <td>0.739095</td>\n",
       "      <td>0.713564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.183400</td>\n",
       "      <td>0.234117</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.747433</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.783638</td>\n",
       "      <td>0.775393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.183400</td>\n",
       "      <td>0.243326</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.761871</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.779823</td>\n",
       "      <td>0.775361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.140300</td>\n",
       "      <td>0.254697</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.765106</td>\n",
       "      <td>0.763952</td>\n",
       "      <td>0.764528</td>\n",
       "      <td>0.754246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.103300</td>\n",
       "      <td>0.267602</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.758496</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.774456</td>\n",
       "      <td>0.768681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.103300</td>\n",
       "      <td>0.277164</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.764317</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.774554</td>\n",
       "      <td>0.767586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>0.302076</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.754261</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.776884</td>\n",
       "      <td>0.769504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.061400</td>\n",
       "      <td>0.318296</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.815234</td>\n",
       "      <td>0.776860</td>\n",
       "      <td>0.770884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>0.308500</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.774336</td>\n",
       "      <td>0.766956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.92      0.90       362\n",
      "                sara       0.63      0.68      0.65       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.72      0.80      0.76       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.74      0.82      0.78      1326\n",
      "        weighted avg       0.75      0.82      0.78      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5641: Accuracy: 0.7144694533762058, F1 Micro: 0.7836383207750268, F1 Macro: 0.7753931306661289\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.92      0.90       362\n",
      "                sara       0.63      0.68      0.65       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.72      0.80      0.76       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.74      0.82      0.78      1326\n",
      "        weighted avg       0.75      0.82      0.78      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 16.57730484008789\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.354459524154663 seconds\n",
      "New train size: 5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3660' max='3660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3660/3660 12:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243803</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.760091</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.756347</td>\n",
       "      <td>0.749167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.283300</td>\n",
       "      <td>0.231283</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.795868</td>\n",
       "      <td>0.726244</td>\n",
       "      <td>0.759464</td>\n",
       "      <td>0.748422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.193600</td>\n",
       "      <td>0.225458</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.765926</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.772795</td>\n",
       "      <td>0.768107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.193600</td>\n",
       "      <td>0.235379</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.759857</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.779125</td>\n",
       "      <td>0.774247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.148800</td>\n",
       "      <td>0.254342</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.784012</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.776551</td>\n",
       "      <td>0.762433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.107400</td>\n",
       "      <td>0.283828</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.732713</td>\n",
       "      <td>0.831071</td>\n",
       "      <td>0.778799</td>\n",
       "      <td>0.773025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.082800</td>\n",
       "      <td>0.278972</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.780895</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.778828</td>\n",
       "      <td>0.769306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.082800</td>\n",
       "      <td>0.306718</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.778571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.304299</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.766813</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.778768</td>\n",
       "      <td>0.771365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>0.310846</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.761871</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.779823</td>\n",
       "      <td>0.773568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.93      0.92       362\n",
      "                sara       0.62      0.70      0.66       237\n",
      "         radikalisme       0.72      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.79      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.79      1326\n",
      "           macro avg       0.74      0.82      0.78      1326\n",
      "        weighted avg       0.75      0.82      0.79      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5841: Accuracy: 0.7234726688102894, F1 Micro: 0.7850467289719627, F1 Macro: 0.7785714782423613\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.93      0.92       362\n",
      "                sara       0.62      0.70      0.66       237\n",
      "         radikalisme       0.72      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.79      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.79      1326\n",
      "           macro avg       0.74      0.82      0.78      1326\n",
      "        weighted avg       0.75      0.82      0.79      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 16.031789016723632\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 200\n",
      "Sampling duration: 1.5897789001464844 seconds\n",
      "New train size: 6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3780' max='3780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3780/3780 12:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.239734</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.787162</td>\n",
       "      <td>0.702866</td>\n",
       "      <td>0.742629</td>\n",
       "      <td>0.717210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.290200</td>\n",
       "      <td>0.221439</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.769865</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.772180</td>\n",
       "      <td>0.761544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.195300</td>\n",
       "      <td>0.228407</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.794643</td>\n",
       "      <td>0.738311</td>\n",
       "      <td>0.765442</td>\n",
       "      <td>0.750499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.153500</td>\n",
       "      <td>0.233392</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.778539</td>\n",
       "      <td>0.768864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.153500</td>\n",
       "      <td>0.254408</td>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.765759</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.785452</td>\n",
       "      <td>0.775450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.110500</td>\n",
       "      <td>0.259782</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.787201</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.778498</td>\n",
       "      <td>0.768201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.087700</td>\n",
       "      <td>0.285838</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.762213</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.780721</td>\n",
       "      <td>0.771908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.293162</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.775722</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.782966</td>\n",
       "      <td>0.776723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.309461</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.812971</td>\n",
       "      <td>0.782293</td>\n",
       "      <td>0.777526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>0.305776</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.773739</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.780105</td>\n",
       "      <td>0.772214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.91       362\n",
      "                sara       0.64      0.64      0.64       237\n",
      "         radikalisme       0.72      0.88      0.79       235\n",
      "pencemaran_nama_baik       0.75      0.77      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.75      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6041: Accuracy: 0.7286173633440515, F1 Micro: 0.7854518736223365, F1 Macro: 0.7754497005624232\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.91       362\n",
      "                sara       0.64      0.64      0.64       237\n",
      "         radikalisme       0.72      0.88      0.79       235\n",
      "pencemaran_nama_baik       0.75      0.77      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.75      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 14.691578483581543\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 177\n",
      "Sampling duration: 1.1325621604919434 seconds\n",
      "New train size: 6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3890/3890 12:45, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.237993</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.791134</td>\n",
       "      <td>0.699849</td>\n",
       "      <td>0.742697</td>\n",
       "      <td>0.736520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.297700</td>\n",
       "      <td>0.225474</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.778638</td>\n",
       "      <td>0.758673</td>\n",
       "      <td>0.768526</td>\n",
       "      <td>0.761790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.238067</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.837858</td>\n",
       "      <td>0.782119</td>\n",
       "      <td>0.778567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.159700</td>\n",
       "      <td>0.233897</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.785441</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.779171</td>\n",
       "      <td>0.771292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.159700</td>\n",
       "      <td>0.252658</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.765988</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.780163</td>\n",
       "      <td>0.772169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.121700</td>\n",
       "      <td>0.271063</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.760901</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.774981</td>\n",
       "      <td>0.768353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>0.291518</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.753879</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.779155</td>\n",
       "      <td>0.772546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.073900</td>\n",
       "      <td>0.291287</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.778198</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.776728</td>\n",
       "      <td>0.772292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>0.307712</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.763728</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.780074</td>\n",
       "      <td>0.774082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>0.309851</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.779134</td>\n",
       "      <td>0.773814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.61      0.73      0.66       237\n",
      "         radikalisme       0.70      0.91      0.79       235\n",
      "pencemaran_nama_baik       0.70      0.82      0.75       492\n",
      "\n",
      "           micro avg       0.73      0.84      0.78      1326\n",
      "           macro avg       0.73      0.84      0.78      1326\n",
      "        weighted avg       0.74      0.84      0.79      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6218: Accuracy: 0.7138263665594855, F1 Micro: 0.7821189721928897, F1 Macro: 0.778567135554925\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.61      0.73      0.66       237\n",
      "         radikalisme       0.70      0.91      0.79       235\n",
      "pencemaran_nama_baik       0.70      0.82      0.75       492\n",
      "\n",
      "           micro avg       0.73      0.84      0.78      1326\n",
      "           macro avg       0.73      0.84      0.78      1326\n",
      "        weighted avg       0.74      0.84      0.79      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\n",
      "Total sampling time: 183.57 seconds\n",
      "Total runtime: 11648.511019468307 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4241c239",
   "metadata": {},
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b811df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 02:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.458386</td>\n",
       "      <td>0.505466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080694</td>\n",
       "      <td>0.149337</td>\n",
       "      <td>0.114072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.384749</td>\n",
       "      <td>0.584566</td>\n",
       "      <td>0.914454</td>\n",
       "      <td>0.233786</td>\n",
       "      <td>0.372372</td>\n",
       "      <td>0.251831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.356113</td>\n",
       "      <td>0.571704</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.348416</td>\n",
       "      <td>0.475798</td>\n",
       "      <td>0.347973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.330139</td>\n",
       "      <td>0.593569</td>\n",
       "      <td>0.773109</td>\n",
       "      <td>0.416290</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.453938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.312512</td>\n",
       "      <td>0.608360</td>\n",
       "      <td>0.758850</td>\n",
       "      <td>0.517345</td>\n",
       "      <td>0.615247</td>\n",
       "      <td>0.548237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.303364</td>\n",
       "      <td>0.628296</td>\n",
       "      <td>0.745247</td>\n",
       "      <td>0.591252</td>\n",
       "      <td>0.659378</td>\n",
       "      <td>0.634356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.297518</td>\n",
       "      <td>0.625080</td>\n",
       "      <td>0.737660</td>\n",
       "      <td>0.608597</td>\n",
       "      <td>0.666942</td>\n",
       "      <td>0.633439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.296958</td>\n",
       "      <td>0.624437</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.567119</td>\n",
       "      <td>0.646604</td>\n",
       "      <td>0.609105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.293293</td>\n",
       "      <td>0.627653</td>\n",
       "      <td>0.743662</td>\n",
       "      <td>0.597285</td>\n",
       "      <td>0.662484</td>\n",
       "      <td>0.635006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.293404</td>\n",
       "      <td>0.627653</td>\n",
       "      <td>0.747126</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.658228</td>\n",
       "      <td>0.629208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.83      0.85      0.84       362\n",
      "                sara       0.72      0.29      0.41       237\n",
      "         radikalisme       0.72      0.61      0.66       235\n",
      "pencemaran_nama_baik       0.67      0.59      0.63       492\n",
      "\n",
      "           micro avg       0.74      0.61      0.67      1326\n",
      "           macro avg       0.73      0.58      0.63      1326\n",
      "        weighted avg       0.73      0.61      0.65      1326\n",
      "         samples avg       0.38      0.35      0.35      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 388: Accuracy: 0.62508038585209, F1 Micro: 0.6669421487603305, F1 Macro: 0.6334393870554681\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.83      0.85      0.84       362\n",
      "                sara       0.72      0.29      0.41       237\n",
      "         radikalisme       0.72      0.61      0.66       235\n",
      "pencemaran_nama_baik       0.67      0.59      0.63       492\n",
      "\n",
      "           micro avg       0.74      0.61      0.67      1326\n",
      "           macro avg       0.73      0.58      0.63      1326\n",
      "        weighted avg       0.73      0.61      0.65      1326\n",
      "         samples avg       0.38      0.35      0.35      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 26.603021430969243\n",
      "Samples above threshold: 583\n",
      "Acquired samples: 583\n",
      "Sampling duration: 20.864587545394897 seconds\n",
      "New train size: 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [610/610 03:19, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.378975</td>\n",
       "      <td>0.558199</td>\n",
       "      <td>0.825521</td>\n",
       "      <td>0.239065</td>\n",
       "      <td>0.370760</td>\n",
       "      <td>0.242515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.325853</td>\n",
       "      <td>0.591640</td>\n",
       "      <td>0.829670</td>\n",
       "      <td>0.341629</td>\n",
       "      <td>0.483974</td>\n",
       "      <td>0.340743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.295100</td>\n",
       "      <td>0.643087</td>\n",
       "      <td>0.734079</td>\n",
       "      <td>0.643288</td>\n",
       "      <td>0.685691</td>\n",
       "      <td>0.671884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.289647</td>\n",
       "      <td>0.621865</td>\n",
       "      <td>0.683920</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.714234</td>\n",
       "      <td>0.700222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.283788</td>\n",
       "      <td>0.653376</td>\n",
       "      <td>0.727344</td>\n",
       "      <td>0.702112</td>\n",
       "      <td>0.714505</td>\n",
       "      <td>0.693483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.286634</td>\n",
       "      <td>0.669453</td>\n",
       "      <td>0.750413</td>\n",
       "      <td>0.684766</td>\n",
       "      <td>0.716088</td>\n",
       "      <td>0.700938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.293994</td>\n",
       "      <td>0.661736</td>\n",
       "      <td>0.762697</td>\n",
       "      <td>0.656863</td>\n",
       "      <td>0.705835</td>\n",
       "      <td>0.681453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.297643</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.761946</td>\n",
       "      <td>0.661388</td>\n",
       "      <td>0.708115</td>\n",
       "      <td>0.689465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.303592</td>\n",
       "      <td>0.664952</td>\n",
       "      <td>0.744939</td>\n",
       "      <td>0.693816</td>\n",
       "      <td>0.718469</td>\n",
       "      <td>0.701903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.305558</td>\n",
       "      <td>0.665595</td>\n",
       "      <td>0.760345</td>\n",
       "      <td>0.665158</td>\n",
       "      <td>0.709574</td>\n",
       "      <td>0.685553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.86      0.88      0.87       362\n",
      "                sara       0.68      0.49      0.57       237\n",
      "         radikalisme       0.70      0.67      0.68       235\n",
      "pencemaran_nama_baik       0.70      0.66      0.68       492\n",
      "\n",
      "           micro avg       0.74      0.69      0.72      1326\n",
      "           macro avg       0.74      0.68      0.70      1326\n",
      "        weighted avg       0.74      0.69      0.71      1326\n",
      "         samples avg       0.40      0.39      0.38      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 971: Accuracy: 0.6649517684887459, F1 Micro: 0.7184693479109723, F1 Macro: 0.7019032146516351\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.86      0.88      0.87       362\n",
      "                sara       0.68      0.49      0.57       237\n",
      "         radikalisme       0.70      0.67      0.68       235\n",
      "pencemaran_nama_baik       0.70      0.66      0.68       492\n",
      "\n",
      "           micro avg       0.74      0.69      0.72      1326\n",
      "           macro avg       0.74      0.68      0.70      1326\n",
      "        weighted avg       0.74      0.69      0.71      1326\n",
      "         samples avg       0.40      0.39      0.38      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 24.79934539794922\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 18.705563068389893 seconds\n",
      "New train size: 1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [940/940 04:08, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.352474</td>\n",
       "      <td>0.561415</td>\n",
       "      <td>0.801282</td>\n",
       "      <td>0.282805</td>\n",
       "      <td>0.418060</td>\n",
       "      <td>0.281852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.299060</td>\n",
       "      <td>0.627653</td>\n",
       "      <td>0.861199</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.474100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.268803</td>\n",
       "      <td>0.650161</td>\n",
       "      <td>0.769161</td>\n",
       "      <td>0.643288</td>\n",
       "      <td>0.700616</td>\n",
       "      <td>0.647708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.292332</td>\n",
       "      <td>0.659164</td>\n",
       "      <td>0.843596</td>\n",
       "      <td>0.516591</td>\n",
       "      <td>0.640786</td>\n",
       "      <td>0.572550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.269028</td>\n",
       "      <td>0.672026</td>\n",
       "      <td>0.768007</td>\n",
       "      <td>0.691554</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>0.702153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.273564</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.756156</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.736557</td>\n",
       "      <td>0.720663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.288191</td>\n",
       "      <td>0.670740</td>\n",
       "      <td>0.768968</td>\n",
       "      <td>0.680241</td>\n",
       "      <td>0.721889</td>\n",
       "      <td>0.696995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.294172</td>\n",
       "      <td>0.673312</td>\n",
       "      <td>0.757353</td>\n",
       "      <td>0.699095</td>\n",
       "      <td>0.727059</td>\n",
       "      <td>0.705667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.303783</td>\n",
       "      <td>0.675241</td>\n",
       "      <td>0.767007</td>\n",
       "      <td>0.680241</td>\n",
       "      <td>0.721023</td>\n",
       "      <td>0.696971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.302241</td>\n",
       "      <td>0.681672</td>\n",
       "      <td>0.760163</td>\n",
       "      <td>0.705128</td>\n",
       "      <td>0.731612</td>\n",
       "      <td>0.710914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.86      0.89       362\n",
      "                sara       0.63      0.49      0.55       237\n",
      "         radikalisme       0.73      0.74      0.73       235\n",
      "pencemaran_nama_baik       0.70      0.71      0.71       492\n",
      "\n",
      "           micro avg       0.76      0.72      0.74      1326\n",
      "           macro avg       0.75      0.70      0.72      1326\n",
      "        weighted avg       0.75      0.72      0.73      1326\n",
      "         samples avg       0.42      0.41      0.40      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1496: Accuracy: 0.682315112540193, F1 Micro: 0.7365570599613154, F1 Macro: 0.7206626583745689\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.86      0.89       362\n",
      "                sara       0.63      0.49      0.55       237\n",
      "         radikalisme       0.73      0.74      0.73       235\n",
      "pencemaran_nama_baik       0.70      0.71      0.71       492\n",
      "\n",
      "           micro avg       0.76      0.72      0.74      1326\n",
      "           macro avg       0.75      0.70      0.72      1326\n",
      "        weighted avg       0.75      0.72      0.73      1326\n",
      "         samples avg       0.42      0.41      0.40      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 23.189731407165528\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 16.830559015274048 seconds\n",
      "New train size: 1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1240' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1240/1240 05:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.351712</td>\n",
       "      <td>0.584566</td>\n",
       "      <td>0.938838</td>\n",
       "      <td>0.231523</td>\n",
       "      <td>0.371446</td>\n",
       "      <td>0.247617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.275260</td>\n",
       "      <td>0.642444</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.520362</td>\n",
       "      <td>0.637119</td>\n",
       "      <td>0.560176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.262711</td>\n",
       "      <td>0.674598</td>\n",
       "      <td>0.756779</td>\n",
       "      <td>0.694570</td>\n",
       "      <td>0.724341</td>\n",
       "      <td>0.705491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.264828</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.751767</td>\n",
       "      <td>0.721719</td>\n",
       "      <td>0.736437</td>\n",
       "      <td>0.724180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.287469</td>\n",
       "      <td>0.668810</td>\n",
       "      <td>0.797310</td>\n",
       "      <td>0.625943</td>\n",
       "      <td>0.701310</td>\n",
       "      <td>0.668039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.290559</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.760130</td>\n",
       "      <td>0.707391</td>\n",
       "      <td>0.732812</td>\n",
       "      <td>0.717175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.310743</td>\n",
       "      <td>0.678457</td>\n",
       "      <td>0.780686</td>\n",
       "      <td>0.652338</td>\n",
       "      <td>0.710764</td>\n",
       "      <td>0.681464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.312312</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.770213</td>\n",
       "      <td>0.682504</td>\n",
       "      <td>0.723711</td>\n",
       "      <td>0.698729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.684244</td>\n",
       "      <td>0.760033</td>\n",
       "      <td>0.699849</td>\n",
       "      <td>0.728700</td>\n",
       "      <td>0.710309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>0.310858</td>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.765095</td>\n",
       "      <td>0.697587</td>\n",
       "      <td>0.729783</td>\n",
       "      <td>0.713042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.87      0.89       362\n",
      "                sara       0.63      0.52      0.57       237\n",
      "         radikalisme       0.75      0.72      0.74       235\n",
      "pencemaran_nama_baik       0.69      0.71      0.70       492\n",
      "\n",
      "           micro avg       0.75      0.72      0.74      1326\n",
      "           macro avg       0.75      0.71      0.72      1326\n",
      "        weighted avg       0.75      0.72      0.74      1326\n",
      "         samples avg       0.42      0.42      0.41      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1969: Accuracy: 0.6855305466237942, F1 Micro: 0.7364370911889188, F1 Macro: 0.7241803335553336\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.87      0.89       362\n",
      "                sara       0.63      0.52      0.57       237\n",
      "         radikalisme       0.75      0.72      0.74       235\n",
      "pencemaran_nama_baik       0.69      0.71      0.70       492\n",
      "\n",
      "           micro avg       0.75      0.72      0.74      1326\n",
      "           macro avg       0.75      0.71      0.72      1326\n",
      "        weighted avg       0.75      0.72      0.74      1326\n",
      "         samples avg       0.42      0.42      0.41      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 22.646933746337893\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 425\n",
      "Sampling duration: 15.111121654510498 seconds\n",
      "New train size: 2394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:43, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.355296</td>\n",
       "      <td>0.578135</td>\n",
       "      <td>0.801923</td>\n",
       "      <td>0.314480</td>\n",
       "      <td>0.451788</td>\n",
       "      <td>0.341604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.269292</td>\n",
       "      <td>0.654019</td>\n",
       "      <td>0.843256</td>\n",
       "      <td>0.523379</td>\n",
       "      <td>0.645882</td>\n",
       "      <td>0.591689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.281708</td>\n",
       "      <td>0.674598</td>\n",
       "      <td>0.820803</td>\n",
       "      <td>0.601056</td>\n",
       "      <td>0.693949</td>\n",
       "      <td>0.659657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>0.261695</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.753478</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.744275</td>\n",
       "      <td>0.728212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>0.282775</td>\n",
       "      <td>0.686817</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.677979</td>\n",
       "      <td>0.723250</td>\n",
       "      <td>0.696288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>0.291721</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.742560</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.747566</td>\n",
       "      <td>0.740738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>0.294806</td>\n",
       "      <td>0.679743</td>\n",
       "      <td>0.737657</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.746180</td>\n",
       "      <td>0.738452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>0.304893</td>\n",
       "      <td>0.682958</td>\n",
       "      <td>0.773032</td>\n",
       "      <td>0.696078</td>\n",
       "      <td>0.732540</td>\n",
       "      <td>0.712060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>0.313142</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.763432</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.739992</td>\n",
       "      <td>0.721408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.033400</td>\n",
       "      <td>0.317750</td>\n",
       "      <td>0.680386</td>\n",
       "      <td>0.747893</td>\n",
       "      <td>0.736048</td>\n",
       "      <td>0.741923</td>\n",
       "      <td>0.726636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.87      0.90       362\n",
      "                sara       0.59      0.60      0.60       237\n",
      "         radikalisme       0.71      0.81      0.76       235\n",
      "pencemaran_nama_baik       0.70      0.72      0.71       492\n",
      "\n",
      "           micro avg       0.74      0.75      0.75      1326\n",
      "           macro avg       0.74      0.75      0.74      1326\n",
      "        weighted avg       0.75      0.75      0.75      1326\n",
      "         samples avg       0.42      0.43      0.41      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2394: Accuracy: 0.692604501607717, F1 Micro: 0.7475655430711611, F1 Macro: 0.7407383256979893\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.87      0.90       362\n",
      "                sara       0.59      0.60      0.60       237\n",
      "         radikalisme       0.71      0.81      0.76       235\n",
      "pencemaran_nama_baik       0.70      0.72      0.71       492\n",
      "\n",
      "           micro avg       0.74      0.75      0.75      1326\n",
      "           macro avg       0.74      0.75      0.74      1326\n",
      "        weighted avg       0.75      0.75      0.75      1326\n",
      "         samples avg       0.42      0.43      0.41      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 23.581730270385744\n",
      "Samples above threshold: 383\n",
      "Acquired samples: 383\n",
      "Sampling duration: 13.534852504730225 seconds\n",
      "New train size: 2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1740' max='1740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1740/1740 06:21, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.307452</td>\n",
       "      <td>0.592926</td>\n",
       "      <td>0.846435</td>\n",
       "      <td>0.349170</td>\n",
       "      <td>0.494394</td>\n",
       "      <td>0.404703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.255652</td>\n",
       "      <td>0.659164</td>\n",
       "      <td>0.801223</td>\n",
       "      <td>0.592760</td>\n",
       "      <td>0.681404</td>\n",
       "      <td>0.634314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.165100</td>\n",
       "      <td>0.250727</td>\n",
       "      <td>0.682958</td>\n",
       "      <td>0.810212</td>\n",
       "      <td>0.634238</td>\n",
       "      <td>0.711506</td>\n",
       "      <td>0.687207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.165100</td>\n",
       "      <td>0.270248</td>\n",
       "      <td>0.681029</td>\n",
       "      <td>0.726368</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.747896</td>\n",
       "      <td>0.733500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.165100</td>\n",
       "      <td>0.273686</td>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.787271</td>\n",
       "      <td>0.680995</td>\n",
       "      <td>0.730287</td>\n",
       "      <td>0.714671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.301389</td>\n",
       "      <td>0.679743</td>\n",
       "      <td>0.703196</td>\n",
       "      <td>0.812971</td>\n",
       "      <td>0.754110</td>\n",
       "      <td>0.744103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.319846</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.689113</td>\n",
       "      <td>0.825792</td>\n",
       "      <td>0.751286</td>\n",
       "      <td>0.747141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.297737</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.745712</td>\n",
       "      <td>0.754148</td>\n",
       "      <td>0.749906</td>\n",
       "      <td>0.735130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>0.310180</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.758540</td>\n",
       "      <td>0.736802</td>\n",
       "      <td>0.747513</td>\n",
       "      <td>0.732588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>0.314052</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.731237</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.750826</td>\n",
       "      <td>0.740664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.86      0.92      0.89       362\n",
      "                sara       0.59      0.62      0.60       237\n",
      "         radikalisme       0.70      0.81      0.75       235\n",
      "pencemaran_nama_baik       0.65      0.83      0.73       492\n",
      "\n",
      "           micro avg       0.70      0.81      0.75      1326\n",
      "           macro avg       0.70      0.79      0.74      1326\n",
      "        weighted avg       0.71      0.81      0.75      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2777: Accuracy: 0.6797427652733119, F1 Micro: 0.7541098286114025, F1 Macro: 0.7441028698264844\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.86      0.92      0.89       362\n",
      "                sara       0.59      0.62      0.60       237\n",
      "         radikalisme       0.70      0.81      0.75       235\n",
      "pencemaran_nama_baik       0.65      0.83      0.73       492\n",
      "\n",
      "           micro avg       0.70      0.81      0.75      1326\n",
      "           macro avg       0.70      0.79      0.74      1326\n",
      "        weighted avg       0.71      0.81      0.75      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 22.041595458984375\n",
      "Samples above threshold: 345\n",
      "Acquired samples: 345\n",
      "Sampling duration: 12.391844987869263 seconds\n",
      "New train size: 3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='1960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/1960 07:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.337693</td>\n",
       "      <td>0.594855</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0.337104</td>\n",
       "      <td>0.489595</td>\n",
       "      <td>0.396421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.264855</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.716075</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.744843</td>\n",
       "      <td>0.730915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.179300</td>\n",
       "      <td>0.267459</td>\n",
       "      <td>0.673312</td>\n",
       "      <td>0.705726</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.749646</td>\n",
       "      <td>0.738766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.179300</td>\n",
       "      <td>0.266823</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.768791</td>\n",
       "      <td>0.709653</td>\n",
       "      <td>0.738039</td>\n",
       "      <td>0.723255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.179300</td>\n",
       "      <td>0.286420</td>\n",
       "      <td>0.679100</td>\n",
       "      <td>0.726579</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.756776</td>\n",
       "      <td>0.745037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.085600</td>\n",
       "      <td>0.307254</td>\n",
       "      <td>0.680386</td>\n",
       "      <td>0.716099</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.759476</td>\n",
       "      <td>0.753157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.085600</td>\n",
       "      <td>0.300640</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.748154</td>\n",
       "      <td>0.763952</td>\n",
       "      <td>0.755970</td>\n",
       "      <td>0.743328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>0.317711</td>\n",
       "      <td>0.688103</td>\n",
       "      <td>0.731175</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.756462</td>\n",
       "      <td>0.745790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>0.317852</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.743608</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.755473</td>\n",
       "      <td>0.744372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>0.325449</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.737179</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.758242</td>\n",
       "      <td>0.747780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       362\n",
      "                sara       0.62      0.61      0.62       237\n",
      "         radikalisme       0.71      0.81      0.76       235\n",
      "pencemaran_nama_baik       0.63      0.84      0.72       492\n",
      "\n",
      "           micro avg       0.72      0.81      0.76      1326\n",
      "           macro avg       0.73      0.79      0.75      1326\n",
      "        weighted avg       0.73      0.81      0.76      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3122: Accuracy: 0.6803858520900321, F1 Micro: 0.7594757350336521, F1 Macro: 0.7531574538203383\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       362\n",
      "                sara       0.62      0.61      0.62       237\n",
      "         radikalisme       0.71      0.81      0.76       235\n",
      "pencemaran_nama_baik       0.63      0.84      0.72       492\n",
      "\n",
      "           micro avg       0.72      0.81      0.76      1326\n",
      "           macro avg       0.73      0.79      0.75      1326\n",
      "        weighted avg       0.73      0.81      0.76      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 21.46354389190674\n",
      "Samples above threshold: 310\n",
      "Acquired samples: 310\n",
      "Sampling duration: 11.144921064376831 seconds\n",
      "New train size: 3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2150/2150 07:32, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.305319</td>\n",
       "      <td>0.583923</td>\n",
       "      <td>0.772464</td>\n",
       "      <td>0.401961</td>\n",
       "      <td>0.528770</td>\n",
       "      <td>0.415425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.261149</td>\n",
       "      <td>0.681672</td>\n",
       "      <td>0.782108</td>\n",
       "      <td>0.665913</td>\n",
       "      <td>0.719348</td>\n",
       "      <td>0.706097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.193700</td>\n",
       "      <td>0.254260</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.752600</td>\n",
       "      <td>0.763952</td>\n",
       "      <td>0.758234</td>\n",
       "      <td>0.746675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.193700</td>\n",
       "      <td>0.259355</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.740129</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.758367</td>\n",
       "      <td>0.749375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.285300</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.715872</td>\n",
       "      <td>0.826546</td>\n",
       "      <td>0.767238</td>\n",
       "      <td>0.764425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.314697</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.705031</td>\n",
       "      <td>0.845400</td>\n",
       "      <td>0.768861</td>\n",
       "      <td>0.767707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>0.295251</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.750366</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.761516</td>\n",
       "      <td>0.752072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>0.318868</td>\n",
       "      <td>0.686817</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.765248</td>\n",
       "      <td>0.760874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>0.320395</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.738279</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.765880</td>\n",
       "      <td>0.761684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.320747</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.740845</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.766205</td>\n",
       "      <td>0.760561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.90       362\n",
      "                sara       0.61      0.71      0.66       237\n",
      "         radikalisme       0.70      0.89      0.78       235\n",
      "pencemaran_nama_baik       0.64      0.85      0.73       492\n",
      "\n",
      "           micro avg       0.71      0.85      0.77      1326\n",
      "           macro avg       0.71      0.84      0.77      1326\n",
      "        weighted avg       0.72      0.85      0.77      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3432: Accuracy: 0.682315112540193, F1 Micro: 0.7688614540466392, F1 Macro: 0.7677069924958002\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.90       362\n",
      "                sara       0.61      0.71      0.66       237\n",
      "         radikalisme       0.70      0.89      0.78       235\n",
      "pencemaran_nama_baik       0.64      0.85      0.73       492\n",
      "\n",
      "           micro avg       0.71      0.85      0.77      1326\n",
      "           macro avg       0.71      0.84      0.77      1326\n",
      "        weighted avg       0.72      0.85      0.77      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 20.314455032348633\n",
      "Samples above threshold: 279\n",
      "Acquired samples: 279\n",
      "Sampling duration: 9.942038536071777 seconds\n",
      "New train size: 3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2320/2320 08:04, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.285125</td>\n",
       "      <td>0.609646</td>\n",
       "      <td>0.830216</td>\n",
       "      <td>0.435143</td>\n",
       "      <td>0.571004</td>\n",
       "      <td>0.488491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.239230</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.781276</td>\n",
       "      <td>0.711161</td>\n",
       "      <td>0.744572</td>\n",
       "      <td>0.732297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.206900</td>\n",
       "      <td>0.238312</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.783103</td>\n",
       "      <td>0.726998</td>\n",
       "      <td>0.754009</td>\n",
       "      <td>0.740985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.206900</td>\n",
       "      <td>0.270473</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.713465</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.772900</td>\n",
       "      <td>0.769046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.108400</td>\n",
       "      <td>0.268980</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.763514</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.765237</td>\n",
       "      <td>0.754862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.108400</td>\n",
       "      <td>0.278441</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.752525</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.769174</td>\n",
       "      <td>0.761264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.069400</td>\n",
       "      <td>0.299765</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.738179</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.762669</td>\n",
       "      <td>0.750888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.069400</td>\n",
       "      <td>0.294076</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.761481</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.768311</td>\n",
       "      <td>0.758948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>0.314721</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.745533</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.765505</td>\n",
       "      <td>0.754478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>0.316014</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.746818</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.762975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.60      0.70      0.64       237\n",
      "         radikalisme       0.71      0.87      0.78       235\n",
      "pencemaran_nama_baik       0.65      0.86      0.74       492\n",
      "\n",
      "           micro avg       0.71      0.84      0.77      1326\n",
      "           macro avg       0.72      0.83      0.77      1326\n",
      "        weighted avg       0.73      0.84      0.78      1326\n",
      "         samples avg       0.46      0.48      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3711: Accuracy: 0.6938906752411576, F1 Micro: 0.7729001036985828, F1 Macro: 0.7690459303281029\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.60      0.70      0.64       237\n",
      "         radikalisme       0.71      0.87      0.78       235\n",
      "pencemaran_nama_baik       0.65      0.86      0.74       492\n",
      "\n",
      "           micro avg       0.71      0.84      0.77      1326\n",
      "           macro avg       0.72      0.83      0.77      1326\n",
      "        weighted avg       0.73      0.84      0.78      1326\n",
      "         samples avg       0.46      0.48      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 20.01470375061035\n",
      "Samples above threshold: 251\n",
      "Acquired samples: 175\n",
      "Sampling duration: 9.129427671432495 seconds\n",
      "New train size: 3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2430' max='2430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2430/2430 08:23, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.286603</td>\n",
       "      <td>0.609646</td>\n",
       "      <td>0.826399</td>\n",
       "      <td>0.434389</td>\n",
       "      <td>0.569451</td>\n",
       "      <td>0.475345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.245838</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.726018</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.758198</td>\n",
       "      <td>0.747459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.216700</td>\n",
       "      <td>0.235923</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.774713</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.768529</td>\n",
       "      <td>0.762701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.216700</td>\n",
       "      <td>0.262805</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.723702</td>\n",
       "      <td>0.819759</td>\n",
       "      <td>0.768741</td>\n",
       "      <td>0.767772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.115900</td>\n",
       "      <td>0.295531</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.708701</td>\n",
       "      <td>0.847662</td>\n",
       "      <td>0.771978</td>\n",
       "      <td>0.770998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.115900</td>\n",
       "      <td>0.299922</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.724917</td>\n",
       "      <td>0.822775</td>\n",
       "      <td>0.770752</td>\n",
       "      <td>0.764950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0.308216</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.732606</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.769341</td>\n",
       "      <td>0.766846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0.310254</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.758160</td>\n",
       "      <td>0.747866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>0.326400</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.732267</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.761939</td>\n",
       "      <td>0.755129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>0.323881</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.743790</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.766362</td>\n",
       "      <td>0.760711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.89      0.91       362\n",
      "                sara       0.58      0.79      0.67       237\n",
      "         radikalisme       0.67      0.87      0.76       235\n",
      "pencemaran_nama_baik       0.66      0.84      0.74       492\n",
      "\n",
      "           micro avg       0.71      0.85      0.77      1326\n",
      "           macro avg       0.72      0.85      0.77      1326\n",
      "        weighted avg       0.73      0.85      0.78      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3886: Accuracy: 0.6977491961414791, F1 Micro: 0.7719780219780219, F1 Macro: 0.77099829712646\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.89      0.91       362\n",
      "                sara       0.58      0.79      0.67       237\n",
      "         radikalisme       0.67      0.87      0.76       235\n",
      "pencemaran_nama_baik       0.66      0.84      0.74       492\n",
      "\n",
      "           micro avg       0.71      0.85      0.77      1326\n",
      "           macro avg       0.72      0.85      0.77      1326\n",
      "        weighted avg       0.73      0.85      0.78      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 20.29145755767822\n",
      "Samples above threshold: 234\n",
      "Acquired samples: 234\n",
      "Sampling duration: 8.337588548660278 seconds\n",
      "New train size: 4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 08:47, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.264519</td>\n",
       "      <td>0.659807</td>\n",
       "      <td>0.805815</td>\n",
       "      <td>0.585219</td>\n",
       "      <td>0.678025</td>\n",
       "      <td>0.611635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.213900</td>\n",
       "      <td>0.241520</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.786318</td>\n",
       "      <td>0.702112</td>\n",
       "      <td>0.741833</td>\n",
       "      <td>0.715342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.213900</td>\n",
       "      <td>0.249462</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.742165</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.763370</td>\n",
       "      <td>0.751997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.120500</td>\n",
       "      <td>0.257680</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.757463</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.761440</td>\n",
       "      <td>0.749966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.120500</td>\n",
       "      <td>0.284970</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.735913</td>\n",
       "      <td>0.817496</td>\n",
       "      <td>0.774562</td>\n",
       "      <td>0.768385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.292320</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.734948</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.766510</td>\n",
       "      <td>0.760848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.309123</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.745931</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.769624</td>\n",
       "      <td>0.762022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>0.320262</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.748212</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.767988</td>\n",
       "      <td>0.761926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>0.327361</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.751601</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.773343</td>\n",
       "      <td>0.766668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.035700</td>\n",
       "      <td>0.330687</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.745954</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.771751</td>\n",
       "      <td>0.766347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.88      0.91       362\n",
      "                sara       0.64      0.65      0.64       237\n",
      "         radikalisme       0.72      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.67      0.85      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.82      0.77      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.82      0.78      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4120: Accuracy: 0.7009646302250804, F1 Micro: 0.7745623436941764, F1 Macro: 0.7683852899703885\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.88      0.91       362\n",
      "                sara       0.64      0.65      0.64       237\n",
      "         radikalisme       0.72      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.67      0.85      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.82      0.77      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.82      0.78      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 19.321107864379883\n",
      "Samples above threshold: 210\n",
      "Acquired samples: 210\n",
      "Sampling duration: 7.643132925033569 seconds\n",
      "New train size: 4330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2710' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2710/2710 09:16, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.268761</td>\n",
       "      <td>0.676527</td>\n",
       "      <td>0.719606</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.744998</td>\n",
       "      <td>0.729980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.225800</td>\n",
       "      <td>0.240383</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.806540</td>\n",
       "      <td>0.669683</td>\n",
       "      <td>0.731768</td>\n",
       "      <td>0.711346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.225800</td>\n",
       "      <td>0.234919</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.769641</td>\n",
       "      <td>0.760935</td>\n",
       "      <td>0.765264</td>\n",
       "      <td>0.751175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.131600</td>\n",
       "      <td>0.248648</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.753034</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.773744</td>\n",
       "      <td>0.766487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.131600</td>\n",
       "      <td>0.269104</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.816742</td>\n",
       "      <td>0.776622</td>\n",
       "      <td>0.774436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>0.297242</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.729694</td>\n",
       "      <td>0.826546</td>\n",
       "      <td>0.775106</td>\n",
       "      <td>0.772171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>0.300860</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.741777</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.769510</td>\n",
       "      <td>0.764943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.056900</td>\n",
       "      <td>0.301053</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.768171</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>0.762628</td>\n",
       "      <td>0.750927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.056900</td>\n",
       "      <td>0.332804</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.724850</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.769721</td>\n",
       "      <td>0.767388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.042800</td>\n",
       "      <td>0.327818</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.738832</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.773103</td>\n",
       "      <td>0.769744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.97      0.88      0.92       362\n",
      "                sara       0.61      0.73      0.67       237\n",
      "         radikalisme       0.70      0.85      0.77       235\n",
      "pencemaran_nama_baik       0.69      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.82      0.78      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.82      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4330: Accuracy: 0.715112540192926, F1 Micro: 0.7766224453209034, F1 Macro: 0.7744361270470002\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.97      0.88      0.92       362\n",
      "                sara       0.61      0.73      0.67       237\n",
      "         radikalisme       0.70      0.85      0.77       235\n",
      "pencemaran_nama_baik       0.69      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.82      0.78      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.82      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 19.567958641052247\n",
      "Samples above threshold: 189\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.9065821170806885 seconds\n",
      "New train size: 4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2840' max='2840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2840/2840 09:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.274823</td>\n",
       "      <td>0.652733</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.485671</td>\n",
       "      <td>0.620723</td>\n",
       "      <td>0.549437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.233700</td>\n",
       "      <td>0.246532</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.794826</td>\n",
       "      <td>0.671946</td>\n",
       "      <td>0.728239</td>\n",
       "      <td>0.720465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.233700</td>\n",
       "      <td>0.247496</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.761406</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.764551</td>\n",
       "      <td>0.752347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.138500</td>\n",
       "      <td>0.254469</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.732974</td>\n",
       "      <td>0.819759</td>\n",
       "      <td>0.773941</td>\n",
       "      <td>0.768889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.138500</td>\n",
       "      <td>0.278006</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.735532</td>\n",
       "      <td>0.824284</td>\n",
       "      <td>0.777383</td>\n",
       "      <td>0.768169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.094500</td>\n",
       "      <td>0.289884</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.743802</td>\n",
       "      <td>0.814480</td>\n",
       "      <td>0.777538</td>\n",
       "      <td>0.770747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.094500</td>\n",
       "      <td>0.294640</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.748081</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.777093</td>\n",
       "      <td>0.772083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.060900</td>\n",
       "      <td>0.308721</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.747546</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.774709</td>\n",
       "      <td>0.768192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.316271</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.754436</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.777331</td>\n",
       "      <td>0.770201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.329123</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.735913</td>\n",
       "      <td>0.817496</td>\n",
       "      <td>0.774562</td>\n",
       "      <td>0.768757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.91       362\n",
      "                sara       0.61      0.68      0.65       237\n",
      "         radikalisme       0.72      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.81      0.78      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4530: Accuracy: 0.7144694533762058, F1 Micro: 0.7775377969762418, F1 Macro: 0.7707473424541633\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.91       362\n",
      "                sara       0.61      0.68      0.65       237\n",
      "         radikalisme       0.72      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.81      0.78      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 20.46924934387207\n",
      "Samples above threshold: 169\n",
      "Acquired samples: 133\n",
      "Sampling duration: 6.4248480796813965 seconds\n",
      "New train size: 4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2920' max='2920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2920/2920 09:58, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.661093</td>\n",
       "      <td>0.750399</td>\n",
       "      <td>0.709653</td>\n",
       "      <td>0.729457</td>\n",
       "      <td>0.687002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.240100</td>\n",
       "      <td>0.231787</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.763052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.240100</td>\n",
       "      <td>0.234690</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.763939</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.779461</td>\n",
       "      <td>0.770527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.143900</td>\n",
       "      <td>0.250465</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.751758</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.778020</td>\n",
       "      <td>0.769483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.143900</td>\n",
       "      <td>0.274256</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.841629</td>\n",
       "      <td>0.786469</td>\n",
       "      <td>0.782159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.096100</td>\n",
       "      <td>0.287708</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.737903</td>\n",
       "      <td>0.828054</td>\n",
       "      <td>0.780384</td>\n",
       "      <td>0.773959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.298087</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.740816</td>\n",
       "      <td>0.821267</td>\n",
       "      <td>0.778970</td>\n",
       "      <td>0.772735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.314402</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.739013</td>\n",
       "      <td>0.824284</td>\n",
       "      <td>0.779323</td>\n",
       "      <td>0.773553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.330954</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.724789</td>\n",
       "      <td>0.840121</td>\n",
       "      <td>0.778205</td>\n",
       "      <td>0.775169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.316940</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.757184</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.775570</td>\n",
       "      <td>0.766414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.91      0.92       362\n",
      "                sara       0.63      0.72      0.67       237\n",
      "         radikalisme       0.71      0.87      0.78       235\n",
      "pencemaran_nama_baik       0.68      0.84      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.84      0.79      1326\n",
      "           macro avg       0.74      0.83      0.78      1326\n",
      "        weighted avg       0.75      0.84      0.79      1326\n",
      "         samples avg       0.46      0.48      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4663: Accuracy: 0.7196141479099678, F1 Micro: 0.7864693446088794, F1 Macro: 0.7821589511843442\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.91      0.92       362\n",
      "                sara       0.63      0.72      0.67       237\n",
      "         radikalisme       0.71      0.87      0.78       235\n",
      "pencemaran_nama_baik       0.68      0.84      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.84      0.79      1326\n",
      "           macro avg       0.74      0.83      0.78      1326\n",
      "        weighted avg       0.75      0.84      0.79      1326\n",
      "         samples avg       0.46      0.48      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 19.54924774169922\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.757965087890625 seconds\n",
      "New train size: 4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3040' max='3040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3040/3040 10:17, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.248303</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.778154</td>\n",
       "      <td>0.693062</td>\n",
       "      <td>0.733147</td>\n",
       "      <td>0.720832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.246500</td>\n",
       "      <td>0.231357</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.762787</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.769346</td>\n",
       "      <td>0.751530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.246500</td>\n",
       "      <td>0.236339</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.761216</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.776957</td>\n",
       "      <td>0.770073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.151000</td>\n",
       "      <td>0.265279</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.722861</td>\n",
       "      <td>0.853695</td>\n",
       "      <td>0.782849</td>\n",
       "      <td>0.778199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.108100</td>\n",
       "      <td>0.272458</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.747426</td>\n",
       "      <td>0.821267</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.780182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.108100</td>\n",
       "      <td>0.290981</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.774496</td>\n",
       "      <td>0.766828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.307998</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.743572</td>\n",
       "      <td>0.828808</td>\n",
       "      <td>0.783880</td>\n",
       "      <td>0.777822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.315748</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.743537</td>\n",
       "      <td>0.824284</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.774200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.320503</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.742818</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>0.779053</td>\n",
       "      <td>0.771143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.042300</td>\n",
       "      <td>0.321487</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.746905</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>0.781295</td>\n",
       "      <td>0.775329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.91      0.92       362\n",
      "                sara       0.64      0.69      0.67       237\n",
      "         radikalisme       0.71      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.69      0.84      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.83      0.78      1326\n",
      "           macro avg       0.75      0.82      0.78      1326\n",
      "        weighted avg       0.75      0.83      0.79      1326\n",
      "         samples avg       0.47      0.47      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4863: Accuracy: 0.712540192926045, F1 Micro: 0.7838801711840228, F1 Macro: 0.7778219395544442\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.91      0.92       362\n",
      "                sara       0.64      0.69      0.67       237\n",
      "         radikalisme       0.71      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.69      0.84      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.83      0.78      1326\n",
      "           macro avg       0.75      0.82      0.78      1326\n",
      "        weighted avg       0.75      0.83      0.79      1326\n",
      "         samples avg       0.47      0.47      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 19.358652114868164\n",
      "Samples above threshold: 136\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.02797532081604 seconds\n",
      "New train size: 5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3170' max='3170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3170/3170 10:31, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.244462</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.775244</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.745497</td>\n",
       "      <td>0.728590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.252500</td>\n",
       "      <td>0.232953</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.748775</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.776770</td>\n",
       "      <td>0.768871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.252500</td>\n",
       "      <td>0.239255</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.745324</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.762887</td>\n",
       "      <td>0.755874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.161000</td>\n",
       "      <td>0.244595</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.763494</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.786394</td>\n",
       "      <td>0.776540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.113300</td>\n",
       "      <td>0.269883</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.734448</td>\n",
       "      <td>0.828054</td>\n",
       "      <td>0.778447</td>\n",
       "      <td>0.771373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.113300</td>\n",
       "      <td>0.284140</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.742916</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.775334</td>\n",
       "      <td>0.766490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.079300</td>\n",
       "      <td>0.291468</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.764020</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.777325</td>\n",
       "      <td>0.768746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.308282</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.754411</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.779439</td>\n",
       "      <td>0.773012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.326500</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.738079</td>\n",
       "      <td>0.828808</td>\n",
       "      <td>0.780817</td>\n",
       "      <td>0.775317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.045300</td>\n",
       "      <td>0.321538</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.750870</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.781035</td>\n",
       "      <td>0.774717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.67      0.64      0.65       237\n",
      "         radikalisme       0.73      0.82      0.77       235\n",
      "pencemaran_nama_baik       0.71      0.82      0.76       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5063: Accuracy: 0.7209003215434083, F1 Micro: 0.7863935625457206, F1 Macro: 0.776540471074806\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.67      0.64      0.65       237\n",
      "         radikalisme       0.73      0.82      0.77       235\n",
      "pencemaran_nama_baik       0.71      0.82      0.76       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 18.079985427856446\n",
      "Samples above threshold: 116\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.244022369384766 seconds\n",
      "New train size: 5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3290' max='3290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3290/3290 10:49, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.249045</td>\n",
       "      <td>0.672669</td>\n",
       "      <td>0.834208</td>\n",
       "      <td>0.599548</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.657607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.262600</td>\n",
       "      <td>0.232443</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.752475</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.776642</td>\n",
       "      <td>0.768524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.262600</td>\n",
       "      <td>0.221977</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.793130</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.779440</td>\n",
       "      <td>0.770040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.241721</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.781155</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.778198</td>\n",
       "      <td>0.771595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.120800</td>\n",
       "      <td>0.256209</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.752606</td>\n",
       "      <td>0.816742</td>\n",
       "      <td>0.783363</td>\n",
       "      <td>0.774875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.120800</td>\n",
       "      <td>0.275725</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.754533</td>\n",
       "      <td>0.815988</td>\n",
       "      <td>0.784058</td>\n",
       "      <td>0.779582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.087700</td>\n",
       "      <td>0.304416</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.741604</td>\n",
       "      <td>0.815988</td>\n",
       "      <td>0.777020</td>\n",
       "      <td>0.767999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.306134</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.753357</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.777818</td>\n",
       "      <td>0.769796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.321798</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>0.824284</td>\n",
       "      <td>0.781552</td>\n",
       "      <td>0.776348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.317718</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.751943</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.776359</td>\n",
       "      <td>0.767535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.97      0.89      0.93       362\n",
      "                sara       0.59      0.73      0.66       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.75      0.81      0.78      1326\n",
      "        weighted avg       0.77      0.82      0.79      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5263: Accuracy: 0.7157556270096463, F1 Micro: 0.7840579710144927, F1 Macro: 0.7795816574804101\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.97      0.89      0.93       362\n",
      "                sara       0.59      0.73      0.66       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.75      0.81      0.78      1326\n",
      "        weighted avg       0.77      0.82      0.79      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 18.77902641296387\n",
      "Samples above threshold: 96\n",
      "Acquired samples: 178\n",
      "Sampling duration: 3.7901928424835205 seconds\n",
      "New train size: 5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3410' max='3410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3410/3410 11:24, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.242958</td>\n",
       "      <td>0.686817</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.659879</td>\n",
       "      <td>0.724338</td>\n",
       "      <td>0.705162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.269800</td>\n",
       "      <td>0.228862</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.787589</td>\n",
       "      <td>0.746606</td>\n",
       "      <td>0.766551</td>\n",
       "      <td>0.759787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.231656</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.808848</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.767829</td>\n",
       "      <td>0.752131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.233883</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.779739</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.758262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.260243</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.745480</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.775687</td>\n",
       "      <td>0.769937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.275790</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.749826</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.780470</td>\n",
       "      <td>0.774318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.291721</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.752999</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.777980</td>\n",
       "      <td>0.770714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.311988</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.818250</td>\n",
       "      <td>0.776109</td>\n",
       "      <td>0.770262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.315659</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.748782</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.778864</td>\n",
       "      <td>0.771582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.317291</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.751938</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.777413</td>\n",
       "      <td>0.771064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.92      0.92       362\n",
      "                sara       0.63      0.67      0.65       237\n",
      "         radikalisme       0.74      0.82      0.78       235\n",
      "pencemaran_nama_baik       0.69      0.80      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5441: Accuracy: 0.7138263665594855, F1 Micro: 0.7804701627486437, F1 Macro: 0.7743178059013909\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.92      0.92       362\n",
      "                sara       0.63      0.67      0.65       237\n",
      "         radikalisme       0.74      0.82      0.78       235\n",
      "pencemaran_nama_baik       0.69      0.80      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 17.678473663330077\n",
      "Samples above threshold: 78\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.0581915378570557 seconds\n",
      "New train size: 5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3530' max='3530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3530/3530 11:44, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.254129</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.819980</td>\n",
       "      <td>0.625189</td>\n",
       "      <td>0.709457</td>\n",
       "      <td>0.686683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.277200</td>\n",
       "      <td>0.235269</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.751226</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.778787</td>\n",
       "      <td>0.774449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.181100</td>\n",
       "      <td>0.231993</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.760200</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.780022</td>\n",
       "      <td>0.772011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.181100</td>\n",
       "      <td>0.235933</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.770241</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.783092</td>\n",
       "      <td>0.775767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.246629</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.794304</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>0.775290</td>\n",
       "      <td>0.767010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>0.268305</td>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.791894</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.778842</td>\n",
       "      <td>0.768675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>0.292269</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.740163</td>\n",
       "      <td>0.822775</td>\n",
       "      <td>0.779286</td>\n",
       "      <td>0.774837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.302072</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.748257</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.777536</td>\n",
       "      <td>0.770605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>0.302960</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.755977</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.782387</td>\n",
       "      <td>0.777351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>0.310391</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.753695</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.779760</td>\n",
       "      <td>0.773500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.90      0.92       362\n",
      "                sara       0.62      0.69      0.65       237\n",
      "         radikalisme       0.73      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.75      0.76      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5641: Accuracy: 0.7234726688102894, F1 Micro: 0.7830923248053392, F1 Macro: 0.7757672202082376\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.90      0.92       362\n",
      "                sara       0.62      0.69      0.65       237\n",
      "         radikalisme       0.73      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.75      0.76      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 17.052099990844727\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.3230693340301514 seconds\n",
      "New train size: 5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3660' max='3660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3660/3660 12:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.245765</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.739286</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.759354</td>\n",
       "      <td>0.749230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.279300</td>\n",
       "      <td>0.228293</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.802542</td>\n",
       "      <td>0.714178</td>\n",
       "      <td>0.755786</td>\n",
       "      <td>0.746769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.188100</td>\n",
       "      <td>0.227777</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.773599</td>\n",
       "      <td>0.757977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.188100</td>\n",
       "      <td>0.231627</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.765387</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.780938</td>\n",
       "      <td>0.772943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.145400</td>\n",
       "      <td>0.255073</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.773787</td>\n",
       "      <td>0.765860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.104400</td>\n",
       "      <td>0.285242</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.732707</td>\n",
       "      <td>0.822775</td>\n",
       "      <td>0.775133</td>\n",
       "      <td>0.770365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>0.291476</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.750533</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.772777</td>\n",
       "      <td>0.766486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>0.296889</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.758922</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.772138</td>\n",
       "      <td>0.764236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.313983</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.755524</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.776841</td>\n",
       "      <td>0.769367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.048600</td>\n",
       "      <td>0.314133</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.755764</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.773029</td>\n",
       "      <td>0.766669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.92       362\n",
      "                sara       0.62      0.67      0.64       237\n",
      "         radikalisme       0.74      0.82      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5841: Accuracy: 0.715112540192926, F1 Micro: 0.7809383080901368, F1 Macro: 0.7729432484022782\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.92       362\n",
      "                sara       0.62      0.67      0.64       237\n",
      "         radikalisme       0.74      0.82      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 15.9430570602417\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 200\n",
      "Sampling duration: 1.6040830612182617 seconds\n",
      "New train size: 6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3780' max='3780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3780/3780 12:24, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241220</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.793451</td>\n",
       "      <td>0.712670</td>\n",
       "      <td>0.750894</td>\n",
       "      <td>0.745173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.286800</td>\n",
       "      <td>0.222238</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.800987</td>\n",
       "      <td>0.734540</td>\n",
       "      <td>0.766326</td>\n",
       "      <td>0.752811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.191300</td>\n",
       "      <td>0.221446</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.766858</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.786029</td>\n",
       "      <td>0.776456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.151000</td>\n",
       "      <td>0.235832</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.793184</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.782575</td>\n",
       "      <td>0.774609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.151000</td>\n",
       "      <td>0.263562</td>\n",
       "      <td>0.731190</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.837858</td>\n",
       "      <td>0.793005</td>\n",
       "      <td>0.788364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.111400</td>\n",
       "      <td>0.262224</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.783643</td>\n",
       "      <td>0.777714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.274147</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.779456</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.778868</td>\n",
       "      <td>0.772430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.301894</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.750172</td>\n",
       "      <td>0.822021</td>\n",
       "      <td>0.784455</td>\n",
       "      <td>0.780527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.304071</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.764748</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.782769</td>\n",
       "      <td>0.778168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>0.311327</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.763480</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.781745</td>\n",
       "      <td>0.776145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.62      0.74      0.68       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.71      0.82      0.76       492\n",
      "\n",
      "           micro avg       0.75      0.84      0.79      1326\n",
      "           macro avg       0.75      0.83      0.79      1326\n",
      "        weighted avg       0.76      0.84      0.80      1326\n",
      "         samples avg       0.47      0.48      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6041: Accuracy: 0.7311897106109325, F1 Micro: 0.7930049964311205, F1 Macro: 0.78836435871646\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.62      0.74      0.68       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.71      0.82      0.76       492\n",
      "\n",
      "           micro avg       0.75      0.84      0.79      1326\n",
      "           macro avg       0.75      0.83      0.79      1326\n",
      "        weighted avg       0.76      0.84      0.80      1326\n",
      "         samples avg       0.47      0.48      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 14.581657409667969\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 177\n",
      "Sampling duration: 1.1257624626159668 seconds\n",
      "New train size: 6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3890/3890 12:46, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.239204</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.756024</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>0.756594</td>\n",
       "      <td>0.746679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.296100</td>\n",
       "      <td>0.221539</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.786400</td>\n",
       "      <td>0.741327</td>\n",
       "      <td>0.763199</td>\n",
       "      <td>0.753022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.200200</td>\n",
       "      <td>0.236429</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.738160</td>\n",
       "      <td>0.822775</td>\n",
       "      <td>0.778174</td>\n",
       "      <td>0.771569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.159700</td>\n",
       "      <td>0.238722</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.787666</td>\n",
       "      <td>0.760935</td>\n",
       "      <td>0.774070</td>\n",
       "      <td>0.760082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.159700</td>\n",
       "      <td>0.245433</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.776453</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.781109</td>\n",
       "      <td>0.771466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>0.270487</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.761803</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.781938</td>\n",
       "      <td>0.773271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.275160</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.769062</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.779926</td>\n",
       "      <td>0.772661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.294963</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.771956</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.780306</td>\n",
       "      <td>0.769489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.305569</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.764281</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.780362</td>\n",
       "      <td>0.772545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.306267</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.767844</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.785109</td>\n",
       "      <td>0.778222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.92      0.92       362\n",
      "                sara       0.64      0.67      0.65       237\n",
      "         radikalisme       0.75      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6218: Accuracy: 0.7228295819935692, F1 Micro: 0.7851087357169186, F1 Macro: 0.7782218911931085\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.92      0.92       362\n",
      "                sara       0.64      0.67      0.65       237\n",
      "         radikalisme       0.75      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n",
      "Total sampling time: 183.9 seconds\n",
      "Total runtime: 11669.858672380447 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5992938,
     "sourceId": 9782034,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22395.422372,
   "end_time": "2024-12-18T21:48:22.188654",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-18T15:35:06.766282",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "041b17bfaf484382bfefdf5f96d3d0a9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d3bf3d2b580047d59cf6e02e0d052efd",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9fc6ec4a8c244312a4d71dc0c319e5c2",
       "value": 2
      }
     },
     "047d76449c84453086f66664596e4576": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "096723ab9ce944c0b26f26cbd5b5f181": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "108e87483eff4dca8e9f61efe3e2e253": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "150b60233ba2427284985a430a275cd5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "15f4b85a290342fc8e7a2a6bc8e2cb65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_df4d9d10c70c437fa78dd310748c1c63",
       "placeholder": "​",
       "style": "IPY_MODEL_af5b13c47332471bad1299cc8083f6a5",
       "value": " 229k/229k [00:00&lt;00:00, 1.41MB/s]"
      }
     },
     "1b245da7033547259695b21b52a33b93": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2057f066df164746bad12ae7155999a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "257f9a114baf4ccfa6d630404a57a23d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "29b564be03dd49c3818aa684efd8eaae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_546d6f09756d4e3dafea7e9ea67a5037",
       "placeholder": "​",
       "style": "IPY_MODEL_f378d7cb94a54a95b687216bf7252d6e",
       "value": "config.json: 100%"
      }
     },
     "2ba4e70368fd4fbd9baf48f5ea6055e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4877988b05184173b99aa24eef2dbbbc",
       "placeholder": "​",
       "style": "IPY_MODEL_108e87483eff4dca8e9f61efe3e2e253",
       "value": " 2.00/2.00 [00:00&lt;00:00, 198B/s]"
      }
     },
     "2e26f32646e54fe99976871a4a35b0b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_53256ba5a75d4656942dfe47f3930dbd",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7eb2c894e03d4dcca17fe903a52467f9",
       "value": 1534
      }
     },
     "30c8d057a21e4c79b07e51687885eb51": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_669842066ae14f7db78ac6ef006baedb",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3808a3a3bfbe4fb9b6841738b0bdd8e9",
       "value": 112
      }
     },
     "3808a3a3bfbe4fb9b6841738b0bdd8e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3f6def1b1c674a78af751f858f085706": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_438d2b025b0f4d648b55446f41d2c376",
        "IPY_MODEL_5ec8d096e62e465e89292f574efa7d8b",
        "IPY_MODEL_580d5e20d38b40d18f563609a5ea808b"
       ],
       "layout": "IPY_MODEL_047d76449c84453086f66664596e4576"
      }
     },
     "40e42ccdb7c54da7addf142f710d4398": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "438d2b025b0f4d648b55446f41d2c376": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1b245da7033547259695b21b52a33b93",
       "placeholder": "​",
       "style": "IPY_MODEL_40e42ccdb7c54da7addf142f710d4398",
       "value": "pytorch_model.bin: 100%"
      }
     },
     "4555c5e212814eb8b309d1555be3fc41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4877988b05184173b99aa24eef2dbbbc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "53256ba5a75d4656942dfe47f3930dbd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "546d6f09756d4e3dafea7e9ea67a5037": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "54eaa5bd55104d30b20012befd6cf930": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "580d5e20d38b40d18f563609a5ea808b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ccbd7ce7f4fd4711b0f2e3a9afc07021",
       "placeholder": "​",
       "style": "IPY_MODEL_257f9a114baf4ccfa6d630404a57a23d",
       "value": " 498M/498M [00:02&lt;00:00, 223MB/s]"
      }
     },
     "5ec8d096e62e465e89292f574efa7d8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f64db6dd2fda4bf580db821aaa4985f7",
       "max": 497810400,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e0ebd620442e4b62a3bf088bea93198c",
       "value": 497810400
      }
     },
     "669842066ae14f7db78ac6ef006baedb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6dee5648268c4098b9c92ea1e694dc50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7482dfba8dc5418cb2550daac23cb1ad",
        "IPY_MODEL_e2c21e81ccb949e986e492ed4d6d9bc1",
        "IPY_MODEL_15f4b85a290342fc8e7a2a6bc8e2cb65"
       ],
       "layout": "IPY_MODEL_9ca869bca7874761b12b65e1b68d3b37"
      }
     },
     "7096062315a74028a12b154162095780": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7482dfba8dc5418cb2550daac23cb1ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c269799a50764487a00aebca791a0f9c",
       "placeholder": "​",
       "style": "IPY_MODEL_2057f066df164746bad12ae7155999a3",
       "value": "vocab.txt: 100%"
      }
     },
     "7eb2c894e03d4dcca17fe903a52467f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7ed4949047fe4bc5b2fb55e14a45c2e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8640ff9e29e144c29d363544a9d0d6a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "880dcaf3f44941dfa2f6741433bc8f54": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8640ff9e29e144c29d363544a9d0d6a4",
       "placeholder": "​",
       "style": "IPY_MODEL_096723ab9ce944c0b26f26cbd5b5f181",
       "value": " 1.53k/1.53k [00:00&lt;00:00, 150kB/s]"
      }
     },
     "8fc9d04fc6b64b8bb96a1be2726d99c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c32874f12c724706847d844880e18511",
        "IPY_MODEL_041b17bfaf484382bfefdf5f96d3d0a9",
        "IPY_MODEL_2ba4e70368fd4fbd9baf48f5ea6055e0"
       ],
       "layout": "IPY_MODEL_4555c5e212814eb8b309d1555be3fc41"
      }
     },
     "8ff787ad6c574526b15b16d352f37e75": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9928cf37391948cd8ebf9edd873967b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9ca869bca7874761b12b65e1b68d3b37": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9e6648ea4abe4a0eb4d2302086bb7d6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f95dac889bbf4cd28d39e9f72295adfb",
        "IPY_MODEL_30c8d057a21e4c79b07e51687885eb51",
        "IPY_MODEL_a123ce9f51bc4f5ca4c9046c05b5f385"
       ],
       "layout": "IPY_MODEL_b4af16f5e9974ba2bf627b6c2c586f8e"
      }
     },
     "9fc6ec4a8c244312a4d71dc0c319e5c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a123ce9f51bc4f5ca4c9046c05b5f385": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9928cf37391948cd8ebf9edd873967b9",
       "placeholder": "​",
       "style": "IPY_MODEL_7ed4949047fe4bc5b2fb55e14a45c2e0",
       "value": " 112/112 [00:00&lt;00:00, 10.6kB/s]"
      }
     },
     "af5b13c47332471bad1299cc8083f6a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b4af16f5e9974ba2bf627b6c2c586f8e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c269799a50764487a00aebca791a0f9c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c32874f12c724706847d844880e18511": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_150b60233ba2427284985a430a275cd5",
       "placeholder": "​",
       "style": "IPY_MODEL_c9c54bf41cef401ca549187016f40c0f",
       "value": "tokenizer_config.json: 100%"
      }
     },
     "c9c54bf41cef401ca549187016f40c0f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ccbd7ce7f4fd4711b0f2e3a9afc07021": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d3bf3d2b580047d59cf6e02e0d052efd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d907d32c05dd44f2ab97d04430b30079": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "df4d9d10c70c437fa78dd310748c1c63": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e0ebd620442e4b62a3bf088bea93198c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e2c21e81ccb949e986e492ed4d6d9bc1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d907d32c05dd44f2ab97d04430b30079",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e7ee362dcd8f4cb98c067bf68413e269",
       "value": 229167
      }
     },
     "e7ee362dcd8f4cb98c067bf68413e269": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ee5d1ee199d74961a4aa93c827c7eaa8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_29b564be03dd49c3818aa684efd8eaae",
        "IPY_MODEL_2e26f32646e54fe99976871a4a35b0b4",
        "IPY_MODEL_880dcaf3f44941dfa2f6741433bc8f54"
       ],
       "layout": "IPY_MODEL_7096062315a74028a12b154162095780"
      }
     },
     "f378d7cb94a54a95b687216bf7252d6e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f64db6dd2fda4bf580db821aaa4985f7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f95dac889bbf4cd28d39e9f72295adfb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8ff787ad6c574526b15b16d352f37e75",
       "placeholder": "​",
       "style": "IPY_MODEL_54eaa5bd55104d30b20012befd6cf930",
       "value": "special_tokens_map.json: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
