{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "664d0231",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T03:26:55.071144Z",
     "iopub.status.busy": "2024-12-21T03:26:55.070868Z",
     "iopub.status.idle": "2024-12-21T03:27:14.641127Z",
     "shell.execute_reply": "2024-12-21T03:27:14.640425Z"
    },
    "papermill": {
     "duration": 19.578034,
     "end_time": "2024-12-21T03:27:14.643189",
     "exception": false,
     "start_time": "2024-12-21T03:26:55.065155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import wandb\n",
    "import random\n",
    "import math\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13ecae9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T03:27:14.653381Z",
     "iopub.status.busy": "2024-12-21T03:27:14.652835Z",
     "iopub.status.idle": "2024-12-21T03:27:15.640349Z",
     "shell.execute_reply": "2024-12-21T03:27:15.639556Z"
    },
    "papermill": {
     "duration": 0.994578,
     "end_time": "2024-12-21T03:27:15.642388",
     "exception": false,
     "start_time": "2024-12-21T03:27:14.647810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "secret_value_0 = user_secrets.get_secret(\"wandb\")\n",
    "\n",
    "wandb.login(key=secret_value_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5cefee6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T03:27:15.653481Z",
     "iopub.status.busy": "2024-12-21T03:27:15.653226Z",
     "iopub.status.idle": "2024-12-21T03:27:15.657355Z",
     "shell.execute_reply": "2024-12-21T03:27:15.656553Z"
    },
    "papermill": {
     "duration": 0.011978,
     "end_time": "2024-12-21T03:27:15.658952",
     "exception": false,
     "start_time": "2024-12-21T03:27:15.646974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e103b13a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T03:27:15.668324Z",
     "iopub.status.busy": "2024-12-21T03:27:15.668059Z",
     "iopub.status.idle": "2024-12-21T03:27:15.826371Z",
     "shell.execute_reply": "2024-12-21T03:27:15.825577Z"
    },
    "papermill": {
     "duration": 0.164946,
     "end_time": "2024-12-21T03:27:15.828146",
     "exception": false,
     "start_time": "2024-12-21T03:27:15.663200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7773, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/netifier/processed_train.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/netifier/processed_test.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data], ignore_index=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a14af295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T03:27:15.838864Z",
     "iopub.status.busy": "2024-12-21T03:27:15.838586Z",
     "iopub.status.idle": "2024-12-21T03:27:15.853433Z",
     "shell.execute_reply": "2024-12-21T03:27:15.852641Z"
    },
    "papermill": {
     "duration": 0.022002,
     "end_time": "2024-12-21T03:27:15.855065",
     "exception": false,
     "start_time": "2024-12-21T03:27:15.833063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>source</th>\n",
       "      <th>pornografi</th>\n",
       "      <th>sara</th>\n",
       "      <th>radikalisme</th>\n",
       "      <th>pencemaran_nama_baik</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[QUOTE=jessepinkman16;5a50ac34d89b093f368b456e...</td>\n",
       "      <td>kaskus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>jabar memang provinsi barokah boleh juga dan n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@verosvante kita2 aja nitizen yang pada kepo,t...</td>\n",
       "      <td>instagram</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kita saja nitizen yang pada penasaran toh kelu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"#SidangAhok smg sipenista agama n ateknya mat...</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sidangahok semoga sipenista agama dan ateknya ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@bolususulembang.jkt barusan baca undang2 ini....</td>\n",
       "      <td>instagram</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jakarta barusan baca undang ini tetap dibedaka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bikin anak mulu lu nof \\nkaga mikir apa kasian...</td>\n",
       "      <td>kaskus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>buat anak melulu kamu nof nkaga mikir apa kasi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text     source  pornografi  \\\n",
       "0  [QUOTE=jessepinkman16;5a50ac34d89b093f368b456e...     kaskus           0   \n",
       "1  @verosvante kita2 aja nitizen yang pada kepo,t...  instagram           0   \n",
       "2  \"#SidangAhok smg sipenista agama n ateknya mat...    twitter           0   \n",
       "3  @bolususulembang.jkt barusan baca undang2 ini....  instagram           0   \n",
       "4  bikin anak mulu lu nof \\nkaga mikir apa kasian...     kaskus           0   \n",
       "\n",
       "   sara  radikalisme  pencemaran_nama_baik  \\\n",
       "0     0            0                     1   \n",
       "1     0            0                     0   \n",
       "2     1            1                     1   \n",
       "3     0            0                     0   \n",
       "4     0            0                     0   \n",
       "\n",
       "                                      processed_text  \n",
       "0  jabar memang provinsi barokah boleh juga dan n...  \n",
       "1  kita saja nitizen yang pada penasaran toh kelu...  \n",
       "2  sidangahok semoga sipenista agama dan ateknya ...  \n",
       "3  jakarta barusan baca undang ini tetap dibedaka...  \n",
       "4  buat anak melulu kamu nof nkaga mikir apa kasi...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55c94411",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T03:27:15.865068Z",
     "iopub.status.busy": "2024-12-21T03:27:15.864805Z",
     "iopub.status.idle": "2024-12-21T03:27:15.873439Z",
     "shell.execute_reply": "2024-12-21T03:27:15.872581Z"
    },
    "papermill": {
     "duration": 0.015435,
     "end_time": "2024-12-21T03:27:15.875081",
     "exception": false,
     "start_time": "2024-12-21T03:27:15.859646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c864ba3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T03:27:15.885105Z",
     "iopub.status.busy": "2024-12-21T03:27:15.884646Z",
     "iopub.status.idle": "2024-12-21T03:27:15.892620Z",
     "shell.execute_reply": "2024-12-21T03:27:15.891873Z"
    },
    "papermill": {
     "duration": 0.015426,
     "end_time": "2024-12-21T03:27:15.894907",
     "exception": false,
     "start_time": "2024-12-21T03:27:15.879481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6218,) (6218, 4)\n",
      "(1555,) (1555, 4)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[2:6]\n",
    "val_labels = val_data.columns[2:6]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['processed_text'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['processed_text'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9062bbac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T03:27:15.905803Z",
     "iopub.status.busy": "2024-12-21T03:27:15.905259Z",
     "iopub.status.idle": "2024-12-21T03:27:17.275055Z",
     "shell.execute_reply": "2024-12-21T03:27:17.274239Z"
    },
    "papermill": {
     "duration": 1.377049,
     "end_time": "2024-12-21T03:27:17.276948",
     "exception": false,
     "start_time": "2024-12-21T03:27:15.899899",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53a86a36e234010b5651f947a60ec8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c990d4b987f407ea7df8a8c1c455d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dffece0c42c4a1f9c22a2b85e409295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19c93727a8b4800908b9bf3fa1569d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Define custom Dataset class\n",
    "class NetifierDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(labels, dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d51d469",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T03:27:17.288751Z",
     "iopub.status.busy": "2024-12-21T03:27:17.288399Z",
     "iopub.status.idle": "2024-12-21T03:27:17.293706Z",
     "shell.execute_reply": "2024-12-21T03:27:17.292821Z"
    },
    "papermill": {
     "duration": 0.012998,
     "end_time": "2024-12-21T03:27:17.295326",
     "exception": false,
     "start_time": "2024-12-21T03:27:17.282328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define compute metrics for evaluation\n",
    "def compute_metrics(p):\n",
    "    preds = torch.sigmoid(torch.tensor(p.predictions)).round()  # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    a, b, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b82cec91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T03:27:17.306164Z",
     "iopub.status.busy": "2024-12-21T03:27:17.305891Z",
     "iopub.status.idle": "2024-12-21T03:27:17.310883Z",
     "shell.execute_reply": "2024-12-21T03:27:17.310231Z"
    },
    "papermill": {
     "duration": 0.012142,
     "end_time": "2024-12-21T03:27:17.312338",
     "exception": false,
     "start_time": "2024-12-21T03:27:17.300196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define compute metrics for evaluation\n",
    "def compute_metrics_eval(p):\n",
    "    result = compute_metrics(p)\n",
    "    \n",
    "    preds = torch.sigmoid(torch.tensor(p.predictions)).round()  # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "    \n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        target_names=['pornografi', 'sara', 'radikalisme', 'pencemaran_nama_baik'],\n",
    "        zero_division=0\n",
    "    )    \n",
    "    return {\n",
    "        'accuracy': result['accuracy'],\n",
    "        'precision': result['precision'],\n",
    "        'recall': result['recall'],\n",
    "        'f1_micro': result['f1_micro'],\n",
    "        'f1_macro': result['f1_macro'],\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c8ba72",
   "metadata": {
    "papermill": {
     "duration": 0.004685,
     "end_time": "2024-12-21T03:27:17.321862",
     "exception": false,
     "start_time": "2024-12-21T03:27:17.317177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ACTIVE LEARNING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "907dd43e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T03:27:17.333027Z",
     "iopub.status.busy": "2024-12-21T03:27:17.332556Z",
     "iopub.status.idle": "2024-12-21T03:27:17.336196Z",
     "shell.execute_reply": "2024-12-21T03:27:17.335434Z"
    },
    "papermill": {
     "duration": 0.010631,
     "end_time": "2024-12-21T03:27:17.337722",
     "exception": false,
     "start_time": "2024-12-21T03:27:17.327091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "f1_micros = []\n",
    "f1_macros = []\n",
    "sampling_dur = []\n",
    "data_used = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b56d3805",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T03:27:17.348612Z",
     "iopub.status.busy": "2024-12-21T03:27:17.347991Z",
     "iopub.status.idle": "2024-12-21T03:27:17.352340Z",
     "shell.execute_reply": "2024-12-21T03:27:17.351678Z"
    },
    "papermill": {
     "duration": 0.011358,
     "end_time": "2024-12-21T03:27:17.353873",
     "exception": false,
     "start_time": "2024-12-21T03:27:17.342515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = 'netifier-kmeans'\n",
    "epochs = 10\n",
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5833d1ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T03:27:17.365078Z",
     "iopub.status.busy": "2024-12-21T03:27:17.364723Z",
     "iopub.status.idle": "2024-12-21T03:27:17.379402Z",
     "shell.execute_reply": "2024-12-21T03:27:17.378744Z"
    },
    "papermill": {
     "duration": 0.02203,
     "end_time": "2024-12-21T03:27:17.380957",
     "exception": false,
     "start_time": "2024-12-21T03:27:17.358927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def kmeans_clustering_sampling(model, X_pool, train_indices, remaining_indices, tokenizer, trials, n_clusters=min_increment):\n",
    "    start_time = time.time()\n",
    "    current_train_size = len(train_indices)\n",
    "    embeddings = []\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    dataset = NetifierDataset(X_pool, np.zeros((len(X_pool), 4)), tokenizer, max_length=80)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=16,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            input_ids = data['input_ids'].to(device)\n",
    "            attention_mask = data['attention_mask'].to(device)\n",
    "            outputs = model.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            hidden_states = outputs.last_hidden_state.mean(dim=1)  # Mean of hidden states for vector representation\n",
    "            embeddings.append(hidden_states.cpu().numpy())\n",
    "    \n",
    "    # Convert embeddings list to numpy array\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    embeddings = np.array(embeddings)\n",
    "    collected_indices = set()  # Initialize set to store selected indices\n",
    "\n",
    "    num_of_candidates = len(embeddings[:math.ceil(0.1 * len(embeddings))])\n",
    "\n",
    "    # Check nearest checkpoint\n",
    "    nearest_cp = 0\n",
    "    arrived_at_cp = False\n",
    "    for cp in checkpoints:\n",
    "        if cp > current_train_size:\n",
    "            nearest_cp = cp\n",
    "            break\n",
    "\n",
    "    # Determine number of clusters\n",
    "    if num_of_candidates <= n_clusters and n_clusters < nearest_cp - current_train_size:\n",
    "        n_clusters = n_clusters\n",
    "    elif num_of_candidates > n_clusters and num_of_candidates < nearest_cp - current_train_size:\n",
    "        n_clusters = num_of_candidates\n",
    "    else:\n",
    "        arrived_at_cp = True\n",
    "        n_clusters = nearest_cp - current_train_size\n",
    "        \n",
    "    kmeans=KMeans(n_clusters=n_clusters, n_init=1)\n",
    "    kmeans.fit(embeddings)\n",
    "\n",
    "    if current_train_size > checkpoints[len(checkpoints)-1] - min_increment:\n",
    "        temp = train_indices.copy()\n",
    "        temp.extend(collected_indices)\n",
    "        \n",
    "        # Save acquired data up to checkpoint\n",
    "        acquired_data = pd.DataFrame({\n",
    "            'processed_text': [X_train[i] for i in temp],\n",
    "            'pornografi': [y_train[i][0] for i in temp],\n",
    "            'sara': [y_train[i][1] for i in temp],\n",
    "            'radikalisme': [y_train[i][2] for i in temp],\n",
    "            'pencemaran_nama_baik': [y_train[i][3] for i in temp],\n",
    "        })\n",
    "\n",
    "        acquired_data.to_csv(f'{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "        end_time = time.time()  # Record the end time\n",
    "        duration = end_time - start_time  # Calculate the duration in seconds\n",
    "        \n",
    "        print(\"Nearest checkpoint:\", nearest_cp)\n",
    "        print(\"Samples above threshold:\", num_of_candidates)\n",
    "        print(\"Acquired samples:\", len(remaining_indices))\n",
    "        print(f\"Sampling duration: {duration} seconds\")\n",
    "        sampling_dur.append(duration)\n",
    "        return remaining_indices\n",
    "    else:\n",
    "        # Get center of each cluster\n",
    "        for cluster_id in range(n_clusters):\n",
    "            # Cluster center and indices of samples in the current cluster\n",
    "            cluster_center = kmeans.cluster_centers_[cluster_id]\n",
    "            cluster_indices = np.where(kmeans.labels_ == cluster_id)[0]  # Indices of samples in the current cluster\n",
    "            \n",
    "            if cluster_indices.size == 0:\n",
    "                # Skip clusters with no members\n",
    "                print(f\"Cluster {cluster_id} has no members, skipping.\")\n",
    "                continue\n",
    "        \n",
    "            # Calculate distances to the cluster center\n",
    "            cluster_distances = np.linalg.norm(embeddings[cluster_indices] - cluster_center, axis=1)\n",
    "            closest_sample_index = cluster_indices[np.argmin(cluster_distances)]  # Closest sample index\n",
    "            collected_indices.add(closest_sample_index)\n",
    "\n",
    "    if arrived_at_cp:\n",
    "        temp = train_indices.copy()\n",
    "        temp.extend(collected_indices)\n",
    "        \n",
    "        # Save acquired data up to checkpoint\n",
    "        acquired_data = pd.DataFrame({\n",
    "            'processed_text': [X_train[i] for i in temp],\n",
    "            'pornografi': [y_train[i][0] for i in temp],\n",
    "            'sara': [y_train[i][1] for i in temp],\n",
    "            'radikalisme': [y_train[i][2] for i in temp],\n",
    "            'pencemaran_nama_baik': [y_train[i][3] for i in temp],\n",
    "        })\n",
    "\n",
    "        acquired_data.to_csv(f'{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "    \n",
    "    end_time = time.time()  # Record the end time\n",
    "    duration = end_time - start_time  # Calculate the duration in seconds\n",
    "    \n",
    "    print(\"Nearest checkpoint:\", nearest_cp)\n",
    "    print(\"Samples above threshold:\", num_of_candidates)\n",
    "    print(\"Acquired samples:\", len(collected_indices))\n",
    "    print(f\"Sampling duration: {duration} seconds\")\n",
    "\n",
    "    sampling_dur.append(duration)\n",
    "    \n",
    "    return [remaining_indices[i] for i in collected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce482a4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T03:27:17.391905Z",
     "iopub.status.busy": "2024-12-21T03:27:17.391683Z",
     "iopub.status.idle": "2024-12-21T03:27:17.399603Z",
     "shell.execute_reply": "2024-12-21T03:27:17.398931Z"
    },
    "papermill": {
     "duration": 0.015366,
     "end_time": "2024-12-21T03:27:17.401239",
     "exception": false,
     "start_time": "2024-12-21T03:27:17.385873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, trials, seed):\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in model.named_parameters():\n",
    "        # Specify the layers you want to freeze (e.g., first 6 layers)\n",
    "        if \"encoder.layer\" in name:\n",
    "            # Extract the layer number safely\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                # Freeze only the first 6 layers\n",
    "                if int(layer_num) < 9:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                # Skip any parameter names that don’t follow the expected format\n",
    "                continue\n",
    "    \n",
    "    # Create Dataset with current training data\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    train_dataset = NetifierDataset(current_X_train, current_y_train, tokenizer, max_length=128)\n",
    "    val_dataset = NetifierDataset(X_val, y_val, tokenizer, max_length=128)\n",
    "    \n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'./results/{filename}-{trials+1}',\n",
    "        eval_strategy=\"epoch\",                    # Evaluate after every epoch\n",
    "        save_strategy=\"epoch\",                    # Save model after every epoch\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=epochs,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='f1_micro',\n",
    "        save_total_limit=1,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate after training\n",
    "    trainer.compute_metrics = compute_metrics_eval\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"Iteration {current_train_size}: Accuracy: {eval_results['eval_accuracy']}, F1 Micro: {eval_results['eval_f1_micro']}, F1 Macro: {eval_results['eval_f1_macro']}\")\n",
    "    print(eval_results['eval_report'])\n",
    "\n",
    "    torch.save(model.state_dict(), f'{filename}-{trials+1}-model.pth')\n",
    "    model.config.to_json_file(f'{filename}-{trials+1}-config.json')\n",
    "\n",
    "    data_used.append(current_train_size)\n",
    "    accuracies.append(eval_results['eval_accuracy'])\n",
    "    f1_micros.append(eval_results['eval_f1_micro'])\n",
    "    f1_macros.append(eval_results['eval_f1_macro'])\n",
    "    \n",
    "    return model, trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64e7c437",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T03:27:17.412015Z",
     "iopub.status.busy": "2024-12-21T03:27:17.411775Z",
     "iopub.status.idle": "2024-12-21T03:27:17.417329Z",
     "shell.execute_reply": "2024-12-21T03:27:17.416656Z"
    },
    "papermill": {
     "duration": 0.01296,
     "end_time": "2024-12-21T03:27:17.419098",
     "exception": false,
     "start_time": "2024-12-21T03:27:17.406138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "006a40bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T03:27:17.430103Z",
     "iopub.status.busy": "2024-12-21T03:27:17.429835Z",
     "iopub.status.idle": "2024-12-21T03:27:17.437683Z",
     "shell.execute_reply": "2024-12-21T03:27:17.437019Z"
    },
    "papermill": {
     "duration": 0.015094,
     "end_time": "2024-12-21T03:27:17.439183",
     "exception": false,
     "start_time": "2024-12-21T03:27:17.424089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    accuracies.clear()\n",
    "    f1_micros.clear()\n",
    "    f1_macros.clear()\n",
    "    sampling_dur.clear()\n",
    "    data_used.clear()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        model, trainer = train_model(current_train_size, train_indices, i, seed)\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = kmeans_clustering_sampling(\n",
    "            model, \n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices,\n",
    "            remaining_indices,\n",
    "            tokenizer, \n",
    "            trials=i,\n",
    "        )\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    model, trainer = train_model(current_train_size, train_indices, i, seed)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time  # Calculate the duration in seconds\n",
    "    \n",
    "    print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    sampling_dur.insert(0, 0)\n",
    "    \n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    \n",
    "    results.to_csv(f'{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6283b4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T03:27:17.449988Z",
     "iopub.status.busy": "2024-12-21T03:27:17.449750Z",
     "iopub.status.idle": "2024-12-21T03:27:17.453383Z",
     "shell.execute_reply": "2024-12-21T03:27:17.452674Z"
    },
    "papermill": {
     "duration": 0.010749,
     "end_time": "2024-12-21T03:27:17.454996",
     "exception": false,
     "start_time": "2024-12-21T03:27:17.444247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd347d9",
   "metadata": {
    "papermill": {
     "duration": 0.004923,
     "end_time": "2024-12-21T03:27:17.464743",
     "exception": false,
     "start_time": "2024-12-21T03:27:17.459820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6406ba3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T03:27:17.475771Z",
     "iopub.status.busy": "2024-12-21T03:27:17.475254Z",
     "iopub.status.idle": "2024-12-21T06:36:03.673803Z",
     "shell.execute_reply": "2024-12-21T06:36:03.672873Z"
    },
    "papermill": {
     "duration": 11326.20592,
     "end_time": "2024-12-21T06:36:03.675558",
     "exception": false,
     "start_time": "2024-12-21T03:27:17.469638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc6501ac34a4dfd8e6be9d53ea525e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnicost918\u001b[0m (\u001b[33mnicost918-petra-christian-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241221_032729-7nm5j4nm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m./results/netifier-kmeans-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/nicost918-petra-christian-university/huggingface\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/nicost918-petra-christian-university/huggingface/runs/7nm5j4nm\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 02:08, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.471070</td>\n",
       "      <td>0.441801</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.019345</td>\n",
       "      <td>0.016121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.408955</td>\n",
       "      <td>0.549839</td>\n",
       "      <td>0.937743</td>\n",
       "      <td>0.181750</td>\n",
       "      <td>0.304485</td>\n",
       "      <td>0.212706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.356134</td>\n",
       "      <td>0.570418</td>\n",
       "      <td>0.760807</td>\n",
       "      <td>0.398190</td>\n",
       "      <td>0.522772</td>\n",
       "      <td>0.458811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.333005</td>\n",
       "      <td>0.578135</td>\n",
       "      <td>0.745169</td>\n",
       "      <td>0.465309</td>\n",
       "      <td>0.572888</td>\n",
       "      <td>0.519570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.328695</td>\n",
       "      <td>0.599357</td>\n",
       "      <td>0.754325</td>\n",
       "      <td>0.493213</td>\n",
       "      <td>0.596443</td>\n",
       "      <td>0.562729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.316878</td>\n",
       "      <td>0.602572</td>\n",
       "      <td>0.734064</td>\n",
       "      <td>0.555807</td>\n",
       "      <td>0.632618</td>\n",
       "      <td>0.600391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.322708</td>\n",
       "      <td>0.605788</td>\n",
       "      <td>0.756849</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.602180</td>\n",
       "      <td>0.576849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.310757</td>\n",
       "      <td>0.618006</td>\n",
       "      <td>0.728030</td>\n",
       "      <td>0.593514</td>\n",
       "      <td>0.653926</td>\n",
       "      <td>0.632917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.310798</td>\n",
       "      <td>0.616720</td>\n",
       "      <td>0.731638</td>\n",
       "      <td>0.585973</td>\n",
       "      <td>0.650754</td>\n",
       "      <td>0.631457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.310642</td>\n",
       "      <td>0.616077</td>\n",
       "      <td>0.733840</td>\n",
       "      <td>0.582202</td>\n",
       "      <td>0.649285</td>\n",
       "      <td>0.630442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.80      0.85       362\n",
      "                sara       0.62      0.32      0.42       237\n",
      "         radikalisme       0.69      0.66      0.68       235\n",
      "pencemaran_nama_baik       0.64      0.54      0.59       492\n",
      "\n",
      "           micro avg       0.73      0.59      0.65      1326\n",
      "           macro avg       0.71      0.58      0.63      1326\n",
      "        weighted avg       0.72      0.59      0.64      1326\n",
      "         samples avg       0.35      0.33      0.33      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 388: Accuracy: 0.6180064308681672, F1 Micro: 0.653926049023681, F1 Macro: 0.6329171582051338\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.80      0.85       362\n",
      "                sara       0.62      0.32      0.42       237\n",
      "         radikalisme       0.69      0.66      0.68       235\n",
      "pencemaran_nama_baik       0.64      0.54      0.59       492\n",
      "\n",
      "           micro avg       0.73      0.59      0.65      1326\n",
      "           macro avg       0.71      0.58      0.63      1326\n",
      "        weighted avg       0.72      0.59      0.64      1326\n",
      "         samples avg       0.35      0.33      0.33      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 583\n",
      "Acquired samples: 583\n",
      "Sampling duration: 23.56547713279724 seconds\n",
      "New train size: 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [610/610 03:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.364405</td>\n",
       "      <td>0.544051</td>\n",
       "      <td>0.798658</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.402707</td>\n",
       "      <td>0.295299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.304867</td>\n",
       "      <td>0.611576</td>\n",
       "      <td>0.781100</td>\n",
       "      <td>0.492459</td>\n",
       "      <td>0.604070</td>\n",
       "      <td>0.590934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.651447</td>\n",
       "      <td>0.738540</td>\n",
       "      <td>0.656109</td>\n",
       "      <td>0.694888</td>\n",
       "      <td>0.685450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.284335</td>\n",
       "      <td>0.659807</td>\n",
       "      <td>0.767841</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.698726</td>\n",
       "      <td>0.679953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.272437</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.739907</td>\n",
       "      <td>0.718703</td>\n",
       "      <td>0.729151</td>\n",
       "      <td>0.716838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.277123</td>\n",
       "      <td>0.664952</td>\n",
       "      <td>0.728302</td>\n",
       "      <td>0.727753</td>\n",
       "      <td>0.728027</td>\n",
       "      <td>0.713019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.276055</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.755645</td>\n",
       "      <td>0.706637</td>\n",
       "      <td>0.730320</td>\n",
       "      <td>0.717224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.283300</td>\n",
       "      <td>0.674598</td>\n",
       "      <td>0.764200</td>\n",
       "      <td>0.669683</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.695395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.284596</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.755483</td>\n",
       "      <td>0.701357</td>\n",
       "      <td>0.727415</td>\n",
       "      <td>0.709325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.286238</td>\n",
       "      <td>0.683601</td>\n",
       "      <td>0.748442</td>\n",
       "      <td>0.724736</td>\n",
       "      <td>0.736398</td>\n",
       "      <td>0.720846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.87      0.88       362\n",
      "                sara       0.64      0.49      0.56       237\n",
      "         radikalisme       0.71      0.78      0.74       235\n",
      "pencemaran_nama_baik       0.71      0.70      0.71       492\n",
      "\n",
      "           micro avg       0.75      0.72      0.74      1326\n",
      "           macro avg       0.74      0.71      0.72      1326\n",
      "        weighted avg       0.75      0.72      0.73      1326\n",
      "         samples avg       0.41      0.41      0.40      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 971: Accuracy: 0.6836012861736335, F1 Micro: 0.7363984674329501, F1 Macro: 0.7208461556505217\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.87      0.88       362\n",
      "                sara       0.64      0.49      0.56       237\n",
      "         radikalisme       0.71      0.78      0.74       235\n",
      "pencemaran_nama_baik       0.71      0.70      0.71       492\n",
      "\n",
      "           micro avg       0.75      0.72      0.74      1326\n",
      "           macro avg       0.74      0.71      0.72      1326\n",
      "        weighted avg       0.75      0.72      0.73      1326\n",
      "         samples avg       0.41      0.41      0.40      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 20.453656673431396 seconds\n",
      "New train size: 1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [940/940 04:06, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.323311</td>\n",
       "      <td>0.589711</td>\n",
       "      <td>0.776159</td>\n",
       "      <td>0.441931</td>\n",
       "      <td>0.563191</td>\n",
       "      <td>0.542374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.279142</td>\n",
       "      <td>0.660450</td>\n",
       "      <td>0.755516</td>\n",
       "      <td>0.645551</td>\n",
       "      <td>0.696218</td>\n",
       "      <td>0.684415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.261769</td>\n",
       "      <td>0.677814</td>\n",
       "      <td>0.766866</td>\n",
       "      <td>0.677225</td>\n",
       "      <td>0.719263</td>\n",
       "      <td>0.710706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266941</td>\n",
       "      <td>0.683601</td>\n",
       "      <td>0.726888</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.751003</td>\n",
       "      <td>0.746485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.262173</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.758674</td>\n",
       "      <td>0.742081</td>\n",
       "      <td>0.750286</td>\n",
       "      <td>0.741196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.266100</td>\n",
       "      <td>0.281247</td>\n",
       "      <td>0.688103</td>\n",
       "      <td>0.723214</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.748379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.266100</td>\n",
       "      <td>0.283805</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.731848</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.749356</td>\n",
       "      <td>0.740513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.266100</td>\n",
       "      <td>0.290623</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.717227</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.750988</td>\n",
       "      <td>0.742833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.266100</td>\n",
       "      <td>0.288310</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.750838</td>\n",
       "      <td>0.740616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.266100</td>\n",
       "      <td>0.290240</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.737221</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.754328</td>\n",
       "      <td>0.745072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.85      0.91      0.88       362\n",
      "                sara       0.62      0.64      0.63       237\n",
      "         radikalisme       0.70      0.82      0.76       235\n",
      "pencemaran_nama_baik       0.69      0.77      0.73       492\n",
      "\n",
      "           micro avg       0.72      0.79      0.76      1326\n",
      "           macro avg       0.72      0.78      0.75      1326\n",
      "        weighted avg       0.72      0.79      0.76      1326\n",
      "         samples avg       0.44      0.45      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1496: Accuracy: 0.6881028938906752, F1 Micro: 0.7570093457943925, F1 Macro: 0.7483792527882581\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.85      0.91      0.88       362\n",
      "                sara       0.62      0.64      0.63       237\n",
      "         radikalisme       0.70      0.82      0.76       235\n",
      "pencemaran_nama_baik       0.69      0.77      0.73       492\n",
      "\n",
      "           micro avg       0.72      0.79      0.76      1326\n",
      "           macro avg       0.72      0.78      0.75      1326\n",
      "        weighted avg       0.72      0.79      0.76      1326\n",
      "         samples avg       0.44      0.45      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 17.497504234313965 seconds\n",
      "New train size: 1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1240' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1240/1240 04:54, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.305580</td>\n",
       "      <td>0.610289</td>\n",
       "      <td>0.721172</td>\n",
       "      <td>0.575415</td>\n",
       "      <td>0.640101</td>\n",
       "      <td>0.636585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.258682</td>\n",
       "      <td>0.678457</td>\n",
       "      <td>0.771084</td>\n",
       "      <td>0.675716</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.708637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250521</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.743929</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.753073</td>\n",
       "      <td>0.746018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.260632</td>\n",
       "      <td>0.688103</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.750838</td>\n",
       "      <td>0.739350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.282900</td>\n",
       "      <td>0.259196</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.759815</td>\n",
       "      <td>0.744344</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.738018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.282900</td>\n",
       "      <td>0.257513</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.764796</td>\n",
       "      <td>0.750377</td>\n",
       "      <td>0.757518</td>\n",
       "      <td>0.747161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.282900</td>\n",
       "      <td>0.268618</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.750742</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.756918</td>\n",
       "      <td>0.746967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.282900</td>\n",
       "      <td>0.286436</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.725730</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.763844</td>\n",
       "      <td>0.758732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.135100</td>\n",
       "      <td>0.283294</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.740186</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.760543</td>\n",
       "      <td>0.751760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.135100</td>\n",
       "      <td>0.282949</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.752036</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.759059</td>\n",
       "      <td>0.749352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.88      0.89       362\n",
      "                sara       0.61      0.67      0.64       237\n",
      "         radikalisme       0.71      0.85      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.80      0.73       492\n",
      "\n",
      "           micro avg       0.73      0.81      0.76      1326\n",
      "           macro avg       0.72      0.80      0.76      1326\n",
      "        weighted avg       0.73      0.81      0.77      1326\n",
      "         samples avg       0.44      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1969: Accuracy: 0.6913183279742765, F1 Micro: 0.7638442300821723, F1 Macro: 0.7587321491375985\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.88      0.89       362\n",
      "                sara       0.61      0.67      0.64       237\n",
      "         radikalisme       0.71      0.85      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.80      0.73       492\n",
      "\n",
      "           micro avg       0.73      0.81      0.76      1326\n",
      "           macro avg       0.72      0.80      0.76      1326\n",
      "        weighted avg       0.73      0.81      0.77      1326\n",
      "         samples avg       0.44      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 425\n",
      "Sampling duration: 15.251070737838745 seconds\n",
      "New train size: 2394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.289559</td>\n",
       "      <td>0.616720</td>\n",
       "      <td>0.791096</td>\n",
       "      <td>0.522624</td>\n",
       "      <td>0.629428</td>\n",
       "      <td>0.618963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.257649</td>\n",
       "      <td>0.679743</td>\n",
       "      <td>0.732364</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.745650</td>\n",
       "      <td>0.737174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.248215</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.745346</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.750094</td>\n",
       "      <td>0.740203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.292300</td>\n",
       "      <td>0.243702</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.705128</td>\n",
       "      <td>0.747103</td>\n",
       "      <td>0.736188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.292300</td>\n",
       "      <td>0.259163</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.759755</td>\n",
       "      <td>0.748869</td>\n",
       "      <td>0.754273</td>\n",
       "      <td>0.742201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.292300</td>\n",
       "      <td>0.273138</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.761425</td>\n",
       "      <td>0.741327</td>\n",
       "      <td>0.751242</td>\n",
       "      <td>0.740668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.145200</td>\n",
       "      <td>0.275410</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.761496</td>\n",
       "      <td>0.736802</td>\n",
       "      <td>0.748946</td>\n",
       "      <td>0.738511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.145200</td>\n",
       "      <td>0.274310</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.762158</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.759273</td>\n",
       "      <td>0.752902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.145200</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.757689</td>\n",
       "      <td>0.761689</td>\n",
       "      <td>0.759684</td>\n",
       "      <td>0.752535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.089600</td>\n",
       "      <td>0.282005</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.764796</td>\n",
       "      <td>0.750377</td>\n",
       "      <td>0.757518</td>\n",
       "      <td>0.749239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.87      0.88      0.88       362\n",
      "                sara       0.68      0.60      0.64       237\n",
      "         radikalisme       0.75      0.79      0.77       235\n",
      "pencemaran_nama_baik       0.71      0.74      0.72       492\n",
      "\n",
      "           micro avg       0.76      0.76      0.76      1326\n",
      "           macro avg       0.75      0.75      0.75      1326\n",
      "        weighted avg       0.76      0.76      0.76      1326\n",
      "         samples avg       0.44      0.43      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2394: Accuracy: 0.6990353697749196, F1 Micro: 0.7596840917638209, F1 Macro: 0.7525353367164054\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.87      0.88      0.88       362\n",
      "                sara       0.68      0.60      0.64       237\n",
      "         radikalisme       0.75      0.79      0.77       235\n",
      "pencemaran_nama_baik       0.71      0.74      0.72       492\n",
      "\n",
      "           micro avg       0.76      0.76      0.76      1326\n",
      "           macro avg       0.75      0.75      0.75      1326\n",
      "        weighted avg       0.76      0.76      0.76      1326\n",
      "         samples avg       0.44      0.43      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 383\n",
      "Acquired samples: 383\n",
      "Sampling duration: 13.49991774559021 seconds\n",
      "New train size: 2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1740' max='1740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1740/1740 06:19, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.274065</td>\n",
       "      <td>0.661736</td>\n",
       "      <td>0.760398</td>\n",
       "      <td>0.634238</td>\n",
       "      <td>0.691612</td>\n",
       "      <td>0.684465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.245274</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.763710</td>\n",
       "      <td>0.714178</td>\n",
       "      <td>0.738114</td>\n",
       "      <td>0.733577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.297400</td>\n",
       "      <td>0.246510</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.723390</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.761871</td>\n",
       "      <td>0.756294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.297400</td>\n",
       "      <td>0.252451</td>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.725463</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.759612</td>\n",
       "      <td>0.750787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.297400</td>\n",
       "      <td>0.255290</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.742837</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.761940</td>\n",
       "      <td>0.751076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.158300</td>\n",
       "      <td>0.263181</td>\n",
       "      <td>0.688103</td>\n",
       "      <td>0.766317</td>\n",
       "      <td>0.717195</td>\n",
       "      <td>0.740943</td>\n",
       "      <td>0.726150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.158300</td>\n",
       "      <td>0.267071</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.773913</td>\n",
       "      <td>0.738311</td>\n",
       "      <td>0.755693</td>\n",
       "      <td>0.746775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.158300</td>\n",
       "      <td>0.282180</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.733032</td>\n",
       "      <td>0.751740</td>\n",
       "      <td>0.740442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.098300</td>\n",
       "      <td>0.285759</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.760091</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.756347</td>\n",
       "      <td>0.747683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.098300</td>\n",
       "      <td>0.284399</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.759063</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.758491</td>\n",
       "      <td>0.750170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.87      0.90      0.88       362\n",
      "                sara       0.64      0.61      0.63       237\n",
      "         radikalisme       0.74      0.77      0.75       235\n",
      "pencemaran_nama_baik       0.70      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.78      0.76      1326\n",
      "           macro avg       0.74      0.77      0.75      1326\n",
      "        weighted avg       0.74      0.78      0.76      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2777: Accuracy: 0.6977491961414791, F1 Micro: 0.7619397501836885, F1 Macro: 0.7510760846420111\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.87      0.90      0.88       362\n",
      "                sara       0.64      0.61      0.63       237\n",
      "         radikalisme       0.74      0.77      0.75       235\n",
      "pencemaran_nama_baik       0.70      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.78      0.76      1326\n",
      "           macro avg       0.74      0.77      0.75      1326\n",
      "        weighted avg       0.74      0.78      0.76      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 345\n",
      "Acquired samples: 345\n",
      "Sampling duration: 11.832486391067505 seconds\n",
      "New train size: 3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='1960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/1960 06:53, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.275423</td>\n",
       "      <td>0.659807</td>\n",
       "      <td>0.713241</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.724100</td>\n",
       "      <td>0.715063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.244268</td>\n",
       "      <td>0.687460</td>\n",
       "      <td>0.797368</td>\n",
       "      <td>0.685520</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.714846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.298500</td>\n",
       "      <td>0.241565</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.752042</td>\n",
       "      <td>0.763952</td>\n",
       "      <td>0.757950</td>\n",
       "      <td>0.746841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.298500</td>\n",
       "      <td>0.245533</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.742081</td>\n",
       "      <td>0.757506</td>\n",
       "      <td>0.746707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.298500</td>\n",
       "      <td>0.252050</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.791561</td>\n",
       "      <td>0.707391</td>\n",
       "      <td>0.747113</td>\n",
       "      <td>0.726494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.262867</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.760448</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.764441</td>\n",
       "      <td>0.756994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.277299</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.734212</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.764727</td>\n",
       "      <td>0.757424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.106400</td>\n",
       "      <td>0.291063</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.734116</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.766402</td>\n",
       "      <td>0.760658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.106400</td>\n",
       "      <td>0.285250</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.756152</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.760405</td>\n",
       "      <td>0.752095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.106400</td>\n",
       "      <td>0.288333</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.749817</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.760134</td>\n",
       "      <td>0.752010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.85      0.91      0.88       362\n",
      "                sara       0.65      0.68      0.67       237\n",
      "         radikalisme       0.71      0.84      0.77       235\n",
      "pencemaran_nama_baik       0.71      0.76      0.73       492\n",
      "\n",
      "           micro avg       0.73      0.80      0.77      1326\n",
      "           macro avg       0.73      0.80      0.76      1326\n",
      "        weighted avg       0.73      0.80      0.77      1326\n",
      "         samples avg       0.44      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3122: Accuracy: 0.6971061093247588, F1 Micro: 0.7664023071377072, F1 Macro: 0.760657968362842\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.85      0.91      0.88       362\n",
      "                sara       0.65      0.68      0.67       237\n",
      "         radikalisme       0.71      0.84      0.77       235\n",
      "pencemaran_nama_baik       0.71      0.76      0.73       492\n",
      "\n",
      "           micro avg       0.73      0.80      0.77      1326\n",
      "           macro avg       0.73      0.80      0.76      1326\n",
      "        weighted avg       0.73      0.80      0.77      1326\n",
      "         samples avg       0.44      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 310\n",
      "Acquired samples: 310\n",
      "Sampling duration: 10.471867084503174 seconds\n",
      "New train size: 3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2150/2150 07:25, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.258631</td>\n",
       "      <td>0.679100</td>\n",
       "      <td>0.756400</td>\n",
       "      <td>0.690799</td>\n",
       "      <td>0.722113</td>\n",
       "      <td>0.715711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241250</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.739726</td>\n",
       "      <td>0.721879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.301600</td>\n",
       "      <td>0.233474</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.803618</td>\n",
       "      <td>0.703620</td>\n",
       "      <td>0.750302</td>\n",
       "      <td>0.735536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.301600</td>\n",
       "      <td>0.237356</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.771272</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.757959</td>\n",
       "      <td>0.750929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.175900</td>\n",
       "      <td>0.248218</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.789819</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.756289</td>\n",
       "      <td>0.743641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.175900</td>\n",
       "      <td>0.260547</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.756554</td>\n",
       "      <td>0.761689</td>\n",
       "      <td>0.759113</td>\n",
       "      <td>0.752943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.118500</td>\n",
       "      <td>0.272642</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.767871</td>\n",
       "      <td>0.753394</td>\n",
       "      <td>0.760563</td>\n",
       "      <td>0.753434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.118500</td>\n",
       "      <td>0.278412</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.769290</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.764326</td>\n",
       "      <td>0.756797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.118500</td>\n",
       "      <td>0.290557</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.759970</td>\n",
       "      <td>0.761689</td>\n",
       "      <td>0.760829</td>\n",
       "      <td>0.753060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>0.290788</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.763238</td>\n",
       "      <td>0.760935</td>\n",
       "      <td>0.762085</td>\n",
       "      <td>0.754026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.88      0.89       362\n",
      "                sara       0.68      0.60      0.64       237\n",
      "         radikalisme       0.75      0.79      0.77       235\n",
      "pencemaran_nama_baik       0.72      0.73      0.73       492\n",
      "\n",
      "           micro avg       0.77      0.76      0.76      1326\n",
      "           macro avg       0.76      0.75      0.76      1326\n",
      "        weighted avg       0.77      0.76      0.76      1326\n",
      "         samples avg       0.44      0.43      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3432: Accuracy: 0.7067524115755627, F1 Micro: 0.7643263757115749, F1 Macro: 0.7567971211209173\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.88      0.89       362\n",
      "                sara       0.68      0.60      0.64       237\n",
      "         radikalisme       0.75      0.79      0.77       235\n",
      "pencemaran_nama_baik       0.72      0.73      0.73       492\n",
      "\n",
      "           micro avg       0.77      0.76      0.76      1326\n",
      "           macro avg       0.76      0.75      0.76      1326\n",
      "        weighted avg       0.77      0.76      0.76      1326\n",
      "         samples avg       0.44      0.43      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 279\n",
      "Acquired samples: 279\n",
      "Sampling duration: 9.29615044593811 seconds\n",
      "New train size: 3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2320/2320 07:55, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.264105</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.784071</td>\n",
       "      <td>0.668175</td>\n",
       "      <td>0.721498</td>\n",
       "      <td>0.691847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.238535</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.762763</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.764485</td>\n",
       "      <td>0.754523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.304900</td>\n",
       "      <td>0.244520</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.778854</td>\n",
       "      <td>0.727753</td>\n",
       "      <td>0.752437</td>\n",
       "      <td>0.742533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.304900</td>\n",
       "      <td>0.248233</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.742254</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.767662</td>\n",
       "      <td>0.758688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.184400</td>\n",
       "      <td>0.256957</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.746469</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.770970</td>\n",
       "      <td>0.764348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.184400</td>\n",
       "      <td>0.268049</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.780800</td>\n",
       "      <td>0.736048</td>\n",
       "      <td>0.757764</td>\n",
       "      <td>0.747397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.119200</td>\n",
       "      <td>0.275012</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.778132</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.756107</td>\n",
       "      <td>0.740805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.119200</td>\n",
       "      <td>0.287619</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.763774</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.763485</td>\n",
       "      <td>0.757010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.086300</td>\n",
       "      <td>0.290704</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.766184</td>\n",
       "      <td>0.758673</td>\n",
       "      <td>0.762410</td>\n",
       "      <td>0.752834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.086300</td>\n",
       "      <td>0.291430</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.762227</td>\n",
       "      <td>0.763952</td>\n",
       "      <td>0.763089</td>\n",
       "      <td>0.753526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.90      0.90       362\n",
      "                sara       0.64      0.66      0.65       237\n",
      "         radikalisme       0.70      0.86      0.77       235\n",
      "pencemaran_nama_baik       0.72      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.77      1326\n",
      "           macro avg       0.74      0.79      0.76      1326\n",
      "        weighted avg       0.75      0.80      0.77      1326\n",
      "         samples avg       0.44      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3711: Accuracy: 0.7061093247588425, F1 Micro: 0.7709700948212984, F1 Macro: 0.7643481278663946\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.90      0.90       362\n",
      "                sara       0.64      0.66      0.65       237\n",
      "         radikalisme       0.70      0.86      0.77       235\n",
      "pencemaran_nama_baik       0.72      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.77      1326\n",
      "           macro avg       0.74      0.79      0.76      1326\n",
      "        weighted avg       0.75      0.80      0.77      1326\n",
      "         samples avg       0.44      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 251\n",
      "Acquired samples: 175\n",
      "Sampling duration: 8.425032138824463 seconds\n",
      "New train size: 3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2430' max='2430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2430/2430 08:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.258886</td>\n",
       "      <td>0.675884</td>\n",
       "      <td>0.746865</td>\n",
       "      <td>0.718703</td>\n",
       "      <td>0.732513</td>\n",
       "      <td>0.720401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.239074</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.743273</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.749704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.307600</td>\n",
       "      <td>0.252582</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.713636</td>\n",
       "      <td>0.828808</td>\n",
       "      <td>0.766923</td>\n",
       "      <td>0.763748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.307600</td>\n",
       "      <td>0.241005</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.787113</td>\n",
       "      <td>0.727753</td>\n",
       "      <td>0.756270</td>\n",
       "      <td>0.746069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.188300</td>\n",
       "      <td>0.258889</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.792875</td>\n",
       "      <td>0.721719</td>\n",
       "      <td>0.755626</td>\n",
       "      <td>0.742655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.188300</td>\n",
       "      <td>0.267838</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.772478</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.758541</td>\n",
       "      <td>0.749096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.125300</td>\n",
       "      <td>0.280338</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.753676</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.763217</td>\n",
       "      <td>0.754624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.125300</td>\n",
       "      <td>0.290329</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.761440</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.763445</td>\n",
       "      <td>0.754009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.088800</td>\n",
       "      <td>0.295800</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.758340</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.764860</td>\n",
       "      <td>0.755466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.088800</td>\n",
       "      <td>0.297817</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.758136</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.765497</td>\n",
       "      <td>0.756425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.86      0.90      0.88       362\n",
      "                sara       0.62      0.73      0.67       237\n",
      "         radikalisme       0.68      0.88      0.77       235\n",
      "pencemaran_nama_baik       0.67      0.80      0.73       492\n",
      "\n",
      "           micro avg       0.71      0.83      0.77      1326\n",
      "           macro avg       0.71      0.83      0.76      1326\n",
      "        weighted avg       0.72      0.83      0.77      1326\n",
      "         samples avg       0.44      0.46      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3886: Accuracy: 0.6964630225080386, F1 Micro: 0.7669225401256108, F1 Macro: 0.7637481066616959\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.86      0.90      0.88       362\n",
      "                sara       0.62      0.73      0.67       237\n",
      "         radikalisme       0.68      0.88      0.77       235\n",
      "pencemaran_nama_baik       0.67      0.80      0.73       492\n",
      "\n",
      "           micro avg       0.71      0.83      0.77      1326\n",
      "           macro avg       0.71      0.83      0.76      1326\n",
      "        weighted avg       0.72      0.83      0.77      1326\n",
      "         samples avg       0.44      0.46      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Samples above threshold: 234\n",
      "Acquired samples: 234\n",
      "Sampling duration: 7.546650409698486 seconds\n",
      "New train size: 4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 08:38, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256182</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.757430</td>\n",
       "      <td>0.711161</td>\n",
       "      <td>0.733567</td>\n",
       "      <td>0.728543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.305300</td>\n",
       "      <td>0.240709</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.761042</td>\n",
       "      <td>0.756697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.305300</td>\n",
       "      <td>0.233352</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.782367</td>\n",
       "      <td>0.742836</td>\n",
       "      <td>0.762089</td>\n",
       "      <td>0.751457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.188200</td>\n",
       "      <td>0.244952</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.759151</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.770431</td>\n",
       "      <td>0.764342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.188200</td>\n",
       "      <td>0.252278</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.754758</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.765973</td>\n",
       "      <td>0.757708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.128700</td>\n",
       "      <td>0.279195</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.735744</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.765557</td>\n",
       "      <td>0.758092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.128700</td>\n",
       "      <td>0.290043</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.754801</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.762687</td>\n",
       "      <td>0.753583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.297341</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.758258</td>\n",
       "      <td>0.761689</td>\n",
       "      <td>0.759970</td>\n",
       "      <td>0.751752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.301037</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.762840</td>\n",
       "      <td>0.761689</td>\n",
       "      <td>0.762264</td>\n",
       "      <td>0.753095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.306716</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.754256</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.761300</td>\n",
       "      <td>0.753396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.89      0.90       362\n",
      "                sara       0.68      0.64      0.66       237\n",
      "         radikalisme       0.71      0.84      0.77       235\n",
      "pencemaran_nama_baik       0.72      0.74      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.78      0.77      1326\n",
      "           macro avg       0.75      0.78      0.76      1326\n",
      "        weighted avg       0.76      0.78      0.77      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4120: Accuracy: 0.7080385852090032, F1 Micro: 0.7704309063893016, F1 Macro: 0.7643422729944718\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.89      0.90       362\n",
      "                sara       0.68      0.64      0.66       237\n",
      "         radikalisme       0.71      0.84      0.77       235\n",
      "pencemaran_nama_baik       0.72      0.74      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.78      0.77      1326\n",
      "           macro avg       0.75      0.78      0.76      1326\n",
      "        weighted avg       0.76      0.78      0.77      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Samples above threshold: 210\n",
      "Acquired samples: 210\n",
      "Sampling duration: 6.865053176879883 seconds\n",
      "New train size: 4330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2710' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2710/2710 08:59, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.249405</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.757410</td>\n",
       "      <td>0.732278</td>\n",
       "      <td>0.744632</td>\n",
       "      <td>0.734965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.301100</td>\n",
       "      <td>0.236970</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.787448</td>\n",
       "      <td>0.709653</td>\n",
       "      <td>0.746529</td>\n",
       "      <td>0.734394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.301100</td>\n",
       "      <td>0.236605</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.811620</td>\n",
       "      <td>0.695324</td>\n",
       "      <td>0.748985</td>\n",
       "      <td>0.730788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.193000</td>\n",
       "      <td>0.240735</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.781473</td>\n",
       "      <td>0.744344</td>\n",
       "      <td>0.762457</td>\n",
       "      <td>0.752171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.193000</td>\n",
       "      <td>0.251632</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.766962</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.775541</td>\n",
       "      <td>0.765726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.135100</td>\n",
       "      <td>0.263857</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.765813</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.766390</td>\n",
       "      <td>0.761036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.135100</td>\n",
       "      <td>0.278292</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.786278</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.768697</td>\n",
       "      <td>0.761654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.095100</td>\n",
       "      <td>0.295295</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.751273</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.764902</td>\n",
       "      <td>0.759626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.095100</td>\n",
       "      <td>0.294713</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.778204</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.771396</td>\n",
       "      <td>0.765818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>0.298836</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.770443</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.772471</td>\n",
       "      <td>0.766309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.91      0.89       362\n",
      "                sara       0.70      0.58      0.63       237\n",
      "         radikalisme       0.79      0.79      0.79       235\n",
      "pencemaran_nama_baik       0.70      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.78      0.78      1326\n",
      "           macro avg       0.77      0.77      0.77      1326\n",
      "        weighted avg       0.77      0.78      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4330: Accuracy: 0.7093247588424437, F1 Micro: 0.7755406413124535, F1 Macro: 0.7657264606131258\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.91      0.89       362\n",
      "                sara       0.70      0.58      0.63       237\n",
      "         radikalisme       0.79      0.79      0.79       235\n",
      "pencemaran_nama_baik       0.70      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.78      0.78      1326\n",
      "           macro avg       0.77      0.77      0.77      1326\n",
      "        weighted avg       0.77      0.78      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Samples above threshold: 189\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.989232778549194 seconds\n",
      "New train size: 4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2840' max='2840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2840/2840 09:21, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250590</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.754440</td>\n",
       "      <td>0.736802</td>\n",
       "      <td>0.745517</td>\n",
       "      <td>0.737698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.302800</td>\n",
       "      <td>0.235701</td>\n",
       "      <td>0.686817</td>\n",
       "      <td>0.798253</td>\n",
       "      <td>0.689291</td>\n",
       "      <td>0.739781</td>\n",
       "      <td>0.719042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.302800</td>\n",
       "      <td>0.227436</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.761421</td>\n",
       "      <td>0.753144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.193000</td>\n",
       "      <td>0.237108</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.786159</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.774119</td>\n",
       "      <td>0.770148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.193000</td>\n",
       "      <td>0.257202</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.767547</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.767258</td>\n",
       "      <td>0.759791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.279925</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.740331</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.772891</td>\n",
       "      <td>0.766835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.280130</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.771731</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.770857</td>\n",
       "      <td>0.763918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.097600</td>\n",
       "      <td>0.294150</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.751070</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.771994</td>\n",
       "      <td>0.766298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.293596</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.776497</td>\n",
       "      <td>0.771112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.297332</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.768601</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.773783</td>\n",
       "      <td>0.768103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.66      0.66      0.66       237\n",
      "         radikalisme       0.74      0.82      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.75      0.73       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4530: Accuracy: 0.7144694533762058, F1 Micro: 0.7764968389735961, F1 Macro: 0.7711118183518814\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.66      0.66      0.66       237\n",
      "         radikalisme       0.74      0.82      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.75      0.73       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Samples above threshold: 169\n",
      "Acquired samples: 133\n",
      "Sampling duration: 5.268255710601807 seconds\n",
      "New train size: 4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2920' max='2920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2920/2920 09:35, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256940</td>\n",
       "      <td>0.682958</td>\n",
       "      <td>0.713435</td>\n",
       "      <td>0.812971</td>\n",
       "      <td>0.759958</td>\n",
       "      <td>0.754783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.229875</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.763217</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.768078</td>\n",
       "      <td>0.760968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.229865</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.813516</td>\n",
       "      <td>0.717195</td>\n",
       "      <td>0.762325</td>\n",
       "      <td>0.745365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.194500</td>\n",
       "      <td>0.239799</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.754797</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.777168</td>\n",
       "      <td>0.770463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.194500</td>\n",
       "      <td>0.258163</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.763256</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.766979</td>\n",
       "      <td>0.753863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.139600</td>\n",
       "      <td>0.267636</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.779739</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.764759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.100600</td>\n",
       "      <td>0.286068</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.769461</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.772352</td>\n",
       "      <td>0.764305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.100600</td>\n",
       "      <td>0.291448</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.770880</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.778649</td>\n",
       "      <td>0.772919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.300370</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.771385</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.769928</td>\n",
       "      <td>0.762488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.302778</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.766099</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.773254</td>\n",
       "      <td>0.766419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.90      0.90       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.76      0.82      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4663: Accuracy: 0.7163987138263666, F1 Micro: 0.778648749533408, F1 Macro: 0.7729194563732116\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.90      0.90       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.76      0.82      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.159751892089844 seconds\n",
      "New train size: 4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3040' max='3040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3040/3040 09:56, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.253183</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.742470</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.743029</td>\n",
       "      <td>0.734273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.233380</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.803404</td>\n",
       "      <td>0.711916</td>\n",
       "      <td>0.754898</td>\n",
       "      <td>0.736187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.224199</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.789013</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.767622</td>\n",
       "      <td>0.756738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.198600</td>\n",
       "      <td>0.254358</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.735662</td>\n",
       "      <td>0.841629</td>\n",
       "      <td>0.785086</td>\n",
       "      <td>0.781718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.145600</td>\n",
       "      <td>0.251414</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.765224</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.775753</td>\n",
       "      <td>0.767629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.145600</td>\n",
       "      <td>0.265248</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.782844</td>\n",
       "      <td>0.763952</td>\n",
       "      <td>0.773282</td>\n",
       "      <td>0.764782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>0.281934</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.771943</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.773975</td>\n",
       "      <td>0.769484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>0.285752</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.782676</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.772814</td>\n",
       "      <td>0.765720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.076700</td>\n",
       "      <td>0.298259</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.769174</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.771766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>0.299786</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.773543</td>\n",
       "      <td>0.766416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.91       362\n",
      "                sara       0.65      0.72      0.68       237\n",
      "         radikalisme       0.72      0.88      0.79       235\n",
      "pencemaran_nama_baik       0.68      0.84      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.84      0.79      1326\n",
      "           macro avg       0.74      0.83      0.78      1326\n",
      "        weighted avg       0.74      0.84      0.79      1326\n",
      "         samples avg       0.46      0.48      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4863: Accuracy: 0.7157556270096463, F1 Micro: 0.7850861765740414, F1 Macro: 0.7817175573236697\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.91       362\n",
      "                sara       0.65      0.72      0.68       237\n",
      "         radikalisme       0.72      0.88      0.79       235\n",
      "pencemaran_nama_baik       0.68      0.84      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.84      0.79      1326\n",
      "           macro avg       0.74      0.83      0.78      1326\n",
      "        weighted avg       0.74      0.84      0.79      1326\n",
      "         samples avg       0.46      0.48      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Samples above threshold: 136\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.51766037940979 seconds\n",
      "New train size: 5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3170' max='3170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3170/3170 10:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.253699</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.735699</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.750646</td>\n",
       "      <td>0.749037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.303800</td>\n",
       "      <td>0.229521</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.750708</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.774288</td>\n",
       "      <td>0.764314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.303800</td>\n",
       "      <td>0.226078</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.787950</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.773425</td>\n",
       "      <td>0.764431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.202700</td>\n",
       "      <td>0.248087</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.737408</td>\n",
       "      <td>0.828054</td>\n",
       "      <td>0.780107</td>\n",
       "      <td>0.775488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.148100</td>\n",
       "      <td>0.241793</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.788162</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.775479</td>\n",
       "      <td>0.763955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.148100</td>\n",
       "      <td>0.269257</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.759657</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.779736</td>\n",
       "      <td>0.775252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.108100</td>\n",
       "      <td>0.279751</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.780142</td>\n",
       "      <td>0.776777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.285930</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.771513</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.777861</td>\n",
       "      <td>0.770941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.296529</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.769795</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.780669</td>\n",
       "      <td>0.773027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>0.299220</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.767133</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.775997</td>\n",
       "      <td>0.769719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.65      0.62      0.64       237\n",
      "         radikalisme       0.76      0.85      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5063: Accuracy: 0.7189710610932476, F1 Micro: 0.7806691449814126, F1 Macro: 0.7730265369065072\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.65      0.62      0.64       237\n",
      "         radikalisme       0.76      0.85      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Samples above threshold: 116\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.847898244857788 seconds\n",
      "New train size: 5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3290' max='3290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3290/3290 10:31, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.248709</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.762646</td>\n",
       "      <td>0.739065</td>\n",
       "      <td>0.750670</td>\n",
       "      <td>0.743473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.301900</td>\n",
       "      <td>0.231226</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.757728</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.775856</td>\n",
       "      <td>0.766866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.301900</td>\n",
       "      <td>0.229158</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.758719</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.780666</td>\n",
       "      <td>0.772038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.206900</td>\n",
       "      <td>0.240386</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.753501</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.781409</td>\n",
       "      <td>0.772167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.152800</td>\n",
       "      <td>0.245764</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.795075</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.774468</td>\n",
       "      <td>0.765841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.152800</td>\n",
       "      <td>0.259940</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.782940</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.779083</td>\n",
       "      <td>0.770114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.112600</td>\n",
       "      <td>0.268377</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.790902</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.768515</td>\n",
       "      <td>0.759899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>0.291957</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.763838</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.772100</td>\n",
       "      <td>0.763925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>0.299981</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.762427</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.774313</td>\n",
       "      <td>0.767298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.300892</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.763292</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.776584</td>\n",
       "      <td>0.769644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.91      0.90       362\n",
      "                sara       0.67      0.62      0.64       237\n",
      "         radikalisme       0.71      0.88      0.79       235\n",
      "pencemaran_nama_baik       0.71      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5263: Accuracy: 0.7099678456591639, F1 Micro: 0.7814088598402323, F1 Macro: 0.7721666231160412\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.91      0.90       362\n",
      "                sara       0.67      0.62      0.64       237\n",
      "         radikalisme       0.71      0.88      0.79       235\n",
      "pencemaran_nama_baik       0.71      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Samples above threshold: 96\n",
      "Acquired samples: 178\n",
      "Sampling duration: 3.2870094776153564 seconds\n",
      "New train size: 5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3410' max='3410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3410/3410 10:52, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.246874</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.730453</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.765086</td>\n",
       "      <td>0.759727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.306800</td>\n",
       "      <td>0.225400</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.777434</td>\n",
       "      <td>0.758673</td>\n",
       "      <td>0.767939</td>\n",
       "      <td>0.748872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.207700</td>\n",
       "      <td>0.246399</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.849925</td>\n",
       "      <td>0.782367</td>\n",
       "      <td>0.779134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.207700</td>\n",
       "      <td>0.233191</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.794811</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.778291</td>\n",
       "      <td>0.764735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.152200</td>\n",
       "      <td>0.249528</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.777861</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.781074</td>\n",
       "      <td>0.771212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.115400</td>\n",
       "      <td>0.259890</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.780620</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.769878</td>\n",
       "      <td>0.757948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.115400</td>\n",
       "      <td>0.280142</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.783189</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.767218</td>\n",
       "      <td>0.757552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.086600</td>\n",
       "      <td>0.294104</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.761421</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.776340</td>\n",
       "      <td>0.768550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.296487</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.768945</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.774701</td>\n",
       "      <td>0.765708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.299538</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.775849</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.775556</td>\n",
       "      <td>0.766699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.90      0.90       362\n",
      "                sara       0.63      0.73      0.67       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.66      0.87      0.75       492\n",
      "\n",
      "           micro avg       0.72      0.85      0.78      1326\n",
      "           macro avg       0.73      0.84      0.78      1326\n",
      "        weighted avg       0.73      0.85      0.79      1326\n",
      "         samples avg       0.47      0.48      0.47      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5441: Accuracy: 0.7061093247588425, F1 Micro: 0.7823672335994446, F1 Macro: 0.779134124334266\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.90      0.90       362\n",
      "                sara       0.63      0.73      0.67       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.66      0.87      0.75       492\n",
      "\n",
      "           micro avg       0.72      0.85      0.78      1326\n",
      "           macro avg       0.73      0.84      0.78      1326\n",
      "        weighted avg       0.73      0.85      0.79      1326\n",
      "         samples avg       0.47      0.48      0.47      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Samples above threshold: 78\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.6696012020111084 seconds\n",
      "New train size: 5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3530' max='3530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3530/3530 11:08, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.245042</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.735928</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.766004</td>\n",
       "      <td>0.759212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.303200</td>\n",
       "      <td>0.224186</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.775056</td>\n",
       "      <td>0.767934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.209000</td>\n",
       "      <td>0.228817</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.805509</td>\n",
       "      <td>0.727753</td>\n",
       "      <td>0.764659</td>\n",
       "      <td>0.752737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.209000</td>\n",
       "      <td>0.232794</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.768841</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.784183</td>\n",
       "      <td>0.777729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.154800</td>\n",
       "      <td>0.246195</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.764291</td>\n",
       "      <td>0.816742</td>\n",
       "      <td>0.789646</td>\n",
       "      <td>0.786777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>0.257135</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.796193</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>0.776189</td>\n",
       "      <td>0.768028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>0.274972</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.767779</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.782544</td>\n",
       "      <td>0.776919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.287412</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.777610</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.776435</td>\n",
       "      <td>0.767748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.295314</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.772285</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.774897</td>\n",
       "      <td>0.765944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.058900</td>\n",
       "      <td>0.300455</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.765351</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.777283</td>\n",
       "      <td>0.768903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.67      0.71      0.69       237\n",
      "         radikalisme       0.74      0.88      0.80       235\n",
      "pencemaran_nama_baik       0.72      0.77      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.82      0.79      1326\n",
      "           macro avg       0.76      0.82      0.79      1326\n",
      "        weighted avg       0.77      0.82      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5641: Accuracy: 0.7266881028938906, F1 Micro: 0.7896463725847611, F1 Macro: 0.7867772745633355\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.67      0.71      0.69       237\n",
      "         radikalisme       0.74      0.88      0.80       235\n",
      "pencemaran_nama_baik       0.72      0.77      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.82      0.79      1326\n",
      "           macro avg       0.76      0.82      0.79      1326\n",
      "        weighted avg       0.77      0.82      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.105757713317871 seconds\n",
      "New train size: 5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3660' max='3660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3660/3660 11:32, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241270</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.770106</td>\n",
       "      <td>0.714932</td>\n",
       "      <td>0.741494</td>\n",
       "      <td>0.725332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.303200</td>\n",
       "      <td>0.224460</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.761689</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.763397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.206500</td>\n",
       "      <td>0.226879</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.827281</td>\n",
       "      <td>0.704374</td>\n",
       "      <td>0.760896</td>\n",
       "      <td>0.748572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.206500</td>\n",
       "      <td>0.239213</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.783186</td>\n",
       "      <td>0.774495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.162700</td>\n",
       "      <td>0.244744</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.792730</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.782742</td>\n",
       "      <td>0.774246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.119400</td>\n",
       "      <td>0.268585</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.750696</td>\n",
       "      <td>0.812971</td>\n",
       "      <td>0.780594</td>\n",
       "      <td>0.774660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>0.293251</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.750176</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.775064</td>\n",
       "      <td>0.769582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>0.297571</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.763441</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.782800</td>\n",
       "      <td>0.778321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0.301713</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.770089</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.768156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.307035</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.764835</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.775920</td>\n",
       "      <td>0.770143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.91      0.90       362\n",
      "                sara       0.64      0.64      0.64       237\n",
      "         radikalisme       0.75      0.85      0.80       235\n",
      "pencemaran_nama_baik       0.74      0.77      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5841: Accuracy: 0.7215434083601286, F1 Micro: 0.7831858407079646, F1 Macro: 0.7744949948682389\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.91      0.90       362\n",
      "                sara       0.64      0.64      0.64       237\n",
      "         radikalisme       0.75      0.85      0.80       235\n",
      "pencemaran_nama_baik       0.74      0.77      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 200\n",
      "Sampling duration: 1.4956977367401123 seconds\n",
      "New train size: 6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3780' max='3780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3780/3780 11:56, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.240917</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.723982</td>\n",
       "      <td>0.749415</td>\n",
       "      <td>0.733264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.300300</td>\n",
       "      <td>0.223426</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.790271</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.768217</td>\n",
       "      <td>0.758258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.221723</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.776219</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.784328</td>\n",
       "      <td>0.777525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.161700</td>\n",
       "      <td>0.246995</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.733993</td>\n",
       "      <td>0.838612</td>\n",
       "      <td>0.782823</td>\n",
       "      <td>0.779213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.161700</td>\n",
       "      <td>0.266719</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.737922</td>\n",
       "      <td>0.840875</td>\n",
       "      <td>0.786042</td>\n",
       "      <td>0.782182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.123000</td>\n",
       "      <td>0.260819</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.794002</td>\n",
       "      <td>0.758673</td>\n",
       "      <td>0.775935</td>\n",
       "      <td>0.765128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.094100</td>\n",
       "      <td>0.274859</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.776030</td>\n",
       "      <td>0.771215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.289817</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.768498</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.779636</td>\n",
       "      <td>0.773983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.299776</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.778846</td>\n",
       "      <td>0.774271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.302756</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.770772</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.777113</td>\n",
       "      <td>0.771279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.91       362\n",
      "                sara       0.64      0.70      0.67       237\n",
      "         radikalisme       0.74      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.68      0.85      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.84      0.79      1326\n",
      "           macro avg       0.74      0.83      0.78      1326\n",
      "        weighted avg       0.75      0.84      0.79      1326\n",
      "         samples avg       0.47      0.48      0.47      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6041: Accuracy: 0.7138263665594855, F1 Micro: 0.7860415932322876, F1 Macro: 0.7821822343446307\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.91       362\n",
      "                sara       0.64      0.70      0.67       237\n",
      "         radikalisme       0.74      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.68      0.85      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.84      0.79      1326\n",
      "           macro avg       0.74      0.83      0.78      1326\n",
      "        weighted avg       0.75      0.84      0.79      1326\n",
      "         samples avg       0.47      0.48      0.47      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/tmp/ipykernel_23/2933288740.py:54: ConvergenceWarning: Number of distinct clusters (74) found smaller than n_clusters (177). Possibly due to duplicate points in X.\n",
      "  kmeans.fit(embeddings)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 177\n",
      "Sampling duration: 1.5296058654785156 seconds\n",
      "New train size: 6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3890/3890 12:16, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.237726</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.797945</td>\n",
       "      <td>0.702866</td>\n",
       "      <td>0.747394</td>\n",
       "      <td>0.738374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.293900</td>\n",
       "      <td>0.228493</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.832579</td>\n",
       "      <td>0.784648</td>\n",
       "      <td>0.778111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.203800</td>\n",
       "      <td>0.223897</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.771763</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.783513</td>\n",
       "      <td>0.775706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.158400</td>\n",
       "      <td>0.236879</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.772961</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.783029</td>\n",
       "      <td>0.775567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.158400</td>\n",
       "      <td>0.245601</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.799194</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.772408</td>\n",
       "      <td>0.761660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.125600</td>\n",
       "      <td>0.259732</td>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.796690</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.779191</td>\n",
       "      <td>0.768845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.094700</td>\n",
       "      <td>0.282465</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.763557</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.779623</td>\n",
       "      <td>0.771831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.072600</td>\n",
       "      <td>0.292770</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.765911</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.777571</td>\n",
       "      <td>0.772382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.061500</td>\n",
       "      <td>0.303077</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.762146</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.777079</td>\n",
       "      <td>0.771611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.061500</td>\n",
       "      <td>0.303170</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.774074</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.781016</td>\n",
       "      <td>0.774886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.88      0.90       362\n",
      "                sara       0.63      0.68      0.65       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.69      0.85      0.76       492\n",
      "\n",
      "           micro avg       0.74      0.83      0.78      1326\n",
      "           macro avg       0.74      0.82      0.78      1326\n",
      "        weighted avg       0.75      0.83      0.79      1326\n",
      "         samples avg       0.47      0.47      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6218: Accuracy: 0.715112540192926, F1 Micro: 0.7846481876332624, F1 Macro: 0.7781106631914425\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.88      0.90       362\n",
      "                sara       0.63      0.68      0.65       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.69      0.85      0.76       492\n",
      "\n",
      "           micro avg       0.74      0.83      0.78      1326\n",
      "           macro avg       0.74      0.82      0.78      1326\n",
      "        weighted avg       0.75      0.83      0.79      1326\n",
      "         samples avg       0.47      0.47      0.46      1326\n",
      "\n",
      "Total sampling time: 180.58 seconds\n",
      "Total runtime: 11325.41610789299 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372fd370",
   "metadata": {
    "papermill": {
     "duration": 0.018109,
     "end_time": "2024-12-21T06:36:03.712626",
     "exception": false,
     "start_time": "2024-12-21T06:36:03.694517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3cdba95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T06:36:03.750333Z",
     "iopub.status.busy": "2024-12-21T06:36:03.749566Z",
     "iopub.status.idle": "2024-12-21T09:44:56.102091Z",
     "shell.execute_reply": "2024-12-21T09:44:56.101302Z"
    },
    "papermill": {
     "duration": 11332.373264,
     "end_time": "2024-12-21T09:44:56.103959",
     "exception": false,
     "start_time": "2024-12-21T06:36:03.730695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 02:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.460827</td>\n",
       "      <td>0.440514</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.033937</td>\n",
       "      <td>0.065550</td>\n",
       "      <td>0.044738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.398824</td>\n",
       "      <td>0.576849</td>\n",
       "      <td>0.872222</td>\n",
       "      <td>0.236802</td>\n",
       "      <td>0.372479</td>\n",
       "      <td>0.261927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.353225</td>\n",
       "      <td>0.591640</td>\n",
       "      <td>0.830054</td>\n",
       "      <td>0.349925</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.420032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.330393</td>\n",
       "      <td>0.585852</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.429864</td>\n",
       "      <td>0.553130</td>\n",
       "      <td>0.459224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.593569</td>\n",
       "      <td>0.761511</td>\n",
       "      <td>0.486425</td>\n",
       "      <td>0.593649</td>\n",
       "      <td>0.525215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.306425</td>\n",
       "      <td>0.605145</td>\n",
       "      <td>0.788366</td>\n",
       "      <td>0.480392</td>\n",
       "      <td>0.597001</td>\n",
       "      <td>0.545943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.299625</td>\n",
       "      <td>0.612862</td>\n",
       "      <td>0.739634</td>\n",
       "      <td>0.578431</td>\n",
       "      <td>0.649175</td>\n",
       "      <td>0.610205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.297249</td>\n",
       "      <td>0.616720</td>\n",
       "      <td>0.771834</td>\n",
       "      <td>0.533183</td>\n",
       "      <td>0.630687</td>\n",
       "      <td>0.596109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.294833</td>\n",
       "      <td>0.624437</td>\n",
       "      <td>0.772004</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.641692</td>\n",
       "      <td>0.603582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.295964</td>\n",
       "      <td>0.617363</td>\n",
       "      <td>0.774123</td>\n",
       "      <td>0.532428</td>\n",
       "      <td>0.630920</td>\n",
       "      <td>0.592582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.79      0.84       362\n",
      "                sara       0.74      0.23      0.35       237\n",
      "         radikalisme       0.68      0.60      0.64       235\n",
      "pencemaran_nama_baik       0.65      0.58      0.62       492\n",
      "\n",
      "           micro avg       0.74      0.58      0.65      1326\n",
      "           macro avg       0.74      0.55      0.61      1326\n",
      "        weighted avg       0.74      0.58      0.63      1326\n",
      "         samples avg       0.38      0.34      0.35      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 388: Accuracy: 0.6128617363344051, F1 Micro: 0.649174777824799, F1 Macro: 0.6102054118583491\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.79      0.84       362\n",
      "                sara       0.74      0.23      0.35       237\n",
      "         radikalisme       0.68      0.60      0.64       235\n",
      "pencemaran_nama_baik       0.65      0.58      0.62       492\n",
      "\n",
      "           micro avg       0.74      0.58      0.65      1326\n",
      "           macro avg       0.74      0.55      0.61      1326\n",
      "        weighted avg       0.74      0.58      0.63      1326\n",
      "         samples avg       0.38      0.34      0.35      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 583\n",
      "Acquired samples: 583\n",
      "Sampling duration: 23.490602731704712 seconds\n",
      "New train size: 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [610/610 03:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.372372</td>\n",
       "      <td>0.548553</td>\n",
       "      <td>0.823821</td>\n",
       "      <td>0.250377</td>\n",
       "      <td>0.384037</td>\n",
       "      <td>0.263656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.308020</td>\n",
       "      <td>0.615434</td>\n",
       "      <td>0.770396</td>\n",
       "      <td>0.498492</td>\n",
       "      <td>0.605311</td>\n",
       "      <td>0.572273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.278782</td>\n",
       "      <td>0.637942</td>\n",
       "      <td>0.749117</td>\n",
       "      <td>0.639517</td>\n",
       "      <td>0.689992</td>\n",
       "      <td>0.667184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.281475</td>\n",
       "      <td>0.646945</td>\n",
       "      <td>0.685324</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>0.719455</td>\n",
       "      <td>0.714298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.275558</td>\n",
       "      <td>0.661736</td>\n",
       "      <td>0.723356</td>\n",
       "      <td>0.721719</td>\n",
       "      <td>0.722537</td>\n",
       "      <td>0.714951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.280520</td>\n",
       "      <td>0.652733</td>\n",
       "      <td>0.753859</td>\n",
       "      <td>0.662896</td>\n",
       "      <td>0.705457</td>\n",
       "      <td>0.689547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.278667</td>\n",
       "      <td>0.643730</td>\n",
       "      <td>0.729199</td>\n",
       "      <td>0.700603</td>\n",
       "      <td>0.714615</td>\n",
       "      <td>0.701214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.288798</td>\n",
       "      <td>0.652733</td>\n",
       "      <td>0.716296</td>\n",
       "      <td>0.729261</td>\n",
       "      <td>0.722720</td>\n",
       "      <td>0.715209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.248100</td>\n",
       "      <td>0.284464</td>\n",
       "      <td>0.652733</td>\n",
       "      <td>0.742143</td>\n",
       "      <td>0.694570</td>\n",
       "      <td>0.717569</td>\n",
       "      <td>0.703355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.248100</td>\n",
       "      <td>0.288135</td>\n",
       "      <td>0.647588</td>\n",
       "      <td>0.718585</td>\n",
       "      <td>0.720211</td>\n",
       "      <td>0.719397</td>\n",
       "      <td>0.708108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.86      0.89      0.87       362\n",
      "                sara       0.61      0.59      0.60       237\n",
      "         radikalisme       0.66      0.78      0.72       235\n",
      "pencemaran_nama_baik       0.69      0.65      0.67       492\n",
      "\n",
      "           micro avg       0.72      0.73      0.72      1326\n",
      "           macro avg       0.70      0.73      0.72      1326\n",
      "        weighted avg       0.72      0.73      0.72      1326\n",
      "         samples avg       0.41      0.41      0.40      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 971: Accuracy: 0.6527331189710611, F1 Micro: 0.7227204783258595, F1 Macro: 0.7152086983082173\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.86      0.89      0.87       362\n",
      "                sara       0.61      0.59      0.60       237\n",
      "         radikalisme       0.66      0.78      0.72       235\n",
      "pencemaran_nama_baik       0.69      0.65      0.67       492\n",
      "\n",
      "           micro avg       0.72      0.73      0.72      1326\n",
      "           macro avg       0.70      0.73      0.72      1326\n",
      "        weighted avg       0.72      0.73      0.72      1326\n",
      "         samples avg       0.41      0.41      0.40      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 20.074289321899414 seconds\n",
      "New train size: 1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [940/940 04:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.327914</td>\n",
       "      <td>0.589068</td>\n",
       "      <td>0.742009</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.590372</td>\n",
       "      <td>0.569344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.277279</td>\n",
       "      <td>0.649518</td>\n",
       "      <td>0.762167</td>\n",
       "      <td>0.625943</td>\n",
       "      <td>0.687371</td>\n",
       "      <td>0.680372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.262214</td>\n",
       "      <td>0.664309</td>\n",
       "      <td>0.724872</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.734846</td>\n",
       "      <td>0.732516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.763710</td>\n",
       "      <td>0.714178</td>\n",
       "      <td>0.738114</td>\n",
       "      <td>0.725774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.259208</td>\n",
       "      <td>0.675884</td>\n",
       "      <td>0.737972</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.744864</td>\n",
       "      <td>0.736024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.265200</td>\n",
       "      <td>0.274972</td>\n",
       "      <td>0.673955</td>\n",
       "      <td>0.706977</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.748223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.265200</td>\n",
       "      <td>0.269288</td>\n",
       "      <td>0.678457</td>\n",
       "      <td>0.743783</td>\n",
       "      <td>0.744344</td>\n",
       "      <td>0.744063</td>\n",
       "      <td>0.731148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.265200</td>\n",
       "      <td>0.279729</td>\n",
       "      <td>0.678457</td>\n",
       "      <td>0.747699</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.741445</td>\n",
       "      <td>0.732726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.265200</td>\n",
       "      <td>0.278267</td>\n",
       "      <td>0.681672</td>\n",
       "      <td>0.745673</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.746516</td>\n",
       "      <td>0.738563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.265200</td>\n",
       "      <td>0.279409</td>\n",
       "      <td>0.680386</td>\n",
       "      <td>0.743802</td>\n",
       "      <td>0.746606</td>\n",
       "      <td>0.745201</td>\n",
       "      <td>0.738353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.86      0.90      0.88       362\n",
      "                sara       0.60      0.71      0.65       237\n",
      "         radikalisme       0.69      0.82      0.75       235\n",
      "pencemaran_nama_baik       0.66      0.77      0.71       492\n",
      "\n",
      "           micro avg       0.71      0.80      0.75      1326\n",
      "           macro avg       0.70      0.80      0.75      1326\n",
      "        weighted avg       0.71      0.80      0.75      1326\n",
      "         samples avg       0.44      0.45      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1496: Accuracy: 0.6739549839228296, F1 Micro: 0.7516778523489934, F1 Macro: 0.7482227589419894\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.86      0.90      0.88       362\n",
      "                sara       0.60      0.71      0.65       237\n",
      "         radikalisme       0.69      0.82      0.75       235\n",
      "pencemaran_nama_baik       0.66      0.77      0.71       492\n",
      "\n",
      "           micro avg       0.71      0.80      0.75      1326\n",
      "           macro avg       0.70      0.80      0.75      1326\n",
      "        weighted avg       0.71      0.80      0.75      1326\n",
      "         samples avg       0.44      0.45      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 17.75398898124695 seconds\n",
      "New train size: 1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1240' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1240/1240 04:52, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.297038</td>\n",
       "      <td>0.629582</td>\n",
       "      <td>0.795328</td>\n",
       "      <td>0.539216</td>\n",
       "      <td>0.642697</td>\n",
       "      <td>0.595291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.264764</td>\n",
       "      <td>0.637942</td>\n",
       "      <td>0.756734</td>\n",
       "      <td>0.677979</td>\n",
       "      <td>0.715195</td>\n",
       "      <td>0.670036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.254485</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.745297</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.760709</td>\n",
       "      <td>0.751821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.254211</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.741655</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.755917</td>\n",
       "      <td>0.749079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.273700</td>\n",
       "      <td>0.254462</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.767516</td>\n",
       "      <td>0.726998</td>\n",
       "      <td>0.746708</td>\n",
       "      <td>0.738911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.273700</td>\n",
       "      <td>0.258990</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.773934</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.748930</td>\n",
       "      <td>0.740317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.273700</td>\n",
       "      <td>0.273658</td>\n",
       "      <td>0.682958</td>\n",
       "      <td>0.744822</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.752054</td>\n",
       "      <td>0.743701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.273700</td>\n",
       "      <td>0.280302</td>\n",
       "      <td>0.682958</td>\n",
       "      <td>0.745011</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.752520</td>\n",
       "      <td>0.743848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.124300</td>\n",
       "      <td>0.280441</td>\n",
       "      <td>0.681029</td>\n",
       "      <td>0.742524</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.754913</td>\n",
       "      <td>0.746054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.124300</td>\n",
       "      <td>0.283043</td>\n",
       "      <td>0.679100</td>\n",
       "      <td>0.744996</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.751402</td>\n",
       "      <td>0.742872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.90      0.89       362\n",
      "                sara       0.65      0.60      0.63       237\n",
      "         radikalisme       0.74      0.79      0.77       235\n",
      "pencemaran_nama_baik       0.70      0.77      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.78      0.76      1326\n",
      "           macro avg       0.74      0.76      0.75      1326\n",
      "        weighted avg       0.75      0.78      0.76      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1969: Accuracy: 0.6893890675241158, F1 Micro: 0.7607090103397341, F1 Macro: 0.7518209357737502\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.90      0.89       362\n",
      "                sara       0.65      0.60      0.63       237\n",
      "         radikalisme       0.74      0.79      0.77       235\n",
      "pencemaran_nama_baik       0.70      0.77      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.78      0.76      1326\n",
      "           macro avg       0.74      0.76      0.75      1326\n",
      "        weighted avg       0.75      0.78      0.76      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 425\n",
      "Sampling duration: 15.879387140274048 seconds\n",
      "New train size: 2394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:35, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.281396</td>\n",
       "      <td>0.641801</td>\n",
       "      <td>0.780933</td>\n",
       "      <td>0.580694</td>\n",
       "      <td>0.666090</td>\n",
       "      <td>0.645294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.263672</td>\n",
       "      <td>0.662379</td>\n",
       "      <td>0.827772</td>\n",
       "      <td>0.579940</td>\n",
       "      <td>0.682040</td>\n",
       "      <td>0.637979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.252490</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.762969</td>\n",
       "      <td>0.720965</td>\n",
       "      <td>0.741373</td>\n",
       "      <td>0.732934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.280200</td>\n",
       "      <td>0.248245</td>\n",
       "      <td>0.684244</td>\n",
       "      <td>0.774430</td>\n",
       "      <td>0.717195</td>\n",
       "      <td>0.744714</td>\n",
       "      <td>0.728445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.280200</td>\n",
       "      <td>0.264735</td>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.735863</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.755050</td>\n",
       "      <td>0.751031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.280200</td>\n",
       "      <td>0.266291</td>\n",
       "      <td>0.688103</td>\n",
       "      <td>0.778974</td>\n",
       "      <td>0.709653</td>\n",
       "      <td>0.742699</td>\n",
       "      <td>0.730426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.139400</td>\n",
       "      <td>0.278346</td>\n",
       "      <td>0.679100</td>\n",
       "      <td>0.736152</td>\n",
       "      <td>0.761689</td>\n",
       "      <td>0.748703</td>\n",
       "      <td>0.737678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.139400</td>\n",
       "      <td>0.284320</td>\n",
       "      <td>0.683601</td>\n",
       "      <td>0.751335</td>\n",
       "      <td>0.742836</td>\n",
       "      <td>0.747061</td>\n",
       "      <td>0.735998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.139400</td>\n",
       "      <td>0.287447</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.754601</td>\n",
       "      <td>0.742081</td>\n",
       "      <td>0.748289</td>\n",
       "      <td>0.738782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.084100</td>\n",
       "      <td>0.289636</td>\n",
       "      <td>0.681672</td>\n",
       "      <td>0.742560</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.747566</td>\n",
       "      <td>0.737659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.86      0.89       362\n",
      "                sara       0.62      0.68      0.65       237\n",
      "         radikalisme       0.70      0.80      0.75       235\n",
      "pencemaran_nama_baik       0.69      0.75      0.72       492\n",
      "\n",
      "           micro avg       0.74      0.78      0.76      1326\n",
      "           macro avg       0.73      0.77      0.75      1326\n",
      "        weighted avg       0.74      0.78      0.76      1326\n",
      "         samples avg       0.42      0.43      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2394: Accuracy: 0.6887459807073955, F1 Micro: 0.7550495776716857, F1 Macro: 0.7510307061006944\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.86      0.89       362\n",
      "                sara       0.62      0.68      0.65       237\n",
      "         radikalisme       0.70      0.80      0.75       235\n",
      "pencemaran_nama_baik       0.69      0.75      0.72       492\n",
      "\n",
      "           micro avg       0.74      0.78      0.76      1326\n",
      "           macro avg       0.73      0.77      0.75      1326\n",
      "        weighted avg       0.74      0.78      0.76      1326\n",
      "         samples avg       0.42      0.43      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 383\n",
      "Acquired samples: 383\n",
      "Sampling duration: 13.424089908599854 seconds\n",
      "New train size: 2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1740' max='1740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1740/1740 06:18, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.277462</td>\n",
       "      <td>0.656592</td>\n",
       "      <td>0.763751</td>\n",
       "      <td>0.638763</td>\n",
       "      <td>0.695688</td>\n",
       "      <td>0.679706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.252050</td>\n",
       "      <td>0.681672</td>\n",
       "      <td>0.805061</td>\n",
       "      <td>0.647813</td>\n",
       "      <td>0.717927</td>\n",
       "      <td>0.707305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.290300</td>\n",
       "      <td>0.254728</td>\n",
       "      <td>0.675241</td>\n",
       "      <td>0.716488</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.758694</td>\n",
       "      <td>0.749757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.290300</td>\n",
       "      <td>0.244533</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.781301</td>\n",
       "      <td>0.724736</td>\n",
       "      <td>0.751956</td>\n",
       "      <td>0.739174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.290300</td>\n",
       "      <td>0.265881</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.737179</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.758242</td>\n",
       "      <td>0.754077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.154500</td>\n",
       "      <td>0.269392</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.763566</td>\n",
       "      <td>0.742836</td>\n",
       "      <td>0.753058</td>\n",
       "      <td>0.740085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.154500</td>\n",
       "      <td>0.276899</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.757622</td>\n",
       "      <td>0.749623</td>\n",
       "      <td>0.753601</td>\n",
       "      <td>0.743227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.154500</td>\n",
       "      <td>0.292438</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.741354</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.758290</td>\n",
       "      <td>0.747500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.090500</td>\n",
       "      <td>0.291106</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.755071</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.756492</td>\n",
       "      <td>0.744955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.090500</td>\n",
       "      <td>0.291739</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.758568</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.754831</td>\n",
       "      <td>0.743389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.87      0.91      0.89       362\n",
      "                sara       0.62      0.65      0.63       237\n",
      "         radikalisme       0.74      0.75      0.75       235\n",
      "pencemaran_nama_baik       0.66      0.83      0.73       492\n",
      "\n",
      "           micro avg       0.72      0.81      0.76      1326\n",
      "           macro avg       0.72      0.79      0.75      1326\n",
      "        weighted avg       0.72      0.81      0.76      1326\n",
      "         samples avg       0.45      0.46      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2777: Accuracy: 0.6752411575562701, F1 Micro: 0.758694109297374, F1 Macro: 0.7497572254520368\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.87      0.91      0.89       362\n",
      "                sara       0.62      0.65      0.63       237\n",
      "         radikalisme       0.74      0.75      0.75       235\n",
      "pencemaran_nama_baik       0.66      0.83      0.73       492\n",
      "\n",
      "           micro avg       0.72      0.81      0.76      1326\n",
      "           macro avg       0.72      0.79      0.75      1326\n",
      "        weighted avg       0.72      0.81      0.76      1326\n",
      "         samples avg       0.45      0.46      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 345\n",
      "Acquired samples: 345\n",
      "Sampling duration: 12.642253160476685 seconds\n",
      "New train size: 3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='1960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/1960 06:53, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.270209</td>\n",
       "      <td>0.673955</td>\n",
       "      <td>0.721898</td>\n",
       "      <td>0.745852</td>\n",
       "      <td>0.733680</td>\n",
       "      <td>0.728303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.238705</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.790932</td>\n",
       "      <td>0.710407</td>\n",
       "      <td>0.748510</td>\n",
       "      <td>0.739894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.285700</td>\n",
       "      <td>0.238066</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.754996</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.762047</td>\n",
       "      <td>0.752392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.285700</td>\n",
       "      <td>0.245154</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.773292</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.762050</td>\n",
       "      <td>0.754174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.285700</td>\n",
       "      <td>0.260214</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.740113</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.764406</td>\n",
       "      <td>0.757507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.158100</td>\n",
       "      <td>0.263027</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.751644</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.756696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.158100</td>\n",
       "      <td>0.269085</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.783719</td>\n",
       "      <td>0.740573</td>\n",
       "      <td>0.761535</td>\n",
       "      <td>0.750437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.097600</td>\n",
       "      <td>0.286329</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.752168</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.768266</td>\n",
       "      <td>0.760510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.097600</td>\n",
       "      <td>0.288052</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.758595</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.762012</td>\n",
       "      <td>0.754814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.097600</td>\n",
       "      <td>0.290708</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.762763</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.764485</td>\n",
       "      <td>0.757340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.91      0.90       362\n",
      "                sara       0.66      0.63      0.64       237\n",
      "         radikalisme       0.75      0.79      0.77       235\n",
      "pencemaran_nama_baik       0.70      0.76      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.79      0.77      1326\n",
      "           macro avg       0.75      0.77      0.76      1326\n",
      "        weighted avg       0.75      0.79      0.77      1326\n",
      "         samples avg       0.44      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3122: Accuracy: 0.7028938906752411, F1 Micro: 0.7682656826568266, F1 Macro: 0.7605095915258222\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.91      0.90       362\n",
      "                sara       0.66      0.63      0.64       237\n",
      "         radikalisme       0.75      0.79      0.77       235\n",
      "pencemaran_nama_baik       0.70      0.76      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.79      0.77      1326\n",
      "           macro avg       0.75      0.77      0.76      1326\n",
      "        weighted avg       0.75      0.79      0.77      1326\n",
      "         samples avg       0.44      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 310\n",
      "Acquired samples: 310\n",
      "Sampling duration: 10.338341474533081 seconds\n",
      "New train size: 3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2150/2150 07:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.269061</td>\n",
       "      <td>0.671383</td>\n",
       "      <td>0.723389</td>\n",
       "      <td>0.753394</td>\n",
       "      <td>0.738086</td>\n",
       "      <td>0.732229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.247616</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.828244</td>\n",
       "      <td>0.654600</td>\n",
       "      <td>0.731255</td>\n",
       "      <td>0.706122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.292800</td>\n",
       "      <td>0.235669</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.768934</td>\n",
       "      <td>0.750377</td>\n",
       "      <td>0.759542</td>\n",
       "      <td>0.751027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.292800</td>\n",
       "      <td>0.255149</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.726110</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.767425</td>\n",
       "      <td>0.762906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.168200</td>\n",
       "      <td>0.251932</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.751076</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.769853</td>\n",
       "      <td>0.762206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.168200</td>\n",
       "      <td>0.262121</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.760950</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.766929</td>\n",
       "      <td>0.759460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>0.274069</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.773628</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.769522</td>\n",
       "      <td>0.759612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>0.283180</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.772555</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.770510</td>\n",
       "      <td>0.762620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>0.291051</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.773967</td>\n",
       "      <td>0.748869</td>\n",
       "      <td>0.761211</td>\n",
       "      <td>0.750815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.292264</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.768302</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.768012</td>\n",
       "      <td>0.758340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.90       362\n",
      "                sara       0.67      0.63      0.65       237\n",
      "         radikalisme       0.74      0.80      0.77       235\n",
      "pencemaran_nama_baik       0.74      0.72      0.73       492\n",
      "\n",
      "           micro avg       0.77      0.77      0.77      1326\n",
      "           macro avg       0.76      0.76      0.76      1326\n",
      "        weighted avg       0.77      0.77      0.77      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3432: Accuracy: 0.712540192926045, F1 Micro: 0.7705103969754254, F1 Macro: 0.7626196924518843\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.90       362\n",
      "                sara       0.67      0.63      0.65       237\n",
      "         radikalisme       0.74      0.80      0.77       235\n",
      "pencemaran_nama_baik       0.74      0.72      0.73       492\n",
      "\n",
      "           micro avg       0.77      0.77      0.77      1326\n",
      "           macro avg       0.76      0.76      0.76      1326\n",
      "        weighted avg       0.77      0.77      0.77      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 279\n",
      "Acquired samples: 279\n",
      "Sampling duration: 9.102922916412354 seconds\n",
      "New train size: 3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2320/2320 07:55, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.260769</td>\n",
       "      <td>0.669453</td>\n",
       "      <td>0.802899</td>\n",
       "      <td>0.626697</td>\n",
       "      <td>0.703939</td>\n",
       "      <td>0.697980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.238316</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.754844</td>\n",
       "      <td>0.763952</td>\n",
       "      <td>0.759370</td>\n",
       "      <td>0.754234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.295100</td>\n",
       "      <td>0.243037</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.763707</td>\n",
       "      <td>0.745852</td>\n",
       "      <td>0.754674</td>\n",
       "      <td>0.739680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.295100</td>\n",
       "      <td>0.237803</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.798658</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.756156</td>\n",
       "      <td>0.743174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.171300</td>\n",
       "      <td>0.254957</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.763930</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.774721</td>\n",
       "      <td>0.768082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.171300</td>\n",
       "      <td>0.275246</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.760709</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.768657</td>\n",
       "      <td>0.761120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.112800</td>\n",
       "      <td>0.275567</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.763292</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.776584</td>\n",
       "      <td>0.771239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.112800</td>\n",
       "      <td>0.295725</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.751079</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.768778</td>\n",
       "      <td>0.762905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.294249</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.767020</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.765861</td>\n",
       "      <td>0.754183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.297940</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.760790</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.772373</td>\n",
       "      <td>0.763719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.91       362\n",
      "                sara       0.65      0.66      0.66       237\n",
      "         radikalisme       0.75      0.82      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.79      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3711: Accuracy: 0.7106109324758842, F1 Micro: 0.7765839199703594, F1 Macro: 0.7712393205295713\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.91       362\n",
      "                sara       0.65      0.66      0.66       237\n",
      "         radikalisme       0.75      0.82      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.79      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 251\n",
      "Acquired samples: 175\n",
      "Sampling duration: 7.689352035522461 seconds\n",
      "New train size: 3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2430' max='2430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2430/2430 08:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.269259</td>\n",
       "      <td>0.666238</td>\n",
       "      <td>0.726070</td>\n",
       "      <td>0.703620</td>\n",
       "      <td>0.714669</td>\n",
       "      <td>0.716006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.236838</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.770324</td>\n",
       "      <td>0.736048</td>\n",
       "      <td>0.752796</td>\n",
       "      <td>0.738700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.295100</td>\n",
       "      <td>0.250176</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.760736</td>\n",
       "      <td>0.754268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.295100</td>\n",
       "      <td>0.246100</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.774094</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>0.765536</td>\n",
       "      <td>0.753299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.180400</td>\n",
       "      <td>0.269602</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.734906</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.765450</td>\n",
       "      <td>0.759032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.180400</td>\n",
       "      <td>0.266647</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.763815</td>\n",
       "      <td>0.760935</td>\n",
       "      <td>0.762372</td>\n",
       "      <td>0.753867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.119300</td>\n",
       "      <td>0.283004</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.752688</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.771775</td>\n",
       "      <td>0.766252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.119300</td>\n",
       "      <td>0.291036</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.759354</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.769803</td>\n",
       "      <td>0.765897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.083200</td>\n",
       "      <td>0.295188</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.752547</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.765926</td>\n",
       "      <td>0.760454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.083200</td>\n",
       "      <td>0.297013</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.760448</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.764441</td>\n",
       "      <td>0.757525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.92      0.90       362\n",
      "                sara       0.67      0.63      0.65       237\n",
      "         radikalisme       0.75      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.69      0.76      0.72       492\n",
      "\n",
      "           micro avg       0.75      0.79      0.77      1326\n",
      "           macro avg       0.75      0.78      0.77      1326\n",
      "        weighted avg       0.75      0.79      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3886: Accuracy: 0.7028938906752411, F1 Micro: 0.7717750826901872, F1 Macro: 0.7662520275436775\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.92      0.90       362\n",
      "                sara       0.67      0.63      0.65       237\n",
      "         radikalisme       0.75      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.69      0.76      0.72       492\n",
      "\n",
      "           micro avg       0.75      0.79      0.77      1326\n",
      "           macro avg       0.75      0.78      0.77      1326\n",
      "        weighted avg       0.75      0.79      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Samples above threshold: 234\n",
      "Acquired samples: 234\n",
      "Sampling duration: 7.479095458984375 seconds\n",
      "New train size: 4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 08:37, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.254912</td>\n",
       "      <td>0.678457</td>\n",
       "      <td>0.771667</td>\n",
       "      <td>0.698341</td>\n",
       "      <td>0.733175</td>\n",
       "      <td>0.723301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.299900</td>\n",
       "      <td>0.240618</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.784396</td>\n",
       "      <td>0.705128</td>\n",
       "      <td>0.742653</td>\n",
       "      <td>0.734959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.299900</td>\n",
       "      <td>0.239434</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.736044</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.769175</td>\n",
       "      <td>0.762730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.181600</td>\n",
       "      <td>0.238208</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.775875</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.763692</td>\n",
       "      <td>0.751674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.181600</td>\n",
       "      <td>0.251496</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.802179</td>\n",
       "      <td>0.721719</td>\n",
       "      <td>0.759825</td>\n",
       "      <td>0.748266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.125100</td>\n",
       "      <td>0.266029</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.792763</td>\n",
       "      <td>0.726998</td>\n",
       "      <td>0.758458</td>\n",
       "      <td>0.744193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.125100</td>\n",
       "      <td>0.280982</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.763079</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.766517</td>\n",
       "      <td>0.757445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>0.295551</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.757184</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.775570</td>\n",
       "      <td>0.770372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>0.299468</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.770677</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.771837</td>\n",
       "      <td>0.764331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.300148</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.766117</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.768421</td>\n",
       "      <td>0.760172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.92      0.91       362\n",
      "                sara       0.64      0.67      0.65       237\n",
      "         radikalisme       0.76      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.72      0.75      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.79      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4120: Accuracy: 0.712540192926045, F1 Micro: 0.775570272259014, F1 Macro: 0.7703721715350077\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.92      0.91       362\n",
      "                sara       0.64      0.67      0.65       237\n",
      "         radikalisme       0.76      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.72      0.75      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.79      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Samples above threshold: 210\n",
      "Acquired samples: 210\n",
      "Sampling duration: 6.743224382400513 seconds\n",
      "New train size: 4330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2710' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2710/2710 08:58, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.255983</td>\n",
       "      <td>0.684887</td>\n",
       "      <td>0.774707</td>\n",
       "      <td>0.697587</td>\n",
       "      <td>0.734127</td>\n",
       "      <td>0.723419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.300700</td>\n",
       "      <td>0.238336</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.755894</td>\n",
       "      <td>0.749623</td>\n",
       "      <td>0.752745</td>\n",
       "      <td>0.739203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.300700</td>\n",
       "      <td>0.233283</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.750179</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.768665</td>\n",
       "      <td>0.765118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.184500</td>\n",
       "      <td>0.242587</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.701357</td>\n",
       "      <td>0.751212</td>\n",
       "      <td>0.731836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.184500</td>\n",
       "      <td>0.257895</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.745196</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.766752</td>\n",
       "      <td>0.757095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.128100</td>\n",
       "      <td>0.263825</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.782504</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.758165</td>\n",
       "      <td>0.748370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.128100</td>\n",
       "      <td>0.294862</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.752547</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.765926</td>\n",
       "      <td>0.756555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.090700</td>\n",
       "      <td>0.311956</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.745416</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.770408</td>\n",
       "      <td>0.765305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.090700</td>\n",
       "      <td>0.305060</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.771807</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.759387</td>\n",
       "      <td>0.748805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066200</td>\n",
       "      <td>0.309703</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.752967</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.759162</td>\n",
       "      <td>0.750335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.62      0.67      0.64       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.70      0.75      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.77      1326\n",
      "           macro avg       0.74      0.79      0.77      1326\n",
      "        weighted avg       0.75      0.80      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4330: Accuracy: 0.7035369774919614, F1 Micro: 0.7704081632653063, F1 Macro: 0.7653047872550273\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.62      0.67      0.64       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.70      0.75      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.77      1326\n",
      "           macro avg       0.74      0.79      0.77      1326\n",
      "        weighted avg       0.75      0.80      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Samples above threshold: 189\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.011000156402588 seconds\n",
      "New train size: 4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2840' max='2840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2840/2840 09:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.261880</td>\n",
       "      <td>0.672026</td>\n",
       "      <td>0.742792</td>\n",
       "      <td>0.738311</td>\n",
       "      <td>0.740545</td>\n",
       "      <td>0.724244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.304900</td>\n",
       "      <td>0.234551</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.779136</td>\n",
       "      <td>0.720965</td>\n",
       "      <td>0.748923</td>\n",
       "      <td>0.733265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.304900</td>\n",
       "      <td>0.239962</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.730276</td>\n",
       "      <td>0.816742</td>\n",
       "      <td>0.771093</td>\n",
       "      <td>0.766753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>0.241151</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.761406</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.764551</td>\n",
       "      <td>0.755338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>0.247087</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.783359</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.767692</td>\n",
       "      <td>0.756404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.136900</td>\n",
       "      <td>0.272373</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.751061</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.771632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.136900</td>\n",
       "      <td>0.277391</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.771167</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.766780</td>\n",
       "      <td>0.759472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.096400</td>\n",
       "      <td>0.288116</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.768084</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.772403</td>\n",
       "      <td>0.767795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.298495</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.762182</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.776009</td>\n",
       "      <td>0.770309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.295984</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.773543</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.777027</td>\n",
       "      <td>0.770135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.67      0.62      0.65       237\n",
      "         radikalisme       0.74      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.73      0.73       492\n",
      "\n",
      "           micro avg       0.77      0.78      0.78      1326\n",
      "           macro avg       0.77      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.78      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4530: Accuracy: 0.7196141479099678, F1 Micro: 0.777027027027027, F1 Macro: 0.7701348794206843\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.67      0.62      0.65       237\n",
      "         radikalisme       0.74      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.73      0.73       492\n",
      "\n",
      "           micro avg       0.77      0.78      0.78      1326\n",
      "           macro avg       0.77      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.78      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Samples above threshold: 169\n",
      "Acquired samples: 133\n",
      "Sampling duration: 5.185138702392578 seconds\n",
      "New train size: 4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2920' max='2920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2920/2920 09:33, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250277</td>\n",
       "      <td>0.682958</td>\n",
       "      <td>0.773978</td>\n",
       "      <td>0.699849</td>\n",
       "      <td>0.735050</td>\n",
       "      <td>0.718104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.302200</td>\n",
       "      <td>0.230299</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.770312</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.756715</td>\n",
       "      <td>0.742908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.302200</td>\n",
       "      <td>0.240525</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.734597</td>\n",
       "      <td>0.818250</td>\n",
       "      <td>0.774171</td>\n",
       "      <td>0.765992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.193000</td>\n",
       "      <td>0.234814</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.776929</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.771917</td>\n",
       "      <td>0.761055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.193000</td>\n",
       "      <td>0.252358</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.746606</td>\n",
       "      <td>0.761246</td>\n",
       "      <td>0.753484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.139800</td>\n",
       "      <td>0.271281</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.752696</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.770703</td>\n",
       "      <td>0.762882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.099100</td>\n",
       "      <td>0.288483</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.743945</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.775893</td>\n",
       "      <td>0.771662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.099100</td>\n",
       "      <td>0.295922</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.765766</td>\n",
       "      <td>0.755399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.073300</td>\n",
       "      <td>0.303890</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.758266</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.768143</td>\n",
       "      <td>0.759602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.073300</td>\n",
       "      <td>0.308936</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.754373</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.767235</td>\n",
       "      <td>0.759687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.91      0.90       362\n",
      "                sara       0.63      0.69      0.66       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.70      0.77      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.81      0.78      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4663: Accuracy: 0.7099678456591639, F1 Micro: 0.7758931793576327, F1 Macro: 0.771661542563622\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.91      0.90       362\n",
      "                sara       0.63      0.69      0.66       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.70      0.77      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.81      0.78      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.126023530960083 seconds\n",
      "New train size: 4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3040' max='3040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3040/3040 09:52, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.246795</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.760563</td>\n",
       "      <td>0.733032</td>\n",
       "      <td>0.746544</td>\n",
       "      <td>0.730175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.302800</td>\n",
       "      <td>0.251582</td>\n",
       "      <td>0.679100</td>\n",
       "      <td>0.695971</td>\n",
       "      <td>0.859729</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.766740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.302800</td>\n",
       "      <td>0.225590</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.790193</td>\n",
       "      <td>0.741327</td>\n",
       "      <td>0.764981</td>\n",
       "      <td>0.754381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.197300</td>\n",
       "      <td>0.236636</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.773039</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.761984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.254707</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.770898</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.760886</td>\n",
       "      <td>0.749912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.269662</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.772086</td>\n",
       "      <td>0.764287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>0.277483</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.779141</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.772624</td>\n",
       "      <td>0.761297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>0.291599</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.768429</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.773323</td>\n",
       "      <td>0.767032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.076200</td>\n",
       "      <td>0.299753</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.761205</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.771120</td>\n",
       "      <td>0.765276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.063900</td>\n",
       "      <td>0.301875</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.762082</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.767503</td>\n",
       "      <td>0.760934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.92      0.91       362\n",
      "                sara       0.67      0.62      0.65       237\n",
      "         radikalisme       0.75      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.72      0.73      0.72       492\n",
      "\n",
      "           micro avg       0.77      0.78      0.77      1326\n",
      "           macro avg       0.76      0.77      0.77      1326\n",
      "        weighted avg       0.77      0.78      0.77      1326\n",
      "         samples avg       0.45      0.44      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4863: Accuracy: 0.7138263665594855, F1 Micro: 0.7733233420756838, F1 Macro: 0.7670320850293446\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.92      0.91       362\n",
      "                sara       0.67      0.62      0.65       237\n",
      "         radikalisme       0.75      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.72      0.73      0.72       492\n",
      "\n",
      "           micro avg       0.77      0.78      0.77      1326\n",
      "           macro avg       0.76      0.77      0.77      1326\n",
      "        weighted avg       0.77      0.78      0.77      1326\n",
      "         samples avg       0.45      0.44      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Samples above threshold: 136\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.353994369506836 seconds\n",
      "New train size: 5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3170' max='3170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3170/3170 10:13, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.246566</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.757088</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.751045</td>\n",
       "      <td>0.744924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.301600</td>\n",
       "      <td>0.236230</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.826756</td>\n",
       "      <td>0.647813</td>\n",
       "      <td>0.726427</td>\n",
       "      <td>0.705105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.301600</td>\n",
       "      <td>0.223359</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.772829</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>0.774513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.199500</td>\n",
       "      <td>0.229264</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.788700</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.778457</td>\n",
       "      <td>0.766826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.147700</td>\n",
       "      <td>0.240818</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.795161</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.768511</td>\n",
       "      <td>0.759508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.147700</td>\n",
       "      <td>0.260171</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.811352</td>\n",
       "      <td>0.733032</td>\n",
       "      <td>0.770206</td>\n",
       "      <td>0.757091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.108700</td>\n",
       "      <td>0.277045</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.760901</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.774981</td>\n",
       "      <td>0.768320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.295346</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.750354</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.774453</td>\n",
       "      <td>0.768500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.295046</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.765706</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.773423</td>\n",
       "      <td>0.767086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.298212</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.763120</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.776130</td>\n",
       "      <td>0.770431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.88      0.91       362\n",
      "                sara       0.65      0.67      0.66       237\n",
      "         radikalisme       0.75      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.77      0.78      0.77      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.44      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5063: Accuracy: 0.7189710610932476, F1 Micro: 0.7789001122334456, F1 Macro: 0.7745128535123158\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.88      0.91       362\n",
      "                sara       0.65      0.67      0.66       237\n",
      "         radikalisme       0.75      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.77      0.78      0.77      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.44      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Samples above threshold: 116\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.770887851715088 seconds\n",
      "New train size: 5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3290' max='3290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3290/3290 10:37, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.247570</td>\n",
       "      <td>0.684244</td>\n",
       "      <td>0.742754</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.751431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.303500</td>\n",
       "      <td>0.233101</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.758870</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.774289</td>\n",
       "      <td>0.768707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.303500</td>\n",
       "      <td>0.228325</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.758521</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.773383</td>\n",
       "      <td>0.763090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.202600</td>\n",
       "      <td>0.234342</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.758941</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.779001</td>\n",
       "      <td>0.774066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.146300</td>\n",
       "      <td>0.247241</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.758645</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.783813</td>\n",
       "      <td>0.778661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.146300</td>\n",
       "      <td>0.267786</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.761043</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.776505</td>\n",
       "      <td>0.770858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.110500</td>\n",
       "      <td>0.285502</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.775660</td>\n",
       "      <td>0.769526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.077100</td>\n",
       "      <td>0.290783</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.768889</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.775785</td>\n",
       "      <td>0.769459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.077100</td>\n",
       "      <td>0.295598</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.771174</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.776946</td>\n",
       "      <td>0.769334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.300199</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.763939</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.779461</td>\n",
       "      <td>0.774845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.64      0.69      0.66       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.72      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.78      1326\n",
      "           macro avg       0.75      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5263: Accuracy: 0.715112540192926, F1 Micro: 0.7838133430550491, F1 Macro: 0.7786605859263926\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.64      0.69      0.66       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.72      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.78      1326\n",
      "           macro avg       0.75      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Samples above threshold: 96\n",
      "Acquired samples: 178\n",
      "Sampling duration: 3.2532336711883545 seconds\n",
      "New train size: 5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3410' max='3410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3410/3410 10:53, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241730</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.747475</td>\n",
       "      <td>0.741185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.301000</td>\n",
       "      <td>0.221789</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.775744</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.771331</td>\n",
       "      <td>0.759053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.222662</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.801141</td>\n",
       "      <td>0.741327</td>\n",
       "      <td>0.770074</td>\n",
       "      <td>0.759844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.244237</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.736913</td>\n",
       "      <td>0.828054</td>\n",
       "      <td>0.779830</td>\n",
       "      <td>0.774339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.153100</td>\n",
       "      <td>0.263720</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.742507</td>\n",
       "      <td>0.822021</td>\n",
       "      <td>0.780243</td>\n",
       "      <td>0.772847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.113500</td>\n",
       "      <td>0.277405</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.753338</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.779920</td>\n",
       "      <td>0.773225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.113500</td>\n",
       "      <td>0.291943</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.749472</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.775391</td>\n",
       "      <td>0.768487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.297110</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.749655</td>\n",
       "      <td>0.819759</td>\n",
       "      <td>0.783141</td>\n",
       "      <td>0.779728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.311121</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.746853</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.775036</td>\n",
       "      <td>0.769320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.302910</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.765007</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.776374</td>\n",
       "      <td>0.770803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.63      0.72      0.67       237\n",
      "         radikalisme       0.74      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.70      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.75      0.82      0.78      1326\n",
      "        weighted avg       0.75      0.82      0.79      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5441: Accuracy: 0.7099678456591639, F1 Micro: 0.7831412103746398, F1 Macro: 0.7797276052342316\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.63      0.72      0.67       237\n",
      "         radikalisme       0.74      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.70      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.75      0.82      0.78      1326\n",
      "        weighted avg       0.75      0.82      0.79      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Samples above threshold: 78\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.760442018508911 seconds\n",
      "New train size: 5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3530' max='3530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3530/3530 11:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.244240</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.784497</td>\n",
       "      <td>0.694570</td>\n",
       "      <td>0.736800</td>\n",
       "      <td>0.725921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.308100</td>\n",
       "      <td>0.226640</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.780047</td>\n",
       "      <td>0.748869</td>\n",
       "      <td>0.764140</td>\n",
       "      <td>0.756011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.203700</td>\n",
       "      <td>0.224718</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.773684</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.774849</td>\n",
       "      <td>0.759513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.203700</td>\n",
       "      <td>0.228795</td>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.782738</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.788015</td>\n",
       "      <td>0.779602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.162000</td>\n",
       "      <td>0.247420</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.769511</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.782351</td>\n",
       "      <td>0.776123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.117500</td>\n",
       "      <td>0.258940</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.779893</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.776052</td>\n",
       "      <td>0.763873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.117500</td>\n",
       "      <td>0.271824</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.763402</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.783853</td>\n",
       "      <td>0.777132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.092900</td>\n",
       "      <td>0.281335</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.767923</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.775663</td>\n",
       "      <td>0.768813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.290687</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.770540</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.777736</td>\n",
       "      <td>0.771873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.059700</td>\n",
       "      <td>0.292426</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.779712</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.778240</td>\n",
       "      <td>0.770499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.75      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.75      0.76      0.76       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.79      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5641: Accuracy: 0.7286173633440515, F1 Micro: 0.7880149812734083, F1 Macro: 0.7796018818041107\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.75      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.75      0.76      0.76       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.79      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.169806480407715 seconds\n",
      "New train size: 5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3660' max='3660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3660/3660 11:43, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.239978</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.770998</td>\n",
       "      <td>0.733786</td>\n",
       "      <td>0.751932</td>\n",
       "      <td>0.747682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.305800</td>\n",
       "      <td>0.221767</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.763971</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.773641</td>\n",
       "      <td>0.760311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.203800</td>\n",
       "      <td>0.220209</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.780924</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.785607</td>\n",
       "      <td>0.777862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.203800</td>\n",
       "      <td>0.227305</td>\n",
       "      <td>0.732476</td>\n",
       "      <td>0.820132</td>\n",
       "      <td>0.749623</td>\n",
       "      <td>0.783294</td>\n",
       "      <td>0.769735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.242516</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.768950</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.782061</td>\n",
       "      <td>0.772336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.117700</td>\n",
       "      <td>0.256250</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.789433</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.783435</td>\n",
       "      <td>0.774646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.092400</td>\n",
       "      <td>0.276712</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.766571</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.784083</td>\n",
       "      <td>0.777484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.092400</td>\n",
       "      <td>0.295172</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.754584</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.779883</td>\n",
       "      <td>0.772917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069900</td>\n",
       "      <td>0.300970</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.759207</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.783053</td>\n",
       "      <td>0.775503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.060300</td>\n",
       "      <td>0.298432</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.767896</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.784053</td>\n",
       "      <td>0.777402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.66      0.64      0.65       237\n",
      "         radikalisme       0.75      0.85      0.80       235\n",
      "pencemaran_nama_baik       0.75      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5841: Accuracy: 0.7241157556270097, F1 Micro: 0.7856071964017991, F1 Macro: 0.777862456705172\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.66      0.64      0.65       237\n",
      "         radikalisme       0.75      0.85      0.80       235\n",
      "pencemaran_nama_baik       0.75      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 200\n",
      "Sampling duration: 1.559753179550171 seconds\n",
      "New train size: 6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3780' max='3780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3780/3780 12:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241562</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.761171</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.753049</td>\n",
       "      <td>0.747968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.301300</td>\n",
       "      <td>0.247141</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.721576</td>\n",
       "      <td>0.842383</td>\n",
       "      <td>0.777314</td>\n",
       "      <td>0.772562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.203900</td>\n",
       "      <td>0.217819</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.800158</td>\n",
       "      <td>0.763952</td>\n",
       "      <td>0.781636</td>\n",
       "      <td>0.768246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.235989</td>\n",
       "      <td>0.733119</td>\n",
       "      <td>0.779155</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.792439</td>\n",
       "      <td>0.786503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.264961</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.735139</td>\n",
       "      <td>0.839367</td>\n",
       "      <td>0.783803</td>\n",
       "      <td>0.779441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.122400</td>\n",
       "      <td>0.267686</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.771636</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.785635</td>\n",
       "      <td>0.777802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.091700</td>\n",
       "      <td>0.283032</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.762931</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.774984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.286973</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.771199</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.783222</td>\n",
       "      <td>0.776394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.299031</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.768064</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.784502</td>\n",
       "      <td>0.777580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.059200</td>\n",
       "      <td>0.306129</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.763083</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.787591</td>\n",
       "      <td>0.782012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.63      0.72      0.67       237\n",
      "         radikalisme       0.73      0.88      0.79       235\n",
      "pencemaran_nama_baik       0.78      0.75      0.76       492\n",
      "\n",
      "           micro avg       0.78      0.81      0.79      1326\n",
      "           macro avg       0.77      0.81      0.79      1326\n",
      "        weighted avg       0.79      0.81      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6041: Accuracy: 0.7331189710610932, F1 Micro: 0.792438843587843, F1 Macro: 0.7865025774475751\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.63      0.72      0.67       237\n",
      "         radikalisme       0.73      0.88      0.79       235\n",
      "pencemaran_nama_baik       0.78      0.75      0.76       492\n",
      "\n",
      "           micro avg       0.78      0.81      0.79      1326\n",
      "           macro avg       0.77      0.81      0.79      1326\n",
      "        weighted avg       0.79      0.81      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/tmp/ipykernel_23/2933288740.py:54: ConvergenceWarning: Number of distinct clusters (77) found smaller than n_clusters (177). Possibly due to duplicate points in X.\n",
      "  kmeans.fit(embeddings)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 177\n",
      "Sampling duration: 1.52840256690979 seconds\n",
      "New train size: 6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3890/3890 12:18, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243942</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.716634</td>\n",
       "      <td>0.822021</td>\n",
       "      <td>0.765718</td>\n",
       "      <td>0.762323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.298500</td>\n",
       "      <td>0.225264</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.765146</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.768306</td>\n",
       "      <td>0.758875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.205300</td>\n",
       "      <td>0.223437</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.759062</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.781559</td>\n",
       "      <td>0.775947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.155900</td>\n",
       "      <td>0.237479</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.782002</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.770937</td>\n",
       "      <td>0.765970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.155900</td>\n",
       "      <td>0.262386</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.739772</td>\n",
       "      <td>0.831825</td>\n",
       "      <td>0.783103</td>\n",
       "      <td>0.776382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.121600</td>\n",
       "      <td>0.257708</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.784722</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.775744</td>\n",
       "      <td>0.766426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>0.279469</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.781983</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.780506</td>\n",
       "      <td>0.772426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.073700</td>\n",
       "      <td>0.295487</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.768095</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.767301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.058900</td>\n",
       "      <td>0.303426</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.770132</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.781575</td>\n",
       "      <td>0.773845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.058900</td>\n",
       "      <td>0.309892</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.765262</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.779423</td>\n",
       "      <td>0.772096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.93      0.91       362\n",
      "                sara       0.66      0.65      0.66       237\n",
      "         radikalisme       0.74      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.68      0.83      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.83      0.78      1326\n",
      "           macro avg       0.74      0.82      0.78      1326\n",
      "        weighted avg       0.74      0.83      0.78      1326\n",
      "         samples avg       0.47      0.47      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6218: Accuracy: 0.7118971061093248, F1 Micro: 0.7831025914093007, F1 Macro: 0.7763824590685313\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.93      0.91       362\n",
      "                sara       0.66      0.65      0.66       237\n",
      "         radikalisme       0.74      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.68      0.83      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.83      0.78      1326\n",
      "           macro avg       0.74      0.82      0.78      1326\n",
      "        weighted avg       0.74      0.83      0.78      1326\n",
      "         samples avg       0.47      0.47      0.46      1326\n",
      "\n",
      "Total sampling time: 180.34 seconds\n",
      "Total runtime: 11331.59144449234 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace1472",
   "metadata": {
    "papermill": {
     "duration": 0.031549,
     "end_time": "2024-12-21T09:44:56.169784",
     "exception": false,
     "start_time": "2024-12-21T09:44:56.138235",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c89a38b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T09:44:56.237211Z",
     "iopub.status.busy": "2024-12-21T09:44:56.236873Z",
     "iopub.status.idle": "2024-12-21T12:55:16.750259Z",
     "shell.execute_reply": "2024-12-21T12:55:16.749543Z"
    },
    "papermill": {
     "duration": 11420.549199,
     "end_time": "2024-12-21T12:55:16.751996",
     "exception": false,
     "start_time": "2024-12-21T09:44:56.202797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 02:15, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.466312</td>\n",
       "      <td>0.447588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.022427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.392322</td>\n",
       "      <td>0.554984</td>\n",
       "      <td>0.920290</td>\n",
       "      <td>0.191554</td>\n",
       "      <td>0.317104</td>\n",
       "      <td>0.211713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.349551</td>\n",
       "      <td>0.584566</td>\n",
       "      <td>0.834646</td>\n",
       "      <td>0.319759</td>\n",
       "      <td>0.462377</td>\n",
       "      <td>0.381456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.331326</td>\n",
       "      <td>0.586495</td>\n",
       "      <td>0.799035</td>\n",
       "      <td>0.374811</td>\n",
       "      <td>0.510267</td>\n",
       "      <td>0.438305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.317812</td>\n",
       "      <td>0.590997</td>\n",
       "      <td>0.812303</td>\n",
       "      <td>0.388386</td>\n",
       "      <td>0.525510</td>\n",
       "      <td>0.465296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.312626</td>\n",
       "      <td>0.603859</td>\n",
       "      <td>0.802213</td>\n",
       "      <td>0.437406</td>\n",
       "      <td>0.566130</td>\n",
       "      <td>0.506563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.301693</td>\n",
       "      <td>0.610289</td>\n",
       "      <td>0.758030</td>\n",
       "      <td>0.533937</td>\n",
       "      <td>0.626549</td>\n",
       "      <td>0.600378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.300017</td>\n",
       "      <td>0.610932</td>\n",
       "      <td>0.759957</td>\n",
       "      <td>0.532428</td>\n",
       "      <td>0.626164</td>\n",
       "      <td>0.598342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.301048</td>\n",
       "      <td>0.610289</td>\n",
       "      <td>0.765419</td>\n",
       "      <td>0.524133</td>\n",
       "      <td>0.622202</td>\n",
       "      <td>0.587982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.300751</td>\n",
       "      <td>0.610289</td>\n",
       "      <td>0.768632</td>\n",
       "      <td>0.521116</td>\n",
       "      <td>0.621124</td>\n",
       "      <td>0.587391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.81      0.86       362\n",
      "                sara       0.64      0.25      0.36       237\n",
      "         radikalisme       0.68      0.66      0.67       235\n",
      "pencemaran_nama_baik       0.69      0.41      0.51       492\n",
      "\n",
      "           micro avg       0.76      0.53      0.63      1326\n",
      "           macro avg       0.73      0.53      0.60      1326\n",
      "        weighted avg       0.74      0.53      0.61      1326\n",
      "         samples avg       0.35      0.31      0.32      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 388: Accuracy: 0.6102893890675242, F1 Micro: 0.6265486725663717, F1 Macro: 0.6003779383425171\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.81      0.86       362\n",
      "                sara       0.64      0.25      0.36       237\n",
      "         radikalisme       0.68      0.66      0.67       235\n",
      "pencemaran_nama_baik       0.69      0.41      0.51       492\n",
      "\n",
      "           micro avg       0.76      0.53      0.63      1326\n",
      "           macro avg       0.73      0.53      0.60      1326\n",
      "        weighted avg       0.74      0.53      0.61      1326\n",
      "         samples avg       0.35      0.31      0.32      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 583\n",
      "Acquired samples: 583\n",
      "Sampling duration: 24.094300985336304 seconds\n",
      "New train size: 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [610/610 03:13, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.367995</td>\n",
       "      <td>0.552412</td>\n",
       "      <td>0.811151</td>\n",
       "      <td>0.340121</td>\n",
       "      <td>0.479277</td>\n",
       "      <td>0.413277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.300600</td>\n",
       "      <td>0.631511</td>\n",
       "      <td>0.789644</td>\n",
       "      <td>0.552036</td>\n",
       "      <td>0.649800</td>\n",
       "      <td>0.616700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.276656</td>\n",
       "      <td>0.657878</td>\n",
       "      <td>0.742175</td>\n",
       "      <td>0.679487</td>\n",
       "      <td>0.709449</td>\n",
       "      <td>0.691819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.271861</td>\n",
       "      <td>0.653376</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.692515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.272504</td>\n",
       "      <td>0.679100</td>\n",
       "      <td>0.763970</td>\n",
       "      <td>0.690799</td>\n",
       "      <td>0.725545</td>\n",
       "      <td>0.711017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.273279</td>\n",
       "      <td>0.667524</td>\n",
       "      <td>0.725291</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.738712</td>\n",
       "      <td>0.729352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.273450</td>\n",
       "      <td>0.667524</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.711928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.274310</td>\n",
       "      <td>0.676527</td>\n",
       "      <td>0.743884</td>\n",
       "      <td>0.733786</td>\n",
       "      <td>0.738800</td>\n",
       "      <td>0.726704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.234800</td>\n",
       "      <td>0.275330</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.761218</td>\n",
       "      <td>0.716440</td>\n",
       "      <td>0.738151</td>\n",
       "      <td>0.725207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.234800</td>\n",
       "      <td>0.276002</td>\n",
       "      <td>0.680386</td>\n",
       "      <td>0.752561</td>\n",
       "      <td>0.720211</td>\n",
       "      <td>0.736031</td>\n",
       "      <td>0.723839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.90      0.89       362\n",
      "                sara       0.67      0.50      0.57       237\n",
      "         radikalisme       0.74      0.77      0.76       235\n",
      "pencemaran_nama_baik       0.67      0.71      0.69       492\n",
      "\n",
      "           micro avg       0.74      0.73      0.74      1326\n",
      "           macro avg       0.74      0.72      0.73      1326\n",
      "        weighted avg       0.74      0.73      0.73      1326\n",
      "         samples avg       0.41      0.41      0.40      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 971: Accuracy: 0.6765273311897106, F1 Micro: 0.738800303720577, F1 Macro: 0.726703798338853\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.90      0.89       362\n",
      "                sara       0.67      0.50      0.57       237\n",
      "         radikalisme       0.74      0.77      0.76       235\n",
      "pencemaran_nama_baik       0.67      0.71      0.69       492\n",
      "\n",
      "           micro avg       0.74      0.73      0.74      1326\n",
      "           macro avg       0.74      0.72      0.73      1326\n",
      "        weighted avg       0.74      0.73      0.73      1326\n",
      "         samples avg       0.41      0.41      0.40      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 20.48665165901184 seconds\n",
      "New train size: 1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [940/940 04:08, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.319652</td>\n",
       "      <td>0.581350</td>\n",
       "      <td>0.740175</td>\n",
       "      <td>0.511312</td>\n",
       "      <td>0.604817</td>\n",
       "      <td>0.584831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.275322</td>\n",
       "      <td>0.650804</td>\n",
       "      <td>0.764212</td>\n",
       "      <td>0.618401</td>\n",
       "      <td>0.683618</td>\n",
       "      <td>0.671009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.261600</td>\n",
       "      <td>0.677170</td>\n",
       "      <td>0.786988</td>\n",
       "      <td>0.665913</td>\n",
       "      <td>0.721405</td>\n",
       "      <td>0.703355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.260989</td>\n",
       "      <td>0.679743</td>\n",
       "      <td>0.768852</td>\n",
       "      <td>0.707391</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.721041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.263222</td>\n",
       "      <td>0.683601</td>\n",
       "      <td>0.810861</td>\n",
       "      <td>0.653092</td>\n",
       "      <td>0.723475</td>\n",
       "      <td>0.703338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.261100</td>\n",
       "      <td>0.272116</td>\n",
       "      <td>0.686817</td>\n",
       "      <td>0.745738</td>\n",
       "      <td>0.758673</td>\n",
       "      <td>0.752150</td>\n",
       "      <td>0.743063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.261100</td>\n",
       "      <td>0.267527</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.777143</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.746374</td>\n",
       "      <td>0.735481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.261100</td>\n",
       "      <td>0.273701</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.774659</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.750874</td>\n",
       "      <td>0.741463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.261100</td>\n",
       "      <td>0.279145</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.755796</td>\n",
       "      <td>0.737557</td>\n",
       "      <td>0.746565</td>\n",
       "      <td>0.737303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.261100</td>\n",
       "      <td>0.280913</td>\n",
       "      <td>0.684887</td>\n",
       "      <td>0.766161</td>\n",
       "      <td>0.723982</td>\n",
       "      <td>0.744475</td>\n",
       "      <td>0.732919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.88      0.88       362\n",
      "                sara       0.65      0.58      0.61       237\n",
      "         radikalisme       0.74      0.77      0.75       235\n",
      "pencemaran_nama_baik       0.69      0.75      0.72       492\n",
      "\n",
      "           micro avg       0.75      0.76      0.75      1326\n",
      "           macro avg       0.74      0.75      0.74      1326\n",
      "        weighted avg       0.75      0.76      0.75      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1496: Accuracy: 0.6868167202572347, F1 Micro: 0.7521495327102804, F1 Macro: 0.7430626719291655\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.88      0.88       362\n",
      "                sara       0.65      0.58      0.61       237\n",
      "         radikalisme       0.74      0.77      0.75       235\n",
      "pencemaran_nama_baik       0.69      0.75      0.72       492\n",
      "\n",
      "           micro avg       0.75      0.76      0.75      1326\n",
      "           macro avg       0.74      0.75      0.74      1326\n",
      "        weighted avg       0.75      0.76      0.75      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 18.438194274902344 seconds\n",
      "New train size: 1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1240' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1240/1240 04:58, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.305817</td>\n",
       "      <td>0.591640</td>\n",
       "      <td>0.802778</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.565005</td>\n",
       "      <td>0.557861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.269286</td>\n",
       "      <td>0.667524</td>\n",
       "      <td>0.789374</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.699160</td>\n",
       "      <td>0.685631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.259373</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.737418</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.749722</td>\n",
       "      <td>0.742622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256705</td>\n",
       "      <td>0.683601</td>\n",
       "      <td>0.745902</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.750375</td>\n",
       "      <td>0.738269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.273900</td>\n",
       "      <td>0.259033</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.756353</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.759760</td>\n",
       "      <td>0.750294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.273900</td>\n",
       "      <td>0.261640</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.757807</td>\n",
       "      <td>0.750377</td>\n",
       "      <td>0.754074</td>\n",
       "      <td>0.746143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.273900</td>\n",
       "      <td>0.269478</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.764165</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.758359</td>\n",
       "      <td>0.749517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.273900</td>\n",
       "      <td>0.275213</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.774347</td>\n",
       "      <td>0.737557</td>\n",
       "      <td>0.755504</td>\n",
       "      <td>0.746022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.125200</td>\n",
       "      <td>0.286782</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.761149</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.760287</td>\n",
       "      <td>0.750758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.125200</td>\n",
       "      <td>0.287022</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.753698</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.761016</td>\n",
       "      <td>0.753093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.90      0.89       362\n",
      "                sara       0.66      0.62      0.64       237\n",
      "         radikalisme       0.72      0.80      0.76       235\n",
      "pencemaran_nama_baik       0.72      0.73      0.72       492\n",
      "\n",
      "           micro avg       0.75      0.77      0.76      1326\n",
      "           macro avg       0.75      0.76      0.75      1326\n",
      "        weighted avg       0.75      0.77      0.76      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1969: Accuracy: 0.6951768488745981, F1 Micro: 0.7610156833457805, F1 Macro: 0.753093287969983\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.90      0.89       362\n",
      "                sara       0.66      0.62      0.64       237\n",
      "         radikalisme       0.72      0.80      0.76       235\n",
      "pencemaran_nama_baik       0.72      0.73      0.72       492\n",
      "\n",
      "           micro avg       0.75      0.77      0.76      1326\n",
      "           macro avg       0.75      0.76      0.75      1326\n",
      "        weighted avg       0.75      0.77      0.76      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 425\n",
      "Sampling duration: 15.591101884841919 seconds\n",
      "New train size: 2394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:42, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.289629</td>\n",
       "      <td>0.634727</td>\n",
       "      <td>0.820789</td>\n",
       "      <td>0.518100</td>\n",
       "      <td>0.635229</td>\n",
       "      <td>0.612262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.253698</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.751121</td>\n",
       "      <td>0.743195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.244899</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.756818</td>\n",
       "      <td>0.753394</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.745346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>0.250117</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.760606</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>0.758881</td>\n",
       "      <td>0.751010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>0.256677</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.775753</td>\n",
       "      <td>0.738311</td>\n",
       "      <td>0.756569</td>\n",
       "      <td>0.742029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>0.268641</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.812050</td>\n",
       "      <td>0.680995</td>\n",
       "      <td>0.740771</td>\n",
       "      <td>0.725108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.138100</td>\n",
       "      <td>0.277516</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.732962</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.762663</td>\n",
       "      <td>0.755914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.138100</td>\n",
       "      <td>0.276155</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.748364</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.761940</td>\n",
       "      <td>0.756824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.138100</td>\n",
       "      <td>0.285873</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.750550</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.760878</td>\n",
       "      <td>0.753441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.083900</td>\n",
       "      <td>0.286735</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.749269</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.760950</td>\n",
       "      <td>0.753742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.90      0.89       362\n",
      "                sara       0.62      0.65      0.63       237\n",
      "         radikalisme       0.71      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.69      0.77      0.73       492\n",
      "\n",
      "           micro avg       0.73      0.79      0.76      1326\n",
      "           macro avg       0.73      0.79      0.76      1326\n",
      "        weighted avg       0.74      0.79      0.76      1326\n",
      "         samples avg       0.44      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2394: Accuracy: 0.690032154340836, F1 Micro: 0.7626628075253256, F1 Macro: 0.7559142476309886\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.90      0.89       362\n",
      "                sara       0.62      0.65      0.63       237\n",
      "         radikalisme       0.71      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.69      0.77      0.73       492\n",
      "\n",
      "           micro avg       0.73      0.79      0.76      1326\n",
      "           macro avg       0.73      0.79      0.76      1326\n",
      "        weighted avg       0.74      0.79      0.76      1326\n",
      "         samples avg       0.44      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 383\n",
      "Acquired samples: 383\n",
      "Sampling duration: 13.779268026351929 seconds\n",
      "New train size: 2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1740' max='1740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1740/1740 06:22, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.276500</td>\n",
       "      <td>0.666881</td>\n",
       "      <td>0.746135</td>\n",
       "      <td>0.691554</td>\n",
       "      <td>0.717808</td>\n",
       "      <td>0.707862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.251180</td>\n",
       "      <td>0.677814</td>\n",
       "      <td>0.809432</td>\n",
       "      <td>0.634238</td>\n",
       "      <td>0.711205</td>\n",
       "      <td>0.699672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.290300</td>\n",
       "      <td>0.240828</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.776683</td>\n",
       "      <td>0.713424</td>\n",
       "      <td>0.743711</td>\n",
       "      <td>0.732127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.290300</td>\n",
       "      <td>0.252804</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.760595</td>\n",
       "      <td>0.752210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.290300</td>\n",
       "      <td>0.257477</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.773659</td>\n",
       "      <td>0.739819</td>\n",
       "      <td>0.756361</td>\n",
       "      <td>0.747853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.150800</td>\n",
       "      <td>0.270083</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.753915</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.758155</td>\n",
       "      <td>0.751480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.150800</td>\n",
       "      <td>0.280707</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.760305</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.755690</td>\n",
       "      <td>0.746799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.150800</td>\n",
       "      <td>0.281806</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.768589</td>\n",
       "      <td>0.763952</td>\n",
       "      <td>0.766263</td>\n",
       "      <td>0.759120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.292876</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.757396</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.764750</td>\n",
       "      <td>0.757313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.294560</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.760208</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.766180</td>\n",
       "      <td>0.757940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.89      0.90       362\n",
      "                sara       0.69      0.61      0.65       237\n",
      "         radikalisme       0.73      0.80      0.76       235\n",
      "pencemaran_nama_baik       0.72      0.73      0.72       492\n",
      "\n",
      "           micro avg       0.77      0.76      0.77      1326\n",
      "           macro avg       0.76      0.76      0.76      1326\n",
      "        weighted avg       0.77      0.76      0.77      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2777: Accuracy: 0.7054662379421222, F1 Micro: 0.7662632375189108, F1 Macro: 0.7591198488605666\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.89      0.90       362\n",
      "                sara       0.69      0.61      0.65       237\n",
      "         radikalisme       0.73      0.80      0.76       235\n",
      "pencemaran_nama_baik       0.72      0.73      0.72       492\n",
      "\n",
      "           micro avg       0.77      0.76      0.77      1326\n",
      "           macro avg       0.76      0.76      0.76      1326\n",
      "        weighted avg       0.77      0.76      0.77      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 345\n",
      "Acquired samples: 345\n",
      "Sampling duration: 12.02547812461853 seconds\n",
      "New train size: 3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='1960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/1960 06:58, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.273796</td>\n",
       "      <td>0.660450</td>\n",
       "      <td>0.715751</td>\n",
       "      <td>0.736802</td>\n",
       "      <td>0.726124</td>\n",
       "      <td>0.716310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241035</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.785896</td>\n",
       "      <td>0.697587</td>\n",
       "      <td>0.739113</td>\n",
       "      <td>0.717501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.292400</td>\n",
       "      <td>0.240119</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.780744</td>\n",
       "      <td>0.727753</td>\n",
       "      <td>0.753318</td>\n",
       "      <td>0.742883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.292400</td>\n",
       "      <td>0.244942</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.765329</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.763884</td>\n",
       "      <td>0.756322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.292400</td>\n",
       "      <td>0.263510</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.736589</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.770504</td>\n",
       "      <td>0.762148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.159500</td>\n",
       "      <td>0.262945</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.763910</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.765060</td>\n",
       "      <td>0.756347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.159500</td>\n",
       "      <td>0.281590</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.765015</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.766742</td>\n",
       "      <td>0.759779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.097600</td>\n",
       "      <td>0.287005</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.755636</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.769345</td>\n",
       "      <td>0.762492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.097600</td>\n",
       "      <td>0.292586</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.761183</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>0.759168</td>\n",
       "      <td>0.750785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.097600</td>\n",
       "      <td>0.291769</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.764087</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.765525</td>\n",
       "      <td>0.757823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.88      0.90       362\n",
      "                sara       0.64      0.63      0.63       237\n",
      "         radikalisme       0.73      0.82      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.83      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.81      0.77      1326\n",
      "           macro avg       0.74      0.79      0.76      1326\n",
      "        weighted avg       0.74      0.81      0.77      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3122: Accuracy: 0.6938906752411576, F1 Micro: 0.7705035971223021, F1 Macro: 0.762147720971465\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.88      0.90       362\n",
      "                sara       0.64      0.63      0.63       237\n",
      "         radikalisme       0.73      0.82      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.83      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.81      0.77      1326\n",
      "           macro avg       0.74      0.79      0.76      1326\n",
      "        weighted avg       0.74      0.81      0.77      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 310\n",
      "Acquired samples: 310\n",
      "Sampling duration: 10.693589925765991 seconds\n",
      "New train size: 3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2150/2150 07:29, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.264580</td>\n",
       "      <td>0.670096</td>\n",
       "      <td>0.739164</td>\n",
       "      <td>0.720211</td>\n",
       "      <td>0.729565</td>\n",
       "      <td>0.715988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.244895</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.795296</td>\n",
       "      <td>0.688537</td>\n",
       "      <td>0.738076</td>\n",
       "      <td>0.725167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.291400</td>\n",
       "      <td>0.252811</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.719124</td>\n",
       "      <td>0.816742</td>\n",
       "      <td>0.764831</td>\n",
       "      <td>0.762681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.291400</td>\n",
       "      <td>0.245879</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.795302</td>\n",
       "      <td>0.714932</td>\n",
       "      <td>0.752979</td>\n",
       "      <td>0.739996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.168300</td>\n",
       "      <td>0.262187</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.750179</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.769739</td>\n",
       "      <td>0.765118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.168300</td>\n",
       "      <td>0.267648</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.774980</td>\n",
       "      <td>0.742836</td>\n",
       "      <td>0.758568</td>\n",
       "      <td>0.748804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.274478</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.768879</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.757138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.291705</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.747151</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.768498</td>\n",
       "      <td>0.765976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.293711</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.754500</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.772007</td>\n",
       "      <td>0.768358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.296159</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.765185</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.772048</td>\n",
       "      <td>0.767539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.73      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.73      0.72       492\n",
      "\n",
      "           micro avg       0.77      0.78      0.77      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.78      0.77      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3432: Accuracy: 0.7106109324758842, F1 Micro: 0.7720478325859492, F1 Macro: 0.7675392441013297\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.73      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.73      0.72       492\n",
      "\n",
      "           micro avg       0.77      0.78      0.77      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.78      0.77      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 279\n",
      "Acquired samples: 279\n",
      "Sampling duration: 9.363749742507935 seconds\n",
      "New train size: 3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2320/2320 07:59, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.263238</td>\n",
       "      <td>0.672669</td>\n",
       "      <td>0.763959</td>\n",
       "      <td>0.680995</td>\n",
       "      <td>0.720096</td>\n",
       "      <td>0.712204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.245241</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.765823</td>\n",
       "      <td>0.730015</td>\n",
       "      <td>0.747490</td>\n",
       "      <td>0.739194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.298200</td>\n",
       "      <td>0.238439</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.791254</td>\n",
       "      <td>0.723228</td>\n",
       "      <td>0.755713</td>\n",
       "      <td>0.746703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.298200</td>\n",
       "      <td>0.247891</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.754619</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.762225</td>\n",
       "      <td>0.755633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.171400</td>\n",
       "      <td>0.253370</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.755399</td>\n",
       "      <td>0.745130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.171400</td>\n",
       "      <td>0.270847</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.741958</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.769956</td>\n",
       "      <td>0.766379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.288727</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.746279</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.769456</td>\n",
       "      <td>0.763695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.287518</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.766847</td>\n",
       "      <td>0.746606</td>\n",
       "      <td>0.756592</td>\n",
       "      <td>0.750731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.296505</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.756574</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.757998</td>\n",
       "      <td>0.751123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.297642</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.763718</td>\n",
       "      <td>0.755888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.89      0.89       362\n",
      "                sara       0.63      0.70      0.66       237\n",
      "         radikalisme       0.73      0.82      0.78       235\n",
      "pencemaran_nama_baik       0.69      0.77      0.73       492\n",
      "\n",
      "           micro avg       0.74      0.80      0.77      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.80      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3711: Accuracy: 0.7003215434083602, F1 Micro: 0.7699564586357038, F1 Macro: 0.7663793055234679\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.89      0.89       362\n",
      "                sara       0.63      0.70      0.66       237\n",
      "         radikalisme       0.73      0.82      0.78       235\n",
      "pencemaran_nama_baik       0.69      0.77      0.73       492\n",
      "\n",
      "           micro avg       0.74      0.80      0.77      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.80      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 251\n",
      "Acquired samples: 175\n",
      "Sampling duration: 7.894220590591431 seconds\n",
      "New train size: 3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2430' max='2430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2430/2430 08:18, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.257901</td>\n",
       "      <td>0.676527</td>\n",
       "      <td>0.737237</td>\n",
       "      <td>0.740573</td>\n",
       "      <td>0.738901</td>\n",
       "      <td>0.732532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.240633</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.747269</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.760282</td>\n",
       "      <td>0.754602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.300400</td>\n",
       "      <td>0.239167</td>\n",
       "      <td>0.687460</td>\n",
       "      <td>0.739411</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.757631</td>\n",
       "      <td>0.748225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.300400</td>\n",
       "      <td>0.239992</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.780430</td>\n",
       "      <td>0.739819</td>\n",
       "      <td>0.759582</td>\n",
       "      <td>0.746639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.179400</td>\n",
       "      <td>0.256497</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.771833</td>\n",
       "      <td>0.739819</td>\n",
       "      <td>0.755487</td>\n",
       "      <td>0.741634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.179400</td>\n",
       "      <td>0.275313</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.758200</td>\n",
       "      <td>0.749623</td>\n",
       "      <td>0.753887</td>\n",
       "      <td>0.744326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.116900</td>\n",
       "      <td>0.286923</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.756737</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.759579</td>\n",
       "      <td>0.748731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.116900</td>\n",
       "      <td>0.298067</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.754451</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.760658</td>\n",
       "      <td>0.752156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.082600</td>\n",
       "      <td>0.297694</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.760787</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.759350</td>\n",
       "      <td>0.749670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.082600</td>\n",
       "      <td>0.300897</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.754231</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.763501</td>\n",
       "      <td>0.756486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.91      0.91       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.71      0.80      0.75       235\n",
      "pencemaran_nama_baik       0.72      0.72      0.72       492\n",
      "\n",
      "           micro avg       0.75      0.77      0.76      1326\n",
      "           macro avg       0.75      0.77      0.76      1326\n",
      "        weighted avg       0.75      0.77      0.76      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3886: Accuracy: 0.7022508038585209, F1 Micro: 0.7635009310986964, F1 Macro: 0.7564859047252067\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.91      0.91       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.71      0.80      0.75       235\n",
      "pencemaran_nama_baik       0.72      0.72      0.72       492\n",
      "\n",
      "           micro avg       0.75      0.77      0.76      1326\n",
      "           macro avg       0.75      0.77      0.76      1326\n",
      "        weighted avg       0.75      0.77      0.76      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Samples above threshold: 234\n",
      "Acquired samples: 234\n",
      "Sampling duration: 7.636289834976196 seconds\n",
      "New train size: 4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 08:42, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.264761</td>\n",
       "      <td>0.668810</td>\n",
       "      <td>0.710223</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.748484</td>\n",
       "      <td>0.746037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.300900</td>\n",
       "      <td>0.242942</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.778862</td>\n",
       "      <td>0.722474</td>\n",
       "      <td>0.749609</td>\n",
       "      <td>0.741324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.300900</td>\n",
       "      <td>0.232253</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.775351</td>\n",
       "      <td>0.749623</td>\n",
       "      <td>0.762270</td>\n",
       "      <td>0.751374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.183700</td>\n",
       "      <td>0.243565</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.801920</td>\n",
       "      <td>0.693062</td>\n",
       "      <td>0.743528</td>\n",
       "      <td>0.729307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.183700</td>\n",
       "      <td>0.251481</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.806701</td>\n",
       "      <td>0.708145</td>\n",
       "      <td>0.754217</td>\n",
       "      <td>0.736121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>0.269864</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.767319</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.767898</td>\n",
       "      <td>0.760079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>0.281088</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.755831</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.768718</td>\n",
       "      <td>0.764358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.087200</td>\n",
       "      <td>0.294079</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.763061</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.772439</td>\n",
       "      <td>0.765199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.087200</td>\n",
       "      <td>0.295221</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.765056</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.770498</td>\n",
       "      <td>0.764663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>0.296505</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.766917</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.768072</td>\n",
       "      <td>0.760809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.69      0.62      0.66       237\n",
      "         radikalisme       0.72      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.72      0.75      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.78      0.77      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.76      0.78      0.77      1326\n",
      "         samples avg       0.44      0.44      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4120: Accuracy: 0.712540192926045, F1 Micro: 0.77243947858473, F1 Macro: 0.765199133806509\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.69      0.62      0.66       237\n",
      "         radikalisme       0.72      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.72      0.75      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.78      0.77      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.76      0.78      0.77      1326\n",
      "         samples avg       0.44      0.44      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Samples above threshold: 210\n",
      "Acquired samples: 210\n",
      "Sampling duration: 6.899127244949341 seconds\n",
      "New train size: 4330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2710' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2710/2710 09:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.252061</td>\n",
       "      <td>0.675241</td>\n",
       "      <td>0.764321</td>\n",
       "      <td>0.704374</td>\n",
       "      <td>0.733124</td>\n",
       "      <td>0.718952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.298100</td>\n",
       "      <td>0.231880</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.801695</td>\n",
       "      <td>0.713424</td>\n",
       "      <td>0.754988</td>\n",
       "      <td>0.743280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.298100</td>\n",
       "      <td>0.236754</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.757050</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.772979</td>\n",
       "      <td>0.768089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.239843</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.768999</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.769868</td>\n",
       "      <td>0.765299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.256311</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.752155</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.770419</td>\n",
       "      <td>0.764114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.125700</td>\n",
       "      <td>0.265819</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.763609</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.767904</td>\n",
       "      <td>0.759470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.125700</td>\n",
       "      <td>0.296717</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.740868</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.774217</td>\n",
       "      <td>0.770279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.091800</td>\n",
       "      <td>0.296484</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.754758</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.765973</td>\n",
       "      <td>0.760441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.091800</td>\n",
       "      <td>0.307076</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.752161</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.769344</td>\n",
       "      <td>0.766168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>0.305014</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.758468</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.767511</td>\n",
       "      <td>0.760496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.89      0.90       362\n",
      "                sara       0.64      0.71      0.67       237\n",
      "         radikalisme       0.69      0.87      0.77       235\n",
      "pencemaran_nama_baik       0.71      0.77      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.81      0.77      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4330: Accuracy: 0.7067524115755627, F1 Micro: 0.7742167806985956, F1 Macro: 0.7702792796497815\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.89      0.90       362\n",
      "                sara       0.64      0.71      0.67       237\n",
      "         radikalisme       0.69      0.87      0.77       235\n",
      "pencemaran_nama_baik       0.71      0.77      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.81      0.77      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Samples above threshold: 189\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.809209585189819 seconds\n",
      "New train size: 4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2840' max='2840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2840/2840 09:24, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.258504</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.778957</td>\n",
       "      <td>0.664404</td>\n",
       "      <td>0.717135</td>\n",
       "      <td>0.705838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.304800</td>\n",
       "      <td>0.233382</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.771833</td>\n",
       "      <td>0.739819</td>\n",
       "      <td>0.755487</td>\n",
       "      <td>0.746390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.304800</td>\n",
       "      <td>0.234528</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.783480</td>\n",
       "      <td>0.736802</td>\n",
       "      <td>0.759425</td>\n",
       "      <td>0.749210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.190300</td>\n",
       "      <td>0.257447</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.719287</td>\n",
       "      <td>0.821267</td>\n",
       "      <td>0.766901</td>\n",
       "      <td>0.765300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.190300</td>\n",
       "      <td>0.250946</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.782710</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.770115</td>\n",
       "      <td>0.759665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.139400</td>\n",
       "      <td>0.266064</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.773039</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.762359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.139400</td>\n",
       "      <td>0.272810</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.772624</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.769406</td>\n",
       "      <td>0.763176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.100200</td>\n",
       "      <td>0.295109</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.757091</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.770826</td>\n",
       "      <td>0.762803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.295792</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.764533</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.773929</td>\n",
       "      <td>0.767120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.297469</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.775076</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.772142</td>\n",
       "      <td>0.765611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.89      0.90       362\n",
      "                sara       0.64      0.66      0.65       237\n",
      "         radikalisme       0.75      0.80      0.77       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.78      0.77      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.78      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4530: Accuracy: 0.712540192926045, F1 Micro: 0.7739292364990689, F1 Macro: 0.7671202390737238\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.89      0.90       362\n",
      "                sara       0.64      0.66      0.65       237\n",
      "         radikalisme       0.75      0.80      0.77       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.78      0.77      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.78      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Samples above threshold: 169\n",
      "Acquired samples: 133\n",
      "Sampling duration: 5.276361703872681 seconds\n",
      "New train size: 4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2920' max='2920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2920/2920 09:38, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.251189</td>\n",
       "      <td>0.678457</td>\n",
       "      <td>0.769038</td>\n",
       "      <td>0.693062</td>\n",
       "      <td>0.729076</td>\n",
       "      <td>0.723875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.305100</td>\n",
       "      <td>0.234038</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.760393</td>\n",
       "      <td>0.758673</td>\n",
       "      <td>0.759532</td>\n",
       "      <td>0.755848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.305100</td>\n",
       "      <td>0.242375</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.736589</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.770504</td>\n",
       "      <td>0.766608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.193200</td>\n",
       "      <td>0.250213</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.778391</td>\n",
       "      <td>0.744344</td>\n",
       "      <td>0.760987</td>\n",
       "      <td>0.749029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.193200</td>\n",
       "      <td>0.264502</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.736510</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.763531</td>\n",
       "      <td>0.756470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.139200</td>\n",
       "      <td>0.273397</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.778997</td>\n",
       "      <td>0.749623</td>\n",
       "      <td>0.764028</td>\n",
       "      <td>0.754803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.099200</td>\n",
       "      <td>0.287977</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.764837</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.771129</td>\n",
       "      <td>0.765244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.099200</td>\n",
       "      <td>0.294499</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.766390</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.766679</td>\n",
       "      <td>0.759437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.303166</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.772997</td>\n",
       "      <td>0.767247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.306632</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.759001</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.768887</td>\n",
       "      <td>0.762036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.64      0.67      0.65       237\n",
      "         radikalisme       0.73      0.82      0.77       235\n",
      "pencemaran_nama_baik       0.72      0.74      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.79      0.77      1326\n",
      "           macro avg       0.75      0.78      0.77      1326\n",
      "        weighted avg       0.76      0.79      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4663: Accuracy: 0.7067524115755627, F1 Micro: 0.7729970326409495, F1 Macro: 0.7672468627510594\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.64      0.67      0.65       237\n",
      "         radikalisme       0.73      0.82      0.77       235\n",
      "pencemaran_nama_baik       0.72      0.74      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.79      0.77      1326\n",
      "           macro avg       0.75      0.78      0.77      1326\n",
      "        weighted avg       0.76      0.79      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.151273965835571 seconds\n",
      "New train size: 4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3040' max='3040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3040/3040 09:59, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.251830</td>\n",
       "      <td>0.686817</td>\n",
       "      <td>0.762821</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.739705</td>\n",
       "      <td>0.734497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.305700</td>\n",
       "      <td>0.236316</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.767228</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.761398</td>\n",
       "      <td>0.742088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.305700</td>\n",
       "      <td>0.230872</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.767844</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.769289</td>\n",
       "      <td>0.763380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.200600</td>\n",
       "      <td>0.251427</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.728734</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.771905</td>\n",
       "      <td>0.767185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.142800</td>\n",
       "      <td>0.251231</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.753980</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.769572</td>\n",
       "      <td>0.764092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.142800</td>\n",
       "      <td>0.270221</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.747368</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.774264</td>\n",
       "      <td>0.769854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.103300</td>\n",
       "      <td>0.280891</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.773313</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.771267</td>\n",
       "      <td>0.761545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.103300</td>\n",
       "      <td>0.292454</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.764619</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.771759</td>\n",
       "      <td>0.765580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.079100</td>\n",
       "      <td>0.305123</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.751425</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.772894</td>\n",
       "      <td>0.770240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.304081</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.761730</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.772491</td>\n",
       "      <td>0.766409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.90      0.90       362\n",
      "                sara       0.66      0.67      0.67       237\n",
      "         radikalisme       0.72      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.70      0.77      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.77      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.80      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4863: Accuracy: 0.7016077170418007, F1 Micro: 0.7742639040348965, F1 Macro: 0.7698536283014218\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.90      0.90       362\n",
      "                sara       0.66      0.67      0.67       237\n",
      "         radikalisme       0.72      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.70      0.77      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.77      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.80      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Samples above threshold: 136\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.543551445007324 seconds\n",
      "New train size: 5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3170' max='3170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3170/3170 10:21, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.247322</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.743646</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.757677</td>\n",
       "      <td>0.754447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.307400</td>\n",
       "      <td>0.236011</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.766462</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.760638</td>\n",
       "      <td>0.751336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.307400</td>\n",
       "      <td>0.229535</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.774942</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.765178</td>\n",
       "      <td>0.754887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>0.242028</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.764222</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.767092</td>\n",
       "      <td>0.760408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.147800</td>\n",
       "      <td>0.255077</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.780757</td>\n",
       "      <td>0.746606</td>\n",
       "      <td>0.763300</td>\n",
       "      <td>0.755349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.147800</td>\n",
       "      <td>0.269115</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.745416</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.770408</td>\n",
       "      <td>0.766956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.109800</td>\n",
       "      <td>0.286238</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.745787</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.772364</td>\n",
       "      <td>0.768595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.080200</td>\n",
       "      <td>0.306777</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.731903</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.775018</td>\n",
       "      <td>0.771304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.080200</td>\n",
       "      <td>0.297971</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.764619</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.771759</td>\n",
       "      <td>0.765327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.303800</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.762925</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.770896</td>\n",
       "      <td>0.765583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.63      0.70      0.67       237\n",
      "         radikalisme       0.71      0.86      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.80      0.73       492\n",
      "\n",
      "           micro avg       0.73      0.82      0.78      1326\n",
      "           macro avg       0.73      0.82      0.77      1326\n",
      "        weighted avg       0.74      0.82      0.78      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5063: Accuracy: 0.7022508038585209, F1 Micro: 0.7750177430801987, F1 Macro: 0.7713042013718372\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.63      0.70      0.67       237\n",
      "         radikalisme       0.71      0.86      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.80      0.73       492\n",
      "\n",
      "           micro avg       0.73      0.82      0.78      1326\n",
      "           macro avg       0.73      0.82      0.77      1326\n",
      "        weighted avg       0.74      0.82      0.78      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Samples above threshold: 116\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.878607749938965 seconds\n",
      "New train size: 5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3290' max='3290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3290/3290 10:41, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.246079</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.772764</td>\n",
       "      <td>0.723228</td>\n",
       "      <td>0.747176</td>\n",
       "      <td>0.731616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.306200</td>\n",
       "      <td>0.232453</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.736806</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.771993</td>\n",
       "      <td>0.763771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.306200</td>\n",
       "      <td>0.231497</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.765973</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.771707</td>\n",
       "      <td>0.760212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.207400</td>\n",
       "      <td>0.238505</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.764923</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.773761</td>\n",
       "      <td>0.763826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.149600</td>\n",
       "      <td>0.261060</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.748584</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.772096</td>\n",
       "      <td>0.763755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.149600</td>\n",
       "      <td>0.262872</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.783956</td>\n",
       "      <td>0.744344</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.753294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.113400</td>\n",
       "      <td>0.274796</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.776677</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.772555</td>\n",
       "      <td>0.763573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.288577</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.773414</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.772830</td>\n",
       "      <td>0.766713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.300105</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.764576</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.772846</td>\n",
       "      <td>0.763639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.302725</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.766396</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.775252</td>\n",
       "      <td>0.766390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.65      0.63      0.64       237\n",
      "         radikalisme       0.72      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.73      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.78      0.78      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.78      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5263: Accuracy: 0.7157556270096463, F1 Micro: 0.7752515840477078, F1 Macro: 0.7663899804311303\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.65      0.63      0.64       237\n",
      "         radikalisme       0.72      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.73      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.78      0.78      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.78      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Samples above threshold: 96\n",
      "Acquired samples: 178\n",
      "Sampling duration: 3.334106206893921 seconds\n",
      "New train size: 5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3410' max='3410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3410/3410 10:59, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243292</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.757100</td>\n",
       "      <td>0.763952</td>\n",
       "      <td>0.760511</td>\n",
       "      <td>0.752653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.307200</td>\n",
       "      <td>0.230561</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.782251</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.748722</td>\n",
       "      <td>0.732672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.208800</td>\n",
       "      <td>0.226236</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.753347</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.778871</td>\n",
       "      <td>0.771378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.208800</td>\n",
       "      <td>0.232244</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.785039</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.768105</td>\n",
       "      <td>0.760194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.153000</td>\n",
       "      <td>0.242838</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.785061</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.780895</td>\n",
       "      <td>0.774282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.118300</td>\n",
       "      <td>0.270288</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.750344</td>\n",
       "      <td>0.822775</td>\n",
       "      <td>0.784892</td>\n",
       "      <td>0.781330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.118300</td>\n",
       "      <td>0.279865</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.759062</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.781559</td>\n",
       "      <td>0.776579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.289047</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.774146</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.779940</td>\n",
       "      <td>0.773484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.304587</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.761871</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.779823</td>\n",
       "      <td>0.776526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.303762</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.766035</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.779096</td>\n",
       "      <td>0.774415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.64      0.73      0.68       237\n",
      "         radikalisme       0.71      0.87      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.75      0.82      0.78      1326\n",
      "        weighted avg       0.76      0.82      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5441: Accuracy: 0.712540192926045, F1 Micro: 0.7848920863309352, F1 Macro: 0.7813303986022406\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.64      0.73      0.68       237\n",
      "         radikalisme       0.71      0.87      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.75      0.82      0.78      1326\n",
      "        weighted avg       0.76      0.82      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Samples above threshold: 78\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.6857051849365234 seconds\n",
      "New train size: 5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3530' max='3530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3530/3530 11:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.242964</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.761686</td>\n",
       "      <td>0.749623</td>\n",
       "      <td>0.755606</td>\n",
       "      <td>0.746812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.307200</td>\n",
       "      <td>0.230384</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.753705</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.778709</td>\n",
       "      <td>0.766061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.228047</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.765135</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.777901</td>\n",
       "      <td>0.769948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.234696</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.774099</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.783613</td>\n",
       "      <td>0.777243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.157000</td>\n",
       "      <td>0.259422</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.756219</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.778632</td>\n",
       "      <td>0.775455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.116800</td>\n",
       "      <td>0.261522</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.816102</td>\n",
       "      <td>0.726244</td>\n",
       "      <td>0.768555</td>\n",
       "      <td>0.755072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.116800</td>\n",
       "      <td>0.279127</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.781966</td>\n",
       "      <td>0.773544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.282087</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.780286</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.781168</td>\n",
       "      <td>0.774875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.296261</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.765004</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.781100</td>\n",
       "      <td>0.775834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.299867</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.765173</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.781550</td>\n",
       "      <td>0.775609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.88      0.91       362\n",
      "                sara       0.66      0.65      0.65       237\n",
      "         radikalisme       0.74      0.86      0.80       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5641: Accuracy: 0.7215434083601286, F1 Micro: 0.7836126629422717, F1 Macro: 0.7772431695862133\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.88      0.91       362\n",
      "                sara       0.66      0.65      0.65       237\n",
      "         radikalisme       0.74      0.86      0.80       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.1359217166900635 seconds\n",
      "New train size: 5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3660' max='3660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3660/3660 11:41, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.252323</td>\n",
       "      <td>0.655305</td>\n",
       "      <td>0.772528</td>\n",
       "      <td>0.665913</td>\n",
       "      <td>0.715269</td>\n",
       "      <td>0.684042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.303800</td>\n",
       "      <td>0.228325</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.804518</td>\n",
       "      <td>0.698341</td>\n",
       "      <td>0.747679</td>\n",
       "      <td>0.729277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.210700</td>\n",
       "      <td>0.249286</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.711649</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.771833</td>\n",
       "      <td>0.768378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.210700</td>\n",
       "      <td>0.240745</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.778768</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.784886</td>\n",
       "      <td>0.778528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.163500</td>\n",
       "      <td>0.248416</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.768158</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.778728</td>\n",
       "      <td>0.772839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.118800</td>\n",
       "      <td>0.260984</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.788253</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.771302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.095800</td>\n",
       "      <td>0.286773</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.750173</td>\n",
       "      <td>0.817496</td>\n",
       "      <td>0.782389</td>\n",
       "      <td>0.779744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.095800</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.756320</td>\n",
       "      <td>0.812217</td>\n",
       "      <td>0.783273</td>\n",
       "      <td>0.779491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>0.297729</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.769287</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.779308</td>\n",
       "      <td>0.773550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.300226</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.766019</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.783794</td>\n",
       "      <td>0.777885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.69      0.63      0.66       237\n",
      "         radikalisme       0.73      0.87      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.74      0.74       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.78      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5841: Accuracy: 0.7254019292604501, F1 Micro: 0.784885895997007, F1 Macro: 0.778527990215423\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.69      0.63      0.66       237\n",
      "         radikalisme       0.73      0.87      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.74      0.74       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.78      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 200\n",
      "Sampling duration: 1.5643410682678223 seconds\n",
      "New train size: 6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3780' max='3780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3780/3780 12:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243701</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.778783</td>\n",
       "      <td>0.714178</td>\n",
       "      <td>0.745083</td>\n",
       "      <td>0.729195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.307500</td>\n",
       "      <td>0.222917</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.807432</td>\n",
       "      <td>0.720965</td>\n",
       "      <td>0.761753</td>\n",
       "      <td>0.750089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.209100</td>\n",
       "      <td>0.236235</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.802326</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.752265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.246152</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.805441</td>\n",
       "      <td>0.736802</td>\n",
       "      <td>0.769594</td>\n",
       "      <td>0.759498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.261968</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.765988</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.780163</td>\n",
       "      <td>0.771369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.118700</td>\n",
       "      <td>0.272620</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.759520</td>\n",
       "      <td>0.812217</td>\n",
       "      <td>0.784985</td>\n",
       "      <td>0.780238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.092700</td>\n",
       "      <td>0.282792</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.780728</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.778366</td>\n",
       "      <td>0.769322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.306655</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.748786</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.779906</td>\n",
       "      <td>0.773797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.306863</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.771891</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.781378</td>\n",
       "      <td>0.774382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>0.310352</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.770191</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.780506</td>\n",
       "      <td>0.773729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.65      0.70      0.67       237\n",
      "         radikalisme       0.72      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.78      1326\n",
      "           macro avg       0.76      0.81      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6041: Accuracy: 0.7215434083601286, F1 Micro: 0.7849854227405249, F1 Macro: 0.7802382942978269\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.65      0.70      0.67       237\n",
      "         radikalisme       0.72      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.78      1326\n",
      "           macro avg       0.76      0.81      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/tmp/ipykernel_23/2933288740.py:54: ConvergenceWarning: Number of distinct clusters (77) found smaller than n_clusters (177). Possibly due to duplicate points in X.\n",
      "  kmeans.fit(embeddings)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 177\n",
      "Sampling duration: 1.5571625232696533 seconds\n",
      "New train size: 6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3890/3890 12:16, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.249032</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.744262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.296700</td>\n",
       "      <td>0.223454</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.838889</td>\n",
       "      <td>0.683258</td>\n",
       "      <td>0.753117</td>\n",
       "      <td>0.739142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.202100</td>\n",
       "      <td>0.225372</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.775223</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.781601</td>\n",
       "      <td>0.775001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.156700</td>\n",
       "      <td>0.228108</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.776635</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.786751</td>\n",
       "      <td>0.777352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.156700</td>\n",
       "      <td>0.243432</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.783169</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.781096</td>\n",
       "      <td>0.773957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>0.261229</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.787023</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.782246</td>\n",
       "      <td>0.776060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.091300</td>\n",
       "      <td>0.272734</td>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.803331</td>\n",
       "      <td>0.763952</td>\n",
       "      <td>0.783147</td>\n",
       "      <td>0.771806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.295411</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.760475</td>\n",
       "      <td>0.821267</td>\n",
       "      <td>0.789703</td>\n",
       "      <td>0.785904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.295092</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.778187</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.787179</td>\n",
       "      <td>0.781021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.301223</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.786350</td>\n",
       "      <td>0.779310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.92      0.93       362\n",
      "                sara       0.65      0.70      0.68       237\n",
      "         radikalisme       0.73      0.87      0.79       235\n",
      "pencemaran_nama_baik       0.71      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.82      0.79      1326\n",
      "           macro avg       0.76      0.82      0.79      1326\n",
      "        weighted avg       0.77      0.82      0.79      1326\n",
      "         samples avg       0.47      0.47      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6218: Accuracy: 0.7228295819935692, F1 Micro: 0.7897026831036983, F1 Macro: 0.7859039042505956\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.92      0.93       362\n",
      "                sara       0.65      0.70      0.68       237\n",
      "         radikalisme       0.73      0.87      0.79       235\n",
      "pencemaran_nama_baik       0.71      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.82      0.79      1326\n",
      "           macro avg       0.76      0.82      0.79      1326\n",
      "        weighted avg       0.77      0.82      0.79      1326\n",
      "         samples avg       0.47      0.47      0.46      1326\n",
      "\n",
      "Total sampling time: 183.84 seconds\n",
      "Total runtime: 11419.727169513702 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2fddc9",
   "metadata": {},
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f587b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384cc19ad9544e389d8a77cab8d04932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241221_102943-c6pk9551\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m./results/netifier-kmeans-4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/nicost918-petra-christian-university/huggingface\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/nicost918-petra-christian-university/huggingface/runs/c6pk9551\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 02:18, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.463594</td>\n",
       "      <td>0.462379</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.030166</td>\n",
       "      <td>0.058522</td>\n",
       "      <td>0.049751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.391793</td>\n",
       "      <td>0.568489</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>0.278281</td>\n",
       "      <td>0.416949</td>\n",
       "      <td>0.340929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.357158</td>\n",
       "      <td>0.562701</td>\n",
       "      <td>0.873684</td>\n",
       "      <td>0.250377</td>\n",
       "      <td>0.389215</td>\n",
       "      <td>0.305181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.331397</td>\n",
       "      <td>0.590354</td>\n",
       "      <td>0.783858</td>\n",
       "      <td>0.432127</td>\n",
       "      <td>0.557122</td>\n",
       "      <td>0.487882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.317543</td>\n",
       "      <td>0.603215</td>\n",
       "      <td>0.790637</td>\n",
       "      <td>0.458522</td>\n",
       "      <td>0.580430</td>\n",
       "      <td>0.516101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.307228</td>\n",
       "      <td>0.619293</td>\n",
       "      <td>0.780571</td>\n",
       "      <td>0.515083</td>\n",
       "      <td>0.620627</td>\n",
       "      <td>0.590389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.304412</td>\n",
       "      <td>0.622508</td>\n",
       "      <td>0.775442</td>\n",
       "      <td>0.528658</td>\n",
       "      <td>0.628700</td>\n",
       "      <td>0.586116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.301726</td>\n",
       "      <td>0.622508</td>\n",
       "      <td>0.763407</td>\n",
       "      <td>0.547511</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.605725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.302151</td>\n",
       "      <td>0.625723</td>\n",
       "      <td>0.764644</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.640666</td>\n",
       "      <td>0.610989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.300772</td>\n",
       "      <td>0.628939</td>\n",
       "      <td>0.751984</td>\n",
       "      <td>0.571644</td>\n",
       "      <td>0.649529</td>\n",
       "      <td>0.626356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.76      0.84       362\n",
      "                sara       0.70      0.31      0.43       237\n",
      "         radikalisme       0.65      0.62      0.63       235\n",
      "pencemaran_nama_baik       0.68      0.53      0.60       492\n",
      "\n",
      "           micro avg       0.75      0.57      0.65      1326\n",
      "           macro avg       0.74      0.56      0.63      1326\n",
      "        weighted avg       0.75      0.57      0.64      1326\n",
      "         samples avg       0.35      0.33      0.33      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 388: Accuracy: 0.6289389067524116, F1 Micro: 0.6495287060839761, F1 Macro: 0.626355645176144\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.76      0.84       362\n",
      "                sara       0.70      0.31      0.43       237\n",
      "         radikalisme       0.65      0.62      0.63       235\n",
      "pencemaran_nama_baik       0.68      0.53      0.60       492\n",
      "\n",
      "           micro avg       0.75      0.57      0.65      1326\n",
      "           macro avg       0.74      0.56      0.63      1326\n",
      "        weighted avg       0.75      0.57      0.64      1326\n",
      "         samples avg       0.35      0.33      0.33      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 583\n",
      "Acquired samples: 583\n",
      "Sampling duration: 25.981227159500122 seconds\n",
      "New train size: 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [610/610 03:19, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.362293</td>\n",
       "      <td>0.562058</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.276018</td>\n",
       "      <td>0.416382</td>\n",
       "      <td>0.361363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.296033</td>\n",
       "      <td>0.638585</td>\n",
       "      <td>0.773176</td>\n",
       "      <td>0.591252</td>\n",
       "      <td>0.670085</td>\n",
       "      <td>0.651382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.272725</td>\n",
       "      <td>0.663666</td>\n",
       "      <td>0.762195</td>\n",
       "      <td>0.659879</td>\n",
       "      <td>0.707357</td>\n",
       "      <td>0.690260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.264643</td>\n",
       "      <td>0.676527</td>\n",
       "      <td>0.761106</td>\n",
       "      <td>0.684766</td>\n",
       "      <td>0.720921</td>\n",
       "      <td>0.713978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.265605</td>\n",
       "      <td>0.677814</td>\n",
       "      <td>0.737519</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.736405</td>\n",
       "      <td>0.726195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.263756</td>\n",
       "      <td>0.672026</td>\n",
       "      <td>0.760166</td>\n",
       "      <td>0.690799</td>\n",
       "      <td>0.723825</td>\n",
       "      <td>0.707606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266434</td>\n",
       "      <td>0.682958</td>\n",
       "      <td>0.750195</td>\n",
       "      <td>0.724736</td>\n",
       "      <td>0.737246</td>\n",
       "      <td>0.727980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.272542</td>\n",
       "      <td>0.686817</td>\n",
       "      <td>0.736377</td>\n",
       "      <td>0.754148</td>\n",
       "      <td>0.745156</td>\n",
       "      <td>0.735887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.272809</td>\n",
       "      <td>0.681029</td>\n",
       "      <td>0.758704</td>\n",
       "      <td>0.706637</td>\n",
       "      <td>0.731745</td>\n",
       "      <td>0.721245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.275731</td>\n",
       "      <td>0.675241</td>\n",
       "      <td>0.736006</td>\n",
       "      <td>0.733786</td>\n",
       "      <td>0.734894</td>\n",
       "      <td>0.723752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.87      0.88       362\n",
      "                sara       0.60      0.60      0.60       237\n",
      "         radikalisme       0.70      0.79      0.74       235\n",
      "pencemaran_nama_baik       0.71      0.73      0.72       492\n",
      "\n",
      "           micro avg       0.74      0.75      0.75      1326\n",
      "           macro avg       0.73      0.75      0.74      1326\n",
      "        weighted avg       0.74      0.75      0.75      1326\n",
      "         samples avg       0.42      0.43      0.41      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 971: Accuracy: 0.6868167202572347, F1 Micro: 0.7451564828614009, F1 Macro: 0.735886765259139\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.87      0.88       362\n",
      "                sara       0.60      0.60      0.60       237\n",
      "         radikalisme       0.70      0.79      0.74       235\n",
      "pencemaran_nama_baik       0.71      0.73      0.72       492\n",
      "\n",
      "           micro avg       0.74      0.75      0.75      1326\n",
      "           macro avg       0.73      0.75      0.74      1326\n",
      "        weighted avg       0.74      0.75      0.75      1326\n",
      "         samples avg       0.42      0.43      0.41      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 23.07135558128357 seconds\n",
      "New train size: 1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [940/940 04:16, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.320396</td>\n",
       "      <td>0.589711</td>\n",
       "      <td>0.742553</td>\n",
       "      <td>0.526395</td>\n",
       "      <td>0.616064</td>\n",
       "      <td>0.602041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.270779</td>\n",
       "      <td>0.668810</td>\n",
       "      <td>0.784834</td>\n",
       "      <td>0.624434</td>\n",
       "      <td>0.695506</td>\n",
       "      <td>0.691054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.260071</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.730853</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.743048</td>\n",
       "      <td>0.734603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.252780</td>\n",
       "      <td>0.681672</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.659125</td>\n",
       "      <td>0.719934</td>\n",
       "      <td>0.703299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.260501</td>\n",
       "      <td>0.684244</td>\n",
       "      <td>0.750190</td>\n",
       "      <td>0.742836</td>\n",
       "      <td>0.746495</td>\n",
       "      <td>0.731344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.257400</td>\n",
       "      <td>0.263621</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.735442</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.753036</td>\n",
       "      <td>0.745630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.257400</td>\n",
       "      <td>0.273574</td>\n",
       "      <td>0.686817</td>\n",
       "      <td>0.723803</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.753885</td>\n",
       "      <td>0.747363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.257400</td>\n",
       "      <td>0.270737</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.746816</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.749342</td>\n",
       "      <td>0.740310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.257400</td>\n",
       "      <td>0.269330</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.767331</td>\n",
       "      <td>0.726244</td>\n",
       "      <td>0.746222</td>\n",
       "      <td>0.734648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.257400</td>\n",
       "      <td>0.271857</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.757274</td>\n",
       "      <td>0.745852</td>\n",
       "      <td>0.751520</td>\n",
       "      <td>0.742768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.89      0.89       362\n",
      "                sara       0.60      0.68      0.64       237\n",
      "         radikalisme       0.70      0.79      0.74       235\n",
      "pencemaran_nama_baik       0.69      0.76      0.72       492\n",
      "\n",
      "           micro avg       0.72      0.79      0.75      1326\n",
      "           macro avg       0.72      0.78      0.75      1326\n",
      "        weighted avg       0.73      0.79      0.76      1326\n",
      "         samples avg       0.43      0.44      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1496: Accuracy: 0.6868167202572347, F1 Micro: 0.7538850740874593, F1 Macro: 0.7473627160402005\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.89      0.89       362\n",
      "                sara       0.60      0.68      0.64       237\n",
      "         radikalisme       0.70      0.79      0.74       235\n",
      "pencemaran_nama_baik       0.69      0.76      0.72       492\n",
      "\n",
      "           micro avg       0.72      0.79      0.75      1326\n",
      "           macro avg       0.72      0.78      0.75      1326\n",
      "        weighted avg       0.73      0.79      0.76      1326\n",
      "         samples avg       0.43      0.44      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 19.194788694381714 seconds\n",
      "New train size: 1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1240' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1240/1240 05:07, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.298026</td>\n",
       "      <td>0.646302</td>\n",
       "      <td>0.758242</td>\n",
       "      <td>0.624434</td>\n",
       "      <td>0.684864</td>\n",
       "      <td>0.674015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.255509</td>\n",
       "      <td>0.681029</td>\n",
       "      <td>0.773698</td>\n",
       "      <td>0.683258</td>\n",
       "      <td>0.725671</td>\n",
       "      <td>0.717108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250650</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.755573</td>\n",
       "      <td>0.741327</td>\n",
       "      <td>0.748382</td>\n",
       "      <td>0.739506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.251341</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.754615</td>\n",
       "      <td>0.739819</td>\n",
       "      <td>0.747144</td>\n",
       "      <td>0.739625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.267300</td>\n",
       "      <td>0.286037</td>\n",
       "      <td>0.677814</td>\n",
       "      <td>0.691250</td>\n",
       "      <td>0.834087</td>\n",
       "      <td>0.755981</td>\n",
       "      <td>0.753645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.267300</td>\n",
       "      <td>0.262899</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.769354</td>\n",
       "      <td>0.726998</td>\n",
       "      <td>0.747577</td>\n",
       "      <td>0.738994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.267300</td>\n",
       "      <td>0.268758</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.764660</td>\n",
       "      <td>0.737557</td>\n",
       "      <td>0.750864</td>\n",
       "      <td>0.741599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.267300</td>\n",
       "      <td>0.273493</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.782895</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.749017</td>\n",
       "      <td>0.738397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.121700</td>\n",
       "      <td>0.279497</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.754123</td>\n",
       "      <td>0.758673</td>\n",
       "      <td>0.756391</td>\n",
       "      <td>0.748171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.121700</td>\n",
       "      <td>0.280614</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.762607</td>\n",
       "      <td>0.741327</td>\n",
       "      <td>0.751816</td>\n",
       "      <td>0.742995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.86      0.89       362\n",
      "                sara       0.63      0.63      0.63       237\n",
      "         radikalisme       0.70      0.79      0.74       235\n",
      "pencemaran_nama_baik       0.73      0.73      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.76      0.76      1326\n",
      "           macro avg       0.75      0.75      0.75      1326\n",
      "        weighted avg       0.76      0.76      0.76      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1969: Accuracy: 0.6964630225080386, F1 Micro: 0.7563909774436091, F1 Macro: 0.7481713027237963\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.86      0.89       362\n",
      "                sara       0.63      0.63      0.63       237\n",
      "         radikalisme       0.70      0.79      0.74       235\n",
      "pencemaran_nama_baik       0.73      0.73      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.76      0.76      1326\n",
      "           macro avg       0.75      0.75      0.75      1326\n",
      "        weighted avg       0.76      0.76      0.76      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 425\n",
      "Sampling duration: 16.56714415550232 seconds\n",
      "New train size: 2394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:55, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.289025</td>\n",
       "      <td>0.641158</td>\n",
       "      <td>0.812725</td>\n",
       "      <td>0.510558</td>\n",
       "      <td>0.627142</td>\n",
       "      <td>0.591124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.248460</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.776955</td>\n",
       "      <td>0.711916</td>\n",
       "      <td>0.743015</td>\n",
       "      <td>0.734089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243603</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.765737</td>\n",
       "      <td>0.724736</td>\n",
       "      <td>0.744673</td>\n",
       "      <td>0.730886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.278700</td>\n",
       "      <td>0.240210</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.733786</td>\n",
       "      <td>0.755142</td>\n",
       "      <td>0.743954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.278700</td>\n",
       "      <td>0.251963</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.782468</td>\n",
       "      <td>0.726998</td>\n",
       "      <td>0.753714</td>\n",
       "      <td>0.744941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.278700</td>\n",
       "      <td>0.265312</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.796655</td>\n",
       "      <td>0.682504</td>\n",
       "      <td>0.735175</td>\n",
       "      <td>0.721691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>0.279912</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.748525</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.756898</td>\n",
       "      <td>0.751690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>0.278886</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.757274</td>\n",
       "      <td>0.745852</td>\n",
       "      <td>0.751520</td>\n",
       "      <td>0.744486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>0.285944</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.759690</td>\n",
       "      <td>0.739065</td>\n",
       "      <td>0.749235</td>\n",
       "      <td>0.739195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.287869</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.753754</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>0.755455</td>\n",
       "      <td>0.749394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.88      0.89       362\n",
      "                sara       0.64      0.65      0.64       237\n",
      "         radikalisme       0.71      0.82      0.76       235\n",
      "pencemaran_nama_baik       0.71      0.72      0.71       492\n",
      "\n",
      "           micro avg       0.75      0.77      0.76      1326\n",
      "           macro avg       0.74      0.76      0.75      1326\n",
      "        weighted avg       0.75      0.77      0.76      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2394: Accuracy: 0.6990353697749196, F1 Micro: 0.7568978374347501, F1 Macro: 0.7516899037941153\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.88      0.89       362\n",
      "                sara       0.64      0.65      0.64       237\n",
      "         radikalisme       0.71      0.82      0.76       235\n",
      "pencemaran_nama_baik       0.71      0.72      0.71       492\n",
      "\n",
      "           micro avg       0.75      0.77      0.76      1326\n",
      "           macro avg       0.74      0.76      0.75      1326\n",
      "        weighted avg       0.75      0.77      0.76      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 383\n",
      "Acquired samples: 383\n",
      "Sampling duration: 14.73254942893982 seconds\n",
      "New train size: 2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1740' max='1740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1740/1740 06:34, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.269713</td>\n",
       "      <td>0.671383</td>\n",
       "      <td>0.749792</td>\n",
       "      <td>0.680241</td>\n",
       "      <td>0.713325</td>\n",
       "      <td>0.706403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.246328</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.748886</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.754491</td>\n",
       "      <td>0.747996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.286900</td>\n",
       "      <td>0.254785</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.733859</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.752206</td>\n",
       "      <td>0.741013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.286900</td>\n",
       "      <td>0.260658</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.746657</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.752246</td>\n",
       "      <td>0.747440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.286900</td>\n",
       "      <td>0.252902</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.774902</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.759708</td>\n",
       "      <td>0.753626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.149100</td>\n",
       "      <td>0.276117</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.727460</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.760705</td>\n",
       "      <td>0.755143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.149100</td>\n",
       "      <td>0.274192</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.758308</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>0.757736</td>\n",
       "      <td>0.748461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.149100</td>\n",
       "      <td>0.284535</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.755754</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.761691</td>\n",
       "      <td>0.755333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.093100</td>\n",
       "      <td>0.287994</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.765019</td>\n",
       "      <td>0.758673</td>\n",
       "      <td>0.761833</td>\n",
       "      <td>0.754916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.093100</td>\n",
       "      <td>0.290621</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.752784</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.758698</td>\n",
       "      <td>0.751891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.90      0.90       362\n",
      "                sara       0.68      0.63      0.65       237\n",
      "         radikalisme       0.73      0.77      0.75       235\n",
      "pencemaran_nama_baik       0.72      0.71      0.71       492\n",
      "\n",
      "           micro avg       0.77      0.76      0.76      1326\n",
      "           macro avg       0.76      0.75      0.75      1326\n",
      "        weighted avg       0.76      0.76      0.76      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2777: Accuracy: 0.704823151125402, F1 Micro: 0.7618326391518365, F1 Macro: 0.7549159417298088\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.90      0.90       362\n",
      "                sara       0.68      0.63      0.65       237\n",
      "         radikalisme       0.73      0.77      0.75       235\n",
      "pencemaran_nama_baik       0.72      0.71      0.71       492\n",
      "\n",
      "           micro avg       0.77      0.76      0.76      1326\n",
      "           macro avg       0.76      0.75      0.75      1326\n",
      "        weighted avg       0.76      0.76      0.76      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 345\n",
      "Acquired samples: 345\n",
      "Sampling duration: 14.178729057312012 seconds\n",
      "New train size: 3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='1960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/1960 07:08, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.262183</td>\n",
       "      <td>0.681029</td>\n",
       "      <td>0.751412</td>\n",
       "      <td>0.702112</td>\n",
       "      <td>0.725926</td>\n",
       "      <td>0.716331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.244117</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.744942</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.760886</td>\n",
       "      <td>0.755060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.291100</td>\n",
       "      <td>0.241081</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.791421</td>\n",
       "      <td>0.709653</td>\n",
       "      <td>0.748310</td>\n",
       "      <td>0.744171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.291100</td>\n",
       "      <td>0.256247</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.732278</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.765743</td>\n",
       "      <td>0.762153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.291100</td>\n",
       "      <td>0.252149</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.776978</td>\n",
       "      <td>0.733032</td>\n",
       "      <td>0.754366</td>\n",
       "      <td>0.747537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.159900</td>\n",
       "      <td>0.264006</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.773717</td>\n",
       "      <td>0.750377</td>\n",
       "      <td>0.761868</td>\n",
       "      <td>0.756891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.159900</td>\n",
       "      <td>0.288440</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.738636</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.760790</td>\n",
       "      <td>0.754833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>0.293729</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.736179</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.763702</td>\n",
       "      <td>0.757534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>0.297908</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.740899</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.761276</td>\n",
       "      <td>0.754456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>0.297713</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.751846</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.759701</td>\n",
       "      <td>0.754206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.88      0.89       362\n",
      "                sara       0.61      0.73      0.66       237\n",
      "         radikalisme       0.71      0.82      0.76       235\n",
      "pencemaran_nama_baik       0.70      0.77      0.73       492\n",
      "\n",
      "           micro avg       0.73      0.80      0.77      1326\n",
      "           macro avg       0.73      0.80      0.76      1326\n",
      "        weighted avg       0.74      0.80      0.77      1326\n",
      "         samples avg       0.44      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3122: Accuracy: 0.6964630225080386, F1 Micro: 0.7657430730478589, F1 Macro: 0.7621528953254711\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.88      0.89       362\n",
      "                sara       0.61      0.73      0.66       237\n",
      "         radikalisme       0.71      0.82      0.76       235\n",
      "pencemaran_nama_baik       0.70      0.77      0.73       492\n",
      "\n",
      "           micro avg       0.73      0.80      0.77      1326\n",
      "           macro avg       0.73      0.80      0.76      1326\n",
      "        weighted avg       0.74      0.80      0.77      1326\n",
      "         samples avg       0.44      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 310\n",
      "Acquired samples: 310\n",
      "Sampling duration: 11.347160816192627 seconds\n",
      "New train size: 3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2150/2150 07:45, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.263518</td>\n",
       "      <td>0.677170</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.733032</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.730345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.242364</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.791342</td>\n",
       "      <td>0.689291</td>\n",
       "      <td>0.736800</td>\n",
       "      <td>0.729376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.293500</td>\n",
       "      <td>0.235563</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.778396</td>\n",
       "      <td>0.739065</td>\n",
       "      <td>0.758221</td>\n",
       "      <td>0.751847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.293500</td>\n",
       "      <td>0.242613</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.759108</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.764508</td>\n",
       "      <td>0.758207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.171500</td>\n",
       "      <td>0.254789</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.761544</td>\n",
       "      <td>0.758673</td>\n",
       "      <td>0.760106</td>\n",
       "      <td>0.755202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.171500</td>\n",
       "      <td>0.277154</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.728837</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.762145</td>\n",
       "      <td>0.756629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.111100</td>\n",
       "      <td>0.290310</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.731313</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>0.772679</td>\n",
       "      <td>0.766580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.111100</td>\n",
       "      <td>0.298103</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.739525</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.767948</td>\n",
       "      <td>0.762610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.111100</td>\n",
       "      <td>0.290348</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.758595</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.762012</td>\n",
       "      <td>0.754286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.078400</td>\n",
       "      <td>0.292124</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.760150</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.761295</td>\n",
       "      <td>0.752618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.87      0.92      0.90       362\n",
      "                sara       0.64      0.70      0.67       237\n",
      "         radikalisme       0.72      0.81      0.76       235\n",
      "pencemaran_nama_baik       0.69      0.80      0.74       492\n",
      "\n",
      "           micro avg       0.73      0.82      0.77      1326\n",
      "           macro avg       0.73      0.81      0.77      1326\n",
      "        weighted avg       0.73      0.82      0.77      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3432: Accuracy: 0.7041800643086816, F1 Micro: 0.7726787620064034, F1 Macro: 0.7665797711077083\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.87      0.92      0.90       362\n",
      "                sara       0.64      0.70      0.67       237\n",
      "         radikalisme       0.72      0.81      0.76       235\n",
      "pencemaran_nama_baik       0.69      0.80      0.74       492\n",
      "\n",
      "           micro avg       0.73      0.82      0.77      1326\n",
      "           macro avg       0.73      0.81      0.77      1326\n",
      "        weighted avg       0.73      0.82      0.77      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 279\n",
      "Acquired samples: 279\n",
      "Sampling duration: 10.105342149734497 seconds\n",
      "New train size: 3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2320/2320 08:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.260051</td>\n",
       "      <td>0.676527</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.687783</td>\n",
       "      <td>0.719811</td>\n",
       "      <td>0.711473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.237469</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.770518</td>\n",
       "      <td>0.729261</td>\n",
       "      <td>0.749322</td>\n",
       "      <td>0.744364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.297100</td>\n",
       "      <td>0.234493</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.770945</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.763609</td>\n",
       "      <td>0.757249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.297100</td>\n",
       "      <td>0.249086</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.733379</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.768402</td>\n",
       "      <td>0.760767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.175800</td>\n",
       "      <td>0.253766</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.769290</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.760488</td>\n",
       "      <td>0.748178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.175800</td>\n",
       "      <td>0.270944</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.755178</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.762509</td>\n",
       "      <td>0.754546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.274184</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.763251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.286193</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.739065</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.749834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.295431</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.751269</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.765989</td>\n",
       "      <td>0.757988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.297739</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.760238</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.765081</td>\n",
       "      <td>0.754051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.91      0.90       362\n",
      "                sara       0.67      0.64      0.65       237\n",
      "         radikalisme       0.71      0.83      0.76       235\n",
      "pencemaran_nama_baik       0.73      0.73      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.78      0.77      1326\n",
      "           macro avg       0.75      0.78      0.76      1326\n",
      "        weighted avg       0.76      0.78      0.77      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3711: Accuracy: 0.7131832797427653, F1 Micro: 0.770949720670391, F1 Macro: 0.7632514449898306\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.91      0.90       362\n",
      "                sara       0.67      0.64      0.65       237\n",
      "         radikalisme       0.71      0.83      0.76       235\n",
      "pencemaran_nama_baik       0.73      0.73      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.78      0.77      1326\n",
      "           macro avg       0.75      0.78      0.76      1326\n",
      "        weighted avg       0.76      0.78      0.77      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 251\n",
      "Acquired samples: 175\n",
      "Sampling duration: 8.21538496017456 seconds\n",
      "New train size: 3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2430' max='2430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2430/2430 08:33, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.261452</td>\n",
       "      <td>0.675884</td>\n",
       "      <td>0.740319</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.737798</td>\n",
       "      <td>0.724563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.238526</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.759608</td>\n",
       "      <td>0.748607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.299900</td>\n",
       "      <td>0.232191</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.742081</td>\n",
       "      <td>0.757506</td>\n",
       "      <td>0.744682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.299900</td>\n",
       "      <td>0.238130</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.754373</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.767235</td>\n",
       "      <td>0.760836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.183000</td>\n",
       "      <td>0.250991</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.754298</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.773696</td>\n",
       "      <td>0.767806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.183000</td>\n",
       "      <td>0.257734</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.772657</td>\n",
       "      <td>0.758673</td>\n",
       "      <td>0.765601</td>\n",
       "      <td>0.758847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.124100</td>\n",
       "      <td>0.270659</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.754597</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.778832</td>\n",
       "      <td>0.774647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.124100</td>\n",
       "      <td>0.285093</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.769004</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.777322</td>\n",
       "      <td>0.767581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.087300</td>\n",
       "      <td>0.281932</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.769459</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.776075</td>\n",
       "      <td>0.771183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.087300</td>\n",
       "      <td>0.289125</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.763331</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.768830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.64      0.71      0.67       237\n",
      "         radikalisme       0.74      0.82      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.78      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3886: Accuracy: 0.7138263665594855, F1 Micro: 0.7788321167883211, F1 Macro: 0.7746474084392304\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.64      0.71      0.67       237\n",
      "         radikalisme       0.74      0.82      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.78      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Samples above threshold: 234\n",
      "Acquired samples: 234\n",
      "Sampling duration: 8.201268672943115 seconds\n",
      "New train size: 4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 08:58, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256394</td>\n",
       "      <td>0.679743</td>\n",
       "      <td>0.742435</td>\n",
       "      <td>0.758673</td>\n",
       "      <td>0.750466</td>\n",
       "      <td>0.746954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.299400</td>\n",
       "      <td>0.240718</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.740014</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.767163</td>\n",
       "      <td>0.762710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.299400</td>\n",
       "      <td>0.234591</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.760886</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.769116</td>\n",
       "      <td>0.763457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.184400</td>\n",
       "      <td>0.240052</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.761727</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.766579</td>\n",
       "      <td>0.756071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.184400</td>\n",
       "      <td>0.252705</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.806507</td>\n",
       "      <td>0.710407</td>\n",
       "      <td>0.755413</td>\n",
       "      <td>0.746609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.274413</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.753980</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.769572</td>\n",
       "      <td>0.766545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.282972</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.750887</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.773675</td>\n",
       "      <td>0.771252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.087200</td>\n",
       "      <td>0.297723</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.756637</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.765101</td>\n",
       "      <td>0.758034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.087200</td>\n",
       "      <td>0.301412</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.761658</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.768771</td>\n",
       "      <td>0.764288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>0.305110</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.756044</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.767001</td>\n",
       "      <td>0.763036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.92      0.91       362\n",
      "                sara       0.66      0.69      0.67       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.69      0.75      0.72       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.77      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.80      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4120: Accuracy: 0.7080385852090032, F1 Micro: 0.7736745886654479, F1 Macro: 0.7712517259166565\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.92      0.91       362\n",
      "                sara       0.66      0.69      0.67       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.69      0.75      0.72       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.77      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.80      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Samples above threshold: 210\n",
      "Acquired samples: 210\n",
      "Sampling duration: 7.2051472663879395 seconds\n",
      "New train size: 4330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2710' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2710/2710 09:18, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250667</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.764090</td>\n",
       "      <td>0.715686</td>\n",
       "      <td>0.739097</td>\n",
       "      <td>0.729407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.302900</td>\n",
       "      <td>0.232829</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.784490</td>\n",
       "      <td>0.724736</td>\n",
       "      <td>0.753430</td>\n",
       "      <td>0.748115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.302900</td>\n",
       "      <td>0.232901</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.769578</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.770158</td>\n",
       "      <td>0.765981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.234405</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.774071</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.772023</td>\n",
       "      <td>0.763141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.246783</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.785884</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.766138</td>\n",
       "      <td>0.756798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.133100</td>\n",
       "      <td>0.270289</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.783740</td>\n",
       "      <td>0.726998</td>\n",
       "      <td>0.754304</td>\n",
       "      <td>0.742218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.133100</td>\n",
       "      <td>0.288294</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.743607</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.776055</td>\n",
       "      <td>0.771540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.091900</td>\n",
       "      <td>0.291897</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.770817</td>\n",
       "      <td>0.760935</td>\n",
       "      <td>0.765844</td>\n",
       "      <td>0.758855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.091900</td>\n",
       "      <td>0.302778</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.757379</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.774954</td>\n",
       "      <td>0.770396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>0.303182</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.759797</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.774408</td>\n",
       "      <td>0.770889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.93      0.92       362\n",
      "                sara       0.63      0.70      0.66       237\n",
      "         radikalisme       0.72      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.70      0.76      0.73       492\n",
      "\n",
      "           micro avg       0.74      0.81      0.78      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4330: Accuracy: 0.712540192926045, F1 Micro: 0.7760548142805626, F1 Macro: 0.7715395072759872\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.93      0.92       362\n",
      "                sara       0.63      0.70      0.66       237\n",
      "         radikalisme       0.72      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.70      0.76      0.73       492\n",
      "\n",
      "           micro avg       0.74      0.81      0.78      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Samples above threshold: 189\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.364313840866089 seconds\n",
      "New train size: 4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2840' max='2840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2840/2840 09:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.252603</td>\n",
       "      <td>0.673955</td>\n",
       "      <td>0.746627</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.748872</td>\n",
       "      <td>0.735031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.303800</td>\n",
       "      <td>0.229766</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.771714</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>0.764370</td>\n",
       "      <td>0.757838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.303800</td>\n",
       "      <td>0.238135</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.754487</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.773078</td>\n",
       "      <td>0.766669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.191300</td>\n",
       "      <td>0.240990</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.769697</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.767952</td>\n",
       "      <td>0.760190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.191300</td>\n",
       "      <td>0.260472</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.750355</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.773392</td>\n",
       "      <td>0.764735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.133000</td>\n",
       "      <td>0.269095</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.760790</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.772373</td>\n",
       "      <td>0.765648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.133000</td>\n",
       "      <td>0.292613</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.752307</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.775137</td>\n",
       "      <td>0.767014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.095200</td>\n",
       "      <td>0.296783</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.759602</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.781845</td>\n",
       "      <td>0.776533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>0.303598</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.759420</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.774575</td>\n",
       "      <td>0.769179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>0.305034</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.760948</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.779698</td>\n",
       "      <td>0.773041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.65      0.67      0.66       237\n",
      "         radikalisme       0.74      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.71      0.77      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.78      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4530: Accuracy: 0.7183279742765273, F1 Micro: 0.7818448023426062, F1 Macro: 0.7765328579452679\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.65      0.67      0.66       237\n",
      "         radikalisme       0.74      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.71      0.77      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.78      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Samples above threshold: 169\n",
      "Acquired samples: 133\n",
      "Sampling duration: 5.600373029708862 seconds\n",
      "New train size: 4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2920' max='2920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2920/2920 09:54, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.253878</td>\n",
       "      <td>0.681029</td>\n",
       "      <td>0.768526</td>\n",
       "      <td>0.696078</td>\n",
       "      <td>0.730510</td>\n",
       "      <td>0.703701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.301000</td>\n",
       "      <td>0.233563</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.764574</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.768018</td>\n",
       "      <td>0.754092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.301000</td>\n",
       "      <td>0.231030</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.778555</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.766935</td>\n",
       "      <td>0.752550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.194000</td>\n",
       "      <td>0.249143</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.745739</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.768105</td>\n",
       "      <td>0.757655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.194000</td>\n",
       "      <td>0.257890</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.747159</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.769568</td>\n",
       "      <td>0.765866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.135300</td>\n",
       "      <td>0.265375</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.774548</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.758753</td>\n",
       "      <td>0.750502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.097700</td>\n",
       "      <td>0.287776</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.752673</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.773910</td>\n",
       "      <td>0.769165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.097700</td>\n",
       "      <td>0.296974</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.748924</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.767647</td>\n",
       "      <td>0.763004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.305832</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.750897</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.769401</td>\n",
       "      <td>0.764412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.308216</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.750360</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.768041</td>\n",
       "      <td>0.762363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.92      0.91       362\n",
      "                sara       0.65      0.67      0.66       237\n",
      "         radikalisme       0.73      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.70      0.75      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.77      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.75      0.80      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4663: Accuracy: 0.7067524115755627, F1 Micro: 0.7739098570905094, F1 Macro: 0.7691652997394693\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.92      0.91       362\n",
      "                sara       0.65      0.67      0.66       237\n",
      "         radikalisme       0.73      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.70      0.75      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.77      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.75      0.80      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.402950763702393 seconds\n",
      "New train size: 4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3040' max='3040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3040/3040 10:19, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.254939</td>\n",
       "      <td>0.679743</td>\n",
       "      <td>0.730193</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.750275</td>\n",
       "      <td>0.742171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.307600</td>\n",
       "      <td>0.236974</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.767478</td>\n",
       "      <td>0.736802</td>\n",
       "      <td>0.751828</td>\n",
       "      <td>0.731967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.307600</td>\n",
       "      <td>0.235992</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.743113</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.776818</td>\n",
       "      <td>0.769682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.196800</td>\n",
       "      <td>0.239100</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.770865</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.768533</td>\n",
       "      <td>0.763231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.142300</td>\n",
       "      <td>0.259833</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.759797</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.774408</td>\n",
       "      <td>0.767662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.142300</td>\n",
       "      <td>0.277708</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.757662</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.779040</td>\n",
       "      <td>0.771892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.102100</td>\n",
       "      <td>0.293091</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.752778</td>\n",
       "      <td>0.817496</td>\n",
       "      <td>0.783803</td>\n",
       "      <td>0.778015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.102100</td>\n",
       "      <td>0.299383</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.761119</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.780147</td>\n",
       "      <td>0.775802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.079200</td>\n",
       "      <td>0.313119</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.752281</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.779353</td>\n",
       "      <td>0.773630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>0.310779</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.761290</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.780595</td>\n",
       "      <td>0.775919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.91       362\n",
      "                sara       0.64      0.70      0.67       237\n",
      "         radikalisme       0.72      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.75      0.82      0.78      1326\n",
      "        weighted avg       0.76      0.82      0.78      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4863: Accuracy: 0.7183279742765273, F1 Micro: 0.7838033261026753, F1 Macro: 0.7780147732029825\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.91       362\n",
      "                sara       0.64      0.70      0.67       237\n",
      "         radikalisme       0.72      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.75      0.82      0.78      1326\n",
      "        weighted avg       0.76      0.82      0.78      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Samples above threshold: 136\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.654093027114868 seconds\n",
      "New train size: 5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3170' max='3170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3170/3170 10:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250197</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.728709</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.762761</td>\n",
       "      <td>0.755772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.302900</td>\n",
       "      <td>0.228058</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.765565</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.758279</td>\n",
       "      <td>0.744508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.302900</td>\n",
       "      <td>0.224886</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.768084</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.772403</td>\n",
       "      <td>0.764101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.203200</td>\n",
       "      <td>0.251808</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.731204</td>\n",
       "      <td>0.828808</td>\n",
       "      <td>0.776953</td>\n",
       "      <td>0.773568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.147500</td>\n",
       "      <td>0.248944</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.769175</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.781447</td>\n",
       "      <td>0.771651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.147500</td>\n",
       "      <td>0.275537</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.756955</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.768202</td>\n",
       "      <td>0.757617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.288116</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.762009</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.775556</td>\n",
       "      <td>0.769922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.085100</td>\n",
       "      <td>0.290062</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.758896</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.773215</td>\n",
       "      <td>0.764977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.085100</td>\n",
       "      <td>0.300476</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>0.764319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067300</td>\n",
       "      <td>0.304602</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.760029</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.772710</td>\n",
       "      <td>0.766128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.92       362\n",
      "                sara       0.66      0.61      0.64       237\n",
      "         radikalisme       0.76      0.81      0.79       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5063: Accuracy: 0.7170418006430869, F1 Micro: 0.7814471243042672, F1 Macro: 0.7716511723762342\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.92       362\n",
      "                sara       0.66      0.61      0.64       237\n",
      "         radikalisme       0.76      0.81      0.79       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Samples above threshold: 116\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.071511268615723 seconds\n",
      "New train size: 5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3290' max='3290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3290/3290 11:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243833</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.753150</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.759626</td>\n",
       "      <td>0.752437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.304900</td>\n",
       "      <td>0.231983</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.758850</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.767338</td>\n",
       "      <td>0.760318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.304900</td>\n",
       "      <td>0.224152</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.808960</td>\n",
       "      <td>0.721719</td>\n",
       "      <td>0.762854</td>\n",
       "      <td>0.752121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>0.263761</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.706064</td>\n",
       "      <td>0.860483</td>\n",
       "      <td>0.775663</td>\n",
       "      <td>0.774435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.150700</td>\n",
       "      <td>0.245403</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.765772</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.780776</td>\n",
       "      <td>0.774570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.150700</td>\n",
       "      <td>0.263251</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.782853</td>\n",
       "      <td>0.736802</td>\n",
       "      <td>0.759130</td>\n",
       "      <td>0.741611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.114600</td>\n",
       "      <td>0.272455</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.761095</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.768484</td>\n",
       "      <td>0.767156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.085400</td>\n",
       "      <td>0.292910</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.749650</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.777939</td>\n",
       "      <td>0.772833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.085400</td>\n",
       "      <td>0.289194</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.780620</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.769878</td>\n",
       "      <td>0.764469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.297765</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.760145</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.775314</td>\n",
       "      <td>0.770898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.75      0.84      0.80       235\n",
      "pencemaran_nama_baik       0.72      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5263: Accuracy: 0.7170418006430869, F1 Micro: 0.7807763401109058, F1 Macro: 0.7745700237527571\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.75      0.84      0.80       235\n",
      "pencemaran_nama_baik       0.72      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Samples above threshold: 96\n",
      "Acquired samples: 178\n",
      "Sampling duration: 3.481360912322998 seconds\n",
      "New train size: 5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3410' max='3410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3410/3410 11:19, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241799</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.752336</td>\n",
       "      <td>0.736812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.305600</td>\n",
       "      <td>0.228002</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.785024</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.759346</td>\n",
       "      <td>0.747342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.206900</td>\n",
       "      <td>0.231066</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.738388</td>\n",
       "      <td>0.815234</td>\n",
       "      <td>0.774910</td>\n",
       "      <td>0.768999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.206900</td>\n",
       "      <td>0.232298</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.770958</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.773854</td>\n",
       "      <td>0.768724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.156300</td>\n",
       "      <td>0.246157</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.760174</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.774241</td>\n",
       "      <td>0.764434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.118900</td>\n",
       "      <td>0.256340</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.775940</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.777108</td>\n",
       "      <td>0.770496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.118900</td>\n",
       "      <td>0.282377</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.763023</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.773522</td>\n",
       "      <td>0.764282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.087300</td>\n",
       "      <td>0.297463</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.754610</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.770264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.297585</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.757267</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.771281</td>\n",
       "      <td>0.764463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.299187</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.763971</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.773641</td>\n",
       "      <td>0.766730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.93      0.91       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.75      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.77      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.75      0.80      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5441: Accuracy: 0.7183279742765273, F1 Micro: 0.7777777777777778, F1 Macro: 0.7702643077787216\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.93      0.91       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.75      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.77      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.75      0.80      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Samples above threshold: 78\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.8957359790802 seconds\n",
      "New train size: 5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3530' max='3530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3530/3530 11:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.248455</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.749808</td>\n",
       "      <td>0.736802</td>\n",
       "      <td>0.743248</td>\n",
       "      <td>0.740381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.303200</td>\n",
       "      <td>0.228609</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.750706</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.775346</td>\n",
       "      <td>0.768664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.215300</td>\n",
       "      <td>0.226857</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.753338</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.779920</td>\n",
       "      <td>0.771290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.215300</td>\n",
       "      <td>0.224418</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.784580</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.783692</td>\n",
       "      <td>0.775020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.159200</td>\n",
       "      <td>0.256172</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.748789</td>\n",
       "      <td>0.815988</td>\n",
       "      <td>0.780946</td>\n",
       "      <td>0.772524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.119500</td>\n",
       "      <td>0.253828</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.780689</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.783621</td>\n",
       "      <td>0.773992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.119500</td>\n",
       "      <td>0.276862</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.759207</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.783053</td>\n",
       "      <td>0.775777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.094100</td>\n",
       "      <td>0.284346</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.780562</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.777904</td>\n",
       "      <td>0.769130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.294171</td>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.773529</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.783321</td>\n",
       "      <td>0.775841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.061800</td>\n",
       "      <td>0.297640</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.774099</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.783613</td>\n",
       "      <td>0.777535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.67      0.62      0.64       237\n",
      "         radikalisme       0.77      0.82      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.78      0.78      1326\n",
      "           macro avg       0.78      0.77      0.78      1326\n",
      "        weighted avg       0.79      0.78      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5641: Accuracy: 0.7266881028938906, F1 Micro: 0.7836919592298981, F1 Macro: 0.7750201595242521\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.67      0.62      0.64       237\n",
      "         radikalisme       0.77      0.82      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.78      0.78      1326\n",
      "           macro avg       0.78      0.77      0.78      1326\n",
      "        weighted avg       0.79      0.78      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.2592365741729736 seconds\n",
      "New train size: 5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3660' max='3660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3660/3660 12:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250392</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.781579</td>\n",
       "      <td>0.671946</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.701177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.303600</td>\n",
       "      <td>0.224095</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.781370</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.766135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.221909</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.787102</td>\n",
       "      <td>0.763952</td>\n",
       "      <td>0.775354</td>\n",
       "      <td>0.762980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.231248</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.811973</td>\n",
       "      <td>0.726244</td>\n",
       "      <td>0.766720</td>\n",
       "      <td>0.754464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.158900</td>\n",
       "      <td>0.247769</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.779837</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.786542</td>\n",
       "      <td>0.780627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.120200</td>\n",
       "      <td>0.260501</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.778614</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.779201</td>\n",
       "      <td>0.771453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.095600</td>\n",
       "      <td>0.281430</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.752974</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.781125</td>\n",
       "      <td>0.775855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.095600</td>\n",
       "      <td>0.291015</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.769175</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.785081</td>\n",
       "      <td>0.777905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.302550</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.767662</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.781030</td>\n",
       "      <td>0.773246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.300048</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.773264</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.781343</td>\n",
       "      <td>0.774709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.91      0.92       362\n",
      "                sara       0.68      0.65      0.67       237\n",
      "         radikalisme       0.73      0.88      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.74      0.74       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5841: Accuracy: 0.7247588424437299, F1 Micro: 0.7865420560747663, F1 Macro: 0.7806273228129661\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.91      0.92       362\n",
      "                sara       0.68      0.65      0.67       237\n",
      "         radikalisme       0.73      0.88      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.74      0.74       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 200\n",
      "Sampling duration: 1.6191508769989014 seconds\n",
      "New train size: 6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3780' max='3780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3780/3780 12:23, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.249223</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.747937</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.749906</td>\n",
       "      <td>0.741790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.305100</td>\n",
       "      <td>0.220109</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.783346</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.774685</td>\n",
       "      <td>0.767757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.208200</td>\n",
       "      <td>0.223012</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.770300</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.782027</td>\n",
       "      <td>0.772701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.231096</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.774170</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.782544</td>\n",
       "      <td>0.772389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.245839</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.758547</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.780220</td>\n",
       "      <td>0.772390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.122300</td>\n",
       "      <td>0.257560</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.782152</td>\n",
       "      <td>0.774341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.283872</td>\n",
       "      <td>0.729904</td>\n",
       "      <td>0.775480</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.777590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.073400</td>\n",
       "      <td>0.287384</td>\n",
       "      <td>0.731190</td>\n",
       "      <td>0.781927</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.785741</td>\n",
       "      <td>0.780670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.073400</td>\n",
       "      <td>0.296544</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.779699</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.780873</td>\n",
       "      <td>0.774934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.302623</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.770987</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.780179</td>\n",
       "      <td>0.773333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.66      0.66      0.66       237\n",
      "         radikalisme       0.77      0.83      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.79      1326\n",
      "           macro avg       0.78      0.78      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6041: Accuracy: 0.7311897106109325, F1 Micro: 0.7857410881801126, F1 Macro: 0.780669948853556\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.66      0.66      0.66       237\n",
      "         radikalisme       0.77      0.83      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.79      1326\n",
      "           macro avg       0.78      0.78      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "<ipython-input-13-46a36a0f91da>:54: ConvergenceWarning: Number of distinct clusters (72) found smaller than n_clusters (177). Possibly due to duplicate points in X.\n",
      "  kmeans.fit(embeddings)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 177\n",
      "Sampling duration: 1.7077858448028564 seconds\n",
      "New train size: 6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3890/3890 12:40, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.245364</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.805957</td>\n",
       "      <td>0.673454</td>\n",
       "      <td>0.733772</td>\n",
       "      <td>0.721036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.294500</td>\n",
       "      <td>0.225389</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.783239</td>\n",
       "      <td>0.733032</td>\n",
       "      <td>0.757304</td>\n",
       "      <td>0.749167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.206300</td>\n",
       "      <td>0.222889</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.774742</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.782836</td>\n",
       "      <td>0.773282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.161100</td>\n",
       "      <td>0.241086</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.762411</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.785819</td>\n",
       "      <td>0.779184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.161100</td>\n",
       "      <td>0.245132</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.792587</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.774865</td>\n",
       "      <td>0.761858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.123300</td>\n",
       "      <td>0.269409</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.753165</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.779476</td>\n",
       "      <td>0.773041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.271753</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.794488</td>\n",
       "      <td>0.760935</td>\n",
       "      <td>0.777350</td>\n",
       "      <td>0.766770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.285577</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.786159</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.774119</td>\n",
       "      <td>0.763532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.300479</td>\n",
       "      <td>0.727974</td>\n",
       "      <td>0.772059</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.781832</td>\n",
       "      <td>0.774773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.304473</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.772761</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.779978</td>\n",
       "      <td>0.772131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.91       362\n",
      "                sara       0.64      0.66      0.65       237\n",
      "         radikalisme       0.75      0.86      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6218: Accuracy: 0.7234726688102894, F1 Micro: 0.7858187134502924, F1 Macro: 0.779184064067949\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.91       362\n",
      "                sara       0.64      0.66      0.65       237\n",
      "         radikalisme       0.75      0.86      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n",
      "Total sampling time: 196.86 seconds\n",
      "Total runtime: 11777.62056517601 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227d5bfe",
   "metadata": {},
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e071b8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 02:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.458386</td>\n",
       "      <td>0.505466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080694</td>\n",
       "      <td>0.149337</td>\n",
       "      <td>0.114072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.384749</td>\n",
       "      <td>0.584566</td>\n",
       "      <td>0.914454</td>\n",
       "      <td>0.233786</td>\n",
       "      <td>0.372372</td>\n",
       "      <td>0.251831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.356113</td>\n",
       "      <td>0.571704</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.348416</td>\n",
       "      <td>0.475798</td>\n",
       "      <td>0.347973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.330139</td>\n",
       "      <td>0.593569</td>\n",
       "      <td>0.773109</td>\n",
       "      <td>0.416290</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.453938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.312512</td>\n",
       "      <td>0.608360</td>\n",
       "      <td>0.758850</td>\n",
       "      <td>0.517345</td>\n",
       "      <td>0.615247</td>\n",
       "      <td>0.548237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.303364</td>\n",
       "      <td>0.628296</td>\n",
       "      <td>0.745247</td>\n",
       "      <td>0.591252</td>\n",
       "      <td>0.659378</td>\n",
       "      <td>0.634356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.297518</td>\n",
       "      <td>0.625080</td>\n",
       "      <td>0.737660</td>\n",
       "      <td>0.608597</td>\n",
       "      <td>0.666942</td>\n",
       "      <td>0.633439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.296958</td>\n",
       "      <td>0.624437</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.567119</td>\n",
       "      <td>0.646604</td>\n",
       "      <td>0.609105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.293293</td>\n",
       "      <td>0.627653</td>\n",
       "      <td>0.743662</td>\n",
       "      <td>0.597285</td>\n",
       "      <td>0.662484</td>\n",
       "      <td>0.635006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.293404</td>\n",
       "      <td>0.627653</td>\n",
       "      <td>0.747126</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.658228</td>\n",
       "      <td>0.629208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.83      0.85      0.84       362\n",
      "                sara       0.72      0.29      0.41       237\n",
      "         radikalisme       0.72      0.61      0.66       235\n",
      "pencemaran_nama_baik       0.67      0.59      0.63       492\n",
      "\n",
      "           micro avg       0.74      0.61      0.67      1326\n",
      "           macro avg       0.73      0.58      0.63      1326\n",
      "        weighted avg       0.73      0.61      0.65      1326\n",
      "         samples avg       0.38      0.35      0.35      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 388: Accuracy: 0.62508038585209, F1 Micro: 0.6669421487603305, F1 Macro: 0.6334393870554681\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.83      0.85      0.84       362\n",
      "                sara       0.72      0.29      0.41       237\n",
      "         radikalisme       0.72      0.61      0.66       235\n",
      "pencemaran_nama_baik       0.67      0.59      0.63       492\n",
      "\n",
      "           micro avg       0.74      0.61      0.67      1326\n",
      "           macro avg       0.73      0.58      0.63      1326\n",
      "        weighted avg       0.73      0.61      0.65      1326\n",
      "         samples avg       0.38      0.35      0.35      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 583\n",
      "Acquired samples: 583\n",
      "Sampling duration: 25.675012588500977 seconds\n",
      "New train size: 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [610/610 03:21, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.360801</td>\n",
       "      <td>0.567203</td>\n",
       "      <td>0.809619</td>\n",
       "      <td>0.304676</td>\n",
       "      <td>0.442740</td>\n",
       "      <td>0.369517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.295153</td>\n",
       "      <td>0.648232</td>\n",
       "      <td>0.775348</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.668954</td>\n",
       "      <td>0.650684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.274262</td>\n",
       "      <td>0.666238</td>\n",
       "      <td>0.739201</td>\n",
       "      <td>0.684012</td>\n",
       "      <td>0.710537</td>\n",
       "      <td>0.704771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.276720</td>\n",
       "      <td>0.655949</td>\n",
       "      <td>0.705182</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.731300</td>\n",
       "      <td>0.718378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266745</td>\n",
       "      <td>0.670740</td>\n",
       "      <td>0.719886</td>\n",
       "      <td>0.761689</td>\n",
       "      <td>0.740198</td>\n",
       "      <td>0.732761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.263153</td>\n",
       "      <td>0.684244</td>\n",
       "      <td>0.756235</td>\n",
       "      <td>0.708899</td>\n",
       "      <td>0.731802</td>\n",
       "      <td>0.717286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.267500</td>\n",
       "      <td>0.684887</td>\n",
       "      <td>0.768771</td>\n",
       "      <td>0.679487</td>\n",
       "      <td>0.721377</td>\n",
       "      <td>0.704649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.272779</td>\n",
       "      <td>0.684887</td>\n",
       "      <td>0.748638</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.736882</td>\n",
       "      <td>0.724182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.232100</td>\n",
       "      <td>0.273202</td>\n",
       "      <td>0.686817</td>\n",
       "      <td>0.751567</td>\n",
       "      <td>0.723228</td>\n",
       "      <td>0.737125</td>\n",
       "      <td>0.725867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.232100</td>\n",
       "      <td>0.273765</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.757382</td>\n",
       "      <td>0.715686</td>\n",
       "      <td>0.735944</td>\n",
       "      <td>0.724560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.86      0.87       362\n",
      "                sara       0.62      0.61      0.61       237\n",
      "         radikalisme       0.71      0.77      0.74       235\n",
      "pencemaran_nama_baik       0.66      0.76      0.71       492\n",
      "\n",
      "           micro avg       0.72      0.76      0.74      1326\n",
      "           macro avg       0.72      0.75      0.73      1326\n",
      "        weighted avg       0.72      0.76      0.74      1326\n",
      "         samples avg       0.42      0.43      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 971: Accuracy: 0.6707395498392283, F1 Micro: 0.7401978746793698, F1 Macro: 0.7327609596477187\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.86      0.87       362\n",
      "                sara       0.62      0.61      0.61       237\n",
      "         radikalisme       0.71      0.77      0.74       235\n",
      "pencemaran_nama_baik       0.66      0.76      0.71       492\n",
      "\n",
      "           micro avg       0.72      0.76      0.74      1326\n",
      "           macro avg       0.72      0.75      0.73      1326\n",
      "        weighted avg       0.72      0.76      0.74      1326\n",
      "         samples avg       0.42      0.43      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 22.667783975601196 seconds\n",
      "New train size: 1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [940/940 04:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.315933</td>\n",
       "      <td>0.623794</td>\n",
       "      <td>0.772926</td>\n",
       "      <td>0.533937</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.597521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.269527</td>\n",
       "      <td>0.671383</td>\n",
       "      <td>0.735776</td>\n",
       "      <td>0.711916</td>\n",
       "      <td>0.723649</td>\n",
       "      <td>0.717663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.258379</td>\n",
       "      <td>0.682958</td>\n",
       "      <td>0.726027</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.742352</td>\n",
       "      <td>0.732272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.253814</td>\n",
       "      <td>0.674598</td>\n",
       "      <td>0.787004</td>\n",
       "      <td>0.657617</td>\n",
       "      <td>0.716516</td>\n",
       "      <td>0.691250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.255013</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.748855</td>\n",
       "      <td>0.739819</td>\n",
       "      <td>0.744310</td>\n",
       "      <td>0.732909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.260100</td>\n",
       "      <td>0.264439</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.740045</td>\n",
       "      <td>0.742836</td>\n",
       "      <td>0.741438</td>\n",
       "      <td>0.730394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.260100</td>\n",
       "      <td>0.266079</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.764801</td>\n",
       "      <td>0.711161</td>\n",
       "      <td>0.737007</td>\n",
       "      <td>0.720370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.260100</td>\n",
       "      <td>0.275998</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.750961</td>\n",
       "      <td>0.736802</td>\n",
       "      <td>0.743814</td>\n",
       "      <td>0.730025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.260100</td>\n",
       "      <td>0.281896</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.739294</td>\n",
       "      <td>0.742081</td>\n",
       "      <td>0.740685</td>\n",
       "      <td>0.729198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.260100</td>\n",
       "      <td>0.283200</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.745441</td>\n",
       "      <td>0.739819</td>\n",
       "      <td>0.742619</td>\n",
       "      <td>0.730396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.86      0.90       362\n",
      "                sara       0.61      0.60      0.61       237\n",
      "         radikalisme       0.71      0.71      0.71       235\n",
      "pencemaran_nama_baik       0.71      0.73      0.72       492\n",
      "\n",
      "           micro avg       0.75      0.74      0.74      1326\n",
      "           macro avg       0.74      0.73      0.73      1326\n",
      "        weighted avg       0.75      0.74      0.75      1326\n",
      "         samples avg       0.42      0.42      0.41      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1496: Accuracy: 0.692604501607717, F1 Micro: 0.744309559939302, F1 Macro: 0.7329094024673628\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.86      0.90       362\n",
      "                sara       0.61      0.60      0.61       237\n",
      "         radikalisme       0.71      0.71      0.71       235\n",
      "pencemaran_nama_baik       0.71      0.73      0.72       492\n",
      "\n",
      "           micro avg       0.75      0.74      0.74      1326\n",
      "           macro avg       0.74      0.73      0.73      1326\n",
      "        weighted avg       0.75      0.74      0.75      1326\n",
      "         samples avg       0.42      0.42      0.41      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 20.224249362945557 seconds\n",
      "New train size: 1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1240' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1240/1240 05:11, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.296253</td>\n",
       "      <td>0.632154</td>\n",
       "      <td>0.812201</td>\n",
       "      <td>0.512066</td>\n",
       "      <td>0.628122</td>\n",
       "      <td>0.593043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266373</td>\n",
       "      <td>0.664952</td>\n",
       "      <td>0.792527</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.688007</td>\n",
       "      <td>0.665116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.247477</td>\n",
       "      <td>0.684887</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.732045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250876</td>\n",
       "      <td>0.686817</td>\n",
       "      <td>0.737072</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.749907</td>\n",
       "      <td>0.742902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.271200</td>\n",
       "      <td>0.259343</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.737697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.271200</td>\n",
       "      <td>0.266964</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.750742</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.756918</td>\n",
       "      <td>0.749890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.271200</td>\n",
       "      <td>0.280763</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.743478</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.758315</td>\n",
       "      <td>0.750115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.271200</td>\n",
       "      <td>0.281375</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.754689</td>\n",
       "      <td>0.758673</td>\n",
       "      <td>0.756675</td>\n",
       "      <td>0.747446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.117100</td>\n",
       "      <td>0.285242</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.753903</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.759266</td>\n",
       "      <td>0.752330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.117100</td>\n",
       "      <td>0.289513</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.749072</td>\n",
       "      <td>0.760935</td>\n",
       "      <td>0.754957</td>\n",
       "      <td>0.747060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.88      0.90       362\n",
      "                sara       0.66      0.66      0.66       237\n",
      "         radikalisme       0.70      0.77      0.73       235\n",
      "pencemaran_nama_baik       0.72      0.73      0.72       492\n",
      "\n",
      "           micro avg       0.75      0.76      0.76      1326\n",
      "           macro avg       0.75      0.76      0.75      1326\n",
      "        weighted avg       0.76      0.76      0.76      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1969: Accuracy: 0.7016077170418007, F1 Micro: 0.7592661924372893, F1 Macro: 0.7523303171724456\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.88      0.90       362\n",
      "                sara       0.66      0.66      0.66       237\n",
      "         radikalisme       0.70      0.77      0.73       235\n",
      "pencemaran_nama_baik       0.72      0.73      0.72       492\n",
      "\n",
      "           micro avg       0.75      0.76      0.76      1326\n",
      "           macro avg       0.75      0.76      0.75      1326\n",
      "        weighted avg       0.76      0.76      0.76      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 425\n",
      "Sampling duration: 17.01549983024597 seconds\n",
      "New train size: 2394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:51, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.288345</td>\n",
       "      <td>0.609646</td>\n",
       "      <td>0.813625</td>\n",
       "      <td>0.477376</td>\n",
       "      <td>0.601711</td>\n",
       "      <td>0.562884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.251967</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.752722</td>\n",
       "      <td>0.730015</td>\n",
       "      <td>0.741194</td>\n",
       "      <td>0.733942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241954</td>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.787700</td>\n",
       "      <td>0.705128</td>\n",
       "      <td>0.744131</td>\n",
       "      <td>0.731948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.282400</td>\n",
       "      <td>0.255016</td>\n",
       "      <td>0.683601</td>\n",
       "      <td>0.710979</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.753942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.282400</td>\n",
       "      <td>0.254951</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.740203</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.754438</td>\n",
       "      <td>0.745609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.282400</td>\n",
       "      <td>0.259308</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.739888</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.768841</td>\n",
       "      <td>0.762521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.142000</td>\n",
       "      <td>0.275597</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.724915</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.761018</td>\n",
       "      <td>0.754004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.142000</td>\n",
       "      <td>0.271332</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.771474</td>\n",
       "      <td>0.738311</td>\n",
       "      <td>0.754528</td>\n",
       "      <td>0.746951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.142000</td>\n",
       "      <td>0.277104</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.755178</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.762509</td>\n",
       "      <td>0.755563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.085300</td>\n",
       "      <td>0.278325</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.757058</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.762725</td>\n",
       "      <td>0.756533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.89      0.89       362\n",
      "                sara       0.65      0.69      0.67       237\n",
      "         radikalisme       0.69      0.82      0.75       235\n",
      "pencemaran_nama_baik       0.70      0.78      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.80      0.77      1326\n",
      "           macro avg       0.74      0.79      0.76      1326\n",
      "        weighted avg       0.74      0.80      0.77      1326\n",
      "         samples avg       0.44      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2394: Accuracy: 0.7016077170418007, F1 Micro: 0.7688405797101449, F1 Macro: 0.7625210172341319\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.89      0.89       362\n",
      "                sara       0.65      0.69      0.67       237\n",
      "         radikalisme       0.69      0.82      0.75       235\n",
      "pencemaran_nama_baik       0.70      0.78      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.80      0.77      1326\n",
      "           macro avg       0.74      0.79      0.76      1326\n",
      "        weighted avg       0.74      0.80      0.77      1326\n",
      "         samples avg       0.44      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 383\n",
      "Acquired samples: 383\n",
      "Sampling duration: 14.796391010284424 seconds\n",
      "New train size: 2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1740' max='1740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1740/1740 06:35, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.269757</td>\n",
       "      <td>0.677814</td>\n",
       "      <td>0.751403</td>\n",
       "      <td>0.706637</td>\n",
       "      <td>0.728333</td>\n",
       "      <td>0.723495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.244762</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.754775</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.749905</td>\n",
       "      <td>0.747570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.291400</td>\n",
       "      <td>0.239112</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.766041</td>\n",
       "      <td>0.738311</td>\n",
       "      <td>0.751920</td>\n",
       "      <td>0.739738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.291400</td>\n",
       "      <td>0.244523</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.770186</td>\n",
       "      <td>0.763332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.291400</td>\n",
       "      <td>0.261401</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.720884</td>\n",
       "      <td>0.812217</td>\n",
       "      <td>0.763830</td>\n",
       "      <td>0.759686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>0.257680</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.757331</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.768030</td>\n",
       "      <td>0.761719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>0.260334</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.775078</td>\n",
       "      <td>0.745852</td>\n",
       "      <td>0.760184</td>\n",
       "      <td>0.750110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>0.272696</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.774885</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.768997</td>\n",
       "      <td>0.760630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.098100</td>\n",
       "      <td>0.280254</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.759465</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.757331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.098100</td>\n",
       "      <td>0.277224</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.767830</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.765507</td>\n",
       "      <td>0.758032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.89      0.89       362\n",
      "                sara       0.67      0.64      0.65       237\n",
      "         radikalisme       0.71      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.77      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.79      0.77      1326\n",
      "           macro avg       0.74      0.79      0.76      1326\n",
      "        weighted avg       0.75      0.79      0.77      1326\n",
      "         samples avg       0.44      0.45      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2777: Accuracy: 0.7016077170418007, F1 Micro: 0.7701863354037267, F1 Macro: 0.7633324070127037\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.89      0.89       362\n",
      "                sara       0.67      0.64      0.65       237\n",
      "         radikalisme       0.71      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.77      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.79      0.77      1326\n",
      "           macro avg       0.74      0.79      0.76      1326\n",
      "        weighted avg       0.75      0.79      0.77      1326\n",
      "         samples avg       0.44      0.45      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 345\n",
      "Acquired samples: 345\n",
      "Sampling duration: 12.874341011047363 seconds\n",
      "New train size: 3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='1960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/1960 07:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.264612</td>\n",
       "      <td>0.652090</td>\n",
       "      <td>0.776636</td>\n",
       "      <td>0.626697</td>\n",
       "      <td>0.693656</td>\n",
       "      <td>0.658516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.236098</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.774448</td>\n",
       "      <td>0.740573</td>\n",
       "      <td>0.757132</td>\n",
       "      <td>0.745952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.293300</td>\n",
       "      <td>0.249535</td>\n",
       "      <td>0.686817</td>\n",
       "      <td>0.734035</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.760451</td>\n",
       "      <td>0.752691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.293300</td>\n",
       "      <td>0.236984</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.791496</td>\n",
       "      <td>0.730015</td>\n",
       "      <td>0.759514</td>\n",
       "      <td>0.751951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.293300</td>\n",
       "      <td>0.250193</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.769058</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.772523</td>\n",
       "      <td>0.770190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0.254312</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.786223</td>\n",
       "      <td>0.748869</td>\n",
       "      <td>0.767092</td>\n",
       "      <td>0.758321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0.266152</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.763920</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.769921</td>\n",
       "      <td>0.764500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.106600</td>\n",
       "      <td>0.274893</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.773700</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.768413</td>\n",
       "      <td>0.763813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.106600</td>\n",
       "      <td>0.284715</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.753219</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.773128</td>\n",
       "      <td>0.769406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.106600</td>\n",
       "      <td>0.285482</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.762509</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.766229</td>\n",
       "      <td>0.759574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.65      0.68      0.66       237\n",
      "         radikalisme       0.74      0.81      0.77       235\n",
      "pencemaran_nama_baik       0.70      0.76      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.79      0.77      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.79      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3122: Accuracy: 0.7093247588424437, F1 Micro: 0.7731277533039648, F1 Macro: 0.7694063825377553\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.65      0.68      0.66       237\n",
      "         radikalisme       0.74      0.81      0.77       235\n",
      "pencemaran_nama_baik       0.70      0.76      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.79      0.77      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.79      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 310\n",
      "Acquired samples: 310\n",
      "Sampling duration: 11.320905447006226 seconds\n",
      "New train size: 3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2150/2150 07:44, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.262848</td>\n",
       "      <td>0.683601</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.699095</td>\n",
       "      <td>0.724502</td>\n",
       "      <td>0.718718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241768</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.798611</td>\n",
       "      <td>0.693816</td>\n",
       "      <td>0.742534</td>\n",
       "      <td>0.732560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.298000</td>\n",
       "      <td>0.237129</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.765642</td>\n",
       "      <td>0.759168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.298000</td>\n",
       "      <td>0.242105</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.755220</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.772744</td>\n",
       "      <td>0.768206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>0.246066</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.766566</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.767144</td>\n",
       "      <td>0.759799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>0.274427</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.732830</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.767074</td>\n",
       "      <td>0.762224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.112200</td>\n",
       "      <td>0.275566</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.787705</td>\n",
       "      <td>0.724736</td>\n",
       "      <td>0.754910</td>\n",
       "      <td>0.745367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.112200</td>\n",
       "      <td>0.280983</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.764973</td>\n",
       "      <td>0.760935</td>\n",
       "      <td>0.762949</td>\n",
       "      <td>0.756463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.112200</td>\n",
       "      <td>0.291616</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.749269</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.760950</td>\n",
       "      <td>0.752784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.077400</td>\n",
       "      <td>0.292438</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.762472</td>\n",
       "      <td>0.753703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.91       362\n",
      "                sara       0.66      0.67      0.66       237\n",
      "         radikalisme       0.71      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.74      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.79      0.77      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.79      0.77      1326\n",
      "         samples avg       0.45      0.44      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3432: Accuracy: 0.7041800643086816, F1 Micro: 0.7727440147329651, F1 Macro: 0.7682058779348347\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.91       362\n",
      "                sara       0.66      0.67      0.66       237\n",
      "         radikalisme       0.71      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.74      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.79      0.77      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.79      0.77      1326\n",
      "         samples avg       0.45      0.44      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 279\n",
      "Acquired samples: 279\n",
      "Sampling duration: 9.930403709411621 seconds\n",
      "New train size: 3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2320/2320 08:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.258382</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.761944</td>\n",
       "      <td>0.697587</td>\n",
       "      <td>0.728346</td>\n",
       "      <td>0.721444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.233171</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.783034</td>\n",
       "      <td>0.723982</td>\n",
       "      <td>0.752351</td>\n",
       "      <td>0.743453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.297900</td>\n",
       "      <td>0.234776</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.755117</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.766889</td>\n",
       "      <td>0.753997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.297900</td>\n",
       "      <td>0.231199</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.772345</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.767362</td>\n",
       "      <td>0.758248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.180700</td>\n",
       "      <td>0.246002</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.778740</td>\n",
       "      <td>0.745852</td>\n",
       "      <td>0.761941</td>\n",
       "      <td>0.754204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.180700</td>\n",
       "      <td>0.250003</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.778549</td>\n",
       "      <td>0.760935</td>\n",
       "      <td>0.769641</td>\n",
       "      <td>0.758488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>0.269077</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.761835</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.775102</td>\n",
       "      <td>0.765584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>0.270028</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.776840</td>\n",
       "      <td>0.763952</td>\n",
       "      <td>0.770342</td>\n",
       "      <td>0.763514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.082300</td>\n",
       "      <td>0.284755</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.749471</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.774335</td>\n",
       "      <td>0.769033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.082300</td>\n",
       "      <td>0.282312</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.765405</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.771418</td>\n",
       "      <td>0.765710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.91      0.90       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.74      0.77      0.75       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.79      0.78      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.76      0.79      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3711: Accuracy: 0.7144694533762058, F1 Micro: 0.7751018895887365, F1 Macro: 0.7655840903679467\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.91      0.90       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.74      0.77      0.75       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.79      0.78      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.76      0.79      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Samples above threshold: 251\n",
      "Acquired samples: 175\n",
      "Sampling duration: 8.107091426849365 seconds\n",
      "New train size: 3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2430' max='2430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2430/2430 08:34, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.262089</td>\n",
       "      <td>0.666881</td>\n",
       "      <td>0.803960</td>\n",
       "      <td>0.612368</td>\n",
       "      <td>0.695205</td>\n",
       "      <td>0.678920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.234067</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.760755</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.760468</td>\n",
       "      <td>0.755563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.300500</td>\n",
       "      <td>0.226209</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.767020</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.765861</td>\n",
       "      <td>0.756704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.300500</td>\n",
       "      <td>0.230936</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.782541</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>0.769644</td>\n",
       "      <td>0.756702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.182600</td>\n",
       "      <td>0.243399</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.765487</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.774049</td>\n",
       "      <td>0.767212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.182600</td>\n",
       "      <td>0.251848</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.755848</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.767632</td>\n",
       "      <td>0.759203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.122000</td>\n",
       "      <td>0.277664</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.748212</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.767988</td>\n",
       "      <td>0.761556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.122000</td>\n",
       "      <td>0.283680</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.752168</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.768266</td>\n",
       "      <td>0.763103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.083800</td>\n",
       "      <td>0.285809</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.768519</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.759725</td>\n",
       "      <td>0.750480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.083800</td>\n",
       "      <td>0.293652</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.764095</td>\n",
       "      <td>0.759044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.73      0.80      0.77       235\n",
      "pencemaran_nama_baik       0.72      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.78      0.77      1326\n",
      "           macro avg       0.76      0.77      0.77      1326\n",
      "        weighted avg       0.77      0.78      0.77      1326\n",
      "         samples avg       0.45      0.44      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3886: Accuracy: 0.7138263665594855, F1 Micro: 0.774049217002237, F1 Macro: 0.7672123069659951\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.73      0.80      0.77       235\n",
      "pencemaran_nama_baik       0.72      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.78      0.77      1326\n",
      "           macro avg       0.76      0.77      0.77      1326\n",
      "        weighted avg       0.77      0.78      0.77      1326\n",
      "         samples avg       0.45      0.44      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Samples above threshold: 234\n",
      "Acquired samples: 234\n",
      "Sampling duration: 8.185130834579468 seconds\n",
      "New train size: 4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 08:59, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.259823</td>\n",
       "      <td>0.670740</td>\n",
       "      <td>0.822863</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>0.695690</td>\n",
       "      <td>0.677441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.301200</td>\n",
       "      <td>0.235741</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.746753</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.763274</td>\n",
       "      <td>0.758249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.301200</td>\n",
       "      <td>0.230778</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.754436</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.777331</td>\n",
       "      <td>0.772989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.186400</td>\n",
       "      <td>0.237747</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.784921</td>\n",
       "      <td>0.745852</td>\n",
       "      <td>0.764888</td>\n",
       "      <td>0.757951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.186400</td>\n",
       "      <td>0.248500</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.784019</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.765251</td>\n",
       "      <td>0.756540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.124500</td>\n",
       "      <td>0.268656</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.769641</td>\n",
       "      <td>0.760935</td>\n",
       "      <td>0.765264</td>\n",
       "      <td>0.755043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.124500</td>\n",
       "      <td>0.281728</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.760118</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.769460</td>\n",
       "      <td>0.765153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.289295</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.760690</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.762693</td>\n",
       "      <td>0.755727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.291525</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.779540</td>\n",
       "      <td>0.741327</td>\n",
       "      <td>0.759954</td>\n",
       "      <td>0.751309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068700</td>\n",
       "      <td>0.296500</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.761372</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.765654</td>\n",
       "      <td>0.760795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.62      0.73      0.67       237\n",
      "         radikalisme       0.74      0.81      0.77       235\n",
      "pencemaran_nama_baik       0.72      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4120: Accuracy: 0.7054662379421222, F1 Micro: 0.7773308957952468, F1 Macro: 0.7729889079001656\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.62      0.73      0.67       237\n",
      "         radikalisme       0.74      0.81      0.77       235\n",
      "pencemaran_nama_baik       0.72      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Samples above threshold: 210\n",
      "Acquired samples: 210\n",
      "Sampling duration: 7.438388824462891 seconds\n",
      "New train size: 4330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2710' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2710/2710 09:23, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.254185</td>\n",
       "      <td>0.673312</td>\n",
       "      <td>0.811395</td>\n",
       "      <td>0.622926</td>\n",
       "      <td>0.704778</td>\n",
       "      <td>0.676079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.300700</td>\n",
       "      <td>0.232956</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.757864</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.769402</td>\n",
       "      <td>0.762691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.300700</td>\n",
       "      <td>0.227716</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.774046</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.769347</td>\n",
       "      <td>0.758667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.187800</td>\n",
       "      <td>0.233329</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.771619</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.779395</td>\n",
       "      <td>0.772513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.187800</td>\n",
       "      <td>0.244485</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.795200</td>\n",
       "      <td>0.749623</td>\n",
       "      <td>0.771739</td>\n",
       "      <td>0.762320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.133700</td>\n",
       "      <td>0.261776</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.774981</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.770573</td>\n",
       "      <td>0.761803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.133700</td>\n",
       "      <td>0.281494</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.751977</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.769967</td>\n",
       "      <td>0.759412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.092700</td>\n",
       "      <td>0.289335</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.747729</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.776206</td>\n",
       "      <td>0.770536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.092700</td>\n",
       "      <td>0.296262</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.754867</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.771839</td>\n",
       "      <td>0.763829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.072900</td>\n",
       "      <td>0.299363</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.761281</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.774815</td>\n",
       "      <td>0.766381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.67      0.64      0.66       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.77      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.44      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4330: Accuracy: 0.7209003215434083, F1 Micro: 0.7793952967525196, F1 Macro: 0.7725125367318748\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.67      0.64      0.66       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.77      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.44      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Samples above threshold: 189\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.562496662139893 seconds\n",
      "New train size: 4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2840' max='2840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2840/2840 09:42, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.247102</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.789429</td>\n",
       "      <td>0.698341</td>\n",
       "      <td>0.741096</td>\n",
       "      <td>0.722571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.302100</td>\n",
       "      <td>0.229088</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.749822</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.770978</td>\n",
       "      <td>0.762475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.302100</td>\n",
       "      <td>0.223942</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.779648</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.774022</td>\n",
       "      <td>0.765313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.192100</td>\n",
       "      <td>0.248143</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.729358</td>\n",
       "      <td>0.839367</td>\n",
       "      <td>0.780505</td>\n",
       "      <td>0.778899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.192100</td>\n",
       "      <td>0.250633</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.764438</td>\n",
       "      <td>0.758673</td>\n",
       "      <td>0.761544</td>\n",
       "      <td>0.751494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>0.269736</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.822021</td>\n",
       "      <td>0.781082</td>\n",
       "      <td>0.776216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>0.275016</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.753780</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.771271</td>\n",
       "      <td>0.765314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.097600</td>\n",
       "      <td>0.287630</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.757050</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.772979</td>\n",
       "      <td>0.764822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.073600</td>\n",
       "      <td>0.297645</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.749824</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.775228</td>\n",
       "      <td>0.771031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.073600</td>\n",
       "      <td>0.296462</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.759366</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.776713</td>\n",
       "      <td>0.771493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.92      0.90       362\n",
      "                sara       0.62      0.73      0.67       237\n",
      "         radikalisme       0.72      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.82      0.78      1326\n",
      "           macro avg       0.74      0.82      0.78      1326\n",
      "        weighted avg       0.75      0.82      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4530: Accuracy: 0.7118971061093248, F1 Micro: 0.7810820494446435, F1 Macro: 0.7762157287382617\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.92      0.90       362\n",
      "                sara       0.62      0.73      0.67       237\n",
      "         radikalisme       0.72      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.82      0.78      1326\n",
      "           macro avg       0.74      0.82      0.78      1326\n",
      "        weighted avg       0.75      0.82      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Samples above threshold: 169\n",
      "Acquired samples: 133\n",
      "Sampling duration: 5.503233432769775 seconds\n",
      "New train size: 4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2920' max='2920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2920/2920 09:53, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.253603</td>\n",
       "      <td>0.673955</td>\n",
       "      <td>0.784297</td>\n",
       "      <td>0.685520</td>\n",
       "      <td>0.731590</td>\n",
       "      <td>0.704733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.302000</td>\n",
       "      <td>0.227898</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.767584</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>0.762339</td>\n",
       "      <td>0.751878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.302000</td>\n",
       "      <td>0.230109</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.774754</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.773877</td>\n",
       "      <td>0.763048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.195100</td>\n",
       "      <td>0.238989</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.755116</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.780168</td>\n",
       "      <td>0.776508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.195100</td>\n",
       "      <td>0.244114</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.768613</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.781157</td>\n",
       "      <td>0.776568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.140500</td>\n",
       "      <td>0.253856</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.782642</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.775495</td>\n",
       "      <td>0.768779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.098600</td>\n",
       "      <td>0.267364</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.767669</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.768825</td>\n",
       "      <td>0.761777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.098600</td>\n",
       "      <td>0.286218</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.746648</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.771418</td>\n",
       "      <td>0.766752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.290673</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.773557</td>\n",
       "      <td>0.769189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.290964</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.758521</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.773383</td>\n",
       "      <td>0.767998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.64      0.70      0.67       237\n",
      "         radikalisme       0.71      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.75      0.74      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4663: Accuracy: 0.7189710610932476, F1 Micro: 0.7811572700296735, F1 Macro: 0.7765681994570391\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.64      0.70      0.67       237\n",
      "         radikalisme       0.71      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.75      0.74      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.402440547943115 seconds\n",
      "New train size: 4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3040' max='3040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3040/3040 10:15, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243829</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.751381</td>\n",
       "      <td>0.742157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.303700</td>\n",
       "      <td>0.226029</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.762675</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.772609</td>\n",
       "      <td>0.761122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.303700</td>\n",
       "      <td>0.231899</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.745740</td>\n",
       "      <td>0.825038</td>\n",
       "      <td>0.783387</td>\n",
       "      <td>0.779707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.198600</td>\n",
       "      <td>0.237411</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.735467</td>\n",
       "      <td>0.849170</td>\n",
       "      <td>0.788239</td>\n",
       "      <td>0.786021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.149600</td>\n",
       "      <td>0.244219</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.762248</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.774836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.149600</td>\n",
       "      <td>0.251923</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.782743</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.774390</td>\n",
       "      <td>0.763953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.102700</td>\n",
       "      <td>0.278014</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.748611</td>\n",
       "      <td>0.812971</td>\n",
       "      <td>0.779465</td>\n",
       "      <td>0.775775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.102700</td>\n",
       "      <td>0.280551</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.762248</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.775193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>0.294353</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.748059</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.772876</td>\n",
       "      <td>0.767264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.064700</td>\n",
       "      <td>0.294048</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.762111</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.778147</td>\n",
       "      <td>0.773291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.89      0.92       362\n",
      "                sara       0.60      0.78      0.68       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.69      0.85      0.76       492\n",
      "\n",
      "           micro avg       0.74      0.85      0.79      1326\n",
      "           macro avg       0.74      0.84      0.79      1326\n",
      "        weighted avg       0.75      0.85      0.79      1326\n",
      "         samples avg       0.47      0.48      0.47      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4863: Accuracy: 0.7157556270096463, F1 Micro: 0.7882394119705985, F1 Macro: 0.7860208369273232\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.89      0.92       362\n",
      "                sara       0.60      0.78      0.68       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.69      0.85      0.76       492\n",
      "\n",
      "           micro avg       0.74      0.85      0.79      1326\n",
      "           macro avg       0.74      0.84      0.79      1326\n",
      "        weighted avg       0.75      0.85      0.79      1326\n",
      "         samples avg       0.47      0.48      0.47      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Samples above threshold: 136\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.7427732944488525 seconds\n",
      "New train size: 5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3170' max='3170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3170/3170 10:36, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.252727</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.755876</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.753875</td>\n",
       "      <td>0.748834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.305100</td>\n",
       "      <td>0.244021</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.715909</td>\n",
       "      <td>0.855204</td>\n",
       "      <td>0.779381</td>\n",
       "      <td>0.779247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.305100</td>\n",
       "      <td>0.226800</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.762182</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.776009</td>\n",
       "      <td>0.770489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.205000</td>\n",
       "      <td>0.251236</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.729589</td>\n",
       "      <td>0.842383</td>\n",
       "      <td>0.781939</td>\n",
       "      <td>0.776992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.148000</td>\n",
       "      <td>0.260901</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.735609</td>\n",
       "      <td>0.828808</td>\n",
       "      <td>0.779433</td>\n",
       "      <td>0.774153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.148000</td>\n",
       "      <td>0.268773</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.753347</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.778871</td>\n",
       "      <td>0.772037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>0.269272</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.780303</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.778534</td>\n",
       "      <td>0.771543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.083400</td>\n",
       "      <td>0.283837</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.763331</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.768030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.083400</td>\n",
       "      <td>0.295197</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.755131</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.779116</td>\n",
       "      <td>0.772846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.298187</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.779874</td>\n",
       "      <td>0.773780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.65      0.70      0.67       237\n",
      "         radikalisme       0.69      0.89      0.78       235\n",
      "pencemaran_nama_baik       0.68      0.84      0.75       492\n",
      "\n",
      "           micro avg       0.73      0.84      0.78      1326\n",
      "           macro avg       0.73      0.83      0.78      1326\n",
      "        weighted avg       0.74      0.84      0.78      1326\n",
      "         samples avg       0.47      0.48      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5063: Accuracy: 0.7099678456591639, F1 Micro: 0.7819390969548478, F1 Macro: 0.7769919738323875\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.65      0.70      0.67       237\n",
      "         radikalisme       0.69      0.89      0.78       235\n",
      "pencemaran_nama_baik       0.68      0.84      0.75       492\n",
      "\n",
      "           micro avg       0.73      0.84      0.78      1326\n",
      "           macro avg       0.73      0.83      0.78      1326\n",
      "        weighted avg       0.74      0.84      0.78      1326\n",
      "         samples avg       0.47      0.48      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Samples above threshold: 116\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.497631072998047 seconds\n",
      "New train size: 5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3290' max='3290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3290/3290 11:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.245819</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.785476</td>\n",
       "      <td>0.709653</td>\n",
       "      <td>0.745642</td>\n",
       "      <td>0.732928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.307700</td>\n",
       "      <td>0.230099</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.760933</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.773907</td>\n",
       "      <td>0.767813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.307700</td>\n",
       "      <td>0.228521</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.776847</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.773020</td>\n",
       "      <td>0.767497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.235580</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.799519</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.774971</td>\n",
       "      <td>0.757433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.151100</td>\n",
       "      <td>0.247285</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.761488</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.766250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.151100</td>\n",
       "      <td>0.265684</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.761347</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.772660</td>\n",
       "      <td>0.762942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.115900</td>\n",
       "      <td>0.280644</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.760634</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.777737</td>\n",
       "      <td>0.774823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.086100</td>\n",
       "      <td>0.295106</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.756546</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.780577</td>\n",
       "      <td>0.776285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.086100</td>\n",
       "      <td>0.290944</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.773165</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.779813</td>\n",
       "      <td>0.774782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.296663</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.778025</td>\n",
       "      <td>0.773540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.65      0.70      0.68       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.78      1326\n",
      "           macro avg       0.75      0.80      0.78      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5263: Accuracy: 0.7189710610932476, F1 Micro: 0.7805768528660094, F1 Macro: 0.7762849448434221\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.65      0.70      0.68       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.78      1326\n",
      "           macro avg       0.75      0.80      0.78      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Samples above threshold: 96\n",
      "Acquired samples: 178\n",
      "Sampling duration: 3.488745927810669 seconds\n",
      "New train size: 5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3410' max='3410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3410/3410 11:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.245474</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.738451</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.760337</td>\n",
       "      <td>0.754684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.302300</td>\n",
       "      <td>0.231442</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.701357</td>\n",
       "      <td>0.752123</td>\n",
       "      <td>0.746593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.204800</td>\n",
       "      <td>0.222966</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.769737</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.781737</td>\n",
       "      <td>0.776992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.204800</td>\n",
       "      <td>0.236024</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.778682</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.785954</td>\n",
       "      <td>0.776795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.153700</td>\n",
       "      <td>0.244960</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.764832</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.785321</td>\n",
       "      <td>0.777625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.115500</td>\n",
       "      <td>0.264349</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.758250</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.777206</td>\n",
       "      <td>0.774135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.115500</td>\n",
       "      <td>0.283821</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.753156</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.780523</td>\n",
       "      <td>0.773806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.090700</td>\n",
       "      <td>0.292672</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.771021</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.772761</td>\n",
       "      <td>0.765711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.305261</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.752628</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.780240</td>\n",
       "      <td>0.777518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.299262</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.765568</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.776663</td>\n",
       "      <td>0.771058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.66      0.63      0.65       237\n",
      "         radikalisme       0.72      0.87      0.79       235\n",
      "pencemaran_nama_baik       0.76      0.76      0.76       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5441: Accuracy: 0.727331189710611, F1 Micro: 0.7859544265969369, F1 Macro: 0.7767947285494681\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.66      0.63      0.65       237\n",
      "         radikalisme       0.72      0.87      0.79       235\n",
      "pencemaran_nama_baik       0.76      0.76      0.76       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Samples above threshold: 78\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.905487298965454 seconds\n",
      "New train size: 5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3530' max='3530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3530/3530 11:42, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.242423</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.791171</td>\n",
       "      <td>0.702866</td>\n",
       "      <td>0.744409</td>\n",
       "      <td>0.723832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.302300</td>\n",
       "      <td>0.226717</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.744376</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.781955</td>\n",
       "      <td>0.777249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.207900</td>\n",
       "      <td>0.220532</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.800485</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.773011</td>\n",
       "      <td>0.764185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.207900</td>\n",
       "      <td>0.225880</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.802920</td>\n",
       "      <td>0.746606</td>\n",
       "      <td>0.773740</td>\n",
       "      <td>0.764974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.156200</td>\n",
       "      <td>0.248070</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.764331</td>\n",
       "      <td>0.814480</td>\n",
       "      <td>0.788609</td>\n",
       "      <td>0.785226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.118600</td>\n",
       "      <td>0.265672</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.760085</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.784228</td>\n",
       "      <td>0.778300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.118600</td>\n",
       "      <td>0.278138</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.766934</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.780289</td>\n",
       "      <td>0.772740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.088200</td>\n",
       "      <td>0.287355</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.769847</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.783253</td>\n",
       "      <td>0.777996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.294770</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.776198</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.779113</td>\n",
       "      <td>0.772888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.059500</td>\n",
       "      <td>0.300550</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.770300</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.782027</td>\n",
       "      <td>0.776670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.66      0.70      0.68       237\n",
      "         radikalisme       0.77      0.85      0.81       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.79      1326\n",
      "           macro avg       0.76      0.81      0.79      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5641: Accuracy: 0.7241157556270097, F1 Micro: 0.7886089813800657, F1 Macro: 0.7852256738186856\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.66      0.70      0.68       237\n",
      "         radikalisme       0.77      0.85      0.81       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.79      1326\n",
      "           macro avg       0.76      0.81      0.79      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.3922812938690186 seconds\n",
      "New train size: 5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3660' max='3660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3660/3660 12:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241780</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.768868</td>\n",
       "      <td>0.737557</td>\n",
       "      <td>0.752887</td>\n",
       "      <td>0.740987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.300700</td>\n",
       "      <td>0.222182</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.792363</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.771196</td>\n",
       "      <td>0.758853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.206700</td>\n",
       "      <td>0.222830</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.808667</td>\n",
       "      <td>0.745852</td>\n",
       "      <td>0.775991</td>\n",
       "      <td>0.767931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.206700</td>\n",
       "      <td>0.234362</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.810359</td>\n",
       "      <td>0.731523</td>\n",
       "      <td>0.768926</td>\n",
       "      <td>0.758797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.161000</td>\n",
       "      <td>0.252004</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.781129</td>\n",
       "      <td>0.761689</td>\n",
       "      <td>0.771287</td>\n",
       "      <td>0.755517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.118700</td>\n",
       "      <td>0.265021</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.785879</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.779003</td>\n",
       "      <td>0.770362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.091300</td>\n",
       "      <td>0.277940</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.776684</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.775217</td>\n",
       "      <td>0.766784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.091300</td>\n",
       "      <td>0.293970</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.784830</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.774637</td>\n",
       "      <td>0.766436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.072800</td>\n",
       "      <td>0.301846</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.771917</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.777695</td>\n",
       "      <td>0.769618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.061800</td>\n",
       "      <td>0.305445</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.767407</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.774290</td>\n",
       "      <td>0.765655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.66      0.62      0.64       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.77      0.70      0.73       492\n",
      "\n",
      "           micro avg       0.79      0.77      0.78      1326\n",
      "           macro avg       0.77      0.77      0.77      1326\n",
      "        weighted avg       0.79      0.77      0.78      1326\n",
      "         samples avg       0.45      0.44      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5841: Accuracy: 0.7241157556270097, F1 Micro: 0.7790034233548877, F1 Macro: 0.7703624495047866\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.66      0.62      0.64       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.77      0.70      0.73       492\n",
      "\n",
      "           micro avg       0.79      0.77      0.78      1326\n",
      "           macro avg       0.77      0.77      0.77      1326\n",
      "        weighted avg       0.79      0.77      0.78      1326\n",
      "         samples avg       0.45      0.44      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 200\n",
      "Sampling duration: 1.9935762882232666 seconds\n",
      "New train size: 6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3780' max='3780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3780/3780 12:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241931</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.815864</td>\n",
       "      <td>0.651584</td>\n",
       "      <td>0.724528</td>\n",
       "      <td>0.706148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.296800</td>\n",
       "      <td>0.222882</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.773728</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.771093</td>\n",
       "      <td>0.762075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.208300</td>\n",
       "      <td>0.222702</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.772424</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.779065</td>\n",
       "      <td>0.770025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.160600</td>\n",
       "      <td>0.235743</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.753793</td>\n",
       "      <td>0.824284</td>\n",
       "      <td>0.787464</td>\n",
       "      <td>0.781896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.160600</td>\n",
       "      <td>0.241908</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.770788</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.787006</td>\n",
       "      <td>0.779311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.122300</td>\n",
       "      <td>0.267241</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.765168</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.786212</td>\n",
       "      <td>0.778261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>0.269747</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.788226</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.782840</td>\n",
       "      <td>0.774332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.073900</td>\n",
       "      <td>0.280627</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.783825</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.782937</td>\n",
       "      <td>0.774017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.073900</td>\n",
       "      <td>0.289241</td>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.778839</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.788984</td>\n",
       "      <td>0.781176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.061400</td>\n",
       "      <td>0.295279</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.770397</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.787163</td>\n",
       "      <td>0.780123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.93      0.93       362\n",
      "                sara       0.65      0.66      0.65       237\n",
      "         radikalisme       0.75      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.80      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6041: Accuracy: 0.7286173633440515, F1 Micro: 0.788983997022702, F1 Macro: 0.7811757319462316\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.93      0.93       362\n",
      "                sara       0.65      0.66      0.65       237\n",
      "         radikalisme       0.75      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.80      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "<ipython-input-13-46a36a0f91da>:54: ConvergenceWarning: Number of distinct clusters (75) found smaller than n_clusters (177). Possibly due to duplicate points in X.\n",
      "  kmeans.fit(embeddings)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 177\n",
      "Sampling duration: 1.6952800750732422 seconds\n",
      "New train size: 6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3890/3890 12:38, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.242168</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.828050</td>\n",
       "      <td>0.650075</td>\n",
       "      <td>0.728348</td>\n",
       "      <td>0.715684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.294700</td>\n",
       "      <td>0.223362</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.783085</td>\n",
       "      <td>0.754148</td>\n",
       "      <td>0.768344</td>\n",
       "      <td>0.765859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.203200</td>\n",
       "      <td>0.232894</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.751401</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.779230</td>\n",
       "      <td>0.773432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.157300</td>\n",
       "      <td>0.234521</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.796987</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.776962</td>\n",
       "      <td>0.759456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.157300</td>\n",
       "      <td>0.246937</td>\n",
       "      <td>0.727974</td>\n",
       "      <td>0.772793</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.788774</td>\n",
       "      <td>0.782475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>0.263831</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.778271</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.786114</td>\n",
       "      <td>0.780044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.092300</td>\n",
       "      <td>0.291688</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.753643</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>0.784966</td>\n",
       "      <td>0.780565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.300586</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.763597</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.778558</td>\n",
       "      <td>0.770400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.308097</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.770456</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.786110</td>\n",
       "      <td>0.781137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.311979</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.763251</td>\n",
       "      <td>0.814480</td>\n",
       "      <td>0.788034</td>\n",
       "      <td>0.781524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.90      0.93       362\n",
      "                sara       0.64      0.68      0.66       237\n",
      "         radikalisme       0.77      0.81      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.77      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6218: Accuracy: 0.7279742765273312, F1 Micro: 0.7887740029542099, F1 Macro: 0.7824753287808983\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.90      0.93       362\n",
      "                sara       0.64      0.68      0.66       237\n",
      "         radikalisme       0.77      0.81      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.77      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n",
      "Total sampling time: 197.42 seconds\n",
      "Total runtime: 11781.180734872818 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5995036,
     "sourceId": 9784902,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 34106.84712,
   "end_time": "2024-12-21T12:55:19.523707",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-21T03:26:52.676587",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "007d5f7a1ba4410ba09ea053eeba7bf2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0bc6501ac34a4dfd8e6be9d53ea525e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a03a2ad039ed46bebbc72de166b47c5b",
        "IPY_MODEL_2cc7eb8a8a724056a7c97fe70c4e2ba1",
        "IPY_MODEL_bf8142559a6d4a90a2e518922793f62d"
       ],
       "layout": "IPY_MODEL_66f870deeaac494e87b4a16cf3d5584f"
      }
     },
     "119d0a934ed84c95a9501c9110a262ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "11a88a52ae6f4fcdb2f372a620217a2b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "131403d2747041b7a9da4ce12fc928f9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "15c8359dcf904eb3b6840c24356eef6c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "18729b0e913944acbdd9f6958528584b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "19bb301b5c2341d49c5e5db41efe7370": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1af781698af14842a1528e8c682a5f4b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2241e21ba22741298d509333032060fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e5271482dd7943b8aecce6476ea0c250",
       "placeholder": "​",
       "style": "IPY_MODEL_119d0a934ed84c95a9501c9110a262ed",
       "value": " 229k/229k [00:00&lt;00:00, 1.43MB/s]"
      }
     },
     "28cbba2ddd914b6b8de1e26eeb61f34d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_11a88a52ae6f4fcdb2f372a620217a2b",
       "placeholder": "​",
       "style": "IPY_MODEL_1af781698af14842a1528e8c682a5f4b",
       "value": " 1.53k/1.53k [00:00&lt;00:00, 148kB/s]"
      }
     },
     "2971a47277cd439490388ae65d5dc25d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2cc7eb8a8a724056a7c97fe70c4e2ba1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_131403d2747041b7a9da4ce12fc928f9",
       "max": 497810400,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2971a47277cd439490388ae65d5dc25d",
       "value": 497810400
      }
     },
     "2dffece0c42c4a1f9c22a2b85e409295": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3025f6f56cec48e08a2fb14d37d0b93a",
        "IPY_MODEL_35d9e54275ea4b288fe917c7fb69f2cf",
        "IPY_MODEL_83e4079a7166455298dcbf112aca25bc"
       ],
       "layout": "IPY_MODEL_895e7300a3e04730bed3bb00b8e36841"
      }
     },
     "3025f6f56cec48e08a2fb14d37d0b93a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_18729b0e913944acbdd9f6958528584b",
       "placeholder": "​",
       "style": "IPY_MODEL_613ec48f76744ba691f6336ad2e05f8b",
       "value": "special_tokens_map.json: 100%"
      }
     },
     "314f06f72bfb460aae08dff5d6832d23": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3205f4cd32db42acaf150f41f30386aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "35d9e54275ea4b288fe917c7fb69f2cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_007d5f7a1ba4410ba09ea053eeba7bf2",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_cb7cfd65972f4fb3a311511e85e466d4",
       "value": 112
      }
     },
     "42990b88f34040598a6e7de80972e0ae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4b55414764564fbaad2faab1dbb47a91": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4c279b917200445f998dc6255e44699c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "539fa1ff171a4850a417a860e7f2ec6a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "57e99853a072449e9a97333bb96ed13e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5ce4ddb4c9ca4c6f80afa027caefbd52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b9724aa259f84ad8a5df974588138fd4",
       "placeholder": "​",
       "style": "IPY_MODEL_3205f4cd32db42acaf150f41f30386aa",
       "value": " 2.00/2.00 [00:00&lt;00:00, 199B/s]"
      }
     },
     "5d00a9c6fdaf4898980f61ee6fe6d680": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_902937ec048e42a19da30c8d8f79c4c9",
       "placeholder": "​",
       "style": "IPY_MODEL_19bb301b5c2341d49c5e5db41efe7370",
       "value": "tokenizer_config.json: 100%"
      }
     },
     "613ec48f76744ba691f6336ad2e05f8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "63ea4c2650064cca8733654295a4b7c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "66f870deeaac494e87b4a16cf3d5584f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "68727c1318c64ab9aaeb0d4dd8e39055": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4b55414764564fbaad2faab1dbb47a91",
       "placeholder": "​",
       "style": "IPY_MODEL_966873145d644362a52f4afe42f96806",
       "value": "config.json: 100%"
      }
     },
     "6b28384dab5640cabdb22a6012e564f4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6f904c94db9544c190951d26ab7a03ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_15c8359dcf904eb3b6840c24356eef6c",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9bdb4479306f4935bea85bfbab8c1b6f",
       "value": 1534
      }
     },
     "83e4079a7166455298dcbf112aca25bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_539fa1ff171a4850a417a860e7f2ec6a",
       "placeholder": "​",
       "style": "IPY_MODEL_c131a06ff4fd4f13b06f0a744f99c36f",
       "value": " 112/112 [00:00&lt;00:00, 10.2kB/s]"
      }
     },
     "895e7300a3e04730bed3bb00b8e36841": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8c990d4b987f407ea7df8a8c1c455d35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9f301bf40ed9479f833d8935c3acd8b3",
        "IPY_MODEL_ed53918874374e0db32b4cad6d2192ad",
        "IPY_MODEL_2241e21ba22741298d509333032060fa"
       ],
       "layout": "IPY_MODEL_42990b88f34040598a6e7de80972e0ae"
      }
     },
     "902937ec048e42a19da30c8d8f79c4c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "966873145d644362a52f4afe42f96806": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9bdb4479306f4935bea85bfbab8c1b6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9f301bf40ed9479f833d8935c3acd8b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c75f274273784e588b43a0cf2efebc57",
       "placeholder": "​",
       "style": "IPY_MODEL_63ea4c2650064cca8733654295a4b7c6",
       "value": "vocab.txt: 100%"
      }
     },
     "a03a2ad039ed46bebbc72de166b47c5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f3c0850f55c54bb893ff2bfb38968f93",
       "placeholder": "​",
       "style": "IPY_MODEL_e58964c62bce45a7a34568425b5188bb",
       "value": "pytorch_model.bin: 100%"
      }
     },
     "b19c93727a8b4800908b9bf3fa1569d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_68727c1318c64ab9aaeb0d4dd8e39055",
        "IPY_MODEL_6f904c94db9544c190951d26ab7a03ff",
        "IPY_MODEL_28cbba2ddd914b6b8de1e26eeb61f34d"
       ],
       "layout": "IPY_MODEL_e2b124f90e334576b1f7dca235842351"
      }
     },
     "b9724aa259f84ad8a5df974588138fd4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bdb1134db9f74e6bab1e0fe42fccab4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4c279b917200445f998dc6255e44699c",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_cd2050059e4e419da46f4e07881484c1",
       "value": 2
      }
     },
     "bf8142559a6d4a90a2e518922793f62d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6b28384dab5640cabdb22a6012e564f4",
       "placeholder": "​",
       "style": "IPY_MODEL_e39c2b28c2cf4454b1af089f4765740c",
       "value": " 498M/498M [00:08&lt;00:00, 57.6MB/s]"
      }
     },
     "c131a06ff4fd4f13b06f0a744f99c36f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c5398379f3d04b67a2ac5bc615032e02": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c53a86a36e234010b5651f947a60ec8c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5d00a9c6fdaf4898980f61ee6fe6d680",
        "IPY_MODEL_bdb1134db9f74e6bab1e0fe42fccab4e",
        "IPY_MODEL_5ce4ddb4c9ca4c6f80afa027caefbd52"
       ],
       "layout": "IPY_MODEL_314f06f72bfb460aae08dff5d6832d23"
      }
     },
     "c75f274273784e588b43a0cf2efebc57": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cb7cfd65972f4fb3a311511e85e466d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "cd2050059e4e419da46f4e07881484c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e2b124f90e334576b1f7dca235842351": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e39c2b28c2cf4454b1af089f4765740c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e5271482dd7943b8aecce6476ea0c250": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e58964c62bce45a7a34568425b5188bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ed53918874374e0db32b4cad6d2192ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_57e99853a072449e9a97333bb96ed13e",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c5398379f3d04b67a2ac5bc615032e02",
       "value": 229167
      }
     },
     "f3c0850f55c54bb893ff2bfb38968f93": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
